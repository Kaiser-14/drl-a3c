/home/kaiser/Git/drl-a3c/venv/bin/python /home/kaiser/Git/drl-a3c/A3C/agent.py --train --num-workers 1
2021-04-29 11:19:37.278893: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
Namespace(gamma=0.99, lr=0.001, max_eps=400, num_workers=1, train=True, update_freq=20)
/home/kaiser/Git/drl-a3c/venv/lib/python3.8/site-packages/gym/logger.py:30: UserWarning: WARN: Box bound precision lowered by casting to float32
  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))
2021-04-29 11:19:37.951975: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-04-29 11:19:37.952487: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
-------------------------------------
TRAINING INFORMATION
Environment name: A3C.envs.eve:Eve-v0
Number of states: 11. Number of actions: 3
Training episodes: 400
-------------------------------------
2021-04-29 11:19:37.981466: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-04-29 11:19:37.981864: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2021-04-29 11:19:37.981880: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-04-29 11:19:37.983726: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-04-29 11:19:37.983753: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-04-29 11:19:37.984298: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-04-29 11:19:37.984435: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-04-29 11:19:37.985417: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-04-29 11:19:37.985842: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-04-29 11:19:37.985917: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-04-29 11:19:37.985980: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-04-29 11:19:37.986390: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-04-29 11:19:37.986798: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2021-04-29 11:19:37.987021: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-04-29 11:19:37.987611: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-04-29 11:19:37.987697: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-04-29 11:19:37.988062: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2021-04-29 11:19:37.988071: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-04-29 11:19:37.988078: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-04-29 11:19:37.988084: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-04-29 11:19:37.988089: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-04-29 11:19:37.988095: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-04-29 11:19:37.988100: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-04-29 11:19:37.988105: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-04-29 11:19:37.988111: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-04-29 11:19:37.988137: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-04-29 11:19:37.988511: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-04-29 11:19:37.988863: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2021-04-29 11:19:37.988878: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-04-29 11:19:38.332909: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-04-29 11:19:38.332935: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2021-04-29 11:19:38.332940: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2021-04-29 11:19:38.333077: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-04-29 11:19:38.333482: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-04-29 11:19:38.333844: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-04-29 11:19:38.334201: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9363 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5)
2021-04-29 11:19:38.412973: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-04-29 11:19:38.820434: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
Starting worker 0
Current State [[-0.00018205  0.00373221 -0.00045196  0.00013854  0.00134636  0.0079017
  -0.00953145  0.0027925   0.00132138  0.00765726  0.00083259]]
Logits tf.Tensor([[-0.00083055  0.00055024  0.00168863]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3329001 0.3333601 0.3337398]], shape=(1, 3), dtype=float32)
Selected action 1
[0.09, 0.12, 0.032, 0.1417, 0.13723, 0.6, 0.76, 0, 0.002, 0.269, 1.842]
Reward 39.022917260356344
Current State [[0.09    0.12    0.032   0.1417  0.13723 0.6     0.76    0.      0.002
  0.269   1.842  ]]
Logits tf.Tensor([[-0.29740214  0.04692253 -0.3948971 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30137333 0.42524883 0.27337784]], shape=(1, 3), dtype=float32)
Selected action 0
[0.24, 0.2, 0.027, 0.214, 0.13723, 0.6, 0.76, 0, 0.002, 0.269, 1.842]
Reward 39.022917260356344
Current State [[0.24    0.2     0.027   0.214   0.13723 0.6     0.76    0.      0.002
  0.269   1.842  ]]
Logits tf.Tensor([[-0.2842117   0.05291671 -0.3626933 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30071226 0.4212735  0.27801424]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.07, 0.034, 0.13269999999999998, 0.13723, 0.6, 0.72, 0, 0.162, 0.34500000000000003, 0.43499999999999994]
Reward 3.9505518100605888
Current State [[0.07    0.07    0.034   0.1327  0.13723 0.6     0.72    0.      0.162
  0.345   0.435  ]]
Logits tf.Tensor([[ 0.00838241 -0.04650367 -0.19463126]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.36194378 0.34261343 0.2954428 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.13, 0.12, 0.034, 0.15380000000000002, 0.13723, 0.6, 0.68, 0, 0.0146, 0.265, 2.1239999999999997]
Reward 5.770740110904375
Current State [[0.13    0.12    0.034   0.1538  0.13723 0.6     0.68    0.      0.0146
  0.265   2.124  ]]
Logits tf.Tensor([[-0.3260444   0.05654874 -0.41757056]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29597893 0.43392918 0.27009186]], shape=(1, 3), dtype=float32)
Selected action 1
[0.09, 0.12, 0.033, 0.1608, 0.13723, 0.6, 0.82, 0, 0.0661, 0.28500000000000003, 1.9149999999999998]
Reward 4.249658942978902
Current State [[0.09    0.12    0.033   0.1608  0.13723 0.6     0.82    0.      0.0661
  0.285   1.915  ]]
Logits tf.Tensor([[-0.3109511   0.04534736 -0.40106794]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29923475 0.42731732 0.27344802]], shape=(1, 3), dtype=float32)
Selected action 2
[0.09, 0.07, 0.032, 0.12940000000000002, 0.13723, 0.6, 0.68, 0, 0.014499999999999999, 0.261, 2.242]
Reward 5.8035271792868945
Current State [[0.09    0.07    0.032   0.1294  0.13723 0.6     0.68    0.      0.0145
  0.261   2.242  ]]
Logits tf.Tensor([[-0.34630758  0.05611058 -0.44249886]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29379562 0.43935266 0.2668517 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.12, 0.12, 0.034, 0.16419999999999998, 0.13723, 0.6, 0.68, 0, 0.014499999999999999, 0.261, 2.242]
Reward 5.8035271792868945
Current State [[0.12    0.12    0.034   0.1642  0.13723 0.6     0.68    0.      0.0145
  0.261   2.242  ]]
Logits tf.Tensor([[-0.34797484  0.05831745 -0.4359578 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29265288 0.43934256 0.2680046 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.07, 0.032, 0.1365, 0.13723, 0.6, 0.8, 0, 0.0037, 0.304, 2.482]
Reward 21.058996715776235
Current State [[0.07    0.07    0.032   0.1365  0.13723 0.6     0.8     0.      0.0037
  0.304   2.482  ]]
Logits tf.Tensor([[-0.40454188  0.05321512 -0.5007426 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.28663096 0.45302737 0.26034167]], shape=(1, 3), dtype=float32)
Selected action 0
[0.24, 0.2, 0.029, 0.1509, 0.13723, 0.6, 0.45, 0, 0.2506, 0.273, 1.684]
Reward 3.8564734204174695
Current State [[0.24    0.2     0.029   0.1509  0.13723 0.6     0.45    0.      0.2506
  0.273   1.684  ]]
Logits tf.Tensor([[-0.20126209  0.0607423  -0.23508696]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30615938 0.39786395 0.29597673]], shape=(1, 3), dtype=float32)
Selected action 1
[0.16, 0.12, 0.034, 0.1623, 0.13723, 0.6, 0.76, 0, 0.0116, 0.266, 2.255]
Reward 6.841712950994107
Current State [[0.16    0.12    0.034   0.1623  0.13723 0.6     0.76    0.      0.0116
  0.266   2.255  ]]
Logits tf.Tensor([[-0.3543493   0.05750808 -0.4438733 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2920573  0.4408953  0.26704738]], shape=(1, 3), dtype=float32)
Selected action 1
[0.15, 0.12, 0.034, 0.1698, 0.13723, 0.6, 0.76, 0, 0.0116, 0.266, 2.255]
Reward 6.841712950994107
Current State [[0.15    0.12    0.034   0.1698  0.13723 0.6     0.76    0.      0.0116
  0.266   2.255  ]]
Logits tf.Tensor([[-0.35711974  0.05727626 -0.44632202]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29170534 0.4414833  0.26681137]], shape=(1, 3), dtype=float32)
Selected action 1
[0.13, 0.12, 0.029, 0.1769, 0.13723, 0.6, 0.6, 0, 0.2159, 0.333, 2.157]
Reward 3.8919582331978946
Current State [[0.13    0.12    0.029   0.1769  0.13723 0.6     0.6     0.      0.2159
  0.333   2.157  ]]
Logits tf.Tensor([[-0.29636648  0.05503854 -0.3623156 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2978636  0.42328286 0.2788535 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.13, 0.12, 0.024, 0.15469999999999998, 0.13723, 0.6, 0.81, 0, 0.0021, 0.29900000000000004, 1.499]
Reward 39.93165665651925
Current State [[0.13    0.12    0.024   0.1547  0.13723 0.6     0.81    0.      0.0021
  0.299   1.499  ]]
Logits tf.Tensor([[-0.22358036  0.03407485 -0.32317978]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.31258863 0.40445614 0.28295523]], shape=(1, 3), dtype=float32)
Selected action 1
[0.1, 0.12, 0.029, 0.14709999999999998, 0.13723, 0.6, 0.73, 0, 0.019299999999999998, 0.27599999999999997, 0.915]
Reward 5.356458627637921
Current State [[0.1     0.12    0.029   0.1471  0.13723 0.6     0.73    0.      0.0193
  0.276   0.915  ]]
Logits tf.Tensor([[-0.11046593  0.00054293 -0.24437706]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3342165  0.37345514 0.2923284 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.12, 0.12, 0.031, 0.1596, 0.13723, 0.6, 0.73, 0, 0.019299999999999998, 0.27599999999999997, 0.915]
Reward 5.356458627637921
Current State [[0.12    0.12    0.031   0.1596  0.13723 0.6     0.73    0.      0.0193
  0.276   0.915  ]]
Logits tf.Tensor([[-0.10992404  0.00055434 -0.24355438]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.33425525 0.37330034 0.29244438]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.07, 0.036, 0.1865, 0.13723, 0.6, 0.82, 0, 0.0106, 0.316, 1.139]
Reward 7.530696922711027
Current State [[0.08    0.07    0.036   0.1865  0.13723 0.6     0.82    0.      0.0106
  0.316   1.139  ]]
Logits tf.Tensor([[-0.15834877  0.00972889 -0.28653976]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3265078  0.38626802 0.28722414]], shape=(1, 3), dtype=float32)
Selected action 1
[0.06, 0.12, 0.027, 0.1646, 0.13723, 0.6, 0.37, 0, 0.14880000000000002, 0.373, 1.3359999999999999]
Reward 3.8820701393701587
Current State [[0.06    0.12    0.027   0.1646  0.13723 0.6     0.37    0.      0.1488
  0.373   1.336  ]]
Logits tf.Tensor([[-0.15446848  0.03176977 -0.23808786]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3200522  0.3855698  0.29437798]], shape=(1, 3), dtype=float32)
Selected action 0
[0.01, 0.2, 0.017, 0.0837, 0.13723, 0.6, 0.45, 0, 0.168, 0.355, 0.909]
Reward 3.8883672648534278
Current State [[0.01    0.2     0.017   0.0837  0.13723 0.6     0.45    0.      0.168
  0.355   0.909  ]]
Logits tf.Tensor([[-0.09627537 -0.00576867 -0.18584543]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.33233047 0.36381176 0.3038578 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.07, 0.12, 0.021, 0.148, 0.13723, 0.6, 0.45, 0, 0.168, 0.355, 0.909]
Reward 3.8883672648534278
Current State [[0.07    0.12    0.021   0.148   0.13723 0.6     0.45    0.      0.168
  0.355   0.909  ]]
Logits tf.Tensor([[-0.08969203 -0.00549619 -0.19851097]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.33503816 0.36446854 0.3004933 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.07, 0.032, 0.1275, 0.13723, 0.6, 0.82, 0, 0.005600000000000001, 0.351, 1.277]
Reward 13.210994844748363
Episode: 0 | Average Reward: 229 | Episode Reward: 229 | Loss: 298.801 | Steps: 19 | Worker: 0
Saving best model to ./Training/, episode score: 229.15976436294162
Current State [[-4.54485935e-03  1.64603142e-03 -6.18772125e-03 -4.30717759e-03
  -8.55712829e-03 -5.12374768e-03  4.76011924e-03  2.19383177e-03
  -7.29674857e-05  8.42457112e-03  3.51330718e-03]]
Logits tf.Tensor([[-0.0011198  -0.00630516 -0.00520969]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.33436468 0.33263537 0.33299994]], shape=(1, 3), dtype=float32)
Selected action 1
[0.11, 0.12, 0.026, 0.1377, 0.13723, 0.6, 0.62, 0, 0.008, 0.3, 1.251]
Reward 7.588809669402184
Current State [[0.11    0.12    0.026   0.1377  0.13723 0.6     0.62    0.      0.008
  0.3     1.251  ]]
Logits tf.Tensor([[-0.3443199  -0.23835945  0.1328837 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26857612 0.29859698 0.4328269 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.11, 0.12, 0.025, 0.15, 0.13723, 0.6, 0.82, 0, 0.0013, 0.351, 0.853]
Reward 48.960322334708366
Current State [[0.11    0.12    0.025   0.15    0.13723 0.6     0.82    0.      0.0013
  0.351   0.853  ]]
Logits tf.Tensor([[-0.27576825 -0.19038133  0.10861683]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.28106865 0.30612266 0.41280863]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.07, 0.025, 0.1275, 0.13723, 0.6, 0.82, 0, 0.0013, 0.351, 0.853]
Reward 48.960322334708366
Current State [[0.08    0.07    0.025   0.1275  0.13723 0.6     0.82    0.      0.0013
  0.351   0.853  ]]
Logits tf.Tensor([[-0.27963796 -0.20606698  0.11663432]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2806924  0.30212182 0.41718578]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.07, 0.026, 0.1453, 0.13723, 0.6, 0.7, 0, 0.0049, 0.337, 0.10700000000000001]
Reward 12.72114373842476
Current State [[0.07    0.07    0.026   0.1453  0.13723 0.6     0.7     0.      0.0049
  0.337   0.107  ]]
Logits tf.Tensor([[-0.11394066 -0.12861225  0.07052809]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3136748  0.3091063  0.37721884]], shape=(1, 3), dtype=float32)
Selected action 1
[0.13, 0.12, 0.025, 0.1308, 0.13723, 0.6, 0.7, 0, 0.0040999999999999995, 0.294, 0.73]
Reward 15.79153545047097
Current State [[0.13    0.12    0.025   0.1308  0.13723 0.6     0.7     0.      0.0041
  0.294   0.73   ]]
Logits tf.Tensor([[-0.24628663 -0.15437272  0.10553329]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.28425863 0.31162435 0.404117  ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.07, 0.025, 0.128, 0.13723, 0.6, 0.75, 0, 0.0032, 0.32999999999999996, 0.8230000000000001]
Reward 23.03782060539118
Current State [[0.08    0.07    0.025   0.128   0.13723 0.6     0.75    0.      0.0032
  0.33    0.823  ]]
Logits tf.Tensor([[-0.269535   -0.19402218  0.11847842]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.28149295 0.30357245 0.41493458]], shape=(1, 3), dtype=float32)
Selected action 0
[0.21, 0.2, 0.028, 0.246, 0.13723, 0.6, 0.75, 0, 0.0032, 0.32999999999999996, 0.8230000000000001]
Reward 23.03782060539118
Current State [[0.21    0.2     0.028   0.246   0.13723 0.6     0.75    0.      0.0032
  0.33    0.823  ]]
Logits tf.Tensor([[-0.27376407 -0.138023    0.08818263]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.279212   0.31980532 0.40098262]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.07, 0.03, 0.1566, 0.13723, 0.6, 0.67, 0, 0.0132, 0.33799999999999997, 0.063]
Reward 6.000173351725219
Current State [[0.07    0.07    0.03    0.1566  0.13723 0.6     0.67    0.      0.0132
  0.338   0.063  ]]
Logits tf.Tensor([[-0.09803975 -0.1280819   0.06908756]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.31722775 0.30783927 0.37493297]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.07, 0.031, 0.1288, 0.13723, 0.6, 0.71, 0, 0.004699999999999999, 0.29100000000000004, 1.577]
Reward 13.437853528925567
Current State [[0.07    0.07    0.031   0.1288  0.13723 0.6     0.71    0.      0.0047
  0.291   1.577  ]]
Logits tf.Tensor([[-0.40409273 -0.32014734  0.14141394]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2622571  0.28522286 0.45252   ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.08, 0.12, 0.024, 0.149, 0.13723, 0.6, 0.71, 0, 0.004699999999999999, 0.29100000000000004, 1.577]
Reward 13.437853528925567
Current State [[0.08    0.12    0.024   0.149   0.13723 0.6     0.71    0.      0.0047
  0.291   1.577  ]]
Logits tf.Tensor([[-0.38982815 -0.30627736  0.13843006]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26433235 0.28736642 0.4483013 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.06, 0.12, 0.023, 0.1469, 0.13723, 0.6, 0.7, 0, 0.0044, 0.305, 0.769]
Reward 14.300866207967259
Current State [[0.06    0.12    0.023   0.1469  0.13723 0.6     0.7     0.      0.0044
  0.305   0.769  ]]
Logits tf.Tensor([[-0.24022917 -0.1770404   0.11406393]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.28650007 0.30518782 0.40831205]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.07, 0.031, 0.125, 0.13723, 0.6, 0.83, 0, 0.0033, 0.33799999999999997, 1.474]
Reward 24.68770712570475
Current State [[0.05    0.07    0.031   0.125   0.13723 0.6     0.83    0.      0.0033
  0.338   1.474  ]]
Logits tf.Tensor([[-0.39851156 -0.3119893   0.14348535]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2624801  0.28620192 0.451318  ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.15, 0.2, 0.025, 0.19619999999999999, 0.13723, 0.6, 0.83, 0, 0.0033, 0.33799999999999997, 1.474]
Reward 24.68770712570475
Current State [[0.15    0.2     0.025   0.1962  0.13723 0.6     0.83    0.      0.0033
  0.338   1.474  ]]
Logits tf.Tensor([[-0.39004493 -0.25860903  0.12150194]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26258203 0.29946554 0.43795246]], shape=(1, 3), dtype=float32)
Selected action 1
[0.13, 0.12, 0.026, 0.1745, 0.13723, 0.6, 0.74, 0, 0.005, 0.27999999999999997, 1.278]
Reward 13.235907358597679
Current State [[0.13    0.12    0.026   0.1745  0.13723 0.6     0.74    0.      0.005
  0.28    1.278  ]]
Logits tf.Tensor([[-0.3601194  -0.23144697  0.12783964]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26551217 0.3019716  0.4325162 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.11, 0.2, 0.023, 0.1712, 0.13723, 0.6, 0.63, 0, 0.0085, 0.314, 0.9630000000000001]
Reward 7.381305718233647
Current State [[0.11    0.2     0.023   0.1712  0.13723 0.6     0.63    0.      0.0085
  0.314   0.963  ]]
Logits tf.Tensor([[-0.27298275 -0.17723352  0.12078723]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.27909243 0.30713648 0.41377112]], shape=(1, 3), dtype=float32)
Selected action 1
[0.05, 0.12, 0.026, 0.1321, 0.13723, 0.6, 0.82, 0, 0.0139, 0.325, 1.131]
Reward 6.4700279864169525
Current State [[0.05    0.12    0.026   0.1321  0.13723 0.6     0.82    0.      0.0139
  0.325   1.131  ]]
Logits tf.Tensor([[-0.3184908  -0.2450366   0.13729759]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.27369997 0.29456118 0.43173885]], shape=(1, 3), dtype=float32)
Selected action 0
[0.08, 0.2, 0.025, 0.1615, 0.13723, 0.6, 0.88, 0, 0.0048, 0.394, 1.1460000000000001]
Reward 16.963381332215974
Current State [[0.08    0.2     0.025   0.1615  0.13723 0.6     0.88    0.      0.0048
  0.394   1.146  ]]
Logits tf.Tensor([[-0.31843138 -0.24383354  0.1218517 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.27543676 0.2967695  0.42779368]], shape=(1, 3), dtype=float32)
Selected action 1
[0.07, 0.12, 0.026, 0.1827, 0.13723, 0.6, 0.88, 0, 0.0048, 0.394, 1.1460000000000001]
Reward 16.963381332215974
Current State [[0.07    0.12    0.026   0.1827  0.13723 0.6     0.88    0.      0.0048
  0.394   1.146  ]]
Logits tf.Tensor([[-0.33997345 -0.25157732  0.12738536]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.27113536 0.2961939  0.43267074]], shape=(1, 3), dtype=float32)
Selected action 2
[0.09, 0.07, 0.032, 0.14, 0.13723, 0.6, 0.52, 0, 0.2345, 0.281, 2.05]
Reward 3.871888763099803
Current State [[0.09    0.07    0.032   0.14    0.13723 0.6     0.52    0.      0.2345
  0.281   2.05   ]]
Logits tf.Tensor([[-0.42021534 -0.4633227   0.15506338]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2677065  0.25641155 0.475882  ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.07, 0.032, 0.1245, 0.13723, 0.6, 0.59, 0, 0.0761, 0.364, 0.782]
Reward 4.072053975845064
Episode: 1 | Average Reward: 230 | Episode Reward: 345 | Loss: 748.233 | Steps: 19 | Worker: 0
Saving best model to ./Training/, episode score: 345.6078820740751
Current State [[ 0.0079259   0.00866384 -0.00816896 -0.00052683 -0.00349474 -0.00849907
  -0.00508592 -0.00232837  0.00426345  0.00878837 -0.00189485]]
Logits tf.Tensor([[-2.4075746e-03  7.3564006e-05 -9.4187213e-03]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.33383438 0.33466366 0.33150196]], shape=(1, 3), dtype=float32)
Selected action 0
[0.12, 0.2, 0.024, 0.1673, 0.13723, 0.6, 0.59, 0, 0.0761, 0.364, 0.782]
Reward 4.072053975845064
Current State [[0.12    0.2     0.024   0.1673  0.13723 0.6     0.59    0.      0.0761
  0.364   0.782  ]]
Logits tf.Tensor([[-0.24345505 -0.14876279  0.10747242]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.28411475 0.31233314 0.40355211]], shape=(1, 3), dtype=float32)
Selected action 2
[0.09, 0.07, 0.032, 0.126, 0.13723, 0.6, 0.54, 0, 0.0199, 0.36, 1.3279999999999998]
Reward 4.8543515008555405
Current State [[0.09    0.07    0.032   0.126   0.13723 0.6     0.54    0.      0.0199
  0.36    1.328  ]]
Logits tf.Tensor([[-0.38119975 -0.26290414  0.12597266]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26411945 0.29728672 0.4385939 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.07, 0.032, 0.1173, 0.13723, 0.6, 0.5, 0, 0.0191, 0.233, 2.387]
Reward 4.814608196096884
Current State [[0.06    0.07    0.032   0.1173  0.13723 0.6     0.5     0.      0.0191
  0.233   2.387  ]]
Logits tf.Tensor([[-0.51070964 -0.50658405  0.14359279]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25458676 0.25563926 0.489774  ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.07, 0.031, 0.1373, 0.13723, 0.6, 0.5, 0, 0.0191, 0.233, 2.387]
Reward 4.814608196096884
Current State [[0.06    0.07    0.031   0.1373  0.13723 0.6     0.5     0.      0.0191
  0.233   2.387  ]]
Logits tf.Tensor([[-0.5129111  -0.50416493  0.14028768]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25442296 0.25665796 0.48891905]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.07, 0.03, 0.134, 0.13723, 0.6, 0.66, 0, 0.3211, 0.29100000000000004, 0.076]
Reward 3.865406880248918
Current State [[0.03    0.07    0.03    0.134   0.13723 0.6     0.66    0.      0.3211
  0.291   0.076  ]]
Logits tf.Tensor([[-0.01507462 -0.15039308  0.09101713]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3349678 0.2925735 0.3724587]], shape=(1, 3), dtype=float32)
Selected action 0
[0.11, 0.2, 0.024, 0.15, 0.13723, 0.6, 0.72, 0, 0.35229999999999995, 0.272, 0.491]
Reward 3.8656026228227724
Current State [[0.11    0.2     0.024   0.15    0.13723 0.6     0.72    0.      0.3523
  0.272   0.491  ]]
Logits tf.Tensor([[-0.12316167 -0.14638537  0.09747194]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.31018233 0.30306175 0.38675594]], shape=(1, 3), dtype=float32)
Selected action 2
[0.11, 0.07, 0.026, 0.13, 0.13723, 0.6, 0.77, 0, 0.0353, 0.37, 1.373]
Reward 4.6285515168460005
Current State [[0.11    0.07    0.026   0.13    0.13723 0.6     0.77    0.      0.0353
  0.37    1.373  ]]
Logits tf.Tensor([[-0.4063666  -0.26312706  0.12304743]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25960925 0.29959062 0.44080013]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.07, 0.033, 0.148, 0.13723, 0.6, 0.77, 0, 0.0353, 0.37, 1.373]
Reward 4.6285515168460005
Current State [[0.07    0.07    0.033   0.148   0.13723 0.6     0.77    0.      0.0353
  0.37    1.373  ]]
Logits tf.Tensor([[-0.3963928  -0.26940724  0.12583533]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26169926 0.2971335  0.44116724]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.07, 0.033, 0.1264, 0.13723, 0.6, 0.66, 0, 0.0709, 0.313, 0.682]
Reward 4.130460727416307
Current State [[0.07    0.07    0.033   0.1264  0.13723 0.6     0.66    0.      0.0709
  0.313   0.682  ]]
Logits tf.Tensor([[-0.23772588 -0.15514912  0.11048041]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2855017  0.31007823 0.40442008]], shape=(1, 3), dtype=float32)
Selected action 0
[0.11, 0.2, 0.029, 0.19, 0.13723, 0.6, 0.68, 0, 0.0049, 0.257, 2.09]
Reward 12.304722640315696
Current State [[0.11    0.2     0.029   0.19    0.13723 0.6     0.68    0.      0.0049
  0.257   2.09   ]]
Logits tf.Tensor([[-0.4469781  -0.37248105  0.12485105]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25981808 0.279913   0.4602689 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.1, 0.12, 0.031, 0.18130000000000002, 0.13723, 0.6, 0.68, 0, 0.0049, 0.257, 2.09]
Reward 12.304722640315696
Current State [[0.1     0.12    0.031   0.1813  0.13723 0.6     0.68    0.      0.0049
  0.257   2.09   ]]
Logits tf.Tensor([[-0.47530705 -0.39178997  0.12512912]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25575334 0.27803043 0.46621627]], shape=(1, 3), dtype=float32)
Selected action 2
[0.09, 0.07, 0.037, 0.1519, 0.13723, 0.6, 0.74, 0, 0.10619999999999999, 0.272, 1.8690000000000002]
Reward 4.044746944589573
Current State [[0.09    0.07    0.037   0.1519  0.13723 0.6     0.74    0.      0.1062
  0.272   1.869  ]]
Logits tf.Tensor([[-0.44162658 -0.36061716  0.13176854]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2591572  0.2810252  0.45981765]], shape=(1, 3), dtype=float32)
Selected action 0
[0.21, 0.2, 0.031, 0.18, 0.13723, 0.6, 0.66, 0, 0.0096, 0.286, 1.583]
Reward 7.059239563047176
Current State [[0.21    0.2     0.031   0.18    0.13723 0.6     0.66    0.      0.0096
  0.286   1.583  ]]
Logits tf.Tensor([[-0.39730102 -0.24034281  0.11220154]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26079634 0.3051178  0.43408585]], shape=(1, 3), dtype=float32)
Selected action 0
[0.23, 0.2, 0.026, 0.1776, 0.13723, 0.6, 0.82, 0, 0.0202, 0.305, 1.8519999999999999]
Reward 5.482790460454345
Current State [[0.23    0.2     0.026   0.1776  0.13723 0.6     0.82    0.      0.0202
  0.305   1.852  ]]
Logits tf.Tensor([[-0.45354265 -0.29397345  0.11197376]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25423542 0.29821953 0.447545  ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.1, 0.07, 0.04, 0.1469, 0.13723, 0.6, 0.82, 0, 0.0202, 0.305, 1.8519999999999999]
Reward 5.482790460454345
Current State [[0.1     0.07    0.04    0.1469  0.13723 0.6     0.82    0.      0.0202
  0.305   1.852  ]]
Logits tf.Tensor([[-0.47125643 -0.34462065  0.12270318]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25341156 0.28762308 0.4589653 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.13, 0.07, 0.037, 0.1415, 0.13723, 0.6, 0.67, 0, 0.0073, 0.23900000000000002, 2.38]
Reward 8.57804797638831
Current State [[0.13    0.07    0.037   0.1415  0.13723 0.6     0.67    0.      0.0073
  0.239   2.38   ]]
Logits tf.Tensor([[-0.5313929  -0.4723787   0.13599516]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24938095 0.26454085 0.48607823]], shape=(1, 3), dtype=float32)
Selected action 1
[0.1, 0.12, 0.03, 0.1571, 0.13723, 0.6, 0.72, 0, 0.0036, 0.279, 1.33]
Reward 18.670325744156024
Current State [[0.1     0.12    0.03    0.1571  0.13723 0.6     0.72    0.      0.0036
  0.279   1.33   ]]
Logits tf.Tensor([[-0.3720747  -0.22247386  0.12097708]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26324964 0.30573037 0.43102002]], shape=(1, 3), dtype=float32)
Selected action 0
[0.17, 0.2, 0.027, 0.2019, 0.13723, 0.6, 0.72, 0, 0.0036, 0.279, 1.33]
Reward 18.670325744156024
Current State [[0.17    0.2     0.027   0.2019  0.13723 0.6     0.72    0.      0.0036
  0.279   1.33   ]]
Logits tf.Tensor([[-0.36683744 -0.18893124  0.10640424]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26316464 0.3144063  0.42242905]], shape=(1, 3), dtype=float32)
Selected action 1
[0.07, 0.12, 0.033, 0.1679, 0.13723, 0.6, 0.78, 0, 0.0001, 0.329, 0.627]
Reward 50.0
Current State [[7.0000e-02 1.2000e-01 3.3000e-02 1.6790e-01 1.3723e-01 6.0000e-01
  7.8000e-01 0.0000e+00 1.0000e-04 3.2900e-01 6.2700e-01]]
Logits tf.Tensor([[-0.23368078 -0.14250083  0.09007159]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2875405  0.31499088 0.39746863]], shape=(1, 3), dtype=float32)
Selected action 0
[0.19, 0.2, 0.03, 0.1925, 0.13723, 0.6, 0.67, 0, 0.009300000000000001, 0.28900000000000003, 1.137]
Reward 7.18190957299848
Episode: 2 | Average Reward: 229 | Episode Reward: 189 | Loss: 444.758 | Steps: 19 | Worker: 0
Current State [[ 0.00308397  0.00668422  0.00386205 -0.00689154 -0.00630847 -0.00314782
  -0.00233167 -0.00824329 -0.00935045  0.00024488 -0.00782085]]
Logits tf.Tensor([[-0.00081055  0.0019695  -0.00518767]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3335094  0.33443785 0.33205274]], shape=(1, 3), dtype=float32)
Selected action 0
[0.23, 0.2, 0.027, 0.15830000000000002, 0.13723, 0.6, 0.87, 0, 0.0009, 0.353, 1.831]
Reward 49.93493831700621
Current State [[2.3000e-01 2.0000e-01 2.7000e-02 1.5830e-01 1.3723e-01 6.0000e-01
  8.7000e-01 0.0000e+00 9.0000e-04 3.5300e-01 1.8310e+00]]
Logits tf.Tensor([[-0.48522353 -0.29177654  0.12224563]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2469621  0.29967    0.45336795]], shape=(1, 3), dtype=float32)
Selected action 0
[0.19, 0.2, 0.03, 0.1717, 0.13723, 0.6, 0.67, 0, 0.016399999999999998, 0.384, 1.171]
Reward 5.503780411825306
Current State [[0.19    0.2     0.03    0.1717  0.13723 0.6     0.67    0.      0.0164
  0.384   1.171  ]]
Logits tf.Tensor([[-0.3636002  -0.18681237  0.11248039]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26294127 0.3137883  0.42327043]], shape=(1, 3), dtype=float32)
Selected action 1
[0.06, 0.12, 0.031, 0.1667, 0.13723, 0.6, 0.94, 0, 0.0526, 0.31, 1.674]
Reward 4.4700219135069075
Current State [[0.06    0.12    0.031   0.1667  0.13723 0.6     0.94    0.      0.0526
  0.31    1.674  ]]
Logits tf.Tensor([[-0.43527597 -0.3052667   0.13689995]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25569186 0.29119185 0.45311633]], shape=(1, 3), dtype=float32)
Selected action 1
[0.13, 0.12, 0.03, 0.1472, 0.13723, 0.6, 0.94, 0, 0.0526, 0.31, 1.674]
Reward 4.4700219135069075
Current State [[0.13    0.12    0.03    0.1472  0.13723 0.6     0.94    0.      0.0526
  0.31    1.674  ]]
Logits tf.Tensor([[-0.4495268  -0.2898962   0.13194576]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25241387 0.296101   0.45148516]], shape=(1, 3), dtype=float32)
Selected action 1
[0.13, 0.12, 0.034, 0.1692, 0.13723, 0.6, 0.74, 0, 0.1485, 0.27599999999999997, 2.822]
Reward 3.9701610909893175
Current State [[0.13    0.12    0.034   0.1692  0.13723 0.6     0.74    0.      0.1485
  0.276   2.822  ]]
Logits tf.Tensor([[-0.59286827 -0.57684284  0.1587134 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24174996 0.24565531 0.51259476]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.07, 0.033, 0.1333, 0.13723, 0.6, 0.85, 0, 0.0005, 0.296, 1.384]
Reward 49.999914822714366
Current State [[6.0000e-02 7.0000e-02 3.3000e-02 1.3330e-01 1.3723e-01 6.0000e-01
  8.5000e-01 0.0000e+00 5.0000e-04 2.9600e-01 1.3840e+00]]
Logits tf.Tensor([[-0.40539646 -0.26221833  0.139215  ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25787327 0.29756907 0.44455764]], shape=(1, 3), dtype=float32)
Selected action 1
[0.06, 0.12, 0.031, 0.15630000000000002, 0.13723, 0.6, 0.85, 0, 0.0005, 0.296, 1.384]
Reward 49.999914822714366
Current State [[6.0000e-02 1.2000e-01 3.1000e-02 1.5630e-01 1.3723e-01 6.0000e-01
  8.5000e-01 0.0000e+00 5.0000e-04 2.9600e-01 1.3840e+00]]
Logits tf.Tensor([[-0.39360785 -0.25232908  0.13510305]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25984225 0.29927215 0.44088566]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.07, 0.028, 0.1353, 0.13723, 0.6, 0.79, 0, 0.006, 0.294, 1.2570000000000001]
Reward 11.780989515907788
Current State [[0.07    0.07    0.028   0.1353  0.13723 0.6     0.79    0.      0.006
  0.294   1.257  ]]
Logits tf.Tensor([[-0.38146904 -0.23746601  0.13744971]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26074958 0.3011364  0.438114  ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.15, 0.2, 0.031, 0.19619999999999999, 0.13723, 0.6, 0.69, 0, 0.006, 0.27799999999999997, 1.145]
Reward 10.344523576985125
Current State [[0.15    0.2     0.031   0.1962  0.13723 0.6     0.69    0.      0.006
  0.278   1.145  ]]
Logits tf.Tensor([[-0.33932337 -0.16494063  0.11847676]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26517433 0.315693   0.41913268]], shape=(1, 3), dtype=float32)
Selected action 0
[0.28, 0.2, 0.031, 0.2019, 0.13723, 0.6, 0.78, 0, 0.0109, 0.324, 2.3449999999999998]
Reward 7.181224716135875
Current State [[0.28    0.2     0.031   0.2019  0.13723 0.6     0.78    0.      0.0109
  0.324   2.345  ]]
Logits tf.Tensor([[-0.55071455 -0.39589176  0.12483153]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24198094 0.28250092 0.47551814]], shape=(1, 3), dtype=float32)
Selected action 1
[0.12, 0.12, 0.03, 0.15580000000000002, 0.13723, 0.6, 0.78, 0, 0.0109, 0.324, 2.3449999999999998]
Reward 7.181224716135875
Current State [[0.12    0.12    0.03    0.1558  0.13723 0.6     0.78    0.      0.0109
  0.324   2.345  ]]
Logits tf.Tensor([[-0.5562167  -0.45412335  0.1393666 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24316908 0.26930657 0.4875244 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.07, 0.03, 0.136, 0.13723, 0.6, 0.6, 0, 0.49340000000000006, 0.298, 2.3579999999999997]
Reward 3.8354868128312622
Current State [[0.03    0.07    0.03    0.136   0.13723 0.6     0.6     0.      0.4934
  0.298   2.358  ]]
Logits tf.Tensor([[-0.44109797 -0.54829806  0.1767653 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26643175 0.23934792 0.49422038]], shape=(1, 3), dtype=float32)
Selected action 0
[0.19, 0.2, 0.027, 0.2102, 0.13723, 0.6, 0.7, 0, 0.0042, 0.254, 1.387]
Reward 15.268174569377027
Current State [[0.19    0.2     0.027   0.2102  0.13723 0.6     0.7     0.      0.0042
  0.254   1.387  ]]
Logits tf.Tensor([[-0.37739965 -0.19036368  0.1147365 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26031652 0.313856   0.42582753]], shape=(1, 3), dtype=float32)
Selected action 1
[0.16, 0.12, 0.028, 0.1396, 0.13723, 0.6, 0.77, 0, 0.015600000000000001, 0.367, 0.9410000000000001]
Reward 5.93214764012253
Current State [[0.16    0.12    0.028   0.1396  0.13723 0.6     0.77    0.      0.0156
  0.367   0.941  ]]
Logits tf.Tensor([[-0.32539713 -0.17305921  0.11478843]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26899445 0.31325844 0.41774708]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.07, 0.032, 0.1296, 0.13723, 0.6, 0.8, 0, 0.0241, 0.31, 1.142]
Reward 5.135956930074744
Current State [[0.07    0.07    0.032   0.1296  0.13723 0.6     0.8     0.      0.0241
  0.31    1.142  ]]
Logits tf.Tensor([[-0.3545872  -0.22185478  0.13856685]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26459107 0.30214825 0.43326065]], shape=(1, 3), dtype=float32)
Selected action 1
[0.13, 0.12, 0.025, 0.174, 0.13723, 0.6, 0.8, 0, 0.0241, 0.31, 1.142]
Reward 5.135956930074744
Current State [[0.13    0.12    0.025   0.174   0.13723 0.6     0.8     0.      0.0241
  0.31    1.142  ]]
Logits tf.Tensor([[-0.36026856 -0.19687892  0.12548748]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2629573  0.30963102 0.4274117 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.15, 0.2, 0.026, 0.1981, 0.13723, 0.6, 0.45, 0, 0.0354, 0.40700000000000003, 1.275]
Reward 4.258535408819698
Current State [[0.15    0.2     0.026   0.1981  0.13723 0.6     0.45    0.      0.0354
  0.407   1.275  ]]
Logits tf.Tensor([[-0.3525769  -0.22150466  0.11373615]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2677981  0.30530328 0.42689857]], shape=(1, 3), dtype=float32)
Selected action 1
[0.12, 0.12, 0.031, 0.1667, 0.13723, 0.6, 0.44, 0, 0.20149999999999998, 0.417, 1.404]
Reward 3.869684771185744
Current State [[0.12    0.12    0.031   0.1667  0.13723 0.6     0.44    0.      0.2015
  0.417   1.404  ]]
Logits tf.Tensor([[-0.34893727 -0.30067125  0.12899126]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.27306142 0.28656423 0.44037434]], shape=(1, 3), dtype=float32)
Selected action 0
[0.2, 0.2, 0.025, 0.1765, 0.13723, 0.6, 0.9, 0, 0.0011, 0.382, 0.24500000000000002]
Reward 49.87779327478803
Current State [[0.2     0.2     0.025   0.1765  0.13723 0.6     0.9     0.      0.0011
  0.382   0.245  ]]
Logits tf.Tensor([[-0.1690228  -0.11259647  0.04081714]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30381015 0.3214459  0.3747439 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.21, 0.2, 0.025, 0.1923, 0.13723, 0.6, 0.9, 0, 0.0011, 0.382, 0.24500000000000002]
Reward 49.87779327478803
Episode: 3 | Average Reward: 231 | Episode Reward: 348 | Loss: 932.645 | Steps: 19 | Worker: 0
Saving best model to ./Training/, episode score: 348.02824542948986
Current State [[-8.99895160e-03 -1.44118432e-03  8.35389956e-03  9.93628799e-03
  -8.16261046e-03 -4.10644748e-03  3.47026067e-03  5.91211173e-04
   7.46904106e-05  4.88392499e-03 -3.68193034e-03]]
Logits tf.Tensor([[ 0.00225119 -0.00129587 -0.00724268]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.33478293 0.3335975  0.33161956]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.2, 0.023, 0.14, 0.13723, 0.6, 0.64, 0, 0.1543, 0.321, 1.355]
Reward 3.942000587501827
Current State [[0.04    0.2     0.023   0.14    0.13723 0.6     0.64    0.      0.1543
  0.321   1.355  ]]
Logits tf.Tensor([[-0.31196824 -0.24575473  0.12652957]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.27633232 0.2952486  0.4284191 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.07, 0.026, 0.142, 0.13723, 0.6, 0.83, 0, 0.005699999999999999, 0.391, 0.759]
Reward 13.177339264876442
Current State [[0.05    0.07    0.026   0.142   0.13723 0.6     0.83    0.      0.0057
  0.391   0.759  ]]
Logits tf.Tensor([[-0.276049   -0.18157376  0.09860438]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2814072 0.3092896 0.4093032]], shape=(1, 3), dtype=float32)
Selected action 1
[0.16, 0.12, 0.023, 0.1321, 0.13723, 0.6, 0.64, 0, 0.015700000000000002, 0.301, 1.145]
Reward 5.4765645561221366
Current State [[0.16    0.12    0.023   0.1321  0.13723 0.6     0.64    0.      0.0157
  0.301   1.145  ]]
Logits tf.Tensor([[-0.35434103 -0.18149783  0.11088581]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26447645 0.31437778 0.42114577]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.07, 0.024, 0.154, 0.13723, 0.6, 0.64, 0, 0.015700000000000002, 0.301, 1.145]
Reward 5.4765645561221366
Current State [[0.06    0.07    0.024   0.154   0.13723 0.6     0.64    0.      0.0157
  0.301   1.145  ]]
Logits tf.Tensor([[-0.34506652 -0.21180916  0.12050423]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26770413 0.30586377 0.42643207]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.07, 0.032, 0.1245, 0.13723, 0.6, 0.7, 0, 0.0039000000000000003, 0.29900000000000004, 0.654]
Reward 16.433057543121038
Current State [[0.08    0.07    0.032   0.1245  0.13723 0.6     0.7     0.      0.0039
  0.299   0.654  ]]
Logits tf.Tensor([[-0.24635912 -0.13947415  0.09814402]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.28376082 0.3157708  0.40046838]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.07, 0.029, 0.1167, 0.13723, 0.6, 0.73, 0, 0.0054, 0.307, 1.182]
Reward 12.001280795862677
Current State [[0.03    0.07    0.029   0.1167  0.13723 0.6     0.73    0.      0.0054
  0.307   1.182  ]]
Logits tf.Tensor([[-0.35182852 -0.22785343  0.12974076]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.266624   0.30181506 0.43156093]], shape=(1, 3), dtype=float32)
Selected action 0
[0.13, 0.2, 0.026, 0.134, 0.13723, 0.6, 0.53, 0, 0.0335, 0.339, 1.114]
Reward 4.391764359763694
Current State [[0.13    0.2     0.026   0.134   0.13723 0.6     0.53    0.      0.0335
  0.339   1.114  ]]
Logits tf.Tensor([[-0.3171217  -0.17556395  0.11201829]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.27114946 0.31238234 0.41646823]], shape=(1, 3), dtype=float32)
Selected action 1
[0.09, 0.12, 0.023, 0.14809999999999998, 0.13723, 0.6, 0.53, 0, 0.0335, 0.339, 1.114]
Reward 4.391764359763694
Current State [[0.09    0.12    0.023   0.1481  0.13723 0.6     0.53    0.      0.0335
  0.339   1.114  ]]
Logits tf.Tensor([[-0.32864055 -0.2004805   0.11532415]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2705913  0.3075906  0.42181814]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.07, 0.029, 0.1245, 0.13723, 0.6, 0.79, 0, 0.003, 0.341, 1.5939999999999999]
Reward 26.59842659830679
Current State [[0.07    0.07    0.029   0.1245  0.13723 0.6     0.79    0.      0.003
  0.341   1.594  ]]
Logits tf.Tensor([[-0.44443408 -0.29105815  0.12410392]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25435928 0.2965227  0.44911805]], shape=(1, 3), dtype=float32)
Selected action 0
[0.13, 0.2, 0.025, 0.1415, 0.13723, 0.6, 0.75, 0, 0.0029, 0.314, 1.159]
Reward 26.335210307923777
Current State [[0.13    0.2     0.025   0.1415  0.13723 0.6     0.75    0.      0.0029
  0.314   1.159  ]]
Logits tf.Tensor([[-0.34239325 -0.1797681   0.11135721]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26660973 0.31369182 0.41969842]], shape=(1, 3), dtype=float32)
Selected action 0
[0.21, 0.2, 0.027, 0.15, 0.13723, 0.6, 0.72, 0, 0.0187, 0.325, 0.475]
Reward 5.397779391067359
Current State [[0.21    0.2     0.027   0.15    0.13723 0.6     0.72    0.      0.0187
  0.325   0.475  ]]
Logits tf.Tensor([[-0.21403095 -0.09130448  0.06154263]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29003486 0.32790622 0.3820589 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.12, 0.2, 0.024, 0.1358, 0.13723, 0.6, 0.72, 0, 0.0187, 0.325, 0.475]
Reward 5.397779391067359
Current State [[0.12    0.2     0.024   0.1358  0.13723 0.6     0.72    0.      0.0187
  0.325   0.475  ]]
Logits tf.Tensor([[-0.19727191 -0.10996509  0.07438739]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2938263  0.3206325  0.38554117]], shape=(1, 3), dtype=float32)
Selected action 1
[0.15, 0.12, 0.029, 0.151, 0.13723, 0.6, 0.73, 0, 0.051, 0.316, 1.208]
Reward 4.3230420558880525
Current State [[0.15    0.12    0.029   0.151   0.13723 0.6     0.73    0.      0.051
  0.316   1.208  ]]
Logits tf.Tensor([[-0.36261985 -0.19733612  0.11291453]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26394963 0.31138876 0.42466164]], shape=(1, 3), dtype=float32)
Selected action 1
[0.12, 0.12, 0.025, 0.15880000000000002, 0.13723, 0.6, 0.76, 0, 0.0048, 0.335, 1.309]
Reward 14.355628133348292
Current State [[0.12    0.12    0.025   0.1588  0.13723 0.6     0.76    0.      0.0048
  0.335   1.309  ]]
Logits tf.Tensor([[-0.39228252 -0.21977492  0.11303499]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26002443 0.308982   0.43099353]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.07, 0.028, 0.1269, 0.13723, 0.6, 0.77, 0, 0.0218, 0.307, 0.836]
Reward 5.220941479373722
Current State [[0.08    0.07    0.028   0.1269  0.13723 0.6     0.77    0.      0.0218
  0.307   0.836  ]]
Logits tf.Tensor([[-0.2853543  -0.17078178  0.10609789]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2777376  0.31145325 0.4108092 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.07, 0.033, 0.1077, 0.13723, 0.6, 0.77, 0, 0.0218, 0.307, 0.836]
Reward 5.220941479373722
Current State [[0.07    0.07    0.033   0.1077  0.13723 0.6     0.77    0.      0.0218
  0.307   0.836  ]]
Logits tf.Tensor([[-0.28088218 -0.17321502  0.11005981]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.27839258 0.3100394  0.41156802]], shape=(1, 3), dtype=float32)
Selected action 1
[0.15, 0.12, 0.034, 0.15280000000000002, 0.13723, 0.6, 0.75, 0, 0.0052, 0.377, 0.24700000000000003]
Reward 12.97016823974246
Current State [[0.15    0.12    0.034   0.1528  0.13723 0.6     0.75    0.      0.0052
  0.377   0.247  ]]
Logits tf.Tensor([[-0.15594953 -0.10915845  0.05908489]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30415404 0.31872395 0.37712198]], shape=(1, 3), dtype=float32)
Selected action 1
[0.12, 0.12, 0.03, 0.1596, 0.13723, 0.6, 0.75, 0, 0.0181, 0.374, 0.595]
Reward 5.529232211393542
Current State [[0.12    0.12    0.03    0.1596  0.13723 0.6     0.75    0.      0.0181
  0.374   0.595  ]]
Logits tf.Tensor([[-0.2374294  -0.13241865  0.08380471]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.28656983 0.3182996  0.3951306 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.14, 0.12, 0.029, 0.19590000000000002, 0.13723, 0.6, 0.69, 0, 0.0075, 0.36, 1.02]
Reward 8.522784787769227
Current State [[0.14    0.12    0.029   0.1959  0.13723 0.6     0.69    0.      0.0075
  0.36    1.02   ]]
Logits tf.Tensor([[-0.33443135 -0.17242414  0.10178444]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26862144 0.31586352 0.41551504]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.07, 0.032, 0.13269999999999998, 0.13723, 0.6, 0.82, 0, 0.0066, 0.387, 1.924]
Reward 11.091796152179402
Episode: 4 | Average Reward: 230 | Episode Reward: 196 | Loss: 329.641 | Steps: 19 | Worker: 0
Current State [[ 0.00113212 -0.00175341  0.00259408 -0.00818009 -0.00623407  0.00098285
   0.00519071 -0.00197291 -0.00081685  0.0089288   0.0093628 ]]
Logits tf.Tensor([[-0.0044653  -0.00019231 -0.0074707 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.33319104 0.3346178  0.33219117]], shape=(1, 3), dtype=float32)
Selected action 1
[0.13, 0.12, 0.029, 0.16469999999999999, 0.13723, 0.6, 0.82, 0, 0.0066, 0.387, 1.924]
Reward 11.091796152179402
Current State [[0.13    0.12    0.029   0.1647  0.13723 0.6     0.82    0.      0.0066
  0.387   1.924  ]]
Logits tf.Tensor([[-0.5074377  -0.32588577  0.09924551]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24792892 0.29728583 0.45478526]], shape=(1, 3), dtype=float32)
Selected action 1
[0.14, 0.12, 0.03, 0.15419999999999998, 0.13723, 0.6, 0.61, 0, 0.0066, 0.361, 0.768]
Reward 8.543964436844197
Current State [[0.14    0.12    0.03    0.1542  0.13723 0.6     0.61    0.      0.0066
  0.361   0.768  ]]
Logits tf.Tensor([[-0.2746445  -0.13005581  0.09176874]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.27792326 0.32115817 0.40091854]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.07, 0.035, 0.125, 0.13723, 0.6, 0.61, 0, 0.0097, 0.40199999999999997, 1.529]
Reward 6.6632160503761515
Current State [[0.08    0.07    0.035   0.125   0.13723 0.6     0.61    0.      0.0097
  0.402   1.529  ]]
Logits tf.Tensor([[-0.43568808 -0.286151    0.11255946]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25696933 0.2984176  0.444613  ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.14, 0.12, 0.034, 0.1352, 0.13723, 0.6, 0.65, 0, 0.0886, 0.304, 0.8130000000000001]
Reward 4.059948807071193
Current State [[0.14    0.12    0.034   0.1352  0.13723 0.6     0.65    0.      0.0886
  0.304   0.813  ]]
Logits tf.Tensor([[-0.26713532 -0.13647118  0.09718731]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.279398   0.3183978  0.40220425]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.07, 0.032, 0.15, 0.13723, 0.6, 0.65, 0, 0.0886, 0.304, 0.8130000000000001]
Reward 4.059948807071193
Current State [[0.06    0.07    0.032   0.15    0.13723 0.6     0.65    0.      0.0886
  0.304   0.813  ]]
Logits tf.Tensor([[-0.2619832  -0.16242109  0.10565878]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2817686  0.31126612 0.40696535]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.07, 0.027, 0.1212, 0.13723, 0.6, 0.32, 0, 0.3579, 0.24500000000000002, 1.704]
Reward 3.8245340868813362
Current State [[0.05    0.07    0.027   0.1212  0.13723 0.6     0.32    0.      0.3579
  0.245   1.704  ]]
Logits tf.Tensor([[-0.3200911  -0.3724946   0.13179216]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.28407362 0.2695705  0.44635594]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.07, 0.026, 0.14909999999999998, 0.13723, 0.6, 0.64, 0, 0.0063, 0.284, 1.292]
Reward 9.24799767997089
Current State [[0.05    0.07    0.026   0.1491  0.13723 0.6     0.64    0.      0.0063
  0.284   1.292  ]]
Logits tf.Tensor([[-0.3672538  -0.22153687  0.11132896]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26520595 0.3068085  0.42798558]], shape=(1, 3), dtype=float32)
Selected action 1
[0.17, 0.12, 0.034, 0.1725, 0.13723, 0.6, 0.64, 0, 0.0063, 0.284, 1.292]
Reward 9.24799767997089
Current State [[0.17    0.12    0.034   0.1725  0.13723 0.6     0.64    0.      0.0063
  0.284   1.292  ]]
Logits tf.Tensor([[-0.37592852 -0.18135378  0.09640045]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26188165 0.31813228 0.41998607]], shape=(1, 3), dtype=float32)
Selected action 1
[0.12, 0.12, 0.035, 0.16540000000000002, 0.13723, 0.6, 0.67, 0, 0.0116, 0.321, 2.505]
Reward 6.39276068407796
Current State [[0.12    0.12    0.035   0.1654  0.13723 0.6     0.67    0.      0.0116
  0.321   2.505  ]]
Logits tf.Tensor([[-0.576025   -0.4746021   0.11475381]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24378271 0.2698052  0.48641208]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.07, 0.032, 0.1226, 0.13723, 0.6, 0.77, 0, 0.0564, 0.273, 1.89]
Reward 4.300827455972808
Current State [[0.04    0.07    0.032   0.1226  0.13723 0.6     0.77    0.      0.0564
  0.273   1.89   ]]
Logits tf.Tensor([[-0.45843598 -0.34840983  0.12322187]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25606167 0.28584352 0.45809484]], shape=(1, 3), dtype=float32)
Selected action 1
[0.15, 0.12, 0.036, 0.13269999999999998, 0.13723, 0.6, 0.68, 0, 0.0124, 0.279, 1.654]
Reward 6.20719825555546
Current State [[0.15    0.12    0.036   0.1327  0.13723 0.6     0.68    0.      0.0124
  0.279   1.654  ]]
Logits tf.Tensor([[-0.42760897 -0.2605253   0.10968493]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25685662 0.3035668  0.4395766 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.07, 0.033, 0.1346, 0.13723, 0.6, 0.68, 0, 0.0124, 0.279, 1.654]
Reward 6.20719825555546
Current State [[0.04    0.07    0.033   0.1346  0.13723 0.6     0.68    0.      0.0124
  0.279   1.654  ]]
Logits tf.Tensor([[-0.4266956  -0.29265285  0.11724339]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25865048 0.29575175 0.44559777]], shape=(1, 3), dtype=float32)
Selected action 1
[0.11, 0.12, 0.033, 0.1509, 0.13723, 0.6, 0.66, 0, 0.0097, 0.284, 1.532]
Reward 6.957110248405912
Current State [[0.11    0.12    0.033   0.1509  0.13723 0.6     0.66    0.      0.0097
  0.284   1.532  ]]
Logits tf.Tensor([[-0.4040561  -0.24041507  0.10735695]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26004845 0.30628282 0.43366873]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.07, 0.035, 0.134, 0.13723, 0.6, 0.77, 0, 0.0025, 0.302, 1.83]
Reward 32.57697396454173
Current State [[0.08    0.07    0.035   0.134   0.13723 0.6     0.77    0.      0.0025
  0.302   1.83   ]]
Logits tf.Tensor([[-0.47516093 -0.3214125   0.11224484]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25217426 0.29408497 0.45374078]], shape=(1, 3), dtype=float32)
Selected action 1
[0.16, 0.12, 0.034, 0.15380000000000002, 0.13723, 0.6, 0.77, 0, 0.0025, 0.302, 1.83]
Reward 32.57697396454173
Current State [[0.16    0.12    0.034   0.1538  0.13723 0.6     0.77    0.      0.0025
  0.302   1.83   ]]
Logits tf.Tensor([[-0.47266063 -0.29245472  0.10550603]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25124168 0.3008529  0.4479054 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.07, 0.032, 0.144, 0.13723, 0.6, 0.73, 0, 0.0022, 0.261, 2.105]
Reward 34.442170929659454
Current State [[0.08    0.07    0.032   0.144   0.13723 0.6     0.73    0.      0.0022
  0.261   2.105  ]]
Logits tf.Tensor([[-0.5073888  -0.38313252  0.11879499]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24982734 0.282881   0.4672917 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.07, 0.032, 0.1191, 0.13723, 0.6, 0.5, 0, 0.0653, 0.253, 1.611]
Reward 4.072430437746408
Current State [[0.07    0.07    0.032   0.1191  0.13723 0.6     0.5     0.      0.0653
  0.253   1.611  ]]
Logits tf.Tensor([[-0.39552853 -0.29781324  0.12584528]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26406202 0.2911677  0.44477025]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.07, 0.032, 0.12079999999999999, 0.13723, 0.6, 0.5, 0, 0.0653, 0.253, 1.611]
Reward 4.072430437746408
Current State [[0.08    0.07    0.032   0.1208  0.13723 0.6     0.5     0.      0.0653
  0.253   1.611  ]]
Logits tf.Tensor([[-0.3965444  -0.2954267   0.12443058]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.263847   0.29192215 0.44423088]], shape=(1, 3), dtype=float32)
Selected action 0
[0.22, 0.2, 0.032, 0.2196, 0.13723, 0.6, 0.79, 0, 0.0025, 0.344, 0.521]
Reward 33.186206479083246
Current State [[0.22    0.2     0.032   0.2196  0.13723 0.6     0.79    0.      0.0025
  0.344   0.521  ]]
Logits tf.Tensor([[-0.23235169 -0.0849606   0.04214246]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.28779694 0.33350113 0.3787019 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.1, 0.12, 0.033, 0.16119999999999998, 0.13723, 0.6, 0.85, 0, 0.0060999999999999995, 0.32799999999999996, 1.939]
Reward 12.337198701617398
Episode: 5 | Average Reward: 230 | Episode Reward: 240 | Loss: 650.542 | Steps: 19 | Worker: 0
Current State [[ 0.00435876 -0.00364709 -0.00627942  0.00177618  0.00122998 -0.00426864
  -0.00470136 -0.00538803  0.00863925 -0.00544763 -0.00991181]]
Logits tf.Tensor([[-0.0014188   0.00298392 -0.01021063]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.33381635 0.3352893  0.33089438]], shape=(1, 3), dtype=float32)
Selected action 1
[0.15, 0.12, 0.032, 0.1352, 0.13723, 0.6, 0.74, 0, 0.0012, 0.294, 1.957]
Reward 48.84178445202247
Current State [[1.5000e-01 1.2000e-01 3.2000e-02 1.3520e-01 1.3723e-01 6.0000e-01
  7.4000e-01 0.0000e+00 1.2000e-03 2.9400e-01 1.9570e+00]]
Logits tf.Tensor([[-0.49785632 -0.30824113  0.10712969]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24752407 0.29920325 0.45327264]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.07, 0.032, 0.1404, 0.13723, 0.6, 0.74, 0, 0.0012, 0.294, 1.957]
Reward 48.84178445202247
Current State [[7.0000e-02 7.0000e-02 3.2000e-02 1.4040e-01 1.3723e-01 6.0000e-01
  7.4000e-01 0.0000e+00 1.2000e-03 2.9400e-01 1.9570e+00]]
Logits tf.Tensor([[-0.5067598  -0.33702523  0.10951923]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24770781 0.29353136 0.4587608 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.21, 0.2, 0.028, 0.226, 0.13723, 0.6, 0.59, 0, 0.011699999999999999, 0.273, 1.267]
Reward 5.969536293309493
Current State [[0.21    0.2     0.028   0.226   0.13723 0.6     0.59    0.      0.0117
  0.273   1.267  ]]
Logits tf.Tensor([[-0.359651   -0.1339761   0.07545458]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26327607 0.3299292  0.40679476]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.07, 0.033, 0.1347, 0.13723, 0.6, 0.62, 0, 0.8782, 0.3, 2.098]
Reward 3.8176340785336134
Current State [[0.05    0.07    0.033   0.1347  0.13723 0.6     0.62    0.      0.8782
  0.3     2.098  ]]
Logits tf.Tensor([[-0.28623945 -0.5084021   0.15188093]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2984561  0.23899917 0.4625447 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.07, 0.037, 0.1125, 0.13723, 0.6, 0.46, 0, 0.018799999999999997, 0.271, 1.141]
Reward 4.742962736873545
Current State [[0.06    0.07    0.037   0.1125  0.13723 0.6     0.46    0.      0.0188
  0.271   1.141  ]]
Logits tf.Tensor([[-0.33573496 -0.19020538  0.11279841]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26862472 0.31070527 0.42067   ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.2, 0.2, 0.032, 0.198, 0.13723, 0.6, 0.46, 0, 0.018799999999999997, 0.271, 1.141]
Reward 4.742962736873545
Current State [[0.2     0.2     0.032   0.198   0.13723 0.6     0.46    0.      0.0188
  0.271   1.141  ]]
Logits tf.Tensor([[-0.3181052  -0.12693454  0.08087295]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.27019963 0.32712153 0.4026788 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.1, 0.12, 0.032, 0.1731, 0.13723, 0.6, 0.83, 0, 0.0012, 0.339, 1.6199999999999999]
Reward 49.289965023085884
Current State [[1.0000e-01 1.2000e-01 3.2000e-02 1.7310e-01 1.3723e-01 6.0000e-01
  8.3000e-01 0.0000e+00 1.2000e-03 3.3900e-01 1.6200e+00]]
Logits tf.Tensor([[-0.45159602 -0.2402687   0.09457981]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2524007 0.3117948 0.4358045]], shape=(1, 3), dtype=float32)
Selected action 1
[0.14, 0.12, 0.022, 0.1585, 0.13723, 0.6, 0.78, 0, 0.010700000000000001, 0.306, 1.465]
Reward 7.3066241299305945
Current State [[0.14    0.12    0.022   0.1585  0.13723 0.6     0.78    0.      0.0107
  0.306   1.465  ]]
Logits tf.Tensor([[-0.4257676  -0.2042959   0.09373458]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2545111  0.31760737 0.42788157]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.07, 0.042, 0.12940000000000002, 0.13723, 0.6, 0.89, 0, 0.0012, 0.319, 0.40099999999999997]
Reward 49.53648153988808
Current State [[0.07    0.07    0.042   0.1294  0.13723 0.6     0.89    0.      0.0012
  0.319   0.401  ]]
Logits tf.Tensor([[-0.21228138 -0.1178138   0.05790077]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29331735 0.32237732 0.38430527]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.07, 0.032, 0.1352, 0.13723, 0.6, 0.89, 0, 0.0012, 0.319, 0.40099999999999997]
Reward 49.53648153988808
Current State [[0.07    0.07    0.032   0.1352  0.13723 0.6     0.89    0.      0.0012
  0.319   0.401  ]]
Logits tf.Tensor([[-0.21414939 -0.11993343  0.05646288]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29329264 0.3222691  0.38443825]], shape=(1, 3), dtype=float32)
Selected action 0
[0.21, 0.2, 0.028, 0.175, 0.13723, 0.6, 0.47, 0, 0.056100000000000004, 0.265, 1.75]
Reward 4.097900454058753
Current State [[0.21    0.2     0.028   0.175   0.13723 0.6     0.47    0.      0.0561
  0.265   1.75   ]]
Logits tf.Tensor([[-0.4067338  -0.254486    0.10070322]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2614053  0.30439305 0.43420163]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.07, 0.031, 0.1143, 0.13723, 0.6, 0.83, 0, 0.0096, 0.316, 2.355]
Reward 8.147729249074438
Current State [[0.07    0.07    0.031   0.1143  0.13723 0.6     0.83    0.      0.0096
  0.316   2.355  ]]
Logits tf.Tensor([[-0.5798804  -0.43062836  0.11712688]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23988289 0.27849576 0.4816213 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.12, 0.12, 0.03, 0.14909999999999998, 0.13723, 0.6, 0.53, 0, 0.3166, 0.304, 1.144]
Reward 3.8525595412073343
Current State [[0.12    0.12    0.03    0.1491  0.13723 0.6     0.53    0.      0.3166
  0.304   1.144  ]]
Logits tf.Tensor([[-0.25911677 -0.2001688   0.10528381]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.28568402 0.30303076 0.41128522]], shape=(1, 3), dtype=float32)
Selected action 0
[0.21, 0.2, 0.027, 0.2039, 0.13723, 0.6, 0.53, 0, 0.3166, 0.304, 1.144]
Reward 3.8525595412073343
Current State [[0.21    0.2     0.027   0.2039  0.13723 0.6     0.53    0.      0.3166
  0.304   1.144  ]]
Logits tf.Tensor([[-0.25632095 -0.16760483  0.08542061]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.28570068 0.31220523 0.40209413]], shape=(1, 3), dtype=float32)
Selected action 1
[0.14, 0.12, 0.03, 0.15, 0.13723, 0.6, 0.86, 0, 0.0025, 0.378, 0.741]
Reward 36.72003897065202
Current State [[0.14    0.12    0.03    0.15    0.13723 0.6     0.86    0.      0.0025
  0.378   0.741  ]]
Logits tf.Tensor([[-0.2867161  -0.13100049  0.06721671]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.27830708 0.3252001  0.3964928 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.14, 0.12, 0.03, 0.15380000000000002, 0.13723, 0.6, 0.82, 0, 0.0022, 0.286, 2.0829999999999997]
Reward 38.0249617385366
Current State [[0.14    0.12    0.03    0.1538  0.13723 0.6     0.82    0.      0.0022
  0.286   2.083  ]]
Logits tf.Tensor([[-0.5207137  -0.33096266  0.10637814]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24503158 0.29623058 0.45873785]], shape=(1, 3), dtype=float32)
Selected action 0
[0.12, 0.2, 0.024, 0.15630000000000002, 0.13723, 0.6, 0.64, 0, 0.0207, 0.388, 0.7889999999999999]
Reward 5.033352389162983
Current State [[0.12    0.2     0.024   0.1563  0.13723 0.6     0.64    0.      0.0207
  0.388   0.789  ]]
Logits tf.Tensor([[-0.2679798  -0.12599567  0.08420375]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2797416  0.3224185  0.39783993]], shape=(1, 3), dtype=float32)
Selected action 1
[0.11, 0.12, 0.032, 0.1412, 0.13723, 0.6, 0.67, 0, 0.0115, 0.399, 0.844]
Reward 6.378917895601418
Current State [[0.11    0.12    0.032   0.1412  0.13723 0.6     0.67    0.      0.0115
  0.399   0.844  ]]
Logits tf.Tensor([[-0.29793203 -0.14473099  0.09070207]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.27468574 0.3201625  0.40515178]], shape=(1, 3), dtype=float32)
Selected action 2
[0.11, 0.07, 0.033, 0.138, 0.13723, 0.6, 0.67, 0, 0.0115, 0.399, 0.844]
Reward 6.378917895601418
Current State [[0.11    0.07    0.033   0.138   0.13723 0.6     0.67    0.      0.0115
  0.399   0.844  ]]
Logits tf.Tensor([[-0.30886117 -0.1514712   0.09428191]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.27270448 0.31918752 0.40810803]], shape=(1, 3), dtype=float32)
Selected action 1
[0.09, 0.12, 0.027, 0.154, 0.13723, 0.6, 0.58, 0, 0.0085, 0.275, 1.399]
Reward 6.99087053937979
Episode: 6 | Average Reward: 232 | Episode Reward: 392 | Loss: 1019.141 | Steps: 19 | Worker: 0
Saving best model to ./Training/, episode score: 392.1040251969098
Current State [[-0.00142257 -0.0063048  -0.00481516 -0.00367632 -0.00850925 -0.0072052
   0.00896424  0.00666592  0.00050026  0.00022236  0.00047599]]
Logits tf.Tensor([[-0.00386369  0.0017301  -0.01302181]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.33372343 0.33559543 0.3306811 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.12, 0.2, 0.023, 0.1646, 0.13723, 0.6, 0.74, 0, 0.0667, 0.316, 1.489]
Reward 4.20250315841886
Current State [[0.12    0.2     0.023   0.1646  0.13723 0.6     0.74    0.      0.0667
  0.316   1.489  ]]
Logits tf.Tensor([[-0.3987685  -0.1893145   0.08581015]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25930277 0.31972152 0.4209757 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.06, 0.12, 0.021, 0.1585, 0.13723, 0.6, 0.81, 0, 0.0014000000000000002, 0.353, 0.852]
Reward 48.34722377095923
Current State [[0.06    0.12    0.021   0.1585  0.13723 0.6     0.81    0.      0.0014
  0.353   0.852  ]]
Logits tf.Tensor([[-0.30244347 -0.14301479  0.07578211]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.27529    0.3228713  0.40183866]], shape=(1, 3), dtype=float32)
Selected action 0
[0.09, 0.2, 0.024, 0.1667, 0.13723, 0.6, 0.82, 0, 0.0038, 0.348, 0.134]
Reward 20.494773219662584
Current State [[0.09    0.2     0.024   0.1667  0.13723 0.6     0.82    0.      0.0038
  0.348   0.134  ]]
Logits tf.Tensor([[-0.13090988 -0.09101936  0.0165733 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.31253803 0.32525733 0.36220464]], shape=(1, 3), dtype=float32)
Selected action 0
[0.12, 0.2, 0.025, 0.188, 0.13723, 0.6, 0.78, 0, 0.0028000000000000004, 0.343, 0.7070000000000001]
Reward 28.39766475554261
Current State [[0.12    0.2     0.025   0.188   0.13723 0.6     0.78    0.      0.0028
  0.343   0.707  ]]
Logits tf.Tensor([[-0.2624949  -0.09859152  0.05714709]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2813149 0.3314172 0.3872679]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.07, 0.032, 0.1286, 0.13723, 0.6, 0.79, 0, 0.005699999999999999, 0.33999999999999997, 1.133]
Reward 12.231638043059762
Current State [[0.08    0.07    0.032   0.1286  0.13723 0.6     0.79    0.      0.0057
  0.34    1.133  ]]
Logits tf.Tensor([[-0.37582976 -0.17433795  0.09799901]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26114035 0.31943375 0.41942587]], shape=(1, 3), dtype=float32)
Selected action 0
[0.16, 0.2, 0.024, 0.19219999999999998, 0.13723, 0.6, 0.79, 0, 0.005699999999999999, 0.33999999999999997, 1.133]
Reward 12.231638043059762
Current State [[0.16    0.2     0.024   0.1922  0.13723 0.6     0.79    0.      0.0057
  0.34    1.133  ]]
Logits tf.Tensor([[-0.36698607 -0.12836084  0.07558064]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2613559  0.33179197 0.40685207]], shape=(1, 3), dtype=float32)
Selected action 1
[0.1, 0.12, 0.028, 0.14709999999999998, 0.13723, 0.6, 0.68, 0, 0.0078000000000000005, 0.308, 0.732]
Reward 8.20093854400689
Current State [[0.1     0.12    0.028   0.1471  0.13723 0.6     0.68    0.      0.0078
  0.308   0.732  ]]
Logits tf.Tensor([[-0.27301383 -0.10642025  0.07582241]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.27787882 0.328251   0.39387015]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.07, 0.029, 0.1469, 0.13723, 0.6, 0.67, 0, 0.0576, 0.319, 1.9440000000000002]
Reward 4.2224257354497965
Current State [[0.08    0.07    0.029   0.1469  0.13723 0.6     0.67    0.      0.0576
  0.319   1.944  ]]
Logits tf.Tensor([[-0.5123043  -0.32961985  0.1036    ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.246806   0.2962747  0.45691934]], shape=(1, 3), dtype=float32)
Selected action 1
[0.11, 0.12, 0.028, 0.1388, 0.13723, 0.6, 0.63, 0, 0.0083, 0.254, 0.75]
Reward 7.459999329154164
Current State [[0.11    0.12    0.028   0.1388  0.13723 0.6     0.63    0.      0.0083
  0.254   0.75   ]]
Logits tf.Tensor([[-0.27150103 -0.09537221  0.08061785]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2766505  0.32993105 0.39341843]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.07, 0.032, 0.1373, 0.13723, 0.6, 0.7, 0, 0.0202, 0.284, 1.098]
Reward 5.193514609684477
Current State [[0.07    0.07    0.032   0.1373  0.13723 0.6     0.7     0.      0.0202
  0.284   1.098  ]]
Logits tf.Tensor([[-0.3507345  -0.16128944  0.10080388]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26459888 0.31978858 0.41561255]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.07, 0.032, 0.1472, 0.13723, 0.6, 0.7, 0, 0.0202, 0.284, 1.098]
Reward 5.193514609684477
Current State [[0.08    0.07    0.032   0.1472  0.13723 0.6     0.7     0.      0.0202
  0.284   1.098  ]]
Logits tf.Tensor([[-0.35311213 -0.15815873  0.09820369]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2641567  0.32101756 0.41482568]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.07, 0.027, 0.1321, 0.13723, 0.6, 0.7, 0, 0.0058, 0.294, 1.409]
Reward 10.71075271553487
Current State [[0.05    0.07    0.027   0.1321  0.13723 0.6     0.7     0.      0.0058
  0.294   1.409  ]]
Logits tf.Tensor([[-0.41424724 -0.21297859  0.09991547]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2567268  0.31396487 0.42930827]], shape=(1, 3), dtype=float32)
Selected action 1
[0.11, 0.12, 0.027, 0.138, 0.13723, 0.6, 0.71, 0, 0.0069, 0.29100000000000004, 1.2289999999999999]
Reward 9.412126226255275
Current State [[0.11    0.12    0.027   0.138   0.13723 0.6     0.71    0.      0.0069
  0.291   1.229  ]]
Logits tf.Tensor([[-0.381832   -0.16215464  0.09344034]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25946212 0.32320544 0.41733244]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.07, 0.023, 0.1362, 0.13723, 0.6, 0.71, 0, 0.0069, 0.29100000000000004, 1.2289999999999999]
Reward 9.412126226255275
Current State [[0.06    0.07    0.023   0.1362  0.13723 0.6     0.71    0.      0.0069
  0.291   1.229  ]]
Logits tf.Tensor([[-0.38371053 -0.18523984  0.10027979]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2602762  0.31741628 0.4223075 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.17, 0.12, 0.027, 0.1529, 0.13723, 0.6, 0.46, 0, 0.3626, 0.23700000000000002, 1.17]
Reward 3.837606700841931
Current State [[0.17    0.12    0.027   0.1529  0.13723 0.6     0.46    0.      0.3626
  0.237   1.17   ]]
Logits tf.Tensor([[-0.25108054 -0.18668765  0.09399556]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.28747126 0.30659136 0.4059374 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.07, 0.028, 0.1415, 0.13723, 0.6, 0.6, 0, 0.0072, 0.33599999999999997, 1.182]
Reward 7.936714381758718
Current State [[0.07    0.07    0.028   0.1415  0.13723 0.6     0.6     0.      0.0072
  0.336   1.182  ]]
Logits tf.Tensor([[-0.37447545 -0.18440136  0.09594689]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26246655 0.31741107 0.42012236]], shape=(1, 3), dtype=float32)
Selected action 1
[0.1, 0.12, 0.032, 0.1354, 0.13723, 0.6, 0.68, 0, 0.008100000000000001, 0.28900000000000003, 1.6649999999999998]
Reward 7.991440987566037
Current State [[0.1     0.12    0.032   0.1354  0.13723 0.6     0.68    0.      0.0081
  0.289   1.665  ]]
Logits tf.Tensor([[-0.4475208  -0.23990141  0.09816958]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2527458  0.31106555 0.43618858]], shape=(1, 3), dtype=float32)
Selected action 1
[0.13, 0.12, 0.027, 0.15280000000000002, 0.13723, 0.6, 0.62, 0, 0.09269999999999999, 0.357, 1.351]
Reward 4.033618840703805
Current State [[0.13    0.12    0.027   0.1528  0.13723 0.6     0.62    0.      0.0927
  0.357   1.351  ]]
Logits tf.Tensor([[-0.39106742 -0.19762945  0.09208978]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26078346 0.31643835 0.42277816]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.07, 0.026, 0.16040000000000001, 0.13723, 0.6, 0.62, 0, 0.09269999999999999, 0.357, 1.351]
Reward 4.033618840703805
Current State [[0.04    0.07    0.026   0.1604  0.13723 0.6     0.62    0.      0.0927
  0.357   1.351  ]]
Logits tf.Tensor([[-0.38731897 -0.22774774  0.09977304]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26311746 0.30863884 0.42824376]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.07, 0.025, 0.117, 0.13723, 0.6, 0.66, 0, 0.0512, 0.371, 0.529]
Reward 4.27336273484095
Episode: 7 | Average Reward: 232 | Episode Reward: 217 | Loss: 248.465 | Steps: 19 | Worker: 0
Current State [[-0.00180222  0.00372808 -0.00633726 -0.00711447  0.00065463 -0.00847792
   0.00392585  0.00542247 -0.00362608 -0.00516095 -0.00469915]]
Logits tf.Tensor([[ 0.00030493  0.00498425 -0.01450579]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.33444944 0.3360181  0.32953247]], shape=(1, 3), dtype=float32)
Selected action 1
[0.11, 0.12, 0.034, 0.128, 0.13723, 0.6, 0.59, 0, 0.0064, 0.355, 1.045]
Reward 8.57912865224649
Current State [[0.11    0.12    0.034   0.128   0.13723 0.6     0.59    0.      0.0064
  0.355   1.045  ]]
Logits tf.Tensor([[-0.35480702 -0.1356252   0.08612221]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26321274 0.327715   0.40907225]], shape=(1, 3), dtype=float32)
Selected action 0
[0.26, 0.2, 0.027, 0.2333, 0.13723, 0.6, 0.59, 0, 0.0064, 0.355, 1.045]
Reward 8.57912865224649
Current State [[0.26    0.2     0.027   0.2333  0.13723 0.6     0.59    0.      0.0064
  0.355   1.045  ]]
Logits tf.Tensor([[-0.37172696 -0.08079048  0.05467476]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25843698 0.34570587 0.3958572 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.2, 0.2, 0.03, 0.2077, 0.13723, 0.6, 0.62, 0, 0.0506, 0.374, 1.67]
Reward 4.245929357574874
Current State [[0.2     0.2     0.03    0.2077  0.13723 0.6     0.62    0.      0.0506
  0.374   1.67   ]]
Logits tf.Tensor([[-0.46192122 -0.19839324  0.06924235]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2498486  0.3251814  0.42497006]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.07, 0.034, 0.1264, 0.13723, 0.6, 0.75, 0, 0.0165, 0.493, 1.248]
Reward 5.7391836358896615
Current State [[0.06    0.07    0.034   0.1264  0.13723 0.6     0.75    0.      0.0165
  0.493   1.248  ]]
Logits tf.Tensor([[-0.42304388 -0.21093917  0.08851288]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25613686 0.31665617 0.42720696]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.07, 0.028, 0.1442, 0.13723, 0.6, 0.39, 0, 0.1157, 0.248, 1.702]
Reward 3.911339033842461
Current State [[0.05    0.07    0.028   0.1442  0.13723 0.6     0.39    0.      0.1157
  0.248   1.702  ]]
Logits tf.Tensor([[-0.4244161 -0.2922164  0.1111247]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25975996 0.29647347 0.4437666 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.21, 0.2, 0.027, 0.19619999999999999, 0.13723, 0.6, 0.39, 0, 0.1157, 0.248, 1.702]
Reward 3.911339033842461
Current State [[0.21    0.2     0.027   0.1962  0.13723 0.6     0.39    0.      0.1157
  0.248   1.702  ]]
Logits tf.Tensor([[-0.39694443 -0.22255187  0.08433   ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26255968 0.3125833  0.42485705]], shape=(1, 3), dtype=float32)
Selected action 1
[0.07, 0.12, 0.034, 0.1388, 0.13723, 0.6, 0.78, 0, 0.0784, 0.433, 1.424]
Reward 4.1545405225607945
Current State [[0.07    0.12    0.034   0.1388  0.13723 0.6     0.78    0.      0.0784
  0.433   1.424  ]]
Logits tf.Tensor([[-0.4291468  -0.21583515  0.08942224]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25527182 0.3159679  0.42876026]], shape=(1, 3), dtype=float32)
Selected action 0
[0.16, 0.2, 0.03, 0.1904, 0.13723, 0.6, 0.59, 0, 0.1678, 0.3, 2.08]
Reward 3.917027263610688
Current State [[0.16    0.2     0.03    0.1904  0.13723 0.6     0.59    0.      0.1678
  0.3     2.08   ]]
Logits tf.Tensor([[-0.4846576  -0.30832538  0.09867532]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2509514  0.29934344 0.44970518]], shape=(1, 3), dtype=float32)
Selected action 1
[0.06, 0.12, 0.033, 0.1389, 0.13723, 0.6, 0.71, 0, 0.1387, 0.33399999999999996, 1.512]
Reward 3.975628431754303
Current State [[0.06    0.12    0.033   0.1389  0.13723 0.6     0.71    0.      0.1387
  0.334   1.512  ]]
Logits tf.Tensor([[-0.40636575 -0.22040148  0.09610355]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25925696 0.31224376 0.42849928]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.07, 0.036, 0.1148, 0.13723, 0.6, 0.75, 0, 0.0014000000000000002, 0.277, 1.8359999999999999]
Reward 47.20310055292265
Current State [[8.0000e-02 7.0000e-02 3.6000e-02 1.1480e-01 1.3723e-01 6.0000e-01
  7.5000e-01 0.0000e+00 1.4000e-03 2.7700e-01 1.8360e+00]]
Logits tf.Tensor([[-0.5049752  -0.2691106   0.10088773]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2439717  0.30886889 0.44715944]], shape=(1, 3), dtype=float32)
Selected action 0
[0.22, 0.2, 0.03, 0.18869999999999998, 0.13723, 0.6, 0.75, 0, 0.0014000000000000002, 0.277, 1.8359999999999999]
Reward 47.20310055292265
Current State [[2.2000e-01 2.0000e-01 3.0000e-02 1.8870e-01 1.3723e-01 6.0000e-01
  7.5000e-01 0.0000e+00 1.4000e-03 2.7700e-01 1.8360e+00]]
Logits tf.Tensor([[-0.49006182 -0.20395541  0.07694732]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24424674 0.3251496  0.43060365]], shape=(1, 3), dtype=float32)
Selected action 1
[0.07, 0.12, 0.033, 0.1551, 0.13723, 0.6, 0.84, 0, 0.009899999999999999, 0.32599999999999996, 1.8969999999999998]
Reward 8.048251431215151
Current State [[0.07    0.12    0.033   0.1551  0.13723 0.6     0.84    0.      0.0099
  0.326   1.897  ]]
Logits tf.Tensor([[-0.51558506 -0.26678303  0.08573499]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24348591 0.3122678  0.44424632]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.07, 0.031, 0.1288, 0.13723, 0.6, 0.79, 0, 0.0029, 0.29, 1.636]
Reward 28.2971879214062
Current State [[0.08    0.07    0.031   0.1288  0.13723 0.6     0.79    0.      0.0029
  0.29    1.636  ]]
Logits tf.Tensor([[-0.479917   -0.22317348  0.09047125]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24620432 0.31827164 0.43552405]], shape=(1, 3), dtype=float32)
Selected action 0
[0.19, 0.2, 0.031, 0.1623, 0.13723, 0.6, 0.68, 0, 0.006500000000000001, 0.264, 1.4380000000000002]
Reward 9.505519694930998
Current State [[0.19    0.2     0.031   0.1623  0.13723 0.6     0.68    0.      0.0065
  0.264   1.438  ]]
Logits tf.Tensor([[-0.41072735 -0.13778578  0.07838207]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25350556 0.33306158 0.4134329 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.13, 0.12, 0.033, 0.16119999999999998, 0.13723, 0.6, 0.68, 0, 0.006500000000000001, 0.264, 1.4380000000000002]
Reward 9.505519694930998
Current State [[0.13    0.12    0.033   0.1612  0.13723 0.6     0.68    0.      0.0065
  0.264   1.438  ]]
Logits tf.Tensor([[-0.4228589  -0.16167164  0.08435408]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2525809  0.32796893 0.4194501 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.09, 0.07, 0.033, 0.1216, 0.13723, 0.6, 0.57, 0, 0.0033, 0.34900000000000003, 1.482]
Reward 15.807459038392057
Current State [[0.09    0.07    0.033   0.1216  0.13723 0.6     0.57    0.      0.0033
  0.349   1.482  ]]
Logits tf.Tensor([[-0.45101747 -0.22035101  0.09228707]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2511852  0.31635252 0.4324623 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.14, 0.2, 0.024, 0.1926, 0.13723, 0.6, 0.57, 0, 0.004699999999999999, 0.258, 1.4300000000000002]
Reward 10.983352373820438
Current State [[0.14    0.2     0.024   0.1926  0.13723 0.6     0.57    0.      0.0047
  0.258   1.43   ]]
Logits tf.Tensor([[-0.38834062 -0.14873737  0.07971554]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25855616 0.3285589  0.41288498]], shape=(1, 3), dtype=float32)
Selected action 0
[0.18, 0.2, 0.026, 0.1784, 0.13723, 0.6, 0.88, 0, 0.0019, 0.378, 0.489]
Reward 44.348095482322684
Current State [[0.18    0.2     0.026   0.1784  0.13723 0.6     0.88    0.      0.0019
  0.378   0.489  ]]
Logits tf.Tensor([[-0.24701725 -0.07110641  0.0269691 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.28510103 0.339935   0.37496397]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.07, 0.032, 0.1333, 0.13723, 0.6, 0.73, 0, 0.08839999999999999, 0.274, 0.994]
Reward 4.092130163318153
Current State [[0.07    0.07    0.032   0.1333  0.13723 0.6     0.73    0.      0.0884
  0.274   0.994  ]]
Logits tf.Tensor([[-0.3246527  -0.13905254  0.09580257]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26834145 0.32306722 0.40859136]], shape=(1, 3), dtype=float32)
Selected action 0
[0.22, 0.2, 0.028, 0.2038, 0.13723, 0.6, 0.73, 0, 0.08839999999999999, 0.274, 0.994]
Reward 4.092130163318153
Episode: 8 | Average Reward: 232 | Episode Reward: 276 | Loss: 832.944 | Steps: 19 | Worker: 0
Current State [[-0.00810271 -0.00885155  0.00722532 -0.00670646  0.00731515  0.00099186
  -0.00455348  0.00973863 -0.00926011 -0.00115144 -0.00124835]]
Logits tf.Tensor([[-0.00186434  0.00830664 -0.0069913 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.33276662 0.33616847 0.3310649 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.15, 0.12, 0.03, 0.1469, 0.13723, 0.6, 0.86, 0, 0.0195, 0.29100000000000004, 1.47]
Reward 5.65665200589083
Current State [[0.15    0.12    0.03    0.1469  0.13723 0.6     0.86    0.      0.0195
  0.291   1.47   ]]
Logits tf.Tensor([[-0.451791   -0.16087666  0.07071424]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24851532 0.33242652 0.41905814]], shape=(1, 3), dtype=float32)
Selected action 0
[0.21, 0.2, 0.031, 0.198, 0.13723, 0.6, 0.71, 0, 0.0018, 0.357, 0.994]
Reward 41.39673287529666
Current State [[0.21    0.2     0.031   0.198   0.13723 0.6     0.71    0.      0.0018
  0.357   0.994  ]]
Logits tf.Tensor([[-0.3558113  -0.0792816   0.05427715]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26140395 0.34467316 0.39392295]], shape=(1, 3), dtype=float32)
Selected action 1
[0.06, 0.12, 0.033, 0.15280000000000002, 0.13723, 0.6, 0.86, 0, 0.0022, 0.354, 1.5699999999999998]
Reward 40.40248149813962
Current State [[0.06    0.12    0.033   0.1528  0.13723 0.6     0.86    0.      0.0022
  0.354   1.57   ]]
Logits tf.Tensor([[-0.46189982 -0.20582226  0.07497186]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24984384 0.3227615  0.42739463]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.07, 0.039, 0.1173, 0.13723, 0.6, 0.79, 0, 0.0526, 0.29300000000000004, 2.3489999999999998]
Reward 4.357696770163517
Current State [[0.07    0.07    0.039   0.1173  0.13723 0.6     0.79    0.      0.0526
  0.293   2.349  ]]
Logits tf.Tensor([[-0.5916824  -0.38031426  0.09774829]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23652138 0.2921907  0.4712879 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.07, 0.031, 0.1358, 0.13723, 0.6, 0.79, 0, 0.0526, 0.29300000000000004, 2.3489999999999998]
Reward 4.357696770163517
Current State [[0.05    0.07    0.031   0.1358  0.13723 0.6     0.79    0.      0.0526
  0.293   2.349  ]]
Logits tf.Tensor([[-0.5918238  -0.38400963  0.09484807]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23707493 0.29183558 0.4710895 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.09, 0.2, 0.028, 0.1846, 0.13723, 0.6, 0.63, 0, 0.0128, 0.258, 1.826]
Reward 5.907096007272726
Current State [[0.09    0.2     0.028   0.1846  0.13723 0.6     0.63    0.      0.0128
  0.258   1.826  ]]
Logits tf.Tensor([[-0.44756377 -0.22669978  0.08264998]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25339234 0.3160192  0.43058845]], shape=(1, 3), dtype=float32)
Selected action 0
[0.23, 0.2, 0.027, 0.1918, 0.13723, 0.6, 0.88, 0, 0.0054, 0.348, 1.613]
Reward 14.86774321600707
Current State [[0.23    0.2     0.027   0.1918  0.13723 0.6     0.88    0.      0.0054
  0.348   1.613  ]]
Logits tf.Tensor([[-0.49216306 -0.14984857  0.05122689]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24212858 0.34096622 0.4169052 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.07, 0.037, 0.14809999999999998, 0.13723, 0.6, 0.76, 0, 0.0352, 0.35, 1.568]
Reward 4.625202127314271
Current State [[0.08    0.07    0.037   0.1481  0.13723 0.6     0.76    0.      0.0352
  0.35    1.568  ]]
Logits tf.Tensor([[-0.46836004 -0.21426797  0.08034115]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24873807 0.32069558 0.43056634]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.07, 0.038, 0.1377, 0.13723, 0.6, 0.76, 0, 0.0352, 0.35, 1.568]
Reward 4.625202127314271
Current State [[0.08    0.07    0.038   0.1377  0.13723 0.6     0.76    0.      0.0352
  0.35    1.568  ]]
Logits tf.Tensor([[-0.46774334 -0.21536818  0.08176245]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24878871 0.32021064 0.4310007 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.07, 0.036, 0.13019999999999998, 0.13723, 0.6, 0.56, 0, 0.013500000000000002, 0.257, 1.8850000000000002]
Reward 5.5314210693419446
Current State [[0.07    0.07    0.036   0.1302  0.13723 0.6     0.56    0.      0.0135
  0.257   1.885  ]]
Logits tf.Tensor([[-0.4977504  -0.28851786  0.09722528]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24717487 0.30470031 0.44812483]], shape=(1, 3), dtype=float32)
Selected action 1
[0.11, 0.12, 0.027, 0.168, 0.13723, 0.6, 0.63, 0, 0.042199999999999994, 0.31, 1.275]
Reward 4.349285209943423
Current State [[0.11    0.12    0.027   0.168   0.13723 0.6     0.63    0.      0.0422
  0.31    1.275  ]]
Logits tf.Tensor([[-0.38755172 -0.14728326  0.07442595]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25914788 0.32953003 0.4113221 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.07, 0.032, 0.1255, 0.13723, 0.6, 0.75, 0, 0.0052, 0.319, 1.238]
Reward 12.961532543248373
Current State [[0.08    0.07    0.032   0.1255  0.13723 0.6     0.75    0.      0.0052
  0.319   1.238  ]]
Logits tf.Tensor([[-0.40478706 -0.16263497  0.08398776]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25612748 0.32630333 0.41756916]], shape=(1, 3), dtype=float32)
Selected action 1
[0.11, 0.12, 0.03, 0.1784, 0.13723, 0.6, 0.75, 0, 0.0052, 0.319, 1.238]
Reward 12.961532543248373
Current State [[0.11    0.12    0.03    0.1784  0.13723 0.6     0.75    0.      0.0052
  0.319   1.238  ]]
Logits tf.Tensor([[-0.4030757  -0.14182316  0.07181715]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25599036 0.33241767 0.411592  ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.07, 0.12, 0.031, 0.156, 0.13723, 0.6, 0.71, 0, 0.0042, 0.3, 0.9369999999999999]
Reward 15.129198626626206
Current State [[0.07    0.12    0.031   0.156   0.13723 0.6     0.71    0.      0.0042
  0.3     0.937  ]]
Logits tf.Tensor([[-0.32091323 -0.1116746   0.07656661]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26875877 0.33130944 0.39993182]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.07, 0.031, 0.1472, 0.13723, 0.6, 0.57, 0, 0.0207, 0.369, 1.693]
Reward 4.887163719861903
Current State [[0.05    0.07    0.031   0.1472  0.13723 0.6     0.57    0.      0.0207
  0.369   1.693  ]]
Logits tf.Tensor([[-0.48895538 -0.26622587  0.08378565]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24859524 0.31061542 0.44078934]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.07, 0.032, 0.12940000000000002, 0.13723, 0.6, 0.5, 0, 0.0557, 0.29300000000000004, 1.309]
Reward 4.118949057698531
Current State [[0.06    0.07    0.032   0.1294  0.13723 0.6     0.5     0.      0.0557
  0.293   1.309  ]]
Logits tf.Tensor([[-0.38251817 -0.18808216  0.08960553]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26191574 0.31812963 0.4199546 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.07, 0.03, 0.1389, 0.13723, 0.6, 0.4, 0, 0.1009, 0.346, 1.3960000000000001]
Reward 3.9332097695289545
Current State [[0.03    0.07    0.03    0.1389  0.13723 0.6     0.4     0.      0.1009
  0.346   1.396  ]]
Logits tf.Tensor([[-0.38980904 -0.2405385   0.09561523]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26414138 0.3066647  0.42919388]], shape=(1, 3), dtype=float32)
Selected action 1
[0.11, 0.12, 0.027, 0.1585, 0.13723, 0.6, 0.4, 0, 0.1009, 0.346, 1.3960000000000001]
Reward 3.9332097695289545
Current State [[0.11    0.12    0.027   0.1585  0.13723 0.6     0.4     0.      0.1009
  0.346   1.396  ]]
Logits tf.Tensor([[-0.38338906 -0.2064358   0.07833347]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26452366 0.3157289  0.41974744]], shape=(1, 3), dtype=float32)
Selected action 1
[0.15, 0.12, 0.03, 0.14709999999999998, 0.13723, 0.6, 0.78, 0, 0.08220000000000001, 0.318, 0.10200000000000001]
Reward 4.13879768665677
Current State [[0.15    0.12    0.03    0.1471  0.13723 0.6     0.78    0.      0.0822
  0.318   0.102  ]]
Logits tf.Tensor([[-0.12067556 -0.0756259   0.02822745]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3118529  0.32622302 0.36192414]], shape=(1, 3), dtype=float32)
Selected action 1
[0.13, 0.12, 0.026, 0.154, 0.13723, 0.6, 0.79, 0, 0.0048, 0.33799999999999997, 1.163]
Reward 14.960240351797257
Episode: 9 | Average Reward: 232 | Episode Reward: 213 | Loss: 260.58 | Steps: 19 | Worker: 0
Current State [[ 0.00958289 -0.00696982 -0.00384502  0.0080346  -0.00940178  0.00980284
   0.00996047 -0.0095682   0.00473323 -0.00230526 -0.00658031]]
Logits tf.Tensor([[-0.00845165  0.00609743 -0.01602263]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.33254486 0.33741844 0.33003667]], shape=(1, 3), dtype=float32)
Selected action 2
[0.11, 0.07, 0.028, 0.1216, 0.13723, 0.6, 0.8, 0, 0.0021, 0.384, 0.642]
Reward 39.10955620264936
Current State [[0.11    0.07    0.028   0.1216  0.13723 0.6     0.8     0.      0.0021
  0.384   0.642  ]]
Logits tf.Tensor([[-0.28730097 -0.09418292  0.05041727]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.27664268 0.33557475 0.3877826 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.07, 0.033, 0.1373, 0.13723, 0.6, 0.8, 0, 0.0021, 0.384, 0.642]
Reward 39.10955620264936
Current State [[0.06    0.07    0.033   0.1373  0.13723 0.6     0.8     0.      0.0021
  0.384   0.642  ]]
Logits tf.Tensor([[-0.2769012  -0.1022405   0.05448258]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2790384  0.33229068 0.38867098]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.07, 0.024, 0.13269999999999998, 0.13723, 0.6, 0.69, 0, 0.0048, 0.323, 1.145]
Reward 12.865158874813288
Current State [[0.06    0.07    0.024   0.1327  0.13723 0.6     0.69    0.      0.0048
  0.323   1.145  ]]
Logits tf.Tensor([[-0.3809528  -0.15047404  0.0787302 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26022863 0.3276806  0.41209075]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.07, 0.032, 0.1167, 0.13723, 0.6, 0.74, 0, 0.0036, 0.327, 0.77]
Reward 19.439592938974627
Current State [[0.07    0.07    0.032   0.1167  0.13723 0.6     0.74    0.      0.0036
  0.327   0.77   ]]
Logits tf.Tensor([[-0.2989757  -0.10558417  0.06635905]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.27364618 0.33203074 0.39432314]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.07, 0.032, 0.1277, 0.13723, 0.6, 0.73, 0, 0.0062, 0.316, 1.1179999999999999]
Reward 10.506844192449615
Current State [[0.06    0.07    0.032   0.1277  0.13723 0.6     0.73    0.      0.0062
  0.316   1.118  ]]
Logits tf.Tensor([[-0.37362823 -0.14332582  0.08078263]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26080883 0.32835332 0.41083786]], shape=(1, 3), dtype=float32)
Selected action 2
[0.1, 0.07, 0.032, 0.1264, 0.13723, 0.6, 0.73, 0, 0.0062, 0.316, 1.1179999999999999]
Reward 10.506844192449615
Current State [[0.1     0.07    0.032   0.1264  0.13723 0.6     0.73    0.      0.0062
  0.316   1.118  ]]
Logits tf.Tensor([[-0.3828962  -0.1342502   0.07587279]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25877148 0.3318196  0.4094089 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.07, 0.032, 0.1389, 0.13723, 0.6, 0.49, 0, 0.1616, 0.265, 1.001]
Reward 3.899603128822738
Current State [[0.08    0.07    0.032   0.1389  0.13723 0.6     0.49    0.      0.1616
  0.265   1.001  ]]
Logits tf.Tensor([[-0.2917705  -0.12728609  0.08491109]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.27501044 0.32417822 0.40081128]], shape=(1, 3), dtype=float32)
Selected action 2
[0.09, 0.07, 0.03, 0.1196, 0.13723, 0.6, 0.47, 0, 0.0118, 0.29700000000000004, 1.536]
Reward 5.443207061106668
Current State [[0.09    0.07    0.03    0.1196  0.13723 0.6     0.47    0.      0.0118
  0.297   1.536  ]]
Logits tf.Tensor([[-0.441906   -0.22091356  0.0831626 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2539432  0.31674686 0.42930993]], shape=(1, 3), dtype=float32)
Selected action 2
[0.09, 0.07, 0.032, 0.1415, 0.13723, 0.6, 0.47, 0, 0.0118, 0.29700000000000004, 1.536]
Reward 5.443207061106668
Current State [[0.09    0.07    0.032   0.1415  0.13723 0.6     0.47    0.      0.0118
  0.297   1.536  ]]
Logits tf.Tensor([[-0.44197354 -0.21663506  0.07932302]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25400332 0.3182018  0.4277949 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.11, 0.12, 0.031, 0.14809999999999998, 0.13723, 0.6, 0.78, 0, 0.0043, 0.317, 1.064]
Reward 16.88687878590661
Current State [[0.11    0.12    0.031   0.1481  0.13723 0.6     0.78    0.      0.0043
  0.317   1.064  ]]
Logits tf.Tensor([[-0.36324602 -0.11271644  0.06911563]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26139706 0.33581826 0.4027847 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.07, 0.032, 0.1264, 0.13723, 0.6, 0.65, 0, 0.0075, 0.294, 0.41500000000000004]
Reward 8.136819576269907
Current State [[0.08    0.07    0.032   0.1264  0.13723 0.6     0.65    0.      0.0075
  0.294   0.415  ]]
Logits tf.Tensor([[-0.21102268 -0.06370564  0.05911778]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.28827834 0.33403423 0.3776874 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.07, 0.032, 0.1469, 0.13723, 0.6, 0.6, 0, 0.014499999999999999, 0.29300000000000004, 1.2289999999999999]
Reward 5.520541103842174
Current State [[0.07    0.07    0.032   0.1469  0.13723 0.6     0.6     0.      0.0145
  0.293   1.229  ]]
Logits tf.Tensor([[-0.38489288 -0.1511125   0.0762783 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25978768 0.3282072  0.41200516]], shape=(1, 3), dtype=float32)
Selected action 0
[0.18, 0.2, 0.027, 0.1679, 0.13723, 0.6, 0.6, 0, 0.014499999999999999, 0.29300000000000004, 1.2289999999999999]
Reward 5.520541103842174
Current State [[0.18    0.2     0.027   0.1679  0.13723 0.6     0.6     0.      0.0145
  0.293   1.229  ]]
Logits tf.Tensor([[-0.3764538  -0.09511509  0.05774124]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25848997 0.34247395 0.3990361 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.15, 0.12, 0.03, 0.18080000000000002, 0.13723, 0.6, 0.81, 0, 0.005, 0.372, 1.491]
Reward 14.681511014463222
Current State [[0.15    0.12    0.03    0.1808  0.13723 0.6     0.81    0.      0.005
  0.372   1.491  ]]
Logits tf.Tensor([[-0.47375306 -0.16569139  0.05609993]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24633773 0.33521268 0.4184496 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.07, 0.032, 0.1392, 0.13723, 0.6, 0.74, 0, 0.0968, 0.24300000000000002, 0.0]
Reward 4.0691086396095395
Current State [[0.08    0.07    0.032   0.1392  0.13723 0.6     0.74    0.      0.0968
  0.243   0.     ]]
Logits tf.Tensor([[-0.09481353 -0.07343344  0.03316548]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.31664214 0.32348487 0.359873  ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.09, 0.12, 0.023, 0.12079999999999999, 0.13723, 0.6, 0.62, 0, 0.0075, 0.341, 0.853]
Reward 7.9576008335409805
Current State [[0.09    0.12    0.023   0.1208  0.13723 0.6     0.62    0.      0.0075
  0.341   0.853  ]]
Logits tf.Tensor([[-0.3098192  -0.10333744  0.07277287]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.27060488 0.3326668  0.39672834]], shape=(1, 3), dtype=float32)
Selected action 1
[0.06, 0.12, 0.023, 0.1442, 0.13723, 0.6, 0.62, 0, 0.0075, 0.341, 0.853]
Reward 7.9576008335409805
Current State [[0.06    0.12    0.023   0.1442  0.13723 0.6     0.62    0.      0.0075
  0.341   0.853  ]]
Logits tf.Tensor([[-0.3032701  -0.10801645  0.0732374 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.27227142 0.3309784  0.3967502 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.07, 0.026, 0.1358, 0.13723, 0.6, 0.8, 0, 0.0171, 0.389, 0.9720000000000001]
Reward 5.80348527904528
Current State [[0.03    0.07    0.026   0.1358  0.13723 0.6     0.8     0.      0.0171
  0.389   0.972  ]]
Logits tf.Tensor([[-0.34099895 -0.15001297  0.07446154]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26841956 0.32490647 0.40667397]], shape=(1, 3), dtype=float32)
Selected action 1
[0.16, 0.12, 0.029, 0.146, 0.13723, 0.6, 0.61, 0, 0.0075, 0.29500000000000004, 1.323]
Reward 7.806826123207919
Current State [[0.16    0.12    0.029   0.146   0.13723 0.6     0.61    0.      0.0075
  0.295   1.323  ]]
Logits tf.Tensor([[-0.41221184 -0.1328146   0.06571255]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.254126   0.33603904 0.40983492]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.07, 0.029, 0.1388, 0.13723, 0.6, 0.67, 0, 0.0288, 0.418, 1.301]
Reward 4.696495141100984
Episode: 10 | Average Reward: 232 | Episode Reward: 235 | Loss: 266.082 | Steps: 19 | Worker: 0
Current State [[ 0.00828976 -0.00138623 -0.00275628  0.00562066  0.00313624  0.00241963
  -0.0016276   0.00882534 -0.00447664 -0.0001852  -0.00691729]]
Logits tf.Tensor([[-0.00360633  0.00908785 -0.01732643]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.33342797 0.33768752 0.32888454]], shape=(1, 3), dtype=float32)
Selected action 0
[0.19, 0.2, 0.029, 0.2275, 0.13723, 0.6, 0.67, 0, 0.0288, 0.418, 1.301]
Reward 4.696495141100984
Current State [[0.19    0.2     0.029   0.2275  0.13723 0.6     0.67    0.      0.0288
  0.418   1.301  ]]
Logits tf.Tensor([[-0.4230927  -0.11860595  0.0426698 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25321856 0.34334636 0.40343505]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.07, 0.036, 0.13, 0.13723, 0.6, 0.66, 0, 0.018799999999999997, 0.418, 0.744]
Reward 5.224266516423948
Current State [[0.08    0.07    0.036   0.13    0.13723 0.6     0.66    0.      0.0188
  0.418   0.744  ]]
Logits tf.Tensor([[-0.30549502 -0.10764509  0.07003023]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.27214324 0.3316826  0.3961741 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.07, 0.036, 0.125, 0.13723, 0.6, 0.51, 0, 0.0341, 0.307, 1.413]
Reward 4.34832060424476
Current State [[0.07    0.07    0.036   0.125   0.13723 0.6     0.51    0.      0.0341
  0.307   1.413  ]]
Logits tf.Tensor([[-0.41797924 -0.1909778   0.0809301 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25629485 0.32160693 0.4220982 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.13, 0.12, 0.032, 0.1423, 0.13723, 0.6, 0.51, 0, 0.0341, 0.307, 1.413]
Reward 4.34832060424476
Current State [[0.13    0.12    0.032   0.1423  0.13723 0.6     0.51    0.      0.0341
  0.307   1.413  ]]
Logits tf.Tensor([[-0.4136905  -0.16416879  0.07046261]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25600252 0.32855657 0.41544092]], shape=(1, 3), dtype=float32)
Selected action 1
[0.1, 0.12, 0.026, 0.14709999999999998, 0.13723, 0.6, 0.59, 0, 0.0191, 0.29900000000000004, 1.623]
Reward 5.021661752041936
Current State [[0.1     0.12    0.026   0.1471  0.13723 0.6     0.59    0.      0.0191
  0.299   1.623  ]]
Logits tf.Tensor([[-0.45476466 -0.19962788  0.07284074]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25090912 0.32383287 0.42525804]], shape=(1, 3), dtype=float32)
Selected action 1
[0.13, 0.12, 0.032, 0.15769999999999998, 0.13723, 0.6, 0.79, 0, 0.0052, 0.356, 1.285]
Reward 13.63745046030152
Current State [[0.13    0.12    0.032   0.1577  0.13723 0.6     0.79    0.      0.0052
  0.356   1.285  ]]
Logits tf.Tensor([[-0.43032315 -0.13889809  0.06275506]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2515292  0.33662987 0.41184095]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.07, 0.037, 0.117, 0.13723, 0.6, 0.84, 0, 0.0208, 0.466, 1.264]
Reward 5.468156676832415
Current State [[0.07    0.07    0.037   0.117   0.13723 0.6     0.84    0.      0.0208
  0.466   1.264  ]]
Logits tf.Tensor([[-0.4341439  -0.18440393  0.07380451]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2534488  0.3253501  0.42120105]], shape=(1, 3), dtype=float32)
Selected action 1
[0.13, 0.12, 0.034, 0.1408, 0.13723, 0.6, 0.73, 0, 0.0115, 0.29, 1.668]
Reward 6.693022355210589
Current State [[0.13    0.12    0.034   0.1408  0.13723 0.6     0.73    0.      0.0115
  0.29    1.668  ]]
Logits tf.Tensor([[-0.47740045 -0.18725489  0.06910181]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2460737  0.32890752 0.42501876]], shape=(1, 3), dtype=float32)
Selected action 1
[0.06, 0.12, 0.033, 0.1569, 0.13723, 0.6, 0.73, 0, 0.0115, 0.29, 1.668]
Reward 6.693022355210589
Current State [[0.06    0.12    0.033   0.1569  0.13723 0.6     0.73    0.      0.0115
  0.29    1.668  ]]
Logits tf.Tensor([[-0.46358004 -0.1981723   0.06929626]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24951416 0.32535714 0.42512873]], shape=(1, 3), dtype=float32)
Selected action 0
[0.2, 0.2, 0.029, 0.2078, 0.13723, 0.6, 0.85, 0, 0.036699999999999997, 0.26, 1.059]
Reward 4.691575505418199
Current State [[0.2     0.2     0.029   0.2078  0.13723 0.6     0.85    0.      0.0367
  0.26    1.059  ]]
Logits tf.Tensor([[-0.36831722 -0.0669093   0.04301746]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25902772 0.35014346 0.39082885]], shape=(1, 3), dtype=float32)
Selected action 1
[0.14, 0.12, 0.035, 0.137, 0.13723, 0.6, 1.0, 0, 0.024300000000000002, 0.258, 1.144]
Reward 5.511018054927411
Current State [[0.14    0.12    0.035   0.137   0.13723 0.6     1.      0.      0.0243
  0.258   1.144  ]]
Logits tf.Tensor([[-0.39287835 -0.11712414  0.05428586]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25763935 0.33944598 0.40291467]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.07, 0.042, 0.1176, 0.13723, 0.6, 0.77, 0, 0.0086, 0.312, 1.589]
Reward 8.331118709468774
Current State [[0.06    0.07    0.042   0.1176  0.13723 0.6     0.77    0.      0.0086
  0.312   1.589  ]]
Logits tf.Tensor([[-0.4706225  -0.20088284  0.07602748]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24770379 0.3243987  0.42789745]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.07, 0.031, 0.1264, 0.13723, 0.6, 0.77, 0, 0.0086, 0.312, 1.589]
Reward 8.331118709468774
Current State [[0.08    0.07    0.031   0.1264  0.13723 0.6     0.77    0.      0.0086
  0.312   1.589  ]]
Logits tf.Tensor([[-0.478344   -0.19684564  0.07299839]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24626327 0.32632685 0.4274099 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.13, 0.12, 0.034, 0.1385, 0.13723, 0.6, 0.64, 0, 0.0042, 0.236, 2.205]
Reward 13.869197902741107
Current State [[0.13    0.12    0.034   0.1385  0.13723 0.6     0.64    0.      0.0042
  0.236   2.205  ]]
Logits tf.Tensor([[-0.550617   -0.3057727   0.08472976]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24009034 0.30669677 0.4532129 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.18, 0.2, 0.03, 0.2135, 0.13723, 0.6, 0.84, 0, 0.0029, 0.337, 1.828]
Reward 30.05399715503394
Current State [[0.18    0.2     0.03    0.2135  0.13723 0.6     0.84    0.      0.0029
  0.337   1.828  ]]
Logits tf.Tensor([[-0.5145024  -0.17852332  0.04688182]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24082416 0.33698758 0.42218822]], shape=(1, 3), dtype=float32)
Selected action 1
[0.13, 0.12, 0.031, 0.1383, 0.13723, 0.6, 0.83, 0, 0.0409, 0.306, 1.285]
Reward 4.564993747458074
Current State [[0.13    0.12    0.031   0.1383  0.13723 0.6     0.83    0.      0.0409
  0.306   1.285  ]]
Logits tf.Tensor([[-0.41471747 -0.13477084  0.06890006]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25348607 0.33537704 0.41113696]], shape=(1, 3), dtype=float32)
Selected action 1
[0.17, 0.12, 0.032, 0.15769999999999998, 0.13723, 0.6, 0.78, 0, 0.0, 0.312, 1.293]
Reward 50.0
Current State [[0.17    0.12    0.032   0.1577  0.13723 0.6     0.78    0.      0.
  0.312   1.293  ]]
Logits tf.Tensor([[-0.4334672  -0.12072729  0.05936059]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24974373 0.3414411  0.40881515]], shape=(1, 3), dtype=float32)
Selected action 1
[0.14, 0.12, 0.036, 0.1717, 0.13723, 0.6, 0.78, 0, 0.0, 0.312, 1.293]
Reward 50.0
Current State [[0.14    0.12    0.036   0.1717  0.13723 0.6     0.78    0.      0.
  0.312   1.293  ]]
Logits tf.Tensor([[-0.4265692  -0.12559466  0.06148523]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25123617 0.339464   0.4092998 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.12, 0.12, 0.032, 0.15380000000000002, 0.13723, 0.6, 0.81, 0, 0.0004, 0.3, 0.826]
Reward 49.99999491390235
Current State [[1.2000e-01 1.2000e-01 3.2000e-02 1.5380e-01 1.3723e-01 6.0000e-01
  8.1000e-01 0.0000e+00 4.0000e-04 3.0000e-01 8.2600e-01]]
Logits tf.Tensor([[-0.3200121  -0.08320098  0.05089255]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2690887  0.34098968 0.3899216 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.17, 0.12, 0.033, 0.16040000000000001, 0.13723, 0.6, 0.78, 0, 0.0015, 0.28700000000000003, 1.6789999999999998]
Reward 47.29390488885043
Episode: 11 | Average Reward: 233 | Episode Reward: 328 | Loss: 1516.195 | Steps: 19 | Worker: 0
Current State [[ 0.00223638 -0.00183119  0.0037816  -0.0028882   0.00238142  0.00811533
   0.00665943  0.0089302   0.00911653 -0.00690612  0.00138831]]
Logits tf.Tensor([[-0.00256513  0.01237503 -0.01129262]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.33262786 0.33763468 0.32973748]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.07, 0.032, 0.122, 0.13723, 0.6, 0.82, 0, 0.003, 0.34199999999999997, 1.45]
Reward 27.518738695765254
Current State [[0.07    0.07    0.032   0.122   0.13723 0.6     0.82    0.      0.003
  0.342   1.45   ]]
Logits tf.Tensor([[-0.46698797 -0.16964842  0.06580614]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2469161  0.33241636 0.4206675 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.2, 0.2, 0.032, 0.16269999999999998, 0.13723, 0.6, 0.69, 0, 0.0069, 0.29700000000000004, 0.7969999999999999]
Reward 9.12752572150771
Current State [[0.2     0.2     0.032   0.1627  0.13723 0.6     0.69    0.      0.0069
  0.297   0.797  ]]
Logits tf.Tensor([[-0.31879604 -0.03151743  0.04179962]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26546472 0.3538102  0.38072512]], shape=(1, 3), dtype=float32)
Selected action 1
[0.14, 0.12, 0.034, 0.1463, 0.13723, 0.6, 0.69, 0, 0.0069, 0.29700000000000004, 0.7969999999999999]
Reward 9.12752572150771
Current State [[0.14    0.12    0.034   0.1463  0.13723 0.6     0.69    0.      0.0069
  0.297   0.797  ]]
Logits tf.Tensor([[-0.3202088  -0.05794038  0.05304055]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26650167 0.34641895 0.3870794 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.12, 0.12, 0.03, 0.1585, 0.13723, 0.6, 0.87, 0, 0.0235, 0.335, 1.101]
Reward 5.308946273297
Current State [[0.12    0.12    0.03    0.1585  0.13723 0.6     0.87    0.      0.0235
  0.335   1.101  ]]
Logits tf.Tensor([[-0.39118308 -0.10176741  0.05675318]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25636256 0.34240982 0.40122762]], shape=(1, 3), dtype=float32)
Selected action 0
[0.21, 0.2, 0.028, 0.2245, 0.13723, 0.6, 0.77, 0, 0.0296, 0.3, 1.748]
Reward 4.8171202340493835
Current State [[0.21    0.2     0.028   0.2245  0.13723 0.6     0.77    0.      0.0296
  0.3     1.748  ]]
Logits tf.Tensor([[-0.4990772  -0.14323387  0.0387931 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24156107 0.34480038 0.4136386 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.07, 0.031, 0.1333, 0.13723, 0.6, 0.78, 0, 0.0362, 0.314, 1.7550000000000001]
Reward 4.622617373344176
Current State [[0.06    0.07    0.031   0.1333  0.13723 0.6     0.78    0.      0.0362
  0.314   1.755  ]]
Logits tf.Tensor([[-0.51140875 -0.21715827  0.06430939]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24268739 0.32571563 0.43159702]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.07, 0.042, 0.1347, 0.13723, 0.6, 0.72, 0, 0.0039000000000000003, 0.271, 1.815]
Reward 17.147087395342016
Current State [[0.07    0.07    0.042   0.1347  0.13723 0.6     0.72    0.      0.0039
  0.271   1.815  ]]
Logits tf.Tensor([[-0.5150945  -0.22362816  0.0703664 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24188437 0.32373527 0.43438038]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.07, 0.032, 0.134, 0.13723, 0.6, 0.72, 0, 0.0039000000000000003, 0.271, 1.815]
Reward 17.147087395342016
Current State [[0.07    0.07    0.032   0.134   0.13723 0.6     0.72    0.      0.0039
  0.271   1.815  ]]
Logits tf.Tensor([[-0.5163319  -0.22561641  0.06981523]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.241871   0.3234744  0.43465456]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.07, 0.031, 0.1286, 0.13723, 0.6, 0.82, 0, 0.0014000000000000002, 0.29700000000000004, 0.403]
Reward 47.98159480236093
Current State [[0.05    0.07    0.031   0.1286  0.13723 0.6     0.82    0.      0.0014
  0.297   0.403  ]]
Logits tf.Tensor([[-0.23202802 -0.06853836  0.04412258]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.28606907 0.3368787  0.37705228]], shape=(1, 3), dtype=float32)
Selected action 2
[0.09, 0.07, 0.038, 0.126, 0.13723, 0.6, 0.63, 0, 0.0213, 0.217, 2.089]
Reward 4.9683067149385725
Current State [[0.09    0.07    0.038   0.126   0.13723 0.6     0.63    0.      0.0213
  0.217   2.089  ]]
Logits tf.Tensor([[-0.5419083  -0.2846394   0.08274445]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2403274  0.31083778 0.44883484]], shape=(1, 3), dtype=float32)
Selected action 0
[0.16, 0.2, 0.024, 0.1896, 0.13723, 0.6, 0.63, 0, 0.0213, 0.217, 2.089]
Reward 4.9683067149385725
Current State [[0.16    0.2     0.024   0.1896  0.13723 0.6     0.63    0.      0.0213
  0.217   2.089  ]]
Logits tf.Tensor([[-0.5116982  -0.23099329  0.06660074]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24348281 0.3223866  0.43413058]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.07, 0.032, 0.1321, 0.13723, 0.6, 0.82, 0, 0.0024, 0.308, 2.353]
Reward 35.81927808417779
Current State [[0.06    0.07    0.032   0.1321  0.13723 0.6     0.82    0.      0.0024
  0.308   2.353  ]]
Logits tf.Tensor([[-0.62946975 -0.33838776  0.06780839]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23008852 0.3078295  0.46208194]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.07, 0.03, 0.1226, 0.13723, 0.6, 0.48, 0, 0.27190000000000003, 0.294, 1.4449999999999998]
Reward 3.855492550015665
Current State [[0.06    0.07    0.03    0.1226  0.13723 0.6     0.48    0.      0.2719
  0.294   1.445  ]]
Logits tf.Tensor([[-0.36661324 -0.22652532  0.08617169]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2685962  0.30898634 0.42241743]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.07, 0.037, 0.134, 0.13723, 0.6, 0.74, 0, 0.0029, 0.327, 0.755]
Reward 25.862217085286964
Current State [[0.07    0.07    0.037   0.134   0.13723 0.6     0.74    0.      0.0029
  0.327   0.755  ]]
Logits tf.Tensor([[-0.30979133 -0.08522864  0.05929311]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2704029  0.33848363 0.3911134 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.06, 0.2, 0.024, 0.1423, 0.13723, 0.6, 0.74, 0, 0.0029, 0.327, 0.755]
Reward 25.862217085286964
Current State [[0.06    0.2     0.024   0.1423  0.13723 0.6     0.74    0.      0.0029
  0.327   0.755  ]]
Logits tf.Tensor([[-0.2827541  -0.07380955  0.04837876]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.27586806 0.33997333 0.3841586 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.13, 0.2, 0.024, 0.1694, 0.13723, 0.6, 0.85, 0, 0.0051, 0.354, 1.276]
Reward 15.073292109895473
Current State [[0.13    0.2     0.024   0.1694  0.13723 0.6     0.85    0.      0.0051
  0.354   1.276  ]]
Logits tf.Tensor([[-0.42613748 -0.1099575   0.04972088]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.251176   0.34458262 0.40424138]], shape=(1, 3), dtype=float32)
Selected action 1
[0.15, 0.12, 0.024, 0.15, 0.13723, 0.6, 0.55, 0, 0.0102, 0.40099999999999997, 1.299]
Reward 6.187240526426216
Current State [[0.15    0.12    0.024   0.15    0.13723 0.6     0.55    0.      0.0102
  0.401   1.299  ]]
Logits tf.Tensor([[-0.4349013  -0.13771701  0.05444649]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25142586 0.33843514 0.41013893]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.07, 0.025, 0.117, 0.13723, 0.6, 0.67, 0, 0.0546, 0.417, 0.766]
Reward 4.2491556536184545
Current State [[0.03    0.07    0.025   0.117   0.13723 0.6     0.67    0.      0.0546
  0.417   0.766  ]]
Logits tf.Tensor([[-0.30419055 -0.12002013  0.07174658]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.27333036 0.32860342 0.3980662 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.07, 0.031, 0.12079999999999999, 0.13723, 0.6, 0.74, 0, 0.0067, 0.368, 0.659]
Reward 9.891978600744036
Current State [[0.04    0.07    0.031   0.1208  0.13723 0.6     0.74    0.      0.0067
  0.368   0.659  ]]
Logits tf.Tensor([[-0.286886   -0.09061682  0.05860491]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2755172 0.3352643 0.3892185]], shape=(1, 3), dtype=float32)
Selected action 1
[0.14, 0.12, 0.026, 0.15469999999999998, 0.13723, 0.6, 0.74, 0, 0.0067, 0.368, 0.659]
Reward 9.891978600744036
Episode: 12 | Average Reward: 234 | Episode Reward: 289 | Loss: 710.794 | Steps: 19 | Worker: 0
Current State [[-0.00482421 -0.0006927  -0.00692862 -0.00357281  0.00817645 -0.00555131
   0.00461807  0.00248882 -0.00670353 -0.00554543 -0.00529495]]
Logits tf.Tensor([[-0.00252546  0.01016351 -0.01939756]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.33377397 0.3380362  0.32818976]], shape=(1, 3), dtype=float32)
Selected action 0
[0.16, 0.2, 0.023, 0.1653, 0.13723, 0.6, 0.79, 0, 0.0196, 0.329, 1.337]
Reward 5.458045381888137
Current State [[0.16    0.2     0.023   0.1653  0.13723 0.6     0.79    0.      0.0196
  0.329   1.337  ]]
Logits tf.Tensor([[-0.440156   -0.0933658   0.04479115]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24760999 0.35024926 0.4021407 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.07, 0.024, 0.12940000000000002, 0.13723, 0.6, 0.86, 0, 0.0089, 0.378, 0.634]
Reward 8.893847005701545
Current State [[0.06    0.07    0.024   0.1294  0.13723 0.6     0.86    0.      0.0089
  0.378   0.634  ]]
Logits tf.Tensor([[-0.30080432 -0.08582422  0.04413527]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.27384192 0.33951938 0.38663864]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.07, 0.031, 0.1308, 0.13723, 0.6, 0.67, 0, 0.0033, 0.344, 0.9199999999999999]
Reward 19.071726005853325
Current State [[0.06    0.07    0.031   0.1308  0.13723 0.6     0.67    0.      0.0033
  0.344   0.92   ]]
Logits tf.Tensor([[-0.35153696 -0.09899466  0.0703619 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2623193  0.33768204 0.3999987 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.07, 0.03, 0.1354, 0.13723, 0.6, 0.67, 0, 0.0033, 0.344, 0.9199999999999999]
Reward 19.071726005853325
Current State [[0.08    0.07    0.03    0.1354  0.13723 0.6     0.67    0.      0.0033
  0.344   0.92   ]]
Logits tf.Tensor([[-0.35721913 -0.09414998  0.06711739]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26113123 0.33970994 0.39915887]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.07, 0.032, 0.1385, 0.13723, 0.6, 0.58, 0, 0.0259, 0.319, 0.506]
Reward 4.653662900942248
Current State [[0.08    0.07    0.032   0.1385  0.13723 0.6     0.58    0.      0.0259
  0.319   0.506  ]]
Logits tf.Tensor([[-0.24854271 -0.05248541  0.06198858]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2792714  0.33976063 0.38096797]], shape=(1, 3), dtype=float32)
Selected action 0
[0.22, 0.2, 0.027, 0.1717, 0.13723, 0.6, 0.49, 0, 0.0232, 0.29500000000000004, 1.036]
Reward 4.609425487524301
Current State [[0.22    0.2     0.027   0.1717  0.13723 0.6     0.49    0.      0.0232
  0.295   1.036  ]]
Logits tf.Tensor([[-0.3607313  -0.04153493  0.0457602 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.257894   0.3548677  0.38723826]], shape=(1, 3), dtype=float32)
Selected action 1
[0.08, 0.12, 0.028, 0.1226, 0.13723, 0.6, 0.69, 0, 0.1091, 0.381, 1.536]
Reward 4.019824584603088
Current State [[0.08    0.12    0.028   0.1226  0.13723 0.6     0.69    0.      0.1091
  0.381   1.536  ]]
Logits tf.Tensor([[-0.45810804 -0.1793251   0.0668626 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2492566  0.32939768 0.42134568]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.07, 0.032, 0.1189, 0.13723, 0.6, 0.64, 0, 0.006999999999999999, 0.312, 1.319]
Reward 8.521525257972016
Current State [[0.08    0.07    0.032   0.1189  0.13723 0.6     0.64    0.      0.007
  0.312   1.319  ]]
Logits tf.Tensor([[-0.43325284 -0.13861139  0.06685914]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2505292  0.33637175 0.41309908]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.07, 0.031, 0.1347, 0.13723, 0.6, 0.64, 0, 0.006999999999999999, 0.312, 1.319]
Reward 8.521525257972016
Current State [[0.06    0.07    0.031   0.1347  0.13723 0.6     0.64    0.      0.007
  0.312   1.319  ]]
Logits tf.Tensor([[-0.42910156 -0.14120296  0.06570934]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25164765 0.33560288 0.41274947]], shape=(1, 3), dtype=float32)
Selected action 1
[0.13, 0.12, 0.025, 0.1679, 0.13723, 0.6, 0.7, 0, 0.0183, 0.28300000000000003, 0.7190000000000001]
Reward 5.355987949919112
Current State [[0.13    0.12    0.025   0.1679  0.13723 0.6     0.7     0.      0.0183
  0.283   0.719  ]]
Logits tf.Tensor([[-0.30799854 -0.0467959   0.04430359]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26875734 0.3489789  0.3822638 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.14, 0.12, 0.029, 0.1415, 0.13723, 0.6, 0.84, 0, 0.0029, 0.34199999999999997, 1.466]
Reward 29.28280393051092
Current State [[0.14    0.12    0.029   0.1415  0.13723 0.6     0.84    0.      0.0029
  0.342   1.466  ]]
Logits tf.Tensor([[-0.48645905 -0.1318786   0.0498248 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24182485 0.34474126 0.41343388]], shape=(1, 3), dtype=float32)
Selected action 0
[0.13, 0.2, 0.026, 0.1429, 0.13723, 0.6, 0.76, 0, 0.0385, 0.304, 1.725]
Reward 4.549961040693863
Current State [[0.13    0.2     0.026   0.1429  0.13723 0.6     0.76    0.      0.0385
  0.304   1.725  ]]
Logits tf.Tensor([[-0.47728968 -0.15681368  0.0526733 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2452993  0.3379693  0.41673145]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.07, 0.03, 0.1264, 0.13723, 0.6, 0.81, 0, 0.0091, 0.311, 1.311]
Reward 8.370023387752337
Current State [[0.07    0.07    0.03    0.1264  0.13723 0.6     0.81    0.      0.0091
  0.311   1.311  ]]
Logits tf.Tensor([[-0.44269624 -0.13895349  0.06583316]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24889462 0.33723244 0.41387296]], shape=(1, 3), dtype=float32)
Selected action 0
[0.18, 0.2, 0.027, 0.1615, 0.13723, 0.6, 0.81, 0, 0.0091, 0.311, 1.311]
Reward 8.370023387752337
Current State [[0.18    0.2     0.027   0.1615  0.13723 0.6     0.81    0.      0.0091
  0.311   1.311  ]]
Logits tf.Tensor([[-0.4399318  -0.08049949  0.04360783]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24665044 0.3533307  0.40001887]], shape=(1, 3), dtype=float32)
Selected action 2
[0.09, 0.07, 0.028, 0.12079999999999999, 0.13723, 0.6, 0.73, 0, 0.0063, 0.371, 0.8320000000000001]
Reward 10.391777397415268
Current State [[0.09    0.07    0.028   0.1208  0.13723 0.6     0.73    0.      0.0063
  0.371   0.832  ]]
Logits tf.Tensor([[-0.3446134  -0.09118632  0.05985714]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26406527 0.34023052 0.39570418]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.07, 0.03, 0.1264, 0.13723, 0.6, 0.53, 0, 0.0087, 0.36, 0.8710000000000001]
Reward 6.5779636245420186
Current State [[0.07    0.07    0.03    0.1264  0.13723 0.6     0.53    0.      0.0087
  0.36    0.871  ]]
Logits tf.Tensor([[-0.3393441  -0.09754459  0.07136593]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26445043 0.3367879  0.39876166]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.07, 0.032, 0.1269, 0.13723, 0.6, 0.68, 0, 0.027200000000000002, 0.33199999999999996, 1.159]
Reward 4.764224380319412
Current State [[0.08    0.07    0.032   0.1269  0.13723 0.6     0.68    0.      0.0272
  0.332   1.159  ]]
Logits tf.Tensor([[-0.40228653 -0.12365208  0.0676851 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25501922 0.33696306 0.4080177 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.13, 0.2, 0.024, 0.1569, 0.13723, 0.6, 0.68, 0, 0.027200000000000002, 0.33199999999999996, 1.159]
Reward 4.764224380319412
Current State [[0.13    0.2     0.024   0.1569  0.13723 0.6     0.68    0.      0.0272
  0.332   1.159  ]]
Logits tf.Tensor([[-0.3894012  -0.08377004  0.05343423]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2554541  0.34677422 0.3977717 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.29, 0.2, 0.027, 0.18109999999999998, 0.13723, 0.6, 0.73, 0, 0.1069, 0.361, 1.239]
Reward 4.037884233758603
Current State [[0.29    0.2     0.027   0.1811  0.13723 0.6     0.73    0.      0.1069
  0.361   1.239  ]]
Logits tf.Tensor([[-0.43585125 -0.0670156   0.03589358]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24698442 0.3571518  0.39586377]], shape=(1, 3), dtype=float32)
Selected action 1
[0.05, 0.12, 0.026, 0.1423, 0.13723, 0.6, 0.76, 0, 0.0103, 0.43600000000000005, 0.771]
Reward 7.3140491824573255
Episode: 13 | Average Reward: 233 | Episode Reward: 176 | Loss: 236.461 | Steps: 19 | Worker: 0
Current State [[-9.07569928e-03  6.48195481e-03  4.62033132e-03 -5.30064994e-04
   5.42176010e-03 -8.90143861e-03 -9.24421902e-03 -2.17134906e-03
   5.97485755e-03 -9.96466151e-05 -8.86630939e-03]]
Logits tf.Tensor([[ 0.00395585  0.01013419 -0.02182116]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.33548605 0.33756524 0.32694876]], shape=(1, 3), dtype=float32)
Selected action 0
[0.19, 0.2, 0.025, 0.18130000000000002, 0.13723, 0.6, 0.65, 0, 0.0161, 0.39, 0.5349999999999999]
Reward 5.482598907041577
Current State [[0.19    0.2     0.025   0.1813  0.13723 0.6     0.65    0.      0.0161
  0.39    0.535  ]]
Logits tf.Tensor([[-0.2719036  -0.01834226  0.0303386 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.27461246 0.35386738 0.37152016]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.07, 0.033, 0.128, 0.13723, 0.6, 0.7, 0, 0.016200000000000003, 0.488, 1.674]
Reward 5.60855975345503
Current State [[0.08    0.07    0.033   0.128   0.13723 0.6     0.7     0.      0.0162
  0.488   1.674  ]]
Logits tf.Tensor([[-0.5527827  -0.2197604   0.05703037]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23611268 0.32941934 0.434468  ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.15, 0.2, 0.025, 0.1792, 0.13723, 0.6, 0.7, 0, 0.016200000000000003, 0.488, 1.674]
Reward 5.60855975345503
Current State [[0.15    0.2     0.025   0.1792  0.13723 0.6     0.7     0.      0.0162
  0.488   1.674  ]]
Logits tf.Tensor([[-0.53277475 -0.15865211  0.0368319 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23689456 0.3443773  0.4187281 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.17, 0.12, 0.027, 0.15, 0.13723, 0.6, 0.79, 0, 0.0038, 0.481, 1.081]
Reward 19.804740009705228
Current State [[0.17    0.12    0.027   0.15    0.13723 0.6     0.79    0.      0.0038
  0.481   1.081  ]]
Logits tf.Tensor([[-0.43892288 -0.0996893   0.04149861]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24871743 0.34916723 0.40211532]], shape=(1, 3), dtype=float32)
Selected action 1
[0.08, 0.12, 0.029, 0.15930000000000002, 0.13723, 0.6, 0.54, 0, 0.0089, 0.311, 1.6670000000000003]
Reward 6.564766962476992
Current State [[0.08    0.12    0.029   0.1593  0.13723 0.6     0.54    0.      0.0089
  0.311   1.667  ]]
Logits tf.Tensor([[-0.48959848 -0.18649317  0.06258006]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24443361 0.33097708 0.42458928]], shape=(1, 3), dtype=float32)
Selected action 0
[0.13, 0.2, 0.026, 0.19440000000000002, 0.13723, 0.6, 0.65, 0, 0.0058, 0.476, 0.775]
Reward 10.081344818944254
Current State [[0.13    0.2     0.026   0.1944  0.13723 0.6     0.65    0.      0.0058
  0.476   0.775  ]]
Logits tf.Tensor([[-0.32892987 -0.06230175  0.04582826]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2659437  0.3472041  0.38685223]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.07, 0.033, 0.1189, 0.13723, 0.6, 0.89, 0, 0.0194, 0.33599999999999997, 1.105]
Reward 5.761511142797652
Current State [[0.06    0.07    0.033   0.1189  0.13723 0.6     0.89    0.      0.0194
  0.336   1.105  ]]
Logits tf.Tensor([[-0.40217632 -0.11663181  0.06539916]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25467288 0.3388388  0.4064884 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.07, 0.033, 0.1216, 0.13723, 0.6, 0.62, 0, 0.011200000000000002, 0.27, 2.3]
Reward 6.261429920244126
Current State [[0.05    0.07    0.033   0.1216  0.13723 0.6     0.62    0.      0.0112
  0.27    2.3    ]]
Logits tf.Tensor([[-0.611944   -0.33042127  0.07532802]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23183405 0.307214   0.46095198]], shape=(1, 3), dtype=float32)
Selected action 2
[0.1, 0.07, 0.04, 0.1426, 0.13723, 0.6, 0.62, 0, 0.011200000000000002, 0.27, 2.3]
Reward 6.261429920244126
Current State [[0.1     0.07    0.04    0.1426  0.13723 0.6     0.62    0.      0.0112
  0.27    2.3    ]]
Logits tf.Tensor([[-0.6207464  -0.31362888  0.06895325]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22974682 0.31234095 0.45791224]], shape=(1, 3), dtype=float32)
Selected action 0
[0.23, 0.2, 0.027, 0.18869999999999998, 0.13723, 0.6, 0.6, 0, 0.0049, 0.22599999999999998, 2.175]
Reward 10.964262898364275
Current State [[0.23    0.2     0.027   0.1887  0.13723 0.6     0.6     0.      0.0049
  0.226   2.175  ]]
Logits tf.Tensor([[-0.559856   -0.21601796  0.05630122]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23462345 0.33090127 0.43447533]], shape=(1, 3), dtype=float32)
Selected action 0
[0.2, 0.2, 0.031, 0.1667, 0.13723, 0.6, 0.82, 0, 0.0321, 0.277, 2.129]
Reward 4.78378081516154
Current State [[0.2     0.2     0.031   0.1667  0.13723 0.6     0.82    0.      0.0321
  0.277   2.129  ]]
Logits tf.Tensor([[-0.56685424 -0.19923554  0.05146043]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23255332 0.33587474 0.43157193]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.07, 0.037, 0.125, 0.13723, 0.6, 0.63, 0, 0.4702, 0.273, 2.761]
Reward 3.840491127610573
Current State [[0.07    0.07    0.037   0.125   0.13723 0.6     0.63    0.      0.4702
  0.273   2.761  ]]
Logits tf.Tensor([[-0.60244334 -0.47176477  0.10998835]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23931776 0.27272683 0.48795533]], shape=(1, 3), dtype=float32)
Selected action 1
[0.11, 0.12, 0.031, 0.16, 0.13723, 0.6, 0.63, 0, 0.4702, 0.273, 2.761]
Reward 3.840491127610573
Current State [[0.11    0.12    0.031   0.16    0.13723 0.6     0.63    0.      0.4702
  0.273   2.761  ]]
Logits tf.Tensor([[-0.5942713  -0.4474496   0.09847353]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24053825 0.27857876 0.48088297]], shape=(1, 3), dtype=float32)
Selected action 1
[0.11, 0.12, 0.034, 0.15769999999999998, 0.13723, 0.6, 0.77, 0, 0.0031, 0.302, 1.748]
Reward 25.030899662428357
Current State [[0.11    0.12    0.034   0.1577  0.13723 0.6     0.77    0.      0.0031
  0.302   1.748  ]]
Logits tf.Tensor([[-0.5235635  -0.1666806   0.05251946]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23764685 0.3395661  0.42278707]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.07, 0.033, 0.13019999999999998, 0.13723, 0.6, 0.75, 0, 0.0018, 0.306, 2.198]
Reward 41.73594224935332
Current State [[4.0000e-02 7.0000e-02 3.3000e-02 1.3020e-01 1.3723e-01 6.0000e-01
  7.5000e-01 0.0000e+00 1.8000e-03 3.0600e-01 2.1980e+00]]
Logits tf.Tensor([[-0.6128174  -0.29798314  0.06611124]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2303194  0.31554505 0.45413557]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.07, 0.034, 0.1189, 0.13723, 0.6, 0.69, 0, 0.018000000000000002, 0.288, 1.22]
Reward 5.37927583003191
Current State [[0.08    0.07    0.034   0.1189  0.13723 0.6     0.69    0.      0.018
  0.288   1.22   ]]
Logits tf.Tensor([[-0.41793522 -0.11565123  0.06852771]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25128797 0.3399789  0.40873316]], shape=(1, 3), dtype=float32)
Selected action 1
[0.12, 0.12, 0.03, 0.1519, 0.13723, 0.6, 0.69, 0, 0.018000000000000002, 0.288, 1.22]
Reward 5.37927583003191
Current State [[0.12    0.12    0.03    0.1519  0.13723 0.6     0.69    0.      0.018
  0.288   1.22   ]]
Logits tf.Tensor([[-0.41698265 -0.09193079  0.057136  ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2505826  0.346832   0.40258542]], shape=(1, 3), dtype=float32)
Selected action 0
[0.23, 0.2, 0.032, 0.194, 0.13723, 0.6, 0.71, 0, 0.0004, 0.298, 0.9710000000000001]
Reward 49.99996625040708
Current State [[2.3000e-01 2.0000e-01 3.2000e-02 1.9400e-01 1.3723e-01 6.0000e-01
  7.1000e-01 0.0000e+00 4.0000e-04 2.9800e-01 9.7100e-01]]
Logits tf.Tensor([[-0.38306898 -0.02219893  0.03547423]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2528878 0.362787  0.3843252]], shape=(1, 3), dtype=float32)
Selected action 1
[0.17, 0.12, 0.034, 0.18080000000000002, 0.13723, 0.6, 0.77, 0, 0.0746, 0.303, 1.706]
Reward 4.172239021998478
Current State [[0.17    0.12    0.034   0.1808  0.13723 0.6     0.77    0.      0.0746
  0.303   1.706  ]]
Logits tf.Tensor([[-0.5155622  -0.15171191  0.04816243]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23831856 0.34290677 0.41877463]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.07, 0.031, 0.1245, 0.13723, 0.6, 0.82, 0, 0.0015, 0.315, 1.828]
Reward 47.18641755098386
Episode: 14 | Average Reward: 233 | Episode Reward: 273 | Loss: 869.037 | Steps: 19 | Worker: 0
Current State [[-0.00047073  0.00466965 -0.00291676 -0.00382146  0.001277    0.00692055
   0.00521702  0.00442746 -0.00225764  0.00825763  0.00932768]]
Logits tf.Tensor([[-0.00869264  0.01410515 -0.01920995]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.33193943 0.33959386 0.32846665]], shape=(1, 3), dtype=float32)
Selected action 1
[0.13, 0.12, 0.028, 0.1358, 0.13723, 0.6, 0.55, 0, 0.10619999999999999, 0.256, 1.7100000000000002]
Reward 3.9778356294848516
Current State [[0.13    0.12    0.028   0.1358  0.13723 0.6     0.55    0.      0.1062
  0.256   1.71   ]]
Logits tf.Tensor([[-0.47583535 -0.18711247  0.0702422 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2462333  0.32865292 0.42511383]], shape=(1, 3), dtype=float32)
Selected action 1
[0.13, 0.12, 0.032, 0.1692, 0.13723, 0.6, 0.55, 0, 0.10619999999999999, 0.256, 1.7100000000000002]
Reward 3.9778356294848516
Current State [[0.13    0.12    0.032   0.1692  0.13723 0.6     0.55    0.      0.1062
  0.256   1.71   ]]
Logits tf.Tensor([[-0.47674635 -0.1808077   0.06531493]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2460669  0.3308093  0.42312378]], shape=(1, 3), dtype=float32)
Selected action 0
[0.15, 0.2, 0.028, 0.1925, 0.13723, 0.6, 0.78, 0, 0.11699999999999999, 0.27999999999999997, 1.584]
Reward 4.034106951188149
Current State [[0.15    0.2     0.028   0.1925  0.13723 0.6     0.78    0.      0.117
  0.28    1.584  ]]
Logits tf.Tensor([[-0.45674026 -0.11245046  0.04274052]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24637502 0.34763208 0.4059929 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.11, 0.12, 0.031, 0.15, 0.13723, 0.6, 0.84, 0, 0.1858, 0.314, 2.386]
Reward 3.954395904455912
Current State [[0.11    0.12    0.031   0.15    0.13723 0.6     0.84    0.      0.1858
  0.314   2.386  ]]
Logits tf.Tensor([[-0.62025374 -0.312623    0.06529123]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23014686 0.31304544 0.45680773]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.07, 0.034, 0.1333, 0.13723, 0.6, 0.81, 0, 0.0011, 0.298, 1.783]
Reward 49.67021938357923
Current State [[7.0000e-02 7.0000e-02 3.4000e-02 1.3330e-01 1.3723e-01 6.0000e-01
  8.1000e-01 0.0000e+00 1.1000e-03 2.9800e-01 1.7830e+00]]
Logits tf.Tensor([[-0.54549986 -0.18631123  0.05754054]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23475093 0.33620253 0.42904657]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.07, 0.036, 0.15, 0.13723, 0.6, 0.81, 0, 0.0011, 0.298, 1.783]
Reward 49.67021938357923
Current State [[8.0000e-02 7.0000e-02 3.6000e-02 1.5000e-01 1.3723e-01 6.0000e-01
  8.1000e-01 0.0000e+00 1.1000e-03 2.9800e-01 1.7830e+00]]
Logits tf.Tensor([[-0.54907477 -0.18152644  0.05426433]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23406033 0.3380275  0.42791218]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.07, 0.028, 0.1269, 0.13723, 0.6, 0.74, 0, 0.0040999999999999995, 0.264, 1.569]
Reward 16.569872971177453
Current State [[0.07    0.07    0.028   0.1269  0.13723 0.6     0.74    0.      0.0041
  0.264   1.569  ]]
Logits tf.Tensor([[-0.4928412  -0.15076618  0.06139103]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24105272 0.3393699  0.41957733]], shape=(1, 3), dtype=float32)
Selected action 1
[0.18, 0.12, 0.036, 0.1745, 0.13723, 0.6, 0.69, 0, 0.0067, 0.274, 1.081]
Reward 9.311150967486277
Current State [[0.18    0.12    0.036   0.1745  0.13723 0.6     0.69    0.      0.0067
  0.274   1.081  ]]
Logits tf.Tensor([[-0.41027555 -0.05008464  0.04780537]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24908835 0.3570938  0.39381787]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.07, 0.032, 0.1245, 0.13723, 0.6, 0.73, 0, 0.0123, 0.277, 2.058]
Reward 6.461895664890287
Current State [[0.08    0.07    0.032   0.1245  0.13723 0.6     0.73    0.      0.0123
  0.277   2.058  ]]
Logits tf.Tensor([[-0.58518136 -0.25209007  0.066548  ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23179641 0.32341963 0.444784  ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.07, 0.036, 0.1377, 0.13723, 0.6, 0.73, 0, 0.0123, 0.277, 2.058]
Reward 6.461895664890287
Current State [[0.06    0.07    0.036   0.1377  0.13723 0.6     0.73    0.      0.0123
  0.277   2.058  ]]
Logits tf.Tensor([[-0.58313537 -0.25436768  0.06535825]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23245475 0.32293895 0.44460633]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.07, 0.032, 0.132, 0.13723, 0.6, 0.56, 0, 0.025, 0.27599999999999997, 1.791]
Reward 4.653885469640779
Current State [[0.07    0.07    0.032   0.132   0.13723 0.6     0.56    0.      0.025
  0.276   1.791  ]]
Logits tf.Tensor([[-0.522879   -0.21968375  0.07016143]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24017327 0.32523757 0.43458912]], shape=(1, 3), dtype=float32)
Selected action 2
[0.09, 0.07, 0.031, 0.1377, 0.13723, 0.6, 0.61, 0, 0.006, 0.281, 0.8619999999999999]
Reward 9.221589232767387
Current State [[0.09    0.07    0.031   0.1377  0.13723 0.6     0.61    0.      0.006
  0.281   0.862  ]]
Logits tf.Tensor([[-0.34805384 -0.06389125  0.06674313]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26023287 0.3457581  0.39400902]], shape=(1, 3), dtype=float32)
Selected action 1
[0.17, 0.12, 0.024, 0.1472, 0.13723, 0.6, 0.61, 0, 0.006, 0.281, 0.8619999999999999]
Reward 9.221589232767387
Current State [[0.17    0.12    0.024   0.1472  0.13723 0.6     0.61    0.      0.006
  0.281   0.862  ]]
Logits tf.Tensor([[-0.35815272 -0.03596994  0.05281924]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25717384 0.35493517 0.387891  ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.07, 0.033, 0.1245, 0.13723, 0.6, 0.71, 0, 0.0078000000000000005, 0.308, 1.0150000000000001]
Reward 8.468709239450092
Current State [[0.07    0.07    0.033   0.1245  0.13723 0.6     0.71    0.      0.0078
  0.308   1.015  ]]
Logits tf.Tensor([[-0.38309258 -0.09007358  0.06948663]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25556943 0.34258273 0.40184778]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.07, 0.024, 0.13019999999999998, 0.13723, 0.6, 0.78, 0, 0.006999999999999999, 0.271, 1.3880000000000001]
Reward 9.977595873574245
Current State [[0.06    0.07    0.024   0.1302  0.13723 0.6     0.78    0.      0.007
  0.271   1.388  ]]
Logits tf.Tensor([[-0.45878676 -0.13025658  0.06323715]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2454373 0.340894  0.4136687]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.07, 0.029, 0.126, 0.13723, 0.6, 0.52, 0, 0.046, 0.425, 0.805]
Reward 4.21161195222618
Current State [[0.04    0.07    0.029   0.126   0.13723 0.6     0.52    0.      0.046
  0.425   0.805  ]]
Logits tf.Tensor([[-0.33006924 -0.10267962  0.07707699]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26611012 0.33405307 0.3998368 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.15, 0.2, 0.023, 0.198, 0.13723, 0.6, 0.52, 0, 0.046, 0.425, 0.805]
Reward 4.21161195222618
Current State [[0.15    0.2     0.023   0.198   0.13723 0.6     0.52    0.      0.046
  0.425   0.805  ]]
Logits tf.Tensor([[-0.3254767  -0.04929482  0.04995598]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2649913  0.34928176 0.38572696]], shape=(1, 3), dtype=float32)
Selected action 1
[0.09, 0.12, 0.023, 0.1245, 0.13723, 0.6, 0.7, 0, 0.0048, 0.389, 0.8619999999999999]
Reward 12.92296163218441
Current State [[0.09    0.12    0.023   0.1245  0.13723 0.6     0.7     0.      0.0048
  0.389   0.862  ]]
Logits tf.Tensor([[-0.3554541  -0.07813308  0.05797629]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26098853 0.34439787 0.39461353]], shape=(1, 3), dtype=float32)
Selected action 0
[0.17, 0.2, 0.026, 0.19, 0.13723, 0.6, 0.65, 0, 0.051, 0.32, 1.421]
Reward 4.267954442082851
Current State [[0.17    0.2     0.026   0.19    0.13723 0.6     0.65    0.      0.051
  0.32    1.421  ]]
Logits tf.Tensor([[-0.44487798 -0.08493689  0.03973385]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24650033 0.35329536 0.4002043 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.07, 0.029, 0.13140000000000002, 0.13723, 0.6, 0.79, 0, 0.0833, 0.311, 1.629]
Reward 4.1413195827738205
Episode: 15 | Average Reward: 233 | Episode Reward: 225 | Loss: 373.977 | Steps: 19 | Worker: 0
Current State [[ 0.00691195  0.00754482 -0.00442194 -0.00190081  0.00541816  0.00131427
   0.00111335  0.00702364  0.00508339  0.00311953 -0.00957322]]
Logits tf.Tensor([[-0.00107957  0.01200231 -0.02302121]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.33428434 0.33868614 0.3270295 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.11, 0.12, 0.028, 0.1447, 0.13723, 0.6, 0.74, 0, 0.0031, 0.303, 0.853]
Reward 23.572214610392876
Current State [[0.11    0.12    0.028   0.1447  0.13723 0.6     0.74    0.      0.0031
  0.303   0.853  ]]
Logits tf.Tensor([[-0.35859263 -0.05031758  0.053803  ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25829732 0.3515621  0.39014053]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.07, 0.029, 0.1264, 0.13723, 0.6, 0.74, 0, 0.0031, 0.303, 0.853]
Reward 23.572214610392876
Current State [[0.06    0.07    0.029   0.1264  0.13723 0.6     0.74    0.      0.0031
  0.303   0.853  ]]
Logits tf.Tensor([[-0.35558385 -0.07398197  0.06500427]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25986797 0.3443903  0.39574173]], shape=(1, 3), dtype=float32)
Selected action 0
[0.1, 0.2, 0.024, 0.1212, 0.13723, 0.6, 0.69, 0, 0.0009, 0.33999999999999997, 0.242]
Reward 49.597800463035284
Current State [[0.1     0.2     0.024   0.1212  0.13723 0.6     0.69    0.      0.0009
  0.34    0.242  ]]
Logits tf.Tensor([[-0.18081151 -0.02702429  0.03586599]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29341123 0.3421887  0.36440015]], shape=(1, 3), dtype=float32)
Selected action 0
[0.1, 0.2, 0.025, 0.1549, 0.13723, 0.6, 0.77, 0, 0.0292, 0.31, 0.9339999999999999]
Reward 4.824356378888422
Current State [[0.1     0.2     0.025   0.1549  0.13723 0.6     0.77    0.      0.0292
  0.31    0.934  ]]
Logits tf.Tensor([[-0.35194203 -0.0505774   0.0500435 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25997716 0.35141167 0.38861117]], shape=(1, 3), dtype=float32)
Selected action 1
[0.09, 0.12, 0.024, 0.15769999999999998, 0.13723, 0.6, 0.69, 0, 0.01, 0.372, 0.953]
Reward 7.030695517176008
Current State [[0.09    0.12    0.024   0.1577  0.13723 0.6     0.69    0.      0.01
  0.372   0.953  ]]
Logits tf.Tensor([[-0.3809933  -0.07537337  0.0596048 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25568238 0.34708017 0.3972374 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.11, 0.12, 0.027, 0.149, 0.13723, 0.6, 0.77, 0, 0.0128, 0.357, 1.008]
Reward 6.531862668859191
Current State [[0.11    0.12    0.027   0.149   0.13723 0.6     0.77    0.      0.0128
  0.357   1.008  ]]
Logits tf.Tensor([[-0.39867467 -0.07301699  0.05790105]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25229588 0.34941494 0.39828914]], shape=(1, 3), dtype=float32)
Selected action 0
[0.13, 0.2, 0.026, 0.2122, 0.13723, 0.6, 0.77, 0, 0.0128, 0.357, 1.008]
Reward 6.531862668859191
Current State [[0.13    0.2     0.026   0.2122  0.13723 0.6     0.77    0.      0.0128
  0.357   1.008  ]]
Logits tf.Tensor([[-0.38695043 -0.04561215  0.04460965]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25338992 0.3564763  0.39013374]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.07, 0.029, 0.1377, 0.13723, 0.6, 0.8, 0, 0.0018, 0.378, 1.6780000000000002]
Reward 43.53221984844747
Current State [[0.08    0.07    0.029   0.1377  0.13723 0.6     0.8     0.      0.0018
  0.378   1.678  ]]
Logits tf.Tensor([[-0.55321467 -0.1759202   0.05456955]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23284557 0.33956656 0.42758784]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.07, 0.024, 0.128, 0.13723, 0.6, 0.63, 0, 0.2231, 0.256, 0.9390000000000001]
Reward 3.893754008973426
Current State [[0.08    0.07    0.024   0.128   0.13723 0.6     0.63    0.      0.2231
  0.256   0.939  ]]
Logits tf.Tensor([[-0.31833762 -0.08883317  0.07884972]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26697913 0.33585346 0.39716738]], shape=(1, 3), dtype=float32)
Selected action 1
[0.14, 0.12, 0.024, 0.1688, 0.13723, 0.6, 0.59, 0, 0.0101, 0.284, 0.312]
Reward 6.444361318203703
Current State [[0.14    0.12    0.024   0.1688  0.13723 0.6     0.59    0.      0.0101
  0.284   0.312  ]]
Logits tf.Tensor([[-0.2156581  -0.00606477  0.04073459]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2836528  0.34979397 0.36655322]], shape=(1, 3), dtype=float32)
Selected action 1
[0.09, 0.12, 0.024, 0.156, 0.13723, 0.6, 0.59, 0, 0.0101, 0.284, 0.312]
Reward 6.444361318203703
Current State [[0.09    0.12    0.024   0.156   0.13723 0.6     0.59    0.      0.0101
  0.284   0.312  ]]
Logits tf.Tensor([[-0.20847312 -0.01902636  0.04989896]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.28543693 0.34497356 0.36958954]], shape=(1, 3), dtype=float32)
Selected action 0
[0.18, 0.2, 0.026, 0.1804, 0.13723, 0.6, 0.68, 0, 0.0124, 0.333, 1.26]
Reward 6.212444017602283
Current State [[0.18    0.2     0.026   0.1804  0.13723 0.6     0.68    0.      0.0124
  0.333   1.26   ]]
Logits tf.Tensor([[-0.44174972 -0.05904831  0.04010036]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24477963 0.35890573 0.39631462]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.07, 0.03, 0.1449, 0.13723, 0.6, 0.77, 0, 0.1433, 0.343, 1.314]
Reward 3.985956105242389
Current State [[0.07    0.07    0.03    0.1449  0.13723 0.6     0.77    0.      0.1433
  0.343   1.314  ]]
Logits tf.Tensor([[-0.43289545 -0.13801864  0.07020395]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25020015 0.33600903 0.4137908 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.12, 0.2, 0.024, 0.1704, 0.13723, 0.6, 0.67, 0, 0.0177, 0.302, 0.45]
Reward 5.354056940656686
Current State [[0.12    0.2     0.024   0.1704  0.13723 0.6     0.67    0.      0.0177
  0.302   0.45   ]]
Logits tf.Tensor([[-0.2421878  -0.00964321  0.03606654]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.27912465 0.35220137 0.368674  ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.12, 0.12, 0.03, 0.1519, 0.13723, 0.6, 0.67, 0, 0.0177, 0.302, 0.45]
Reward 5.354056940656686
Current State [[0.12    0.12    0.03    0.1519  0.13723 0.6     0.67    0.      0.0177
  0.302   0.45   ]]
Logits tf.Tensor([[-0.2562508  -0.02058178  0.04500353]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.27644864 0.34991634 0.373635  ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.1, 0.07, 0.032, 0.1347, 0.13723, 0.6, 0.69, 0, 0.0064, 0.409, 0.522]
Reward 9.72498354090501
Current State [[0.1     0.07    0.032   0.1347  0.13723 0.6     0.69    0.      0.0064
  0.409   0.522  ]]
Logits tf.Tensor([[-0.28744623 -0.05066644  0.05536379]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.27203014 0.34470627 0.3832636 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.07, 0.033, 0.1451, 0.13723, 0.6, 0.69, 0, 0.0212, 0.35, 0.5389999999999999]
Reward 5.111474308169992
Current State [[0.08    0.07    0.033   0.1451  0.13723 0.6     0.69    0.      0.0212
  0.35    0.539  ]]
Logits tf.Tensor([[-0.2835316  -0.04777237  0.05512458]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.27255902 0.34502414 0.38241687]], shape=(1, 3), dtype=float32)
Selected action 1
[0.15, 0.12, 0.03, 0.1453, 0.13723, 0.6, 0.55, 0, 0.0106, 0.31, 0.8089999999999999]
Reward 6.065761034633769
Current State [[0.15    0.12    0.03    0.1453  0.13723 0.6     0.55    0.      0.0106
  0.31    0.809  ]]
Logits tf.Tensor([[-0.34482223 -0.03765714  0.061287  ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25903165 0.3521705  0.38879788]], shape=(1, 3), dtype=float32)
Selected action 0
[0.16, 0.2, 0.025, 0.18330000000000002, 0.13723, 0.6, 0.55, 0, 0.0106, 0.31, 0.8089999999999999]
Reward 6.065761034633769
Current State [[0.16    0.2     0.025   0.1833  0.13723 0.6     0.55    0.      0.0106
  0.31    0.809  ]]
Logits tf.Tensor([[-0.33090854 -0.01955691  0.05142931]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26103005 0.35637632 0.38259363]], shape=(1, 3), dtype=float32)
Selected action 1
[0.14, 0.12, 0.025, 0.148, 0.13723, 0.6, 0.72, 0, 0.11939999999999999, 0.353, 0.731]
Reward 4.009099918095528
Episode: 16 | Average Reward: 233 | Episode Reward: 233 | Loss: 279.541 | Steps: 19 | Worker: 0
Current State [[-0.00729134  0.00926575 -0.00490928 -0.00206226 -0.0002588  -0.00540194
  -0.00482317  0.00807081 -0.00267149  0.00052296  0.00743839]]
Logits tf.Tensor([[-0.00390699  0.01221067 -0.02328559]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.33366072 0.33908212 0.3272571 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.14, 0.12, 0.03, 0.151, 0.13723, 0.6, 0.61, 0, 0.0709, 0.41100000000000003, 1.041]
Reward 4.103953615925609
Current State [[0.14    0.12    0.03    0.151   0.13723 0.6     0.61    0.      0.0709
  0.411   1.041  ]]
Logits tf.Tensor([[-0.4082246  -0.08374402  0.06025669]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25120085 0.34748915 0.40130997]], shape=(1, 3), dtype=float32)
Selected action 1
[0.14, 0.12, 0.034, 0.15309999999999999, 0.13723, 0.6, 0.65, 0, 0.0148, 0.39, 1.377]
Reward 5.659807801566688
Current State [[0.14    0.12    0.034   0.1531  0.13723 0.6     0.65    0.      0.0148
  0.39    1.377  ]]
Logits tf.Tensor([[-0.48413855 -0.11047778  0.0506941 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24037266 0.3492721  0.41035524]], shape=(1, 3), dtype=float32)
Selected action 1
[0.05, 0.12, 0.028, 0.1321, 0.13723, 0.6, 0.54, 0, 0.011000000000000001, 0.329, 2.275]
Reward 5.925558285437672
Current State [[0.05    0.12    0.028   0.1321  0.13723 0.6     0.54    0.      0.011
  0.329   2.275  ]]
Logits tf.Tensor([[-0.6265486  -0.31426534  0.06901756]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22876042 0.31261066 0.45862892]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.07, 0.029, 0.1321, 0.13723, 0.6, 0.54, 0, 0.011000000000000001, 0.329, 2.275]
Reward 5.925558285437672
Current State [[0.05    0.07    0.029   0.1321  0.13723 0.6     0.54    0.      0.011
  0.329   2.275  ]]
Logits tf.Tensor([[-0.64492345 -0.32603422  0.06907484]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22636013 0.31138077 0.46225908]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.07, 0.029, 0.116, 0.13723, 0.6, 0.39, 0, 0.1542, 0.266, 1.8539999999999999]
Reward 3.88275683581062
Current State [[0.06    0.07    0.029   0.116   0.13723 0.6     0.39    0.      0.1542
  0.266   1.854  ]]
Logits tf.Tensor([[-0.5028946  -0.26666555  0.08624594]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24576648 0.3112545  0.44297898]], shape=(1, 3), dtype=float32)
Selected action 1
[0.21, 0.12, 0.028, 0.1321, 0.13723, 0.6, 0.53, 0, 0.1318, 0.31, 1.412]
Reward 3.9359018577860545
Current State [[0.21    0.12    0.028   0.1321  0.13723 0.6     0.53    0.      0.1318
  0.31    1.412  ]]
Logits tf.Tensor([[-0.4495091  -0.11895432  0.05547021]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24699338 0.3437506  0.409256  ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.07, 0.037, 0.126, 0.13723, 0.6, 0.71, 0, 0.060700000000000004, 0.335, 0.631]
Reward 4.221834964849839
Current State [[0.07    0.07    0.037   0.126   0.13723 0.6     0.71    0.      0.0607
  0.335   0.631  ]]
Logits tf.Tensor([[-0.3044166  -0.05489462  0.06130989]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26845834 0.3445426  0.38699907]], shape=(1, 3), dtype=float32)
Selected action 0
[0.18, 0.2, 0.032, 0.2, 0.13723, 0.6, 0.71, 0, 0.060700000000000004, 0.335, 0.631]
Reward 4.221834964849839
Current State [[0.18    0.2     0.032   0.2     0.13723 0.6     0.71    0.      0.0607
  0.335   0.631  ]]
Logits tf.Tensor([[-0.30519047 -0.00757027  0.03633471]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2664008  0.35874873 0.37485048]], shape=(1, 3), dtype=float32)
Selected action 0
[0.26, 0.2, 0.032, 0.1885, 0.13723, 0.6, 0.76, 0, 0.07980000000000001, 0.28700000000000003, 1.8809999999999998]
Reward 4.139824110789596
Current State [[0.26    0.2     0.032   0.1885  0.13723 0.6     0.76    0.      0.0798
  0.287   1.881  ]]
Logits tf.Tensor([[-0.55127525 -0.13190518  0.04412152]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23069364 0.35088575 0.41842067]], shape=(1, 3), dtype=float32)
Selected action 1
[0.1, 0.12, 0.032, 0.14709999999999998, 0.13723, 0.6, 0.84, 0, 0.0079, 0.271, 2.1350000000000002]
Reward 9.67013229564543
Current State [[0.1     0.12    0.032   0.1471  0.13723 0.6     0.84    0.      0.0079
  0.271   2.135  ]]
Logits tf.Tensor([[-0.60551053 -0.22393368  0.06224259]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22652912 0.33177277 0.44169807]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.07, 0.036, 0.1556, 0.13723, 0.6, 0.82, 0, 0.009399999999999999, 0.324, 1.564]
Reward 8.185933138572041
Current State [[0.08    0.07    0.036   0.1556  0.13723 0.6     0.82    0.      0.0094
  0.324   1.564  ]]
Logits tf.Tensor([[-0.5231579  -0.14262743  0.0569579 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23533255 0.34430578 0.42036167]], shape=(1, 3), dtype=float32)
Selected action 0
[0.25, 0.2, 0.029, 0.1923, 0.13723, 0.6, 0.82, 0, 0.009399999999999999, 0.324, 1.564]
Reward 8.185933138572041
Current State [[0.25    0.2     0.029   0.1923  0.13723 0.6     0.82    0.      0.0094
  0.324   1.564  ]]
Logits tf.Tensor([[-0.5329366  -0.06945719  0.03183528]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22995688 0.36553836 0.4045048 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.15, 0.12, 0.03, 0.152, 0.13723, 0.6, 0.69, 0, 0.0019, 0.267, 1.432]
Reward 38.00672066924021
Current State [[0.15    0.12    0.03    0.152   0.13723 0.6     0.69    0.      0.0019
  0.267   1.432  ]]
Logits tf.Tensor([[-0.47971398 -0.09011699  0.05553262]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23899116 0.35284314 0.4081657 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.09, 0.07, 0.036, 0.14, 0.13723, 0.6, 0.87, 0, 0.0027, 0.348, 1.202]
Reward 34.28410068147494
Current State [[0.09    0.07    0.036   0.14    0.13723 0.6     0.87    0.      0.0027
  0.348   1.202  ]]
Logits tf.Tensor([[-0.4598466  -0.10222884  0.06218391]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2429918  0.34745854 0.40954965]], shape=(1, 3), dtype=float32)
Selected action 1
[0.17, 0.12, 0.033, 0.1358, 0.13723, 0.6, 0.58, 0, 0.034300000000000004, 0.255, 2.218]
Reward 4.424606295691498
Current State [[0.17    0.12    0.033   0.1358  0.13723 0.6     0.58    0.      0.0343
  0.255   2.218  ]]
Logits tf.Tensor([[-0.60591424 -0.25872943  0.06990767]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22827265 0.32302365 0.44870365]], shape=(1, 3), dtype=float32)
Selected action 1
[0.12, 0.12, 0.031, 0.14809999999999998, 0.13723, 0.6, 0.58, 0, 0.0034999999999999996, 0.317, 1.7730000000000001]
Reward 15.200896680282183
Current State [[0.12    0.12    0.031   0.1481  0.13723 0.6     0.58    0.      0.0035
  0.317   1.773  ]]
Logits tf.Tensor([[-0.5412689  -0.18249644  0.05997749]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23496448 0.33636832 0.42866716]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.07, 0.033, 0.1442, 0.13723, 0.6, 0.58, 0, 0.0034999999999999996, 0.317, 1.7730000000000001]
Reward 15.200896680282183
Current State [[0.07    0.07    0.033   0.1442  0.13723 0.6     0.58    0.      0.0035
  0.317   1.773  ]]
Logits tf.Tensor([[-0.5515774  -0.2070825   0.06375786]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23465621 0.3311649  0.43417895]], shape=(1, 3), dtype=float32)
Selected action 0
[0.16, 0.2, 0.03, 0.1941, 0.13723, 0.6, 0.64, 0, 0.1092, 0.308, 0.9380000000000001]
Reward 4.004243917811571
Current State [[0.16    0.2     0.03    0.1941  0.13723 0.6     0.64    0.      0.1092
  0.308   0.938  ]]
Logits tf.Tensor([[-0.3491992  -0.03110514  0.05635294]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25808874 0.3547444  0.38716683]], shape=(1, 3), dtype=float32)
Selected action 0
[0.21, 0.2, 0.03, 0.18130000000000002, 0.13723, 0.6, 0.84, 0, 0.01, 0.282, 2.085]
Reward 7.972317389687767
Current State [[0.21    0.2     0.03    0.1813  0.13723 0.6     0.84    0.      0.01
  0.282   2.085  ]]
Logits tf.Tensor([[-0.59214115 -0.16382492  0.04720655]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22573791 0.34643352 0.4278285 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.07, 0.033, 0.1472, 0.13723, 0.6, 0.75, 0, 0.0897, 0.25, 1.447]
Reward 4.097422253271209
Episode: 17 | Average Reward: 233 | Episode Reward: 191 | Loss: 408.638 | Steps: 19 | Worker: 0
Current State [[ 5.03133009e-03 -1.60495186e-05 -4.78475206e-03 -7.77075183e-03
   9.26395982e-03 -5.79434971e-03 -5.26638784e-03  9.29746477e-03
  -6.85791103e-03  8.07316547e-03  9.16726262e-03]]
Logits tf.Tensor([[-0.01015941  0.01225177 -0.02300772]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.33223718 0.33976704 0.32799578]], shape=(1, 3), dtype=float32)
Selected action 1
[0.11, 0.12, 0.034, 0.166, 0.13723, 0.6, 0.75, 0, 0.0897, 0.25, 1.447]
Reward 4.097422253271209
Current State [[0.11    0.12    0.034   0.166   0.13723 0.6     0.75    0.      0.0897
  0.25    1.447  ]]
Logits tf.Tensor([[-0.4627803  -0.09813811  0.05994993]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24232878 0.34895313 0.4087181 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.07, 0.031, 0.1269, 0.13723, 0.6, 0.75, 0, 0.0058, 0.292, 1.474]
Reward 11.485050776478605
Current State [[0.04    0.07    0.031   0.1269  0.13723 0.6     0.75    0.      0.0058
  0.292   1.474  ]]
Logits tf.Tensor([[-0.4897977  -0.13644202  0.06556683]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24001458 0.34174177 0.41824368]], shape=(1, 3), dtype=float32)
Selected action 0
[0.2, 0.2, 0.03, 0.1827, 0.13723, 0.6, 0.65, 0, 0.005699999999999999, 0.279, 1.5619999999999998]
Reward 10.221188329577812
Current State [[0.2     0.2     0.03    0.1827  0.13723 0.6     0.65    0.      0.0057
  0.279   1.562  ]]
Logits tf.Tensor([[-0.49293274 -0.08239801  0.04642951]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23682447 0.35704222 0.40613335]], shape=(1, 3), dtype=float32)
Selected action 0
[0.19, 0.2, 0.031, 0.18109999999999998, 0.13723, 0.6, 0.75, 0, 0.1173, 0.33599999999999997, 0.817]
Reward 4.024637792348807
Current State [[0.19    0.2     0.031   0.1811  0.13723 0.6     0.75    0.      0.1173
  0.336   0.817  ]]
Logits tf.Tensor([[-0.3491641  -0.0207094   0.04501855]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25826502 0.3586837  0.38305128]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.07, 0.039, 0.1458, 0.13723, 0.6, 0.62, 0, 0.1119, 0.223, 2.2489999999999997]
Reward 3.9931634141047474
Current State [[0.07    0.07    0.039   0.1458  0.13723 0.6     0.62    0.      0.1119
  0.223   2.249  ]]
Logits tf.Tensor([[-0.6004503  -0.2928636   0.08522014]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23013684 0.31301802 0.45684516]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.07, 0.037, 0.1365, 0.13723, 0.6, 0.62, 0, 0.1119, 0.223, 2.2489999999999997]
Reward 3.9931634141047474
Current State [[0.08    0.07    0.037   0.1365  0.13723 0.6     0.62    0.      0.1119
  0.223   2.249  ]]
Logits tf.Tensor([[-0.6010492  -0.29234827  0.08604919]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22990651 0.31305337 0.4570401 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.07, 0.028, 0.1306, 0.13723, 0.6, 0.61, 0, 0.0098, 0.23199999999999998, 1.988]
Reward 6.6610730343021505
Current State [[0.06    0.07    0.028   0.1306  0.13723 0.6     0.61    0.      0.0098
  0.232   1.988  ]]
Logits tf.Tensor([[-0.56922126 -0.23687401  0.07817743]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23229876 0.3238795  0.44382173]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.07, 0.036, 0.1185, 0.13723, 0.6, 0.52, 0, 0.0625, 0.238, 1.623]
Reward 4.094539020195086
Current State [[0.07    0.07    0.036   0.1185  0.13723 0.6     0.52    0.      0.0625
  0.238   1.623  ]]
Logits tf.Tensor([[-0.48422965 -0.178521    0.08336831]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24262354 0.32938254 0.42799395]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.07, 0.032, 0.1429, 0.13723, 0.6, 0.52, 0, 0.0625, 0.238, 1.623]
Reward 4.094539020195086
Current State [[0.04    0.07    0.032   0.1429  0.13723 0.6     0.52    0.      0.0625
  0.238   1.623  ]]
Logits tf.Tensor([[-0.48197788 -0.18181023  0.08164511]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24348007 0.32871887 0.427801  ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.07, 0.032, 0.1288, 0.13723, 0.6, 0.45, 0, 0.319, 0.252, 1.875]
Reward 3.8431315765437124
Current State [[0.08    0.07    0.032   0.1288  0.13723 0.6     0.45    0.      0.319
  0.252   1.875  ]]
Logits tf.Tensor([[-0.478862   -0.26945722  0.09027354]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2500198  0.30826038 0.44171977]], shape=(1, 3), dtype=float32)
Selected action 2
[0.12, 0.07, 0.034, 0.12940000000000002, 0.13723, 0.6, 0.63, 0, 0.005600000000000001, 0.229, 2.513]
Reward 10.072977833894065
Current State [[0.12    0.07    0.034   0.1294  0.13723 0.6     0.63    0.      0.0056
  0.229   2.513  ]]
Logits tf.Tensor([[-0.67867905 -0.32758206  0.07542459]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2199576  0.31247732 0.46756506]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.07, 0.033, 0.13269999999999998, 0.13723, 0.6, 0.66, 0, 0.0054, 0.316, 1.278]
Reward 10.797389497205423
Current State [[0.07    0.07    0.033   0.1327  0.13723 0.6     0.66    0.      0.0054
  0.316   1.278  ]]
Logits tf.Tensor([[-0.453752   -0.10952976  0.06592423]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24435686 0.34476116 0.4108819 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.12, 0.12, 0.031, 0.1519, 0.13723, 0.6, 0.66, 0, 0.0054, 0.316, 1.278]
Reward 10.797389497205423
Current State [[0.12    0.12    0.031   0.1519  0.13723 0.6     0.66    0.      0.0054
  0.316   1.278  ]]
Logits tf.Tensor([[-0.45452252 -0.08327067  0.05525362]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24304487 0.35230523 0.40464988]], shape=(1, 3), dtype=float32)
Selected action 1
[0.12, 0.12, 0.032, 0.15380000000000002, 0.13723, 0.6, 0.78, 0, 0.0032, 0.361, 0.621]
Reward 23.883016987998886
Current State [[0.12    0.12    0.032   0.1538  0.13723 0.6     0.78    0.      0.0032
  0.361   0.621  ]]
Logits tf.Tensor([[-0.32309946 -0.02930184  0.04093289]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26450595 0.354838   0.380656  ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.11, 0.2, 0.026, 0.15769999999999998, 0.13723, 0.6, 0.84, 0, 0.0032, 0.314, 1.829]
Reward 26.210206649874106
Current State [[0.11    0.2     0.026   0.1577  0.13723 0.6     0.84    0.      0.0032
  0.314   1.829  ]]
Logits tf.Tensor([[-0.5454725  -0.1395172   0.04814231]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23195092 0.348097   0.4199521 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.2, 0.12, 0.026, 0.1365, 0.13723, 0.6, 0.63, 0, 0.0128, 0.389, 0.679]
Reward 5.926448185277085
Current State [[0.2     0.12    0.026   0.1365  0.13723 0.6     0.63    0.      0.0128
  0.389   0.679  ]]
Logits tf.Tensor([[-0.34916115 -0.02136744  0.05074635]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25775924 0.3577447  0.384496  ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.07, 0.033, 0.1367, 0.13723, 0.6, 0.57, 0, 0.0259, 0.348, 0.761]
Reward 4.640977740122915
Current State [[0.06    0.07    0.033   0.1367  0.13723 0.6     0.57    0.      0.0259
  0.348   0.761  ]]
Logits tf.Tensor([[-0.33576328 -0.06422807  0.07551208]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2617309  0.34338495 0.39488408]], shape=(1, 3), dtype=float32)
Selected action 1
[0.08, 0.12, 0.026, 0.1673, 0.13723, 0.6, 0.57, 0, 0.0259, 0.348, 0.761]
Reward 4.640977740122915
Current State [[0.08    0.12    0.026   0.1673  0.13723 0.6     0.57    0.      0.0259
  0.348   0.761  ]]
Logits tf.Tensor([[-0.33192068 -0.0497817   0.06686869]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2620557  0.34747612 0.39046812]], shape=(1, 3), dtype=float32)
Selected action 1
[0.1, 0.12, 0.03, 0.1571, 0.13723, 0.6, 0.66, 0, 0.0054, 0.306, 1.444]
Reward 10.91987390867571
Current State [[0.1     0.12    0.03    0.1571  0.13723 0.6     0.66    0.      0.0054
  0.306   1.444  ]]
Logits tf.Tensor([[-0.48138794 -0.1041971   0.05665351]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23976032 0.34961435 0.41062537]], shape=(1, 3), dtype=float32)
Selected action 0
[0.14, 0.2, 0.024, 0.151, 0.13723, 0.6, 0.73, 0, 0.0174, 0.29700000000000004, 1.576]
Reward 5.564233576872692
Episode: 18 | Average Reward: 232 | Episode Reward: 169 | Loss: 283.341 | Steps: 19 | Worker: 0
Current State [[-0.00763399 -0.00474883 -0.00435906  0.00758303  0.0032183  -0.00792948
  -0.00526116  0.00895664  0.00176234 -0.00575011 -0.00311141]]
Logits tf.Tensor([[-0.00451471  0.01425776 -0.02379035]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.33334905 0.33966592 0.32698506]], shape=(1, 3), dtype=float32)
Selected action 1
[0.14, 0.12, 0.025, 0.1388, 0.13723, 0.6, 0.86, 0, 0.0096, 0.356, 0.5700000000000001]
Reward 8.334629839358113
Current State [[0.14    0.12    0.025   0.1388  0.13723 0.6     0.86    0.      0.0096
  0.356   0.57   ]]
Logits tf.Tensor([[-0.32363886 -0.02756537  0.03497761]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26483634 0.35609078 0.37907293]], shape=(1, 3), dtype=float32)
Selected action 1
[0.14, 0.12, 0.025, 0.176, 0.13723, 0.6, 0.9, 0, 0.0025, 0.33999999999999997, 0.23700000000000002]
Reward 38.217674468982146
Current State [[0.14    0.12    0.025   0.176   0.13723 0.6     0.9     0.      0.0025
  0.34    0.237  ]]
Logits tf.Tensor([[-0.23529436 -0.0247904   0.01143281]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.28456545 0.35123914 0.3641954 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.09, 0.07, 0.03, 0.1245, 0.13723, 0.6, 0.73, 0, 0.004699999999999999, 0.33999999999999997, 0.8779999999999999]
Reward 14.014776412458344
Current State [[0.09    0.07    0.03    0.1245  0.13723 0.6     0.73    0.      0.0047
  0.34    0.878  ]]
Logits tf.Tensor([[-0.3863253  -0.06382386  0.06705661]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25289553 0.34914175 0.39796275]], shape=(1, 3), dtype=float32)
Selected action 1
[0.14, 0.12, 0.025, 0.14909999999999998, 0.13723, 0.6, 0.73, 0, 0.004699999999999999, 0.33999999999999997, 0.8779999999999999]
Reward 14.014776412458344
Current State [[0.14    0.12    0.025   0.1491  0.13723 0.6     0.73    0.      0.0047
  0.34    0.878  ]]
Logits tf.Tensor([[-0.39102268 -0.03958453  0.0544595 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25110784 0.35685185 0.3920403 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.13, 0.2, 0.024, 0.1824, 0.13723, 0.6, 0.83, 0, 0.0029, 0.368, 1.213]
Reward 29.778111355628962
Current State [[0.13    0.2     0.024   0.1824  0.13723 0.6     0.83    0.      0.0029
  0.368   1.213  ]]
Logits tf.Tensor([[-0.46033162 -0.0624373   0.04699218]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2409913  0.35876054 0.4002481 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.14, 0.12, 0.028, 0.156, 0.13723, 0.6, 0.75, 0, 0.018600000000000002, 0.302, 1.087]
Reward 5.474027181122611
Current State [[0.14    0.12    0.028   0.156   0.13723 0.6     0.75    0.      0.0186
  0.302   1.087  ]]
Logits tf.Tensor([[-0.42974073 -0.05341364  0.05838575]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24472708 0.35654867 0.39872426]], shape=(1, 3), dtype=float32)
Selected action 1
[0.09, 0.12, 0.025, 0.1469, 0.13723, 0.6, 0.66, 0, 0.006500000000000001, 0.324, 2.0100000000000002]
Reward 9.266775725295192
Current State [[0.09    0.12    0.025   0.1469  0.13723 0.6     0.66    0.      0.0065
  0.324   2.01   ]]
Logits tf.Tensor([[-0.60402787 -0.22308801  0.06607839]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22634141 0.33128676 0.44237185]], shape=(1, 3), dtype=float32)
Selected action 2
[0.1, 0.07, 0.03, 0.1377, 0.13723, 0.6, 0.88, 0, 0.061200000000000004, 0.28500000000000003, 0.461]
Reward 4.32702886935352
Current State [[0.1     0.07    0.03    0.1377  0.13723 0.6     0.88    0.      0.0612
  0.285   0.461  ]]
Logits tf.Tensor([[-0.2896396  -0.03835022  0.0383341 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2721952  0.34995645 0.3778484 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.15, 0.12, 0.025, 0.18869999999999998, 0.13723, 0.6, 0.88, 0, 0.061200000000000004, 0.28500000000000003, 0.461]
Reward 4.32702886935352
Current State [[0.15    0.12    0.025   0.1887  0.13723 0.6     0.88    0.      0.0612
  0.285   0.461  ]]
Logits tf.Tensor([[-0.29568183 -0.01563636  0.02103301]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.27057734 0.35802525 0.37139747]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.07, 0.03, 0.1235, 0.13723, 0.6, 0.75, 0, 0.0049, 0.318, 1.269]
Reward 13.632268824446381
Current State [[0.08    0.07    0.03    0.1235  0.13723 0.6     0.75    0.      0.0049
  0.318   1.269  ]]
Logits tf.Tensor([[-0.47055024 -0.10534589  0.06806912]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24070589 0.34681106 0.41248307]], shape=(1, 3), dtype=float32)
Selected action 1
[0.18, 0.12, 0.025, 0.1759, 0.13723, 0.6, 0.56, 0, 0.013000000000000001, 0.271, 0.6839999999999999]
Reward 5.623082352796759
Current State [[0.18    0.12    0.025   0.1759  0.13723 0.6     0.56    0.      0.013
  0.271   0.684  ]]
Logits tf.Tensor([[-0.33265626 -0.00043994  0.04975318]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25907633 0.36116645 0.3797572 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.09, 0.07, 0.033, 0.1404, 0.13723, 0.6, 0.72, 0, 0.005600000000000001, 0.352, 0.433]
Reward 11.386149392716975
Current State [[0.09    0.07    0.033   0.1404  0.13723 0.6     0.72    0.      0.0056
  0.352   0.433  ]]
Logits tf.Tensor([[-0.27173686 -0.03023652  0.05417727]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2733395 0.3480043 0.3786562]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.07, 0.032, 0.1222, 0.13723, 0.6, 0.72, 0, 0.005600000000000001, 0.352, 0.433]
Reward 11.386149392716975
Current State [[0.06    0.07    0.032   0.1222  0.13723 0.6     0.72    0.      0.0056
  0.352   0.433  ]]
Logits tf.Tensor([[-0.2642014  -0.03878879  0.05874234]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2751768  0.34475237 0.3800708 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.15, 0.2, 0.024, 0.1566, 0.13723, 0.6, 0.44, 0, 0.0432, 0.259, 1.108]
Reward 4.165363947040093
Current State [[0.15    0.2     0.024   0.1566  0.13723 0.6     0.44    0.      0.0432
  0.259   1.108  ]]
Logits tf.Tensor([[-0.3653562  -0.0429174   0.05767511]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25594613 0.35333115 0.39072275]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.07, 0.029, 0.12079999999999999, 0.13723, 0.6, 0.71, 0, 0.0832, 0.331, 1.226]
Reward 4.104386514564697
Current State [[0.07    0.07    0.029   0.1208  0.13723 0.6     0.71    0.      0.0832
  0.331   1.226  ]]
Logits tf.Tensor([[-0.43705797 -0.11234812  0.07415349]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24685636 0.34155765 0.41158602]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.07, 0.039, 0.1189, 0.13723, 0.6, 0.77, 0, 0.0095, 0.318, 1.017]
Reward 7.769580133535124
Current State [[0.08    0.07    0.039   0.1189  0.13723 0.6     0.77    0.      0.0095
  0.318   1.017  ]]
Logits tf.Tensor([[-0.41058278 -0.07355899  0.07316266]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24857622 0.3481987  0.4032251 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.09, 0.07, 0.035, 0.1296, 0.13723, 0.6, 0.77, 0, 0.0095, 0.318, 1.017]
Reward 7.769580133535124
Current State [[0.09    0.07    0.035   0.1296  0.13723 0.6     0.77    0.      0.0095
  0.318   1.017  ]]
Logits tf.Tensor([[-0.41461122 -0.07093401  0.07013549]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24789988 0.34956938 0.4025308 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.07, 0.03, 0.125, 0.13723, 0.6, 0.54, 0, 0.0131, 0.298, 1.561]
Reward 5.517537942135707
Current State [[0.06    0.07    0.03    0.125   0.13723 0.6     0.54    0.      0.0131
  0.298   1.561  ]]
Logits tf.Tensor([[-0.50560117 -0.16525221  0.07419211]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23860043 0.3353381  0.42606145]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.07, 0.031, 0.1375, 0.13723, 0.6, 0.58, 0, 0.043, 0.381, 0.782]
Reward 4.295536534727476
Current State [[0.07    0.07    0.031   0.1375  0.13723 0.6     0.58    0.      0.043
  0.381   0.782  ]]
Logits tf.Tensor([[-0.34885883 -0.06867685  0.07635013]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25951913 0.34344    0.3970409 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.07, 0.038, 0.1235, 0.13723, 0.6, 0.6, 0, 0.005600000000000001, 0.34199999999999997, 1.1019999999999999]
Reward 9.662965202157466
Episode: 19 | Average Reward: 232 | Episode Reward: 213 | Loss: 262.191 | Steps: 19 | Worker: 0
Current State [[ 0.00391456 -0.00611631  0.00160474  0.0007745   0.00151297 -0.00946476
  -0.00372058  0.00692195  0.00386599  0.00365462  0.0057169 ]]
Logits tf.Tensor([[-0.0091568   0.0135251  -0.02456792]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3324857  0.34011328 0.327401  ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.14, 0.12, 0.027, 0.1463, 0.13723, 0.6, 0.6, 0, 0.005600000000000001, 0.34199999999999997, 1.1019999999999999]
Reward 9.662965202157466
Current State [[0.14    0.12    0.027   0.1463  0.13723 0.6     0.6     0.      0.0056
  0.342   1.102  ]]
Logits tf.Tensor([[-0.4388385  -0.0643429   0.06047668]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24379241 0.354537   0.40167058]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.07, 0.033, 0.1321, 0.13723, 0.6, 0.64, 0, 0.0060999999999999995, 0.306, 1.908]
Reward 9.513027732104607
Current State [[0.06    0.07    0.033   0.1321  0.13723 0.6     0.64    0.      0.0061
  0.306   1.908  ]]
Logits tf.Tensor([[-0.5964223  -0.2199468   0.07912505]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22612934 0.32950208 0.44436863]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.07, 0.037, 0.1288, 0.13723, 0.6, 0.57, 0, 0.0204, 0.308, 1.638]
Reward 4.9015912962771555
Current State [[0.08    0.07    0.037   0.1288  0.13723 0.6     0.57    0.      0.0204
  0.308   1.638  ]]
Logits tf.Tensor([[-0.536091   -0.17148913  0.07733054]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23328076 0.33591044 0.43080875]], shape=(1, 3), dtype=float32)
Selected action 0
[0.1, 0.2, 0.023, 0.13269999999999998, 0.13723, 0.6, 0.38, 0, 0.22030000000000002, 0.27, 1.954]
Reward 3.853315853153415
Current State [[0.1     0.2     0.023   0.1327  0.13723 0.6     0.38    0.      0.2203
  0.27    1.954  ]]
Logits tf.Tensor([[-0.49125865 -0.24138029  0.09092278]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24547057 0.31515214 0.43937734]], shape=(1, 3), dtype=float32)
Selected action 0
[0.13, 0.2, 0.024, 0.1694, 0.13723, 0.6, 0.38, 0, 0.22030000000000002, 0.27, 1.954]
Reward 3.853315853153415
Current State [[0.13    0.2     0.024   0.1694  0.13723 0.6     0.38    0.      0.2203
  0.27    1.954  ]]
Logits tf.Tensor([[-0.49656084 -0.22899586  0.08053908]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24463964 0.31968984 0.4356705 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.23, 0.2, 0.026, 0.1741, 0.13723, 0.6, 0.47, 0, 0.19140000000000001, 0.391, 1.452]
Reward 3.879719051313139
Current State [[0.23    0.2     0.026   0.1741  0.13723 0.6     0.47    0.      0.1914
  0.391   1.452  ]]
Logits tf.Tensor([[-0.45453843 -0.11744745  0.05023823]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24645826 0.34525514 0.40828657]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.07, 0.038, 0.1429, 0.13723, 0.6, 0.82, 0, 0.0051, 0.374, 0.24700000000000003]
Reward 14.55927952053823
Current State [[0.07    0.07    0.038   0.1429  0.13723 0.6     0.82    0.      0.0051
  0.374   0.247  ]]
Logits tf.Tensor([[-0.22517228 -0.04182573  0.04552633]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2847291  0.34202528 0.37324566]], shape=(1, 3), dtype=float32)
Selected action 1
[0.17, 0.12, 0.036, 0.1462, 0.13723, 0.6, 0.8, 0, 0.0028000000000000004, 0.288, 1.565]
Reward 29.652196808625586
Current State [[0.17    0.12    0.036   0.1462  0.13723 0.6     0.8     0.      0.0028
  0.288   1.565  ]]
Logits tf.Tensor([[-0.5433311  -0.09440151  0.06068935]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2274747  0.35636964 0.41615567]], shape=(1, 3), dtype=float32)
Selected action 1
[0.13, 0.12, 0.03, 0.1615, 0.13723, 0.6, 0.8, 0, 0.0028000000000000004, 0.288, 1.565]
Reward 29.652196808625586
Current State [[0.13    0.12    0.03    0.1615  0.13723 0.6     0.8     0.      0.0028
  0.288   1.565  ]]
Logits tf.Tensor([[-0.53461856 -0.10224267  0.05902264]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2298067  0.35411242 0.41608092]], shape=(1, 3), dtype=float32)
Selected action 1
[0.12, 0.12, 0.037, 0.14809999999999998, 0.13723, 0.6, 0.74, 0, 0.0012, 0.277, 1.877]
Reward 48.960371002154766
Current State [[1.2000e-01 1.2000e-01 3.7000e-02 1.4810e-01 1.3723e-01 6.0000e-01
  7.4000e-01 0.0000e+00 1.2000e-03 2.7700e-01 1.8770e+00]]
Logits tf.Tensor([[-0.57918024 -0.16503255  0.07139946]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22574729 0.34157383 0.4326789 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.07, 0.033, 0.1367, 0.13723, 0.6, 0.78, 0, 0.009399999999999999, 0.308, 1.9149999999999998]
Reward 7.920092065399732
Current State [[0.05    0.07    0.033   0.1367  0.13723 0.6     0.78    0.      0.0094
  0.308   1.915  ]]
Logits tf.Tensor([[-0.60409606 -0.20593666  0.07349794]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22430497 0.3340084  0.44168663]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.07, 0.034, 0.12079999999999999, 0.13723, 0.6, 0.71, 0, 0.0023, 0.266, 1.557]
Reward 32.501722405831
Current State [[0.08    0.07    0.034   0.1208  0.13723 0.6     0.71    0.      0.0023
  0.266   1.557  ]]
Logits tf.Tensor([[-0.52304435 -0.13200815  0.07507838]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23270895 0.34406295 0.42322806]], shape=(1, 3), dtype=float32)
Selected action 1
[0.14, 0.12, 0.034, 0.1712, 0.13723, 0.6, 0.71, 0, 0.0023, 0.266, 1.557]
Reward 32.501722405831
Current State [[0.14    0.12    0.034   0.1712  0.13723 0.6     0.71    0.      0.0023
  0.266   1.557  ]]
Logits tf.Tensor([[-0.52271515 -0.09907416  0.06268787]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23130865 0.353327   0.41536433]], shape=(1, 3), dtype=float32)
Selected action 0
[0.13, 0.2, 0.03, 0.19390000000000002, 0.13723, 0.6, 0.84, 0, 0.0028000000000000004, 0.33399999999999996, 1.109]
Reward 31.570776850966997
Current State [[0.13    0.2     0.03    0.1939  0.13723 0.6     0.84    0.      0.0028
  0.334   1.109  ]]
Logits tf.Tensor([[-0.43498966 -0.03790865  0.05145742]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24307224 0.36156422 0.39536354]], shape=(1, 3), dtype=float32)
Selected action 0
[0.19, 0.2, 0.027, 0.1596, 0.13723, 0.6, 0.77, 0, 0.04190000000000001, 0.314, 2.072]
Reward 4.487944754554847
Current State [[0.19    0.2     0.027   0.1596  0.13723 0.6     0.77    0.      0.0419
  0.314   2.072  ]]
Logits tf.Tensor([[-0.60871285 -0.17504834  0.06359769]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22214031 0.34274057 0.4351191 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.15, 0.12, 0.028, 0.15769999999999998, 0.13723, 0.6, 0.62, 0, 0.20600000000000002, 0.29500000000000004, 1.658]
Reward 3.8989056815691363
Current State [[0.15    0.12    0.028   0.1577  0.13723 0.6     0.62    0.      0.206
  0.295   1.658  ]]
Logits tf.Tensor([[-0.49821177 -0.15839161  0.0689316 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23992793 0.33702558 0.42304647]], shape=(1, 3), dtype=float32)
Selected action 1
[0.07, 0.12, 0.032, 0.1275, 0.13723, 0.6, 0.84, 0, 0.0023, 0.367, 0.502]
Reward 38.395985867582816
Current State [[0.07    0.12    0.032   0.1275  0.13723 0.6     0.84    0.      0.0023
  0.367   0.502  ]]
Logits tf.Tensor([[-0.29290166 -0.03908548  0.05008369]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2704104  0.34854135 0.3810483 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.21, 0.2, 0.029, 0.19219999999999998, 0.13723, 0.6, 0.84, 0, 0.0023, 0.367, 0.502]
Reward 38.395985867582816
Current State [[0.21    0.2     0.029   0.1922  0.13723 0.6     0.84    0.      0.0023
  0.367   0.502  ]]
Logits tf.Tensor([[-0.3092974   0.00826057  0.01737946]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2659488  0.36535218 0.36869904]], shape=(1, 3), dtype=float32)
Selected action 1
[0.13, 0.12, 0.029, 0.1686, 0.13723, 0.6, 0.76, 0, 0.0060999999999999995, 0.358, 1.365]
Reward 11.092888888779079
Current State [[0.13    0.12    0.029   0.1686  0.13723 0.6     0.76    0.      0.0061
  0.358   1.365  ]]
Logits tf.Tensor([[-0.5073897  -0.09222269  0.05549724]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23417243 0.3546831  0.4111445 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.21, 0.2, 0.029, 0.184, 0.13723, 0.6, 0.73, 0, 0.0025, 0.29700000000000004, 2.199]
Reward 30.648753509337922
Episode: 20 | Average Reward: 234 | Episode Reward: 389 | Loss: 1669.115 | Steps: 19 | Worker: 0
Current State [[ 0.00383546 -0.00595749 -0.0084274   0.00307859  0.00474267 -0.00085873
  -0.00878853  0.00220316 -0.00896781  0.00137839 -0.00759259]]
Logits tf.Tensor([[-0.0079705   0.01349529 -0.02714341]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.33303276 0.34025887 0.3267084 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.07, 0.032, 0.1365, 0.13723, 0.6, 0.76, 0, 0.0048, 0.372, 0.8720000000000001]
Reward 14.056830363903996
Current State [[0.03    0.07    0.032   0.1365  0.13723 0.6     0.76    0.      0.0048
  0.372   0.872  ]]
Logits tf.Tensor([[-0.38067707 -0.07783613  0.07135652]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2547638  0.34487358 0.40036258]], shape=(1, 3), dtype=float32)
Selected action 0
[0.23, 0.2, 0.032, 0.1608, 0.13723, 0.6, 0.68, 0, 0.010700000000000001, 0.266, 2.103]
Reward 6.722192171545224
Current State [[0.23    0.2     0.032   0.1608  0.13723 0.6     0.68    0.      0.0107
  0.266   2.103  ]]
Logits tf.Tensor([[-0.60531193 -0.16943052  0.06733603]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22193892 0.34318978 0.4348713 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.14, 0.12, 0.036, 0.18130000000000002, 0.13723, 0.6, 0.68, 0, 0.010700000000000001, 0.266, 2.103]
Reward 6.722192171545224
Current State [[0.14    0.12    0.036   0.1813  0.13723 0.6     0.68    0.      0.0107
  0.266   2.103  ]]
Logits tf.Tensor([[-0.62297744 -0.20722711  0.07015427]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22146058 0.33562517 0.44291428]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.07, 0.033, 0.1333, 0.13723, 0.6, 0.82, 0, 0.0726, 0.309, 2.007]
Reward 4.208880930151382
Current State [[0.07    0.07    0.033   0.1333  0.13723 0.6     0.82    0.      0.0726
  0.309   2.007  ]]
Logits tf.Tensor([[-0.6171268  -0.22106963  0.07698832]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2228218  0.33110303 0.44607517]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.07, 0.036, 0.15769999999999998, 0.13723, 0.6, 0.61, 0, 0.025699999999999997, 0.258, 2.455]
Reward 4.710682012857139
Current State [[0.07    0.07    0.036   0.1577  0.13723 0.6     0.61    0.      0.0257
  0.258   2.455  ]]
Logits tf.Tensor([[-0.68731207 -0.32384786  0.08454823]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.21729253 0.31253257 0.4701749 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.1, 0.07, 0.038, 0.1388, 0.13723, 0.6, 0.63, 0, 0.0128, 0.23199999999999998, 2.869]
Reward 5.906628328163759
Current State [[0.1     0.07    0.038   0.1388  0.13723 0.6     0.63    0.      0.0128
  0.232   2.869  ]]
Logits tf.Tensor([[-0.7650878  -0.39801338  0.08983288]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.20856392 0.30106312 0.49037296]], shape=(1, 3), dtype=float32)
Selected action 0
[0.26, 0.2, 0.028, 0.19419999999999998, 0.13723, 0.6, 0.63, 0, 0.0128, 0.23199999999999998, 2.869]
Reward 5.906628328163759
Current State [[0.26    0.2     0.028   0.1942  0.13723 0.6     0.63    0.      0.0128
  0.232   2.869  ]]
Logits tf.Tensor([[-0.7498588  -0.31916294  0.06860723]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2081015  0.32012826 0.4717702 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.08, 0.2, 0.03, 0.2135, 0.13723, 0.6, 0.64, 0, 0.006500000000000001, 0.341, 1.879]
Reward 8.922886684458561
Current State [[0.08    0.2     0.03    0.2135  0.13723 0.6     0.64    0.      0.0065
  0.341   1.879  ]]
Logits tf.Tensor([[-0.5643948  -0.16375954  0.05905743]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22945626 0.342526   0.4280177 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.07, 0.034, 0.14709999999999998, 0.13723, 0.6, 0.87, 0, 0.0005, 0.337, 1.8370000000000002]
Reward 49.999995697188545
Current State [[6.0000e-02 7.0000e-02 3.4000e-02 1.4710e-01 1.3723e-01 6.0000e-01
  8.7000e-01 0.0000e+00 5.0000e-04 3.3700e-01 1.8370e+00]]
Logits tf.Tensor([[-0.60635024 -0.17704119  0.06240778]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.222816   0.34228903 0.43489492]], shape=(1, 3), dtype=float32)
Selected action 0
[0.17, 0.2, 0.024, 0.162, 0.13723, 0.6, 0.54, 0, 0.1558, 0.227, 2.649]
Reward 3.9167760702025554
Current State [[0.17    0.2     0.024   0.162   0.13723 0.6     0.54    0.      0.1558
  0.227   2.649  ]]
Logits tf.Tensor([[-0.65674645 -0.32798484  0.09198558]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22204638 0.30847716 0.4694765 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.07, 0.032, 0.1375, 0.13723, 0.6, 0.54, 0, 0.1558, 0.227, 2.649]
Reward 3.9167760702025554
Current State [[0.08    0.07    0.032   0.1375  0.13723 0.6     0.54    0.      0.1558
  0.227   2.649  ]]
Logits tf.Tensor([[-0.6836626  -0.3830867   0.10542623]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.21968238 0.29671103 0.48360655]], shape=(1, 3), dtype=float32)
Selected action 0
[0.2, 0.2, 0.026, 0.19619999999999999, 0.13723, 0.6, 0.55, 0, 0.0258, 0.286, 1.41]
Reward 4.61143032556219
Current State [[0.2     0.2     0.026   0.1962  0.13723 0.6     0.55    0.      0.0258
  0.286   1.41   ]]
Logits tf.Tensor([[-0.46469188 -0.06031488  0.04697112]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24001354 0.3596288  0.4003577 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.13, 0.12, 0.032, 0.1551, 0.13723, 0.6, 0.79, 0, 0.0091, 0.383, 1.037]
Reward 8.165366632887455
Current State [[0.13    0.12    0.032   0.1551  0.13723 0.6     0.79    0.      0.0091
  0.383   1.037  ]]
Logits tf.Tensor([[-0.4388177  -0.05671011  0.05748169]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24342738 0.35671115 0.39986145]], shape=(1, 3), dtype=float32)
Selected action 1
[0.03, 0.12, 0.026, 0.1347, 0.13723, 0.6, 0.83, 0, 0.0059, 0.31, 1.249]
Reward 12.449876250136823
Current State [[0.03    0.12    0.026   0.1347  0.13723 0.6     0.83    0.      0.0059
  0.31    1.249  ]]
Logits tf.Tensor([[-0.45381084 -0.10068293  0.07159289]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24303377 0.34596178 0.41100448]], shape=(1, 3), dtype=float32)
Selected action 1
[0.19, 0.12, 0.032, 0.132, 0.13723, 0.6, 0.45, 0, 0.09369999999999999, 0.421, 1.191]
Reward 3.964933830424883
Current State [[0.19    0.12    0.032   0.132   0.13723 0.6     0.45    0.      0.0937
  0.421   1.191  ]]
Logits tf.Tensor([[-0.45458946 -0.09876019  0.06419029]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24346657 0.34751537 0.40901807]], shape=(1, 3), dtype=float32)
Selected action 0
[0.15, 0.2, 0.025, 0.1571, 0.13723, 0.6, 0.45, 0, 0.09369999999999999, 0.421, 1.191]
Reward 3.964933830424883
Current State [[0.15    0.2     0.025   0.1571  0.13723 0.6     0.45    0.      0.0937
  0.421   1.191  ]]
Logits tf.Tensor([[-0.42133278 -0.08551745  0.05899987]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24902304 0.3484033  0.40257365]], shape=(1, 3), dtype=float32)
Selected action 0
[0.16, 0.2, 0.024, 0.1784, 0.13723, 0.6, 0.44, 0, 0.4677, 0.40700000000000003, 1.609]
Reward 3.8258620613732086
Current State [[0.16    0.2     0.024   0.1784  0.13723 0.6     0.44    0.      0.4677
  0.407   1.609  ]]
Logits tf.Tensor([[-0.4059868  -0.20645073  0.06782462]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26130536 0.31901106 0.4196836 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.1, 0.07, 0.033, 0.1321, 0.13723, 0.6, 0.87, 0, 0.0966, 0.316, 0.062]
Reward 4.122071435668991
Current State [[0.1     0.07    0.033   0.1321  0.13723 0.6     0.87    0.      0.0966
  0.316   0.062  ]]
Logits tf.Tensor([[-0.1609021  -0.04432377  0.03005537]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2999352  0.3370208  0.36304393]], shape=(1, 3), dtype=float32)
Selected action 0
[0.08, 0.2, 0.023, 0.138, 0.13723, 0.6, 0.68, 0, 0.0068000000000000005, 0.29100000000000004, 1.23]
Reward 9.092922459083596
Current State [[0.08    0.2     0.023   0.138   0.13723 0.6     0.68    0.      0.0068
  0.291   1.23   ]]
Logits tf.Tensor([[-0.42900562 -0.06483036  0.06551886]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24515544 0.3528587  0.40198585]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.07, 0.031, 0.15, 0.13723, 0.6, 0.76, 0, 0.0054, 0.314, 0.9470000000000001]
Reward 12.672734222049591
Episode: 21 | Average Reward: 233 | Episode Reward: 177 | Loss: 257.651 | Steps: 19 | Worker: 0
Current State [[ 0.00679035 -0.00200742 -0.00026289  0.00278637 -0.00392367  0.00386232
  -0.00818561 -0.00198986  0.00385541 -0.00590525 -0.00885741]]
Logits tf.Tensor([[-0.00454663  0.01530452 -0.02450525]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.33330125 0.33998376 0.32671496]], shape=(1, 3), dtype=float32)
Selected action 0
[0.1, 0.2, 0.022, 0.15309999999999999, 0.13723, 0.6, 0.76, 0, 0.0054, 0.314, 0.9470000000000001]
Reward 12.672734222049591
Current State [[0.1     0.2     0.022   0.1531  0.13723 0.6     0.76    0.      0.0054
  0.314   0.947  ]]
Logits tf.Tensor([[-0.379482   -0.03135329  0.05222308]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2527617  0.35801536 0.38922292]], shape=(1, 3), dtype=float32)
Selected action 2
[0.09, 0.07, 0.024, 0.1434, 0.13723, 0.6, 0.82, 0, 0.0031, 0.393, 1.169]
Reward 27.18275692212237
Current State [[0.09    0.07    0.024   0.1434  0.13723 0.6     0.82    0.      0.0031
  0.393   1.169  ]]
Logits tf.Tensor([[-0.47339627 -0.09581096  0.06115076]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24007109 0.35020557 0.4097233 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.07, 0.033, 0.1377, 0.13723, 0.6, 0.72, 0, 0.0044, 0.32799999999999996, 0.8390000000000001]
Reward 14.887737594316677
Current State [[0.08    0.07    0.033   0.1377  0.13723 0.6     0.72    0.      0.0044
  0.328   0.839  ]]
Logits tf.Tensor([[-0.37681785 -0.05173515  0.06488642]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25383925 0.3513504  0.39481035]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.07, 0.033, 0.1151, 0.13723, 0.6, 0.72, 0, 0.0052, 0.312, 1.327]
Reward 12.281102074186826
Current State [[0.08    0.07    0.033   0.1151  0.13723 0.6     0.72    0.      0.0052
  0.312   1.327  ]]
Logits tf.Tensor([[-0.48063916 -0.10345431  0.06867248]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23865016 0.3479934  0.41335645]], shape=(1, 3), dtype=float32)
Selected action 1
[0.15, 0.12, 0.032, 0.1615, 0.13723, 0.6, 0.72, 0, 0.0052, 0.312, 1.327]
Reward 12.281102074186826
Current State [[0.15    0.12    0.032   0.1615  0.13723 0.6     0.72    0.      0.0052
  0.312   1.327  ]]
Logits tf.Tensor([[-0.48862115 -0.07040537  0.05198805]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23605499 0.35862616 0.40531883]], shape=(1, 3), dtype=float32)
Selected action 1
[0.16, 0.12, 0.029, 0.1615, 0.13723, 0.6, 0.63, 0, 0.0161, 0.302, 0.998]
Reward 5.407244846354568
Current State [[0.16    0.12    0.029   0.1615  0.13723 0.6     0.63    0.      0.0161
  0.302   0.998  ]]
Logits tf.Tensor([[-0.4140838  -0.03369757  0.05601198]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24612373 0.36004198 0.39383423]], shape=(1, 3), dtype=float32)
Selected action 0
[0.15, 0.2, 0.025, 0.1529, 0.13723, 0.6, 0.48, 0, 0.0058, 0.355, 0.772]
Reward 7.958255939337007
Current State [[0.15    0.2     0.025   0.1529  0.13723 0.6     0.48    0.      0.0058
  0.355   0.772  ]]
Logits tf.Tensor([[-0.33667013 -0.01336177  0.05693129]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2587991  0.35758048 0.38362038]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.07, 0.032, 0.1463, 0.13723, 0.6, 0.48, 0, 0.0058, 0.355, 0.772]
Reward 7.958255939337007
Current State [[0.07    0.07    0.032   0.1463  0.13723 0.6     0.48    0.      0.0058
  0.355   0.772  ]]
Logits tf.Tensor([[-0.34650642 -0.056528    0.0725262 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25927636 0.34649655 0.39422706]], shape=(1, 3), dtype=float32)
Selected action 1
[0.12, 0.12, 0.031, 0.16119999999999998, 0.13723, 0.6, 0.65, 0, 0.0163, 0.298, 0.754]
Reward 5.448651378036453
Current State [[0.12    0.12    0.031   0.1612  0.13723 0.6     0.65    0.      0.0163
  0.298   0.754  ]]
Logits tf.Tensor([[-0.34788263 -0.01865607  0.05694315]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2571399  0.35739684 0.3854633 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.1, 0.2, 0.026, 0.2041, 0.13723, 0.6, 0.56, 0, 0.0103, 0.284, 0.581]
Reward 6.209886175199213
Current State [[0.1     0.2     0.026   0.2041  0.13723 0.6     0.56    0.      0.0103
  0.284   0.581  ]]
Logits tf.Tensor([[-0.2789358   0.00645482  0.04351132]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26948488 0.35849077 0.3720244 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.07, 0.032, 0.15580000000000002, 0.13723, 0.6, 0.72, 0, 0.0084, 0.352, 0.852]
Reward 8.086332676880154
Current State [[0.08    0.07    0.032   0.1558  0.13723 0.6     0.72    0.      0.0084
  0.352   0.852  ]]
Logits tf.Tensor([[-0.38385025 -0.05524106  0.06341645]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25296816 0.35138166 0.39565018]], shape=(1, 3), dtype=float32)
Selected action 0
[0.15, 0.2, 0.026, 0.1431, 0.13723, 0.6, 0.73, 0, 0.0063, 0.302, 0.627]
Reward 10.469405619276547
Current State [[0.15    0.2     0.026   0.1431  0.13723 0.6     0.73    0.      0.0063
  0.302   0.627  ]]
Logits tf.Tensor([[-0.31585667  0.00610461  0.03666946]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2629857  0.36287594 0.3741384 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.12, 0.12, 0.025, 0.1686, 0.13723, 0.6, 0.73, 0, 0.0063, 0.302, 0.627]
Reward 10.469405619276547
Current State [[0.12    0.12    0.025   0.1686  0.13723 0.6     0.73    0.      0.0063
  0.302   0.627  ]]
Logits tf.Tensor([[-0.32746464 -0.01062055  0.04087529]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2619089  0.35954553 0.3785456 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.26, 0.2, 0.027, 0.1837, 0.13723, 0.6, 0.56, 0, 0.2288, 0.29300000000000004, 1.003]
Reward 3.879822156923092
Current State [[0.26    0.2     0.027   0.1837  0.13723 0.6     0.56    0.      0.2288
  0.293   1.003  ]]
Logits tf.Tensor([[-0.3598108  -0.01566623  0.04897616]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25537738 0.36028194 0.38434067]], shape=(1, 3), dtype=float32)
Selected action 0
[0.06, 0.2, 0.023, 0.154, 0.13723, 0.6, 0.78, 0, 0.0055000000000000005, 0.393, 0.20299999999999999]
Reward 12.752325670093386
Current State [[0.06    0.2     0.023   0.154   0.13723 0.6     0.78    0.      0.0055
  0.393   0.203  ]]
Logits tf.Tensor([[-0.18130733 -0.03325985  0.02355196]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29525346 0.3423665  0.36238003]], shape=(1, 3), dtype=float32)
Selected action 0
[0.25, 0.2, 0.028, 0.2115, 0.13723, 0.6, 0.83, 0, 0.0084, 0.394, 1.65]
Reward 9.035602781956674
Current State [[0.25    0.2     0.028   0.2115  0.13723 0.6     0.83    0.      0.0084
  0.394   1.65   ]]
Logits tf.Tensor([[-0.5886203  -0.07656717  0.02811866]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22116116 0.36905468 0.40978417]], shape=(1, 3), dtype=float32)
Selected action 1
[0.11, 0.12, 0.024, 0.12919999999999998, 0.13723, 0.6, 0.61, 0, 0.2473, 0.309, 2.1399999999999997]
Reward 3.8797013934307034
Current State [[0.11    0.12    0.024   0.1292  0.13723 0.6     0.61    0.      0.2473
  0.309   2.14   ]]
Logits tf.Tensor([[-0.58494    -0.27793992  0.08977011]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23133126 0.3144581  0.45421058]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.07, 0.031, 0.1245, 0.13723, 0.6, 0.51, 0, 0.0078000000000000005, 0.446, 0.729]
Reward 6.817285448351851
Current State [[0.05    0.07    0.031   0.1245  0.13723 0.6     0.51    0.      0.0078
  0.446   0.729  ]]
Logits tf.Tensor([[-0.34835118 -0.07382219  0.07700291]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2600075  0.34214666 0.39784583]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.07, 0.028, 0.14909999999999998, 0.13723, 0.6, 0.51, 0, 0.0078000000000000005, 0.446, 0.729]
Reward 6.817285448351851
Current State [[0.07    0.07    0.028   0.1491  0.13723 0.6     0.51    0.      0.0078
  0.446   0.729  ]]
Logits tf.Tensor([[-0.35430223 -0.06736441  0.07076043]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25893134 0.34498495 0.3960837 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.11, 0.12, 0.033, 0.17959999999999998, 0.13723, 0.6, 0.56, 0, 0.030299999999999997, 0.34199999999999997, 1.248]
Reward 4.4897992826354605
Episode: 22 | Average Reward: 233 | Episode Reward: 188 | Loss: 221.343 | Steps: 19 | Worker: 0
Current State [[ 0.00836022 -0.00436773  0.00183118 -0.00614099  0.00782311  0.00308027
   0.00499079  0.00642008 -0.00438145 -0.00674383  0.00215478]]
Logits tf.Tensor([[-0.0071266   0.02016841 -0.0187851 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.33155617 0.34073064 0.32771316]], shape=(1, 3), dtype=float32)
Selected action 1
[0.16, 0.12, 0.028, 0.1216, 0.13723, 0.6, 0.68, 0, 0.0166, 0.356, 2.293]
Reward 5.507716861361751
Current State [[0.16    0.12    0.028   0.1216  0.13723 0.6     0.68    0.      0.0166
  0.356   2.293  ]]
Logits tf.Tensor([[-0.68005496 -0.26847312  0.06831005]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.21632169 0.32647339 0.4572049 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.13, 0.12, 0.034, 0.16540000000000002, 0.13723, 0.6, 0.68, 0, 0.0166, 0.356, 2.293]
Reward 5.507716861361751
Current State [[0.13    0.12    0.034   0.1654  0.13723 0.6     0.68    0.      0.0166
  0.356   2.293  ]]
Logits tf.Tensor([[-0.6801446  -0.26747677  0.06311442]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.21674952 0.32747453 0.45577598]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.07, 0.035, 0.1423, 0.13723, 0.6, 0.58, 0, 0.0176, 0.344, 1.795]
Reward 5.1218625974790575
Current State [[0.05    0.07    0.035   0.1423  0.13723 0.6     0.58    0.      0.0176
  0.344   1.795  ]]
Logits tf.Tensor([[-0.5732021  -0.21194525  0.07222518]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23031215 0.33052835 0.43915954]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.07, 0.032, 0.1245, 0.13723, 0.6, 0.68, 0, 0.0098, 0.292, 0.985]
Reward 7.053585087825296
Current State [[0.05    0.07    0.032   0.1245  0.13723 0.6     0.68    0.      0.0098
  0.292   0.985  ]]
Logits tf.Tensor([[-0.38896346 -0.06925388  0.07471601]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25210246 0.3470765  0.40082103]], shape=(1, 3), dtype=float32)
Selected action 0
[0.21, 0.2, 0.027, 0.1712, 0.13723, 0.6, 0.5, 0, 0.0159, 0.351, 1.027]
Reward 5.066704973260313
Current State [[0.21    0.2     0.027   0.1712  0.13723 0.6     0.5     0.      0.0159
  0.351   1.027  ]]
Logits tf.Tensor([[-0.40584192 -0.02099319  0.04220856]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.247853   0.3641932  0.38795382]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.07, 0.034, 0.1373, 0.13723, 0.6, 0.5, 0, 0.0159, 0.351, 1.027]
Reward 5.066704973260313
Current State [[0.07    0.07    0.034   0.1373  0.13723 0.6     0.5     0.      0.0159
  0.351   1.027  ]]
Logits tf.Tensor([[-0.4002549  -0.08511181  0.06798641]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2520391  0.34540835 0.40255252]], shape=(1, 3), dtype=float32)
Selected action 1
[0.14, 0.12, 0.034, 0.1849, 0.13723, 0.6, 0.61, 0, 0.004699999999999999, 0.353, 0.22000000000000003]
Reward 11.55949174443595
Current State [[0.14    0.12    0.034   0.1849  0.13723 0.6     0.61    0.      0.0047
  0.353   0.22   ]]
Logits tf.Tensor([[-0.19992387 -0.00448986  0.03231446]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.28758284 0.34965432 0.36276284]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.07, 0.038, 0.126, 0.13723, 0.6, 0.87, 0, 0.005699999999999999, 0.327, 1.105]
Reward 13.774277503413893
Current State [[0.07    0.07    0.038   0.126   0.13723 0.6     0.87    0.      0.0057
  0.327   1.105  ]]
Logits tf.Tensor([[-0.4373551  -0.07882908  0.06696402]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24467368 0.3501815  0.40514484]], shape=(1, 3), dtype=float32)
Selected action 0
[0.19, 0.2, 0.031, 0.18630000000000002, 0.13723, 0.6, 0.62, 0, 0.0043, 0.233, 2.118]
Reward 12.918402727944938
Current State [[0.19    0.2     0.031   0.1863  0.13723 0.6     0.62    0.      0.0043
  0.233   2.118  ]]
Logits tf.Tensor([[-0.58500266 -0.18300827  0.06720464]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2265223  0.3386062  0.43487155]], shape=(1, 3), dtype=float32)
Selected action 0
[0.16, 0.2, 0.028, 0.204, 0.13723, 0.6, 0.62, 0, 0.0043, 0.233, 2.118]
Reward 12.918402727944938
Current State [[0.16    0.2     0.028   0.204   0.13723 0.6     0.62    0.      0.0043
  0.233   2.118  ]]
Logits tf.Tensor([[-0.58294183 -0.1882364   0.06592454]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22741139 0.3374664  0.43512222]], shape=(1, 3), dtype=float32)
Selected action 1
[0.12, 0.12, 0.034, 0.15880000000000002, 0.13723, 0.6, 0.83, 0, 0.0684, 0.296, 2.101]
Reward 4.239677460688425
Current State [[0.12    0.12    0.034   0.1588  0.13723 0.6     0.83    0.      0.0684
  0.296   2.101  ]]
Logits tf.Tensor([[-0.61857104 -0.2094336   0.06835292]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22256295 0.33507267 0.4423644 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.09, 0.07, 0.032, 0.12409999999999999, 0.13723, 0.6, 0.8, 0, 0.001, 0.29700000000000004, 1.605]
Reward 49.745973399591556
Current State [[9.0000e-02 7.0000e-02 3.2000e-02 1.2410e-01 1.3723e-01 6.0000e-01
  8.0000e-01 0.0000e+00 1.0000e-03 2.9700e-01 1.6050e+00]]
Logits tf.Tensor([[-0.54457235 -0.13405629  0.06332422]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23019412 0.34703964 0.42276627]], shape=(1, 3), dtype=float32)
Selected action 0
[0.27, 0.2, 0.029, 0.19, 0.13723, 0.6, 0.66, 0, 0.0038, 0.263, 1.4869999999999999]
Reward 16.19772989336398
Current State [[0.27    0.2     0.029   0.19    0.13723 0.6     0.66    0.      0.0038
  0.263   1.487  ]]
Logits tf.Tensor([[-0.5025911  -0.04858544  0.03991192]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2328335  0.36662126 0.4005452 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.16, 0.12, 0.029, 0.1333, 0.13723, 0.6, 0.69, 0, 0.0019, 0.367, 1.514]
Reward 37.10723059922934
Current State [[0.16    0.12    0.029   0.1333  0.13723 0.6     0.69    0.      0.0019
  0.367   1.514  ]]
Logits tf.Tensor([[-0.53550774 -0.10758092  0.05292375]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.230668   0.35386175 0.4154702 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.17, 0.2, 0.027, 0.2216, 0.13723, 0.6, 0.69, 0, 0.0019, 0.367, 1.514]
Reward 37.10723059922934
Current State [[0.17    0.2     0.027   0.2216  0.13723 0.6     0.69    0.      0.0019
  0.367   1.514  ]]
Logits tf.Tensor([[-0.5186182  -0.07319435  0.03415263]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23260064 0.3631249  0.4042744 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.07, 0.026, 0.122, 0.13723, 0.6, 0.75, 0, 0.061399999999999996, 0.321, 1.424]
Reward 4.241418411690222
Current State [[0.04    0.07    0.026   0.122   0.13723 0.6     0.75    0.      0.0614
  0.321   1.424  ]]
Logits tf.Tensor([[-0.48264423 -0.13464946  0.07027635]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24070011 0.34088546 0.4184144 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.13, 0.12, 0.032, 0.1423, 0.13723, 0.6, 0.77, 0, 0.025099999999999997, 0.303, 0.709]
Reward 5.0079844747825355
Current State [[0.13    0.12    0.032   0.1423  0.13723 0.6     0.77    0.      0.0251
  0.303   0.709  ]]
Logits tf.Tensor([[-0.34322274 -0.01679398  0.04217551]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25932202 0.3594228  0.38125518]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.07, 0.033, 0.1519, 0.13723, 0.6, 0.77, 0, 0.025099999999999997, 0.303, 0.709]
Reward 5.0079844747825355
Current State [[0.06    0.07    0.033   0.1519  0.13723 0.6     0.77    0.      0.0251
  0.303   0.709  ]]
Logits tf.Tensor([[-0.3363064  -0.04227366  0.05297555]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2619345  0.351471   0.38659453]], shape=(1, 3), dtype=float32)
Selected action 1
[0.11, 0.12, 0.031, 0.1673, 0.13723, 0.6, 0.54, 0, 0.3011, 0.23399999999999999, 2.176]
Reward 3.8558844493556657
Current State [[0.11    0.12    0.031   0.1673  0.13723 0.6     0.54    0.      0.3011
  0.234   2.176  ]]
Logits tf.Tensor([[-0.5461443  -0.2838587   0.09231542]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23846658 0.30998218 0.4515513 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.07, 0.036, 0.1269, 0.13723, 0.6, 0.78, 0, 0.0015, 0.294, 1.6640000000000001]
Reward 47.23018518087386
Episode: 23 | Average Reward: 233 | Episode Reward: 294 | Loss: 984.015 | Steps: 19 | Worker: 0
Current State [[-0.00086557 -0.00793276  0.0022507   0.00676033  0.00081356  0.00733149
   0.00726219 -0.00411329  0.00460699  0.00904075 -0.00909275]]
Logits tf.Tensor([[-0.00536615  0.01581174 -0.02942796]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.33359697 0.3407372  0.32566583]], shape=(1, 3), dtype=float32)
Selected action 1
[0.08, 0.12, 0.031, 0.15, 0.13723, 0.6, 0.63, 0, 0.011200000000000002, 0.262, 1.105]
Reward 6.309000850821674
Current State [[0.08    0.12    0.031   0.15    0.13723 0.6     0.63    0.      0.0112
  0.262   1.105  ]]
Logits tf.Tensor([[-0.40233237 -0.0588803   0.06262791]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24989024 0.35229677 0.397813  ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.07, 0.032, 0.15, 0.13723, 0.6, 0.63, 0, 0.011200000000000002, 0.262, 1.105]
Reward 6.309000850821674
Current State [[0.05    0.07    0.032   0.15    0.13723 0.6     0.63    0.      0.0112
  0.262   1.105  ]]
Logits tf.Tensor([[-0.4052062  -0.07759927  0.06831566]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25042054 0.34749445 0.402085  ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.16, 0.12, 0.033, 0.14809999999999998, 0.13723, 0.6, 0.8, 0, 0.003, 0.27, 1.359]
Reward 26.951821745368733
Current State [[0.16    0.12    0.033   0.1481  0.13723 0.6     0.8     0.      0.003
  0.27    1.359  ]]
Logits tf.Tensor([[-0.49185094 -0.06427675  0.0504471 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2351012  0.3605354  0.40436342]], shape=(1, 3), dtype=float32)
Selected action 2
[0.09, 0.07, 0.036, 0.1212, 0.13723, 0.6, 0.75, 0, 0.0048, 0.302, 2.4370000000000003]
Reward 13.966535569384048
Current State [[0.09    0.07    0.036   0.1212  0.13723 0.6     0.75    0.      0.0048
  0.302   2.437  ]]
Logits tf.Tensor([[-0.6976917 -0.3116503  0.0771649]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.215451   0.31695977 0.4675892 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.12, 0.12, 0.034, 0.1688, 0.13723, 0.6, 0.75, 0, 0.0048, 0.302, 2.4370000000000003]
Reward 13.966535569384048
Current State [[0.12    0.12    0.034   0.1688  0.13723 0.6     0.75    0.      0.0048
  0.302   2.437  ]]
Logits tf.Tensor([[-0.6899795  -0.28422135  0.06637844]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.21593879 0.3240031  0.46005812]], shape=(1, 3), dtype=float32)
Selected action 0
[0.23, 0.2, 0.028, 0.2115, 0.13723, 0.6, 0.78, 0, 0.0021, 0.29700000000000004, 1.9309999999999998]
Reward 38.5812346342901
Current State [[0.23    0.2     0.028   0.2115  0.13723 0.6     0.78    0.      0.0021
  0.297   1.931  ]]
Logits tf.Tensor([[-0.58971614 -0.12042123  0.04133606]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22329135 0.35701305 0.41969556]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.07, 0.046, 0.14709999999999998, 0.13723, 0.6, 0.76, 0, 0.0709, 0.28300000000000003, 2.351]
Reward 4.1880309398970805
Current State [[0.07    0.07    0.046   0.1471  0.13723 0.6     0.76    0.      0.0709
  0.283   2.351  ]]
Logits tf.Tensor([[-0.6622767  -0.29550222  0.08122966]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.21995571 0.31741202 0.4626323 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.06, 0.2, 0.027, 0.1865, 0.13723, 0.6, 0.76, 0, 0.0709, 0.28300000000000003, 2.351]
Reward 4.1880309398970805
Current State [[0.06    0.2     0.027   0.1865  0.13723 0.6     0.76    0.      0.0709
  0.283   2.351  ]]
Logits tf.Tensor([[-0.6196604  -0.26407662  0.07218585]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22601867 0.3225317  0.45144963]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.07, 0.033, 0.1449, 0.13723, 0.6, 0.52, 0, 0.046799999999999994, 0.256, 2.054]
Reward 4.204069144603164
Current State [[0.04    0.07    0.033   0.1449  0.13723 0.6     0.52    0.      0.0468
  0.256   2.054  ]]
Logits tf.Tensor([[-0.5826698  -0.2683776   0.08703084]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23132393 0.3167495  0.45192653]], shape=(1, 3), dtype=float32)
Selected action 1
[0.09, 0.12, 0.027, 0.14709999999999998, 0.13723, 0.6, 0.44, 0, 0.3292, 0.252, 2.051]
Reward 3.8398456346644574
Current State [[0.09    0.12    0.027   0.1471  0.13723 0.6     0.44    0.      0.3292
  0.252   2.051  ]]
Logits tf.Tensor([[-0.5022321  -0.2870773   0.09252878]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24675207 0.30598584 0.44726214]], shape=(1, 3), dtype=float32)
Selected action 0
[0.15, 0.2, 0.024, 0.1519, 0.13723, 0.6, 0.71, 0, 0.0039000000000000003, 0.325, 0.8480000000000001]
Reward 16.633332641574476
Current State [[0.15    0.2     0.024   0.1519  0.13723 0.6     0.71    0.      0.0039
  0.325   0.848  ]]
Logits tf.Tensor([[-0.3654496  -0.01068135  0.04214083]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25451496 0.36290026 0.38258472]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.07, 0.032, 0.14909999999999998, 0.13723, 0.6, 0.71, 0, 0.0039000000000000003, 0.325, 0.8480000000000001]
Reward 16.633332641574476
Current State [[0.07    0.07    0.032   0.1491  0.13723 0.6     0.71    0.      0.0039
  0.325   0.848  ]]
Logits tf.Tensor([[-0.37048787 -0.05279169  0.06060189]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2555654  0.35113636 0.3932982 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.23, 0.2, 0.03, 0.2154, 0.13723, 0.6, 0.68, 0, 0.014499999999999999, 0.32599999999999996, 0.976]
Reward 5.7900243668888445
Current State [[0.23    0.2     0.03    0.2154  0.13723 0.6     0.68    0.      0.0145
  0.326   0.976  ]]
Logits tf.Tensor([[-0.41044807  0.00420531  0.03313518]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24557193 0.37175804 0.38267004]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.07, 0.031, 0.1385, 0.13723, 0.6, 0.86, 0, 0.0375, 0.318, 1.403]
Reward 4.680556402133472
Current State [[0.04    0.07    0.031   0.1385  0.13723 0.6     0.86    0.      0.0375
  0.318   1.403  ]]
Logits tf.Tensor([[-0.48818076 -0.1278567   0.06523976]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23963659 0.34358948 0.41677397]], shape=(1, 3), dtype=float32)
Selected action 1
[0.04, 0.12, 0.029, 0.1673, 0.13723, 0.6, 0.86, 0, 0.0375, 0.318, 1.403]
Reward 4.680556402133472
Current State [[0.04    0.12    0.029   0.1673  0.13723 0.6     0.86    0.      0.0375
  0.318   1.403  ]]
Logits tf.Tensor([[-0.47864822 -0.11472666  0.05834554]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24097447 0.34675297 0.4122726 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.1, 0.12, 0.025, 0.2019, 0.13723, 0.6, 0.52, 0, 0.09, 0.46299999999999997, 0.745]
Reward 4.002263916032984
Current State [[0.1     0.12    0.025   0.2019  0.13723 0.6     0.52    0.      0.09
  0.463   0.745  ]]
Logits tf.Tensor([[-0.33239752 -0.05561456  0.05763608]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2634414  0.34744763 0.38911095]], shape=(1, 3), dtype=float32)
Selected action 2
[0.09, 0.07, 0.027, 0.15209999999999999, 0.13723, 0.6, 0.6, 0, 0.0098, 0.364, 1.0630000000000002]
Reward 6.589570191559497
Current State [[0.09    0.07    0.027   0.1521  0.13723 0.6     0.6     0.      0.0098
  0.364   1.063  ]]
Logits tf.Tensor([[-0.4223343  -0.08261074  0.0589804 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24858557 0.34915316 0.4022613 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.15, 0.12, 0.028, 0.174, 0.13723, 0.6, 0.6, 0, 0.0098, 0.364, 1.0630000000000002]
Reward 6.589570191559497
Current State [[0.15    0.12    0.028   0.174   0.13723 0.6     0.6     0.      0.0098
  0.364   1.063  ]]
Logits tf.Tensor([[-0.42911002 -0.05450334  0.04745086]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24600579 0.35779554 0.3961987 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.15, 0.2, 0.025, 0.1755, 0.13723, 0.6, 0.65, 0, 0.0179, 0.269, 1.1199999999999999]
Reward 5.278734290291303
Current State [[0.15    0.2     0.025   0.1755  0.13723 0.6     0.65    0.      0.0179
  0.269   1.12   ]]
Logits tf.Tensor([[-0.40667856 -0.0243814   0.04732989]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24750888 0.36276078 0.3897303 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.07, 0.03, 0.13019999999999998, 0.13723, 0.6, 0.8, 0, 0.0653, 0.29700000000000004, 1.3]
Reward 4.246504154424486
Episode: 24 | Average Reward: 233 | Episode Reward: 197 | Loss: 256.042 | Steps: 19 | Worker: 0
Current State [[-0.00651753 -0.00603333 -0.00546083  0.00450188  0.00362002 -0.00649253
  -0.00759086  0.00947769  0.00814865 -0.00519458 -0.00768317]]
Logits tf.Tensor([[-0.00148353  0.01741106 -0.03001858]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.33434278 0.34072012 0.32493713]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.07, 0.028, 0.1151, 0.13723, 0.6, 0.73, 0, 0.005699999999999999, 0.321, 1.01]
Reward 11.504228673663059
Current State [[0.06    0.07    0.028   0.1151  0.13723 0.6     0.73    0.      0.0057
  0.321   1.01   ]]
Logits tf.Tensor([[-0.39981002 -0.07556844  0.06776025]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25131357 0.34756202 0.40112445]], shape=(1, 3), dtype=float32)
Selected action 0
[0.13, 0.2, 0.025, 0.168, 0.13723, 0.6, 0.73, 0, 0.005699999999999999, 0.321, 1.01]
Reward 11.504228673663059
Current State [[0.13    0.2     0.025   0.168   0.13723 0.6     0.73    0.      0.0057
  0.321   1.01   ]]
Logits tf.Tensor([[-0.39101917 -0.02493017  0.04488642]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2507242  0.36156523 0.38771057]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.07, 0.026, 0.1333, 0.13723, 0.6, 0.73, 0, 0.0556, 0.3, 0.42800000000000005]
Reward 4.27970881688754
Current State [[0.03    0.07    0.026   0.1333  0.13723 0.6     0.73    0.      0.0556
  0.3     0.428  ]]
Logits tf.Tensor([[-0.2477034  -0.04000366  0.05097681]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.27941373 0.34391463 0.37667164]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.07, 0.028, 0.12409999999999999, 0.13723, 0.6, 0.68, 0, 0.0054, 0.335, 0.651]
Reward 11.142072985570753
Current State [[0.08    0.07    0.028   0.1241  0.13723 0.6     0.68    0.      0.0054
  0.335   0.651  ]]
Logits tf.Tensor([[-0.32179272 -0.03679219  0.05171745]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26436925 0.35154837 0.38408235]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.07, 0.031, 0.124, 0.13723, 0.6, 0.39, 0, 0.1648, 0.29900000000000004, 1.099]
Reward 3.8769466320329586
Current State [[0.04    0.07    0.031   0.124   0.13723 0.6     0.39    0.      0.1648
  0.299   1.099  ]]
Logits tf.Tensor([[-0.34885675 -0.12431878  0.07528055]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26454917 0.33114788 0.40430292]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.07, 0.031, 0.1275, 0.13723, 0.6, 0.39, 0, 0.1648, 0.29900000000000004, 1.099]
Reward 3.8769466320329586
Current State [[0.04    0.07    0.031   0.1275  0.13723 0.6     0.39    0.      0.1648
  0.299   1.099  ]]
Logits tf.Tensor([[-0.34851658 -0.12361595  0.07460109]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2646264  0.33136475 0.4040088 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.1, 0.12, 0.027, 0.15, 0.13723, 0.6, 0.55, 0, 0.005600000000000001, 0.27, 1.691]
Reward 8.994289890288579
Current State [[0.1     0.12    0.027   0.15    0.13723 0.6     0.55    0.      0.0056
  0.27    1.691  ]]
Logits tf.Tensor([[-0.51263255 -0.16080493  0.06963445]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23743069 0.33754656 0.42502275]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.07, 0.033, 0.12040000000000001, 0.13723, 0.6, 0.64, 0, 0.006, 0.27999999999999997, 0.5740000000000001]
Reward 9.697050772608003
Current State [[0.06    0.07    0.033   0.1204  0.13723 0.6     0.64    0.      0.006
  0.28    0.574  ]]
Logits tf.Tensor([[-0.2869568  -0.02706753  0.05567926]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26987332 0.34996805 0.38015863]], shape=(1, 3), dtype=float32)
Selected action 1
[0.14, 0.12, 0.028, 0.148, 0.13723, 0.6, 0.65, 0, 0.0118, 0.266, 1.331]
Reward 6.220553965459747
Current State [[0.14    0.12    0.028   0.148   0.13723 0.6     0.65    0.      0.0118
  0.266   1.331  ]]
Logits tf.Tensor([[-0.45847833 -0.07150269  0.05376296]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2414556  0.35554832 0.4029961 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.11, 0.12, 0.03, 0.16040000000000001, 0.13723, 0.6, 0.65, 0, 0.0118, 0.266, 1.331]
Reward 6.220553965459747
Current State [[0.11    0.12    0.03    0.1604  0.13723 0.6     0.65    0.      0.0118
  0.266   1.331  ]]
Logits tf.Tensor([[-0.45088595 -0.0747134   0.05417176]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24308546 0.3541022  0.40281233]], shape=(1, 3), dtype=float32)
Selected action 1
[0.12, 0.12, 0.028, 0.1453, 0.13723, 0.6, 0.67, 0, 0.168, 0.315, 0.842]
Reward 3.9356163227350582
Current State [[0.12    0.12    0.028   0.1453  0.13723 0.6     0.67    0.      0.168
  0.315   0.842  ]]
Logits tf.Tensor([[-0.33335203 -0.04687745  0.05984385]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2622309  0.34921926 0.38854977]], shape=(1, 3), dtype=float32)
Selected action 2
[0.12, 0.07, 0.033, 0.1259, 0.13723, 0.6, 0.72, 0, 0.0076, 0.34900000000000003, 0.778]
Reward 8.740470461701733
Current State [[0.12    0.07    0.033   0.1259  0.13723 0.6     0.72    0.      0.0076
  0.349   0.778  ]]
Logits tf.Tensor([[-0.3642422  -0.03953572  0.05086433]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25653154 0.35494328 0.3885252 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.07, 0.032, 0.1415, 0.13723, 0.6, 0.5, 0, 0.0897, 0.269, 0.9339999999999999]
Reward 3.9916687548071006
Current State [[0.07    0.07    0.032   0.1415  0.13723 0.6     0.5     0.      0.0897
  0.269   0.934  ]]
Logits tf.Tensor([[-0.34007657 -0.06324877  0.06938388]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2614417  0.34482577 0.39373255]], shape=(1, 3), dtype=float32)
Selected action 1
[0.12, 0.12, 0.03, 0.149, 0.13723, 0.6, 0.5, 0, 0.0897, 0.269, 0.9339999999999999]
Reward 3.9916687548071006
Current State [[0.12    0.12    0.03    0.149   0.13723 0.6     0.5     0.      0.0897
  0.269   0.934  ]]
Logits tf.Tensor([[-0.34283644 -0.04098904  0.06120538]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2597253  0.35124078 0.38903385]], shape=(1, 3), dtype=float32)
Selected action 1
[0.16, 0.12, 0.025, 0.1667, 0.13723, 0.6, 0.8, 0, 0.013500000000000002, 0.389, 0.43200000000000005]
Reward 6.46302635164843
Current State [[0.16    0.12    0.025   0.1667  0.13723 0.6     0.8     0.      0.0135
  0.389   0.432  ]]
Logits tf.Tensor([[-0.2771837  -0.01114479  0.02232713]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.27367383 0.35708573 0.36924037]], shape=(1, 3), dtype=float32)
Selected action 1
[0.12, 0.12, 0.031, 0.16540000000000002, 0.13723, 0.6, 0.76, 0, 0.0053, 0.318, 0.795]
Reward 12.71640332346275
Current State [[0.12    0.12    0.031   0.1654  0.13723 0.6     0.76    0.      0.0053
  0.318   0.795  ]]
Logits tf.Tensor([[-0.3599919  -0.02356739  0.03990527]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2569634  0.3597316  0.38330495]], shape=(1, 3), dtype=float32)
Selected action 2
[0.09, 0.07, 0.025, 0.1264, 0.13723, 0.6, 0.7, 0, 0.0275, 0.398, 0.9390000000000001]
Reward 4.783043346137619
Current State [[0.09    0.07    0.025   0.1264  0.13723 0.6     0.7     0.      0.0275
  0.398   0.939  ]]
Logits tf.Tensor([[-0.3990752  -0.07594499  0.06082851]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2521835  0.34837767 0.39943886]], shape=(1, 3), dtype=float32)
Selected action 0
[0.19, 0.2, 0.027, 0.1784, 0.13723, 0.6, 0.7, 0, 0.0275, 0.398, 0.9390000000000001]
Reward 4.783043346137619
Current State [[0.19    0.2     0.027   0.1784  0.13723 0.6     0.7     0.      0.0275
  0.398   0.939  ]]
Logits tf.Tensor([[-0.3960914  -0.01955262  0.03874498]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24987866 0.36413118 0.38599014]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.07, 0.03, 0.122, 0.13723, 0.6, 0.82, 0, 0.0151, 0.44400000000000006, 0.837]
Reward 6.2075655479777705
Current State [[0.08    0.07    0.03    0.122   0.13723 0.6     0.82    0.      0.0151
  0.444   0.837  ]]
Logits tf.Tensor([[-0.38521695 -0.07518471  0.05066585]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2557678  0.34873146 0.39550078]], shape=(1, 3), dtype=float32)
Selected action 2
[0.09, 0.07, 0.035, 0.1226, 0.13723, 0.6, 0.48, 0, 0.0195, 0.386, 1.419]
Reward 4.742908974019885
Episode: 25 | Average Reward: 232 | Episode Reward: 137 | Loss: 137.944 | Steps: 19 | Worker: 0
Current State [[ 0.00279246 -0.00203107 -0.00605922 -0.0034453  -0.0077902   0.00838034
  -0.00773145  0.00440353  0.00193697  0.00182474 -0.00162247]]
Logits tf.Tensor([[-0.00669021  0.01559166 -0.02860228]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.333238   0.34074652 0.3260155 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.11, 0.2, 0.027, 0.1529, 0.13723, 0.6, 0.39, 0, 0.1495, 0.269, 1.786]
Reward 3.885442109339471
Current State [[0.11    0.2     0.027   0.1529  0.13723 0.6     0.39    0.      0.1495
  0.269   1.786  ]]
Logits tf.Tensor([[-0.45588627 -0.19730869  0.0738571 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25040174 0.3242919  0.42530638]], shape=(1, 3), dtype=float32)
Selected action 0
[0.23, 0.2, 0.029, 0.2039, 0.13723, 0.6, 0.39, 0, 0.1495, 0.269, 1.786]
Reward 3.885442109339471
Current State [[0.23    0.2     0.029   0.2039  0.13723 0.6     0.39    0.      0.1495
  0.269   1.786  ]]
Logits tf.Tensor([[-0.4742727  -0.16436458  0.0493971 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24682145 0.33649164 0.41668686]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.07, 0.035, 0.1347, 0.13723, 0.6, 0.76, 0, 0.0229, 0.36, 1.3900000000000001]
Reward 5.135029506932878
Current State [[0.08    0.07    0.035   0.1347  0.13723 0.6     0.76    0.      0.0229
  0.36    1.39   ]]
Logits tf.Tensor([[-0.49214336 -0.12138692  0.05737706]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2391628 0.3465063 0.4143309]], shape=(1, 3), dtype=float32)
Selected action 1
[0.15, 0.12, 0.03, 0.1686, 0.13723, 0.6, 0.39, 0, 0.1458, 0.263, 1.765]
Reward 3.8877882784951114
Current State [[0.15    0.12    0.03    0.1686  0.13723 0.6     0.39    0.      0.1458
  0.263   1.765  ]]
Logits tf.Tensor([[-0.48505333 -0.20231777  0.0676807 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24601746 0.3264047  0.42757788]], shape=(1, 3), dtype=float32)
Selected action 1
[0.11, 0.12, 0.026, 0.1489, 0.13723, 0.6, 0.78, 0, 0.0064, 0.458, 1.372]
Reward 10.833429204971724
Current State [[0.11    0.12    0.026   0.1489  0.13723 0.6     0.78    0.      0.0064
  0.458   1.372  ]]
Logits tf.Tensor([[-0.5097786  -0.11755004  0.04334458]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23702577 0.35086355 0.4121107 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.11, 0.07, 0.034, 0.1264, 0.13723, 0.6, 0.51, 0, 0.022799999999999997, 0.281, 1.9629999999999999]
Reward 4.655690948962544
Current State [[0.11    0.07    0.034   0.1264  0.13723 0.6     0.51    0.      0.0228
  0.281   1.963  ]]
Logits tf.Tensor([[-0.5759455  -0.24291795  0.07679812]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23169658 0.3232598  0.44504365]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.07, 0.033, 0.1451, 0.13723, 0.6, 0.51, 0, 0.022799999999999997, 0.281, 1.9629999999999999]
Reward 4.655690948962544
Current State [[0.05    0.07    0.033   0.1451  0.13723 0.6     0.51    0.      0.0228
  0.281   1.963  ]]
Logits tf.Tensor([[-0.5708363  -0.25329855  0.07875968]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23318133 0.3203308  0.44648793]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.07, 0.039, 0.134, 0.13723, 0.6, 0.56, 0, 0.026000000000000002, 0.266, 1.906]
Reward 4.620375940624215
Current State [[0.07    0.07    0.039   0.134   0.13723 0.6     0.56    0.      0.026
  0.266   1.906  ]]
Logits tf.Tensor([[-0.558879   -0.22756067  0.08067982]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23318459 0.3247803  0.4420351 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.23, 0.2, 0.03, 0.1679, 0.13723, 0.6, 0.58, 0, 0.0666, 0.223, 1.9170000000000003]
Reward 4.11093133214292
Current State [[0.23    0.2     0.03    0.1679  0.13723 0.6     0.58    0.      0.0666
  0.223   1.917  ]]
Logits tf.Tensor([[-0.52113676 -0.15173703  0.06583477]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2355491  0.34080797 0.42364293]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.07, 0.038, 0.1408, 0.13723, 0.6, 0.79, 0, 0.0105, 0.304, 1.6059999999999999]
Reward 7.450410809945083
Current State [[0.06    0.07    0.038   0.1408  0.13723 0.6     0.79    0.      0.0105
  0.304   1.606  ]]
Logits tf.Tensor([[-0.52703214 -0.143209    0.05717276]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2346619  0.34445688 0.4208812 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.07, 0.039, 0.1321, 0.13723, 0.6, 0.79, 0, 0.0105, 0.304, 1.6059999999999999]
Reward 7.450410809945083
Current State [[0.07    0.07    0.039   0.1321  0.13723 0.6     0.79    0.      0.0105
  0.304   1.606  ]]
Logits tf.Tensor([[-0.5288646  -0.14193062  0.05824812]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23412368 0.3447376  0.4211387 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.05, 0.12, 0.026, 0.1462, 0.13723, 0.6, 0.65, 0, 0.0018, 0.288, 1.175]
Reward 37.75243569481276
Current State [[0.05    0.12    0.026   0.1462  0.13723 0.6     0.65    0.      0.0018
  0.288   1.175  ]]
Logits tf.Tensor([[-0.41470838 -0.08037435  0.06153055]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24956216 0.3486408  0.40179703]], shape=(1, 3), dtype=float32)
Selected action 0
[0.2, 0.2, 0.029, 0.1792, 0.13723, 0.6, 0.87, 0, 0.003, 0.35, 1.096]
Reward 29.920480340926137
Current State [[0.2     0.2     0.029   0.1792  0.13723 0.6     0.87    0.      0.003
  0.35    1.096  ]]
Logits tf.Tensor([[-0.44055936 -0.01626519  0.02926375]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.242235   0.37025893 0.38750607]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.07, 0.034, 0.1313, 0.13723, 0.6, 0.72, 0, 0.1784, 0.29100000000000004, 1.875]
Reward 3.9372531586539172
Current State [[0.04    0.07    0.034   0.1313  0.13723 0.6     0.72    0.      0.1784
  0.291   1.875  ]]
Logits tf.Tensor([[-0.53697556 -0.23338675  0.07940066]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23770384 0.3220202  0.44027597]], shape=(1, 3), dtype=float32)
Selected action 1
[0.16, 0.12, 0.034, 0.1769, 0.13723, 0.6, 0.72, 0, 0.1784, 0.29100000000000004, 1.875]
Reward 3.9372531586539172
Current State [[0.16    0.12    0.034   0.1769  0.13723 0.6     0.72    0.      0.1784
  0.291   1.875  ]]
Logits tf.Tensor([[-0.5441734  -0.18301341  0.06018992]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2344622  0.33645162 0.42908612]], shape=(1, 3), dtype=float32)
Selected action 0
[0.24, 0.2, 0.032, 0.236, 0.13723, 0.6, 0.66, 0, 0.0019, 0.303, 1.423]
Reward 37.02341784420865
Current State [[0.24    0.2     0.032   0.236   0.13723 0.6     0.66    0.      0.0019
  0.303   1.423  ]]
Logits tf.Tensor([[-0.489243   -0.04155085  0.02527512]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23598659 0.3692475  0.39476597]], shape=(1, 3), dtype=float32)
Selected action 1
[0.14, 0.12, 0.035, 0.1608, 0.13723, 0.6, 0.95, 0, 0.0014000000000000002, 0.366, 0.009]
Reward 49.242617634280926
Current State [[0.14    0.12    0.035   0.1608  0.13723 0.6     0.95    0.      0.0014
  0.366   0.009  ]]
Logits tf.Tensor([[-0.16828063 -0.0377168  -0.01834448]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30291733 0.3451654  0.35191727]], shape=(1, 3), dtype=float32)
Selected action 0
[0.18, 0.2, 0.03, 0.1692, 0.13723, 0.6, 0.73, 0, 0.0259, 0.316, 1.197]
Reward 4.90007938123149
Current State [[0.18    0.2     0.03    0.1692  0.13723 0.6     0.73    0.      0.0259
  0.316   1.197  ]]
Logits tf.Tensor([[-0.43869677 -0.03290072  0.03792297]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24324289 0.36498508 0.39177203]], shape=(1, 3), dtype=float32)
Selected action 1
[0.07, 0.12, 0.032, 0.1549, 0.13723, 0.6, 0.73, 0, 0.0259, 0.316, 1.197]
Reward 4.90007938123149
Current State [[0.07    0.12    0.032   0.1549  0.13723 0.6     0.73    0.      0.0259
  0.316   1.197  ]]
Logits tf.Tensor([[-0.4283118  -0.08058281  0.05774157]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2474185  0.35030708 0.40227443]], shape=(1, 3), dtype=float32)
Selected action 2
[0.09, 0.07, 0.034, 0.1865, 0.13723, 0.6, 0.74, 0, 0.0263, 0.274, 1.426]
Reward 4.9002663187327355
Episode: 26 | Average Reward: 232 | Episode Reward: 237 | Loss: 667.667 | Steps: 19 | Worker: 0
Current State [[-0.00449071  0.00603577 -0.00448044 -0.00525852  0.00473284 -0.00516726
  -0.00827267 -0.00485796 -0.00972446  0.00482226 -0.006879  ]]
Logits tf.Tensor([[-0.00018852  0.01331795 -0.03703019]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.33586046 0.34042752 0.32371196]], shape=(1, 3), dtype=float32)
Selected action 1
[0.16, 0.12, 0.033, 0.17880000000000001, 0.13723, 0.6, 0.7, 0, 0.0086, 0.265, 1.506]
Reward 7.854355641194203
Current State [[0.16    0.12    0.033   0.1788  0.13723 0.6     0.7     0.      0.0086
  0.265   1.506  ]]
Logits tf.Tensor([[-0.4978855  -0.08997323  0.04801049]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23641613 0.35549313 0.40809074]], shape=(1, 3), dtype=float32)
Selected action 1
[0.11, 0.12, 0.034, 0.1434, 0.13723, 0.6, 0.53, 0, 0.9533, 0.312, 2.08]
Reward 3.8125722063468745
Current State [[0.11    0.12    0.034   0.1434  0.13723 0.6     0.53    0.      0.9533
  0.312   2.08   ]]
Logits tf.Tensor([[-0.35002545 -0.37719736  0.110108  ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.28109792 0.2735628  0.4453393 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.14, 0.12, 0.033, 0.1635, 0.13723, 0.6, 0.53, 0, 0.9533, 0.312, 2.08]
Reward 3.8125722063468745
Current State [[0.14    0.12    0.033   0.1635  0.13723 0.6     0.53    0.      0.9533
  0.312   2.08   ]]
Logits tf.Tensor([[-0.35894474 -0.36655363  0.10361837]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.279286   0.277169   0.44354504]], shape=(1, 3), dtype=float32)
Selected action 1
[0.05, 0.12, 0.03, 0.1731, 0.13723, 0.6, 0.54, 0, 0.0062, 0.324, 1.098]
Reward 8.141791774552619
Current State [[0.05    0.12    0.03    0.1731  0.13723 0.6     0.54    0.      0.0062
  0.324   1.098  ]]
Logits tf.Tensor([[-0.3903983  -0.07812762  0.05702961]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2544006  0.34764472 0.3979547 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.19, 0.2, 0.03, 0.18630000000000002, 0.13723, 0.6, 0.8, 0, 0.10869999999999999, 0.255, 1.741]
Reward 4.0602994679528885
Current State [[0.19    0.2     0.03    0.1863  0.13723 0.6     0.8     0.      0.1087
  0.255   1.741  ]]
Logits tf.Tensor([[-0.5059741  -0.11038014  0.04251872]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23719679 0.35230035 0.41050285]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.07, 0.033, 0.1245, 0.13723, 0.6, 0.84, 0, 0.0236, 0.252, 2.088]
Reward 5.244557983881525
Current State [[0.08    0.07    0.033   0.1245  0.13723 0.6     0.84    0.      0.0236
  0.252   2.088  ]]
Logits tf.Tensor([[-0.6035581  -0.22921695  0.07668535]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2258156  0.3283434  0.44584095]], shape=(1, 3), dtype=float32)
Selected action 0
[0.19, 0.2, 0.031, 0.19, 0.13723, 0.6, 0.84, 0, 0.0236, 0.252, 2.088]
Reward 5.244557983881525
Current State [[0.19    0.2     0.031   0.19    0.13723 0.6     0.84    0.      0.0236
  0.252   2.088  ]]
Logits tf.Tensor([[-0.58148474 -0.15870927  0.05135943]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22680108 0.34614193 0.427057  ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.2, 0.2, 0.033, 0.208, 0.13723, 0.6, 0.72, 0, 0.0109, 0.27, 1.022]
Reward 6.844353741376552
Current State [[0.2     0.2     0.033   0.208   0.13723 0.6     0.72    0.      0.0109
  0.27    1.022  ]]
Logits tf.Tensor([[-0.40219745  0.00190575  0.03250869]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24737366 0.3705555  0.38207087]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.07, 0.037, 0.1549, 0.13723, 0.6, 0.66, 0, 0.2447, 0.339, 1.973]
Reward 3.888218865544721
Current State [[0.07    0.07    0.037   0.1549  0.13723 0.6     0.66    0.      0.2447
  0.339   1.973  ]]
Logits tf.Tensor([[-0.5583288  -0.26646566  0.0800629 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23627518 0.31635353 0.44737127]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.07, 0.033, 0.134, 0.13723, 0.6, 0.72, 0, 0.0032, 0.24300000000000002, 2.256]
Reward 21.528277620184298
Current State [[0.07    0.07    0.033   0.134   0.13723 0.6     0.72    0.      0.0032
  0.243   2.256  ]]
Logits tf.Tensor([[-0.6289304  -0.27877483  0.08002134]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22466113 0.3188589  0.45648   ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.07, 0.03, 0.12919999999999998, 0.13723, 0.6, 0.72, 0, 0.0032, 0.24300000000000002, 2.256]
Reward 21.528277620184298
Current State [[0.07    0.07    0.03    0.1292  0.13723 0.6     0.72    0.      0.0032
  0.243   2.256  ]]
Logits tf.Tensor([[-0.6287052  -0.28019533  0.08064388]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22473817 0.31844378 0.45681804]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.07, 0.033, 0.1412, 0.13723, 0.6, 0.66, 0, 0.013500000000000002, 0.288, 1.137]
Reward 5.882416568458546
Current State [[0.08    0.07    0.033   0.1412  0.13723 0.6     0.66    0.      0.0135
  0.288   1.137  ]]
Logits tf.Tensor([[-0.41789982 -0.07998497  0.06073518]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24901076 0.3491183  0.40187094]], shape=(1, 3), dtype=float32)
Selected action 1
[0.15, 0.12, 0.031, 0.15309999999999999, 0.13723, 0.6, 0.73, 0, 0.0032, 0.311, 0.497]
Reward 22.59157913867743
Current State [[0.15    0.12    0.031   0.1531  0.13723 0.6     0.73    0.      0.0032
  0.311   0.497  ]]
Logits tf.Tensor([[-0.28766063  0.00169913  0.03098928]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26948065 0.35991082 0.37060857]], shape=(1, 3), dtype=float32)
Selected action 0
[0.13, 0.2, 0.025, 0.144, 0.13723, 0.6, 0.84, 0, 0.0038, 0.314, 1.8170000000000002]
Reward 21.50254748581632
Current State [[0.13    0.2     0.025   0.144   0.13723 0.6     0.84    0.      0.0038
  0.314   1.817  ]]
Logits tf.Tensor([[-0.5435842  -0.1330294   0.04595458]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23197494 0.34973794 0.41828713]], shape=(1, 3), dtype=float32)
Selected action 0
[0.13, 0.2, 0.025, 0.1769, 0.13723, 0.6, 0.84, 0, 0.0038, 0.314, 1.8170000000000002]
Reward 21.50254748581632
Current State [[0.13    0.2     0.025   0.1769  0.13723 0.6     0.84    0.      0.0038
  0.314   1.817  ]]
Logits tf.Tensor([[-0.5468112  -0.12775846  0.04058324]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23149143 0.35198745 0.41652116]], shape=(1, 3), dtype=float32)
Selected action 1
[0.05, 0.12, 0.019, 0.07690000000000001, 0.13723, 0.6, 0.57, 0, 0.009300000000000001, 0.399, 0.9630000000000001]
Reward 6.568310632376625
Current State [[0.05    0.12    0.019   0.0769  0.13723 0.6     0.57    0.      0.0093
  0.399   0.963  ]]
Logits tf.Tensor([[-0.37599012 -0.08931035  0.06894015]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2569123  0.34220654 0.40088114]], shape=(1, 3), dtype=float32)
Selected action 0
[0.08, 0.2, 0.022, 0.128, 0.13723, 0.6, 0.59, 0, 0.0129, 0.368, 0.897]
Reward 5.731714739908033
Current State [[0.08    0.2     0.022   0.128   0.13723 0.6     0.59    0.      0.0129
  0.368   0.897  ]]
Logits tf.Tensor([[-0.34503502 -0.04748607  0.05749007]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2602709  0.3504689  0.38926023]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.07, 0.034, 0.1113, 0.13723, 0.6, 0.8, 0, 0.0109, 0.421, 0.678]
Reward 7.32102961935877
Current State [[0.08    0.07    0.034   0.1113  0.13723 0.6     0.8     0.      0.0109
  0.421   0.678  ]]
Logits tf.Tensor([[-0.33638632 -0.05766145  0.04623297]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26402196 0.34889016 0.38708782]], shape=(1, 3), dtype=float32)
Selected action 0
[0.12, 0.2, 0.025, 0.1904, 0.13723, 0.6, 0.8, 0, 0.0109, 0.421, 0.678]
Reward 7.32102961935877
Current State [[0.12    0.2     0.025   0.1904  0.13723 0.6     0.8     0.      0.0109
  0.421   0.678  ]]
Logits tf.Tensor([[-0.32347807 -0.02259424  0.02388134]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26550707 0.35871398 0.3757789 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.07, 0.031, 0.1296, 0.13723, 0.6, 0.79, 0, 0.054000000000000006, 0.323, 1.494]
Reward 4.336822180387153
Episode: 27 | Average Reward: 232 | Episode Reward: 194 | Loss: 388.242 | Steps: 19 | Worker: 0
Current State [[ 0.00594062  0.00129343 -0.00594327 -0.00755875  0.00549671  0.00622268
   0.00609016 -0.00479484  0.00263675  0.00741754  0.00433558]]
Logits tf.Tensor([[-0.00676888  0.01848075 -0.0307263 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.33312255 0.34164086 0.32523662]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.07, 0.029, 0.118, 0.13723, 0.6, 0.7, 0, 0.006, 0.301, 1.268]
Reward 10.372424238876127
Current State [[0.06    0.07    0.029   0.118   0.13723 0.6     0.7     0.      0.006
  0.301   1.268  ]]
Logits tf.Tensor([[-0.44491336 -0.10611904  0.06243095]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24605517 0.34527805 0.40866676]], shape=(1, 3), dtype=float32)
Selected action 1
[0.15, 0.12, 0.024, 0.1442, 0.13723, 0.6, 0.58, 0, 0.0019, 0.383, 0.11299999999999999]
Reward 32.722295755614034
Current State [[0.15    0.12    0.024   0.1442  0.13723 0.6     0.58    0.      0.0019
  0.383   0.113  ]]
Logits tf.Tensor([[-0.15176705 -0.02732544  0.02428227]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3007507  0.34060496 0.35864428]], shape=(1, 3), dtype=float32)
Selected action 1
[0.13, 0.12, 0.025, 0.15769999999999998, 0.13723, 0.6, 0.58, 0, 0.0019, 0.383, 0.11299999999999999]
Reward 32.722295755614034
Current State [[0.13    0.12    0.025   0.1577  0.13723 0.6     0.58    0.      0.0019
  0.383   0.113  ]]
Logits tf.Tensor([[-0.15021993 -0.02984593  0.02437075]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30132487 0.33986992 0.3588052 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.13, 0.2, 0.025, 0.1688, 0.13723, 0.6, 0.77, 0, 0.0070999999999999995, 0.373, 1.027]
Reward 9.781468177186948
Current State [[0.13    0.2     0.025   0.1688  0.13723 0.6     0.77    0.      0.0071
  0.373   1.027  ]]
Logits tf.Tensor([[-0.39757058 -0.0398623   0.03779238]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2515361  0.35970882 0.38875505]], shape=(1, 3), dtype=float32)
Selected action 1
[0.14, 0.12, 0.031, 0.1453, 0.13723, 0.6, 0.54, 0, 0.0674, 0.356, 0.8640000000000001]
Reward 4.080798018217617
Current State [[0.14    0.12    0.031   0.1453  0.13723 0.6     0.54    0.      0.0674
  0.356   0.864  ]]
Logits tf.Tensor([[-0.3510664  -0.04499825  0.05666071]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25896862 0.35169876 0.38933262]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.07, 0.031, 0.1615, 0.13723, 0.6, 0.64, 0, 0.0049, 0.346, 1.537]
Reward 11.484822285928965
Current State [[0.08    0.07    0.031   0.1615  0.13723 0.6     0.64    0.      0.0049
  0.346   1.537  ]]
Logits tf.Tensor([[-0.5142148  -0.1461702   0.05213502]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23771428 0.34347492 0.4188108 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.07, 0.031, 0.134, 0.13723, 0.6, 0.64, 0, 0.0049, 0.346, 1.537]
Reward 11.484822285928965
Current State [[0.05    0.07    0.031   0.134   0.13723 0.6     0.64    0.      0.0049
  0.346   1.537  ]]
Logits tf.Tensor([[-0.5070788  -0.15730229  0.05927715]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23920092 0.33936644 0.4214326 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.09, 0.2, 0.024, 0.175, 0.13723, 0.6, 0.69, 0, 0.0045000000000000005, 0.296, 1.572]
Reward 13.664923465051926
Current State [[0.09    0.2     0.024   0.175   0.13723 0.6     0.69    0.      0.0045
  0.296   1.572  ]]
Logits tf.Tensor([[-0.47119987 -0.10355446  0.04662287]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24255955 0.35033596 0.4071045 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.1, 0.2, 0.024, 0.1377, 0.13723, 0.6, 0.78, 0, 0.0495, 0.308, 1.105]
Reward 4.379364414565152
Current State [[0.1     0.2     0.024   0.1377  0.13723 0.6     0.78    0.      0.0495
  0.308   1.105  ]]
Logits tf.Tensor([[-0.38720238 -0.05400072  0.0500461 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25355807 0.3538222  0.39261967]], shape=(1, 3), dtype=float32)
Selected action 1
[0.12, 0.12, 0.029, 0.1623, 0.13723, 0.6, 0.83, 0, 0.08310000000000001, 0.275, 1.5859999999999999]
Reward 4.157230115043767
Current State [[0.12    0.12    0.029   0.1623  0.13723 0.6     0.83    0.      0.0831
  0.275   1.586  ]]
Logits tf.Tensor([[-0.49879184 -0.11583982  0.04869067]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23835047 0.34956658 0.4120829 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.07, 0.031, 0.1269, 0.13723, 0.6, 0.83, 0, 0.0138, 0.33199999999999996, 1.264]
Reward 6.488385052349205
Current State [[0.07    0.07    0.031   0.1269  0.13723 0.6     0.83    0.      0.0138
  0.332   1.264  ]]
Logits tf.Tensor([[-0.46005884 -0.10653375  0.0587089 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24366263 0.3469948  0.40934256]], shape=(1, 3), dtype=float32)
Selected action 1
[0.14, 0.12, 0.024, 0.156, 0.13723, 0.6, 0.83, 0, 0.0138, 0.33199999999999996, 1.264]
Reward 6.488385052349205
Current State [[0.14    0.12    0.024   0.156   0.13723 0.6     0.83    0.      0.0138
  0.332   1.264  ]]
Logits tf.Tensor([[-0.47166005 -0.07680728  0.04392527]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24045491 0.3568749  0.4026702 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.07, 0.03, 0.1216, 0.13723, 0.6, 0.74, 0, 0.0044, 0.298, 1.202]
Reward 15.148866741221317
Current State [[0.05    0.07    0.03    0.1216  0.13723 0.6     0.74    0.      0.0044
  0.298   1.202  ]]
Logits tf.Tensor([[-0.43233508 -0.09915097  0.06435793]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2476055  0.34550977 0.40688467]], shape=(1, 3), dtype=float32)
Selected action 0
[0.21, 0.2, 0.026, 0.1731, 0.13723, 0.6, 0.67, 0, 0.022000000000000002, 0.31, 0.8789999999999999]
Reward 5.001421811056105
Current State [[0.21    0.2     0.026   0.1731  0.13723 0.6     0.67    0.      0.022
  0.31    0.879  ]]
Logits tf.Tensor([[-0.3719428   0.0027967   0.03571728]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25265872 0.36752045 0.37982082]], shape=(1, 3), dtype=float32)
Selected action 1
[0.17, 0.12, 0.028, 0.1306, 0.13723, 0.6, 0.77, 0, 0.0825, 0.348, 1.17]
Reward 4.131396510950644
Current State [[0.17    0.12    0.028   0.1306  0.13723 0.6     0.77    0.      0.0825
  0.348   1.17   ]]
Logits tf.Tensor([[-0.4395978  -0.06843112  0.04946202]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24508563 0.35523313 0.39968127]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.07, 0.032, 0.1189, 0.13723, 0.6, 0.77, 0, 0.0825, 0.348, 1.17]
Reward 4.131396510950644
Current State [[0.07    0.07    0.032   0.1189  0.13723 0.6     0.77    0.      0.0825
  0.348   1.17   ]]
Logits tf.Tensor([[-0.41797137 -0.10336257  0.06477885]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25061095 0.34326768 0.40612134]], shape=(1, 3), dtype=float32)
Selected action 0
[0.18, 0.2, 0.026, 0.1717, 0.13723, 0.6, 0.67, 0, 0.011699999999999999, 0.284, 1.616]
Reward 6.367365050978704
Current State [[0.18    0.2     0.026   0.1717  0.13723 0.6     0.67    0.      0.0117
  0.284   1.616  ]]
Logits tf.Tensor([[-0.49246174 -0.09603938  0.04392147]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23830467 0.3542392  0.40745613]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.07, 0.03, 0.13269999999999998, 0.13723, 0.6, 0.68, 0, 0.018500000000000003, 0.488, 1.085]
Reward 5.300061427928851
Current State [[0.04    0.07    0.03    0.1327  0.13723 0.6     0.68    0.      0.0185
  0.488   1.085  ]]
Logits tf.Tensor([[-0.42608348 -0.12328595  0.05911006]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25137442 0.34027055 0.4083551 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.07, 0.031, 0.1404, 0.13723, 0.6, 0.57, 0, 0.0333, 0.34900000000000003, 1.107]
Reward 4.443508423319311
Current State [[0.05    0.07    0.031   0.1404  0.13723 0.6     0.57    0.      0.0333
  0.349   1.107  ]]
Logits tf.Tensor([[-0.39812276 -0.10183606  0.06247738]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25446063 0.34221286 0.40332645]], shape=(1, 3), dtype=float32)
Selected action 2
[0.09, 0.07, 0.032, 0.12409999999999999, 0.13723, 0.6, 0.57, 0, 0.0333, 0.34900000000000003, 1.107]
Reward 4.443508423319311
Episode: 28 | Average Reward: 231 | Episode Reward: 196 | Loss: 205.568 | Steps: 19 | Worker: 0
Current State [[-0.00886967  0.00417676 -0.00411349 -0.00665689 -0.00167486 -0.00588859
   0.00638617  0.00715729  0.00527132 -0.00430868  0.00658896]]
Logits tf.Tensor([[ 9.9348836e-05  1.7703921e-02 -3.1663146e-02]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.33484045 0.34078738 0.3243722 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.07, 0.031, 0.15, 0.13723, 0.6, 0.52, 0, 0.016200000000000003, 0.346, 0.737]
Reward 5.094610652258512
Current State [[0.06    0.07    0.031   0.15    0.13723 0.6     0.52    0.      0.0162
  0.346   0.737  ]]
Logits tf.Tensor([[-0.31858706 -0.05623521  0.0649661 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26542988 0.34505454 0.38951558]], shape=(1, 3), dtype=float32)
Selected action 2
[0.09, 0.07, 0.031, 0.137, 0.13723, 0.6, 0.43, 0, 0.0384, 0.29100000000000004, 1.875]
Reward 4.206122219764394
Current State [[0.09    0.07    0.031   0.137   0.13723 0.6     0.43    0.      0.0384
  0.291   1.875  ]]
Logits tf.Tensor([[-0.5400287  -0.25190076  0.07491237]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2390357 0.3188564 0.4421079]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.07, 0.032, 0.125, 0.13723, 0.6, 0.43, 0, 0.0384, 0.29100000000000004, 1.875]
Reward 4.206122219764394
Current State [[0.07    0.07    0.032   0.125   0.13723 0.6     0.43    0.      0.0384
  0.291   1.875  ]]
Logits tf.Tensor([[-0.53692555 -0.25771582  0.07982627]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23952186 0.31666815 0.44380996]], shape=(1, 3), dtype=float32)
Selected action 0
[0.16, 0.2, 0.026, 0.1635, 0.13723, 0.6, 0.5, 0, 0.0177, 0.279, 1.492]
Reward 4.902457465696118
Current State [[0.16    0.2     0.026   0.1635  0.13723 0.6     0.5     0.      0.0177
  0.279   1.492  ]]
Logits tf.Tensor([[-0.437426   -0.10052378  0.05021469]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24819611 0.347624   0.40417984]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.07, 0.027, 0.124, 0.13723, 0.6, 0.66, 0, 0.0085, 0.47800000000000004, 0.758]
Reward 7.540525030884032
Current State [[0.06    0.07    0.027   0.124   0.13723 0.6     0.66    0.      0.0085
  0.478   0.758  ]]
Logits tf.Tensor([[-0.35288113 -0.08283015  0.05547147]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2621666 0.3434464 0.394387 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.08, 0.12, 0.032, 0.1423, 0.13723, 0.6, 0.81, 0, 0.0024, 0.28500000000000003, 1.136]
Reward 35.96794299139434
Current State [[0.08    0.12    0.032   0.1423  0.13723 0.6     0.81    0.      0.0024
  0.285   1.136  ]]
Logits tf.Tensor([[-0.41331628 -0.0687255   0.05522591]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24943405 0.35205427 0.39851165]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.07, 0.032, 0.12040000000000001, 0.13723, 0.6, 0.76, 0, 0.004699999999999999, 0.292, 1.9780000000000002]
Reward 14.482494516405476
Current State [[0.07    0.07    0.032   0.1204  0.13723 0.6     0.76    0.      0.0047
  0.292   1.978  ]]
Logits tf.Tensor([[-0.5840764  -0.22938767  0.0724894 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22967935 0.3274623  0.44285837]], shape=(1, 3), dtype=float32)
Selected action 0
[0.26, 0.2, 0.029, 0.18630000000000002, 0.13723, 0.6, 0.76, 0, 0.004699999999999999, 0.292, 1.9780000000000002]
Reward 14.482494516405476
Current State [[0.26    0.2     0.029   0.1863  0.13723 0.6     0.76    0.      0.0047
  0.292   1.978  ]]
Logits tf.Tensor([[-0.5753653  -0.13826561  0.04251556]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2271074  0.35161003 0.42128262]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.07, 0.033, 0.1346, 0.13723, 0.6, 0.78, 0, 0.020099999999999996, 0.261, 2.003]
Reward 5.408319773770894
Current State [[0.07    0.07    0.033   0.1346  0.13723 0.6     0.78    0.      0.0201
  0.261   2.003  ]]
Logits tf.Tensor([[-0.5779221  -0.22703505  0.07392618]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23044601 0.32730865 0.44224536]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.07, 0.032, 0.1288, 0.13723, 0.6, 0.62, 0, 0.010700000000000001, 0.267, 2.0]
Reward 6.3704679535897775
Current State [[0.05    0.07    0.032   0.1288  0.13723 0.6     0.62    0.      0.0107
  0.267   2.     ]]
Logits tf.Tensor([[-0.56895095 -0.25352332  0.08008667]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23339708 0.31995133 0.44665158]], shape=(1, 3), dtype=float32)
Selected action 0
[0.23, 0.2, 0.03, 0.18159999999999998, 0.13723, 0.6, 0.51, 0, 0.39380000000000004, 0.24500000000000002, 2.305]
Reward 3.838151576671827
Current State [[0.23    0.2     0.03    0.1816  0.13723 0.6     0.51    0.      0.3938
  0.245   2.305  ]]
Logits tf.Tensor([[-0.5188899  -0.28781116  0.07043247]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2461402  0.31012642 0.4437333 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.07, 0.031, 0.1388, 0.13723, 0.6, 0.51, 0, 0.39380000000000004, 0.24500000000000002, 2.305]
Reward 3.838151576671827
Current State [[0.07    0.07    0.031   0.1388  0.13723 0.6     0.51    0.      0.3938
  0.245   2.305  ]]
Logits tf.Tensor([[-0.5326832  -0.36393258  0.10317892]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24555096 0.29068932 0.46375972]], shape=(1, 3), dtype=float32)
Selected action 0
[0.24, 0.2, 0.033, 0.22119999999999998, 0.13723, 0.6, 0.82, 0, 0.0227, 0.26, 0.9480000000000001]
Reward 5.264583254926718
Current State [[0.24    0.2     0.033   0.2212  0.13723 0.6     0.82    0.      0.0227
  0.26    0.948  ]]
Logits tf.Tensor([[-0.40090358  0.01358723  0.01748502]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24794756 0.37529337 0.37675905]], shape=(1, 3), dtype=float32)
Selected action 1
[0.04, 0.12, 0.032, 0.1519, 0.13723, 0.6, 0.82, 0, 0.0178, 0.3, 1.6010000000000002]
Reward 5.7747921926596515
Current State [[0.04    0.12    0.032   0.1519  0.13723 0.6     0.82    0.      0.0178
  0.3     1.601  ]]
Logits tf.Tensor([[-0.4947031  -0.14100611  0.05183097]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24087219 0.34307992 0.41604793]], shape=(1, 3), dtype=float32)
Selected action 1
[0.13, 0.12, 0.03, 0.1623, 0.13723, 0.6, 0.6, 0, 0.0051, 0.286, 1.6640000000000001]
Reward 10.454878268889676
Current State [[0.13    0.12    0.03    0.1623  0.13723 0.6     0.6     0.      0.0051
  0.286   1.664  ]]
Logits tf.Tensor([[-0.50789505 -0.14897344  0.05727356]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23857641 0.34159005 0.4198335 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.16, 0.12, 0.031, 0.1373, 0.13723, 0.6, 0.77, 0, 0.0002, 0.32, 0.742]
Reward 50.0
Current State [[1.6000e-01 1.2000e-01 3.1000e-02 1.3730e-01 1.3723e-01 6.0000e-01
  7.7000e-01 0.0000e+00 2.0000e-04 3.2000e-01 7.4200e-01]]
Logits tf.Tensor([[-0.34901324 -0.0158734   0.03105983]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25921953 0.3617     0.37908044]], shape=(1, 3), dtype=float32)
Selected action 1
[0.15, 0.12, 0.035, 0.1556, 0.13723, 0.6, 0.77, 0, 0.0002, 0.32, 0.742]
Reward 50.0
Current State [[1.5000e-01 1.2000e-01 3.5000e-02 1.5560e-01 1.3723e-01 6.0000e-01
  7.7000e-01 0.0000e+00 2.0000e-04 3.2000e-01 7.4200e-01]]
Logits tf.Tensor([[-0.34670317 -0.01588362  0.03101717]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25966853 0.36148682 0.37884468]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.07, 0.036, 0.1377, 0.13723, 0.6, 0.82, 0, 0.0014000000000000002, 0.314, 1.153]
Reward 48.355514263452314
Current State [[0.04    0.07    0.036   0.1377  0.13723 0.6     0.82    0.      0.0014
  0.314   1.153  ]]
Logits tf.Tensor([[-0.42159313 -0.09587131  0.06187307]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24958096 0.34567714 0.4047419 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.07, 0.033, 0.1245, 0.13723, 0.6, 0.76, 0, 0.002, 0.268, 1.826]
Reward 39.54171286642022
Current State [[0.07    0.07    0.033   0.1245  0.13723 0.6     0.76    0.      0.002
  0.268   1.826  ]]
Logits tf.Tensor([[-0.547771   -0.19053072  0.06942449]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23347569 0.3337253  0.432799  ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.13, 0.12, 0.033, 0.1694, 0.13723, 0.6, 0.76, 0, 0.002, 0.268, 1.826]
Reward 39.54171286642022
Episode: 29 | Average Reward: 233 | Episode Reward: 359 | Loss: 1620.442 | Steps: 19 | Worker: 0
Current State [[ 0.00524884  0.00108987  0.00619284  0.00302113 -0.00354171  0.00894537
  -0.00393869  0.00225359  0.00241843  0.0083877  -0.00713933]]
Logits tf.Tensor([[-0.00294683  0.01665781 -0.03304832]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.33443192 0.34105304 0.32451504]], shape=(1, 3), dtype=float32)
Selected action 0
[0.15, 0.2, 0.027, 0.188, 0.13723, 0.6, 0.51, 0, 0.2768, 0.279, 1.2970000000000002]
Reward 3.8583132005938827
Current State [[0.15    0.2     0.027   0.188   0.13723 0.6     0.51    0.      0.2768
  0.279   1.297  ]]
Logits tf.Tensor([[-0.33476964 -0.10065915  0.04603838]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26829427 0.33906603 0.3926397 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.25, 0.2, 0.029, 0.1735, 0.13723, 0.6, 0.79, 0, 0.025699999999999997, 0.29700000000000004, 2.248]
Reward 5.022222513087115
Current State [[0.25    0.2     0.029   0.1735  0.13723 0.6     0.79    0.      0.0257
  0.297   2.248  ]]
Logits tf.Tensor([[-0.61518943 -0.2073791   0.05559405]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22425091 0.33716616 0.43858296]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.07, 0.037, 0.14809999999999998, 0.13723, 0.6, 0.86, 0, 0.0269, 0.335, 2.5789999999999997]
Reward 5.072345881308564
Current State [[0.08    0.07    0.037   0.1481  0.13723 0.6     0.86    0.      0.0269
  0.335   2.579  ]]
Logits tf.Tensor([[-0.71046305 -0.35395962  0.06973615]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.21690877 0.3098165  0.47327474]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.07, 0.033, 0.137, 0.13723, 0.6, 0.86, 0, 0.0269, 0.335, 2.5789999999999997]
Reward 5.072345881308564
Current State [[0.07    0.07    0.033   0.137   0.13723 0.6     0.86    0.      0.0269
  0.335   2.579  ]]
Logits tf.Tensor([[-0.70807797 -0.35915425  0.07207672]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.217422   0.3082046  0.47437343]], shape=(1, 3), dtype=float32)
Selected action 1
[0.11, 0.12, 0.034, 0.175, 0.13723, 0.6, 0.7, 0, 0.0029, 0.23399999999999999, 1.8519999999999999]
Reward 24.036920543904
Current State [[0.11    0.12    0.034   0.175   0.13723 0.6     0.7     0.      0.0029
  0.234   1.852  ]]
Logits tf.Tensor([[-0.5270209  -0.17437744  0.06683547]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23619542 0.33606443 0.4277401 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.1, 0.12, 0.025, 0.1635, 0.13723, 0.6, 0.8, 0, 0.0111, 0.303, 1.324]
Reward 7.195186013617032
Current State [[0.1     0.12    0.025   0.1635  0.13723 0.6     0.8     0.      0.0111
  0.303   1.324  ]]
Logits tf.Tensor([[-0.4601743  -0.09419645  0.04870313]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24358483 0.35123065 0.40518457]], shape=(1, 3), dtype=float32)
Selected action 1
[0.09, 0.12, 0.034, 0.1623, 0.13723, 0.6, 0.89, 0, 0.0012, 0.32, 0.40099999999999997]
Reward 49.63067213040839
Current State [[0.09    0.12    0.034   0.1623  0.13723 0.6     0.89    0.      0.0012
  0.32    0.401  ]]
Logits tf.Tensor([[-0.25900644 -0.02565074  0.01872189]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.279099   0.35245478 0.3684463 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.15, 0.12, 0.035, 0.196, 0.13723, 0.6, 0.89, 0, 0.0012, 0.32, 0.40099999999999997]
Reward 49.63067213040839
Current State [[0.15    0.12    0.035   0.196   0.13723 0.6     0.89    0.      0.0012
  0.32    0.401  ]]
Logits tf.Tensor([[-0.27122965 -0.00949849  0.00458236]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.27648923 0.3592085  0.36430225]], shape=(1, 3), dtype=float32)
Selected action 1
[0.11, 0.12, 0.031, 0.1787, 0.13723, 0.6, 0.76, 0, 0.0022, 0.277, 2.103]
Reward 36.21893955176978
Current State [[0.11    0.12    0.031   0.1787  0.13723 0.6     0.76    0.      0.0022
  0.277   2.103  ]]
Logits tf.Tensor([[-0.5924058  -0.22846416  0.06468058]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22892967 0.3294276  0.44164273]], shape=(1, 3), dtype=float32)
Selected action 2
[0.09, 0.07, 0.032, 0.1188, 0.13723, 0.6, 0.73, 0, 0.052199999999999996, 0.213, 2.754]
Reward 4.3151376922287215
Current State [[0.09    0.07    0.032   0.1188  0.13723 0.6     0.73    0.      0.0522
  0.213   2.754  ]]
Logits tf.Tensor([[-0.68740034 -0.39904264  0.09297367]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22140928 0.29541188 0.48317888]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.07, 0.033, 0.1321, 0.13723, 0.6, 0.73, 0, 0.052199999999999996, 0.213, 2.754]
Reward 4.3151376922287215
Current State [[0.07    0.07    0.033   0.1321  0.13723 0.6     0.73    0.      0.0522
  0.213   2.754  ]]
Logits tf.Tensor([[-0.6858187  -0.4017129   0.09211306]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22194906 0.29487562 0.48317534]], shape=(1, 3), dtype=float32)
Selected action 0
[0.06, 0.2, 0.024, 0.1635, 0.13723, 0.6, 0.54, 0, 0.0072, 0.327, 1.019]
Reward 7.370658847815354
Current State [[0.06    0.2     0.024   0.1635  0.13723 0.6     0.54    0.      0.0072
  0.327   1.019  ]]
Logits tf.Tensor([[-0.3508754  -0.06067544  0.05601966]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26049525 0.34820268 0.39130205]], shape=(1, 3), dtype=float32)
Selected action 1
[0.13, 0.12, 0.029, 0.1469, 0.13723, 0.6, 0.85, 0, 0.0060999999999999995, 0.34700000000000003, 0.8619999999999999]
Reward 12.406179373880384
Current State [[0.13    0.12    0.029   0.1469  0.13723 0.6     0.85    0.      0.0061
  0.347   0.862  ]]
Logits tf.Tensor([[-0.37544334 -0.04434566  0.03470682]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25644052 0.35709235 0.38646716]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.07, 0.029, 0.128, 0.13723, 0.6, 0.85, 0, 0.0017000000000000001, 0.308, 1.9460000000000002]
Reward 46.66953651271217
Current State [[8.0000e-02 7.0000e-02 2.9000e-02 1.2800e-01 1.3723e-01 6.0000e-01
  8.5000e-01 0.0000e+00 1.7000e-03 3.0800e-01 1.9460e+00]]
Logits tf.Tensor([[-0.5858718  -0.21324575  0.06411471]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2289872  0.3323844  0.43862844]], shape=(1, 3), dtype=float32)
Selected action 0
[0.15, 0.2, 0.026, 0.16419999999999998, 0.13723, 0.6, 0.57, 0, 0.0288, 0.33599999999999997, 0.791]
Reward 4.545478857497014
Current State [[0.15    0.2     0.026   0.1642  0.13723 0.6     0.57    0.      0.0288
  0.336   0.791  ]]
Logits tf.Tensor([[-0.32404953 -0.01749751  0.04705507]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26260042 0.35680366 0.38059592]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.07, 0.034, 0.156, 0.13723, 0.6, 0.57, 0, 0.0288, 0.33599999999999997, 0.791]
Reward 4.545478857497014
Current State [[0.06    0.07    0.034   0.156   0.13723 0.6     0.57    0.      0.0288
  0.336   0.791  ]]
Logits tf.Tensor([[-0.33071214 -0.06180649  0.06604706]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26346785 0.344756   0.3917761 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.07, 0.032, 0.125, 0.13723, 0.6, 0.52, 0, 0.024399999999999998, 0.311, 1.048]
Reward 4.605860977748687
Current State [[0.07    0.07    0.032   0.125   0.13723 0.6     0.52    0.      0.0244
  0.311   1.048  ]]
Logits tf.Tensor([[-0.38026136 -0.09134192  0.06611104]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.256567   0.34251288 0.40092012]], shape=(1, 3), dtype=float32)
Selected action 0
[0.19, 0.2, 0.026, 0.164, 0.13723, 0.6, 0.68, 0, 0.0027, 0.45899999999999996, 0.127]
Reward 24.911784506897796
Current State [[0.19    0.2     0.026   0.164   0.13723 0.6     0.68    0.      0.0027
  0.459   0.127  ]]
Logits tf.Tensor([[-0.14994901 -0.03635487 -0.00731968]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30547416 0.34222186 0.352304  ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.1, 0.12, 0.025, 0.1529, 0.13723, 0.6, 0.68, 0, 0.0027, 0.45899999999999996, 0.127]
Reward 24.911784506897796
Current State [[0.1     0.12    0.025   0.1529  0.13723 0.6     0.68    0.      0.0027
  0.459   0.127  ]]
Logits tf.Tensor([[-0.15199362 -0.05762646  0.0185635 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30442065 0.33454707 0.36103234]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.07, 0.025, 0.1154, 0.13723, 0.6, 0.78, 0, 0.0029, 0.366, 0.361]
Reward 27.780980767499102
Episode: 30 | Average Reward: 234 | Episode Reward: 352 | Loss: 1184.027 | Steps: 19 | Worker: 0
Current State [[-0.00049732  0.00050272 -0.00416779 -0.00408678 -0.00414708  0.00669068
   0.00471062  0.00761267 -0.00145867  0.00966261  0.00925467]]
Logits tf.Tensor([[-0.00972329  0.01787364 -0.03193074]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.33266595 0.34197438 0.32535973]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.07, 0.028, 0.12129999999999999, 0.13723, 0.6, 0.69, 0, 0.0034999999999999996, 0.321, 0.8109999999999999]
Reward 18.33103550846347
Current State [[0.06    0.07    0.028   0.1213  0.13723 0.6     0.69    0.      0.0035
  0.321   0.811  ]]
Logits tf.Tensor([[-0.34400606 -0.06726173  0.06067243]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26194125 0.3454558  0.39260295]], shape=(1, 3), dtype=float32)
Selected action 0
[0.12, 0.2, 0.024, 0.142, 0.13723, 0.6, 0.73, 0, 0.004, 0.32799999999999996, 0.759]
Reward 16.595812917717158
Current State [[0.12    0.2     0.024   0.142   0.13723 0.6     0.73    0.      0.004
  0.328   0.759  ]]
Logits tf.Tensor([[-0.3260587  -0.02357008  0.03717131]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2637695  0.35693878 0.37929174]], shape=(1, 3), dtype=float32)
Selected action 1
[0.14, 0.12, 0.027, 0.1442, 0.13723, 0.6, 0.73, 0, 0.004, 0.32799999999999996, 0.759]
Reward 16.595812917717158
Current State [[0.14    0.12    0.027   0.1442  0.13723 0.6     0.73    0.      0.004
  0.328   0.759  ]]
Logits tf.Tensor([[-0.34652424 -0.02943696  0.03991923]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26008752 0.357132   0.38278046]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.07, 0.032, 0.134, 0.13723, 0.6, 0.83, 0, 0.0036, 0.369, 1.1560000000000001]
Reward 22.425026560933738
Current State [[0.07    0.07    0.032   0.134   0.13723 0.6     0.83    0.      0.0036
  0.369   1.156  ]]
Logits tf.Tensor([[-0.43605068 -0.10553874  0.05946937]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24795239 0.3450705  0.40697706]], shape=(1, 3), dtype=float32)
Selected action 0
[0.13, 0.2, 0.025, 0.1418, 0.13723, 0.6, 0.69, 0, 0.009300000000000001, 0.298, 1.022]
Reward 7.321096373685116
Current State [[0.13    0.2     0.025   0.1418  0.13723 0.6     0.69    0.      0.0093
  0.298   1.022  ]]
Logits tf.Tensor([[-0.37536544 -0.03778524  0.05043256]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2543     0.35641465 0.38928536]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.07, 0.028, 0.1291, 0.13723, 0.6, 0.51, 0, 0.0051, 0.367, 0.751]
Reward 9.114684448292786
Current State [[0.06    0.07    0.028   0.1291  0.13723 0.6     0.51    0.      0.0051
  0.367   0.751  ]]
Logits tf.Tensor([[-0.3262459  -0.06926858  0.07013176]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.264589  0.3421178 0.3932932]], shape=(1, 3), dtype=float32)
Selected action 0
[0.08, 0.2, 0.023, 0.15580000000000002, 0.13723, 0.6, 0.51, 0, 0.0051, 0.367, 0.751]
Reward 9.114684448292786
Current State [[0.08    0.2     0.023   0.1558  0.13723 0.6     0.51    0.      0.0051
  0.367   0.751  ]]
Logits tf.Tensor([[-0.29968643 -0.03936991  0.05797572]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26828906 0.3480623  0.38364863]], shape=(1, 3), dtype=float32)
Selected action 0
[0.1, 0.2, 0.024, 0.1373, 0.13723, 0.6, 0.63, 0, 0.0676, 0.24100000000000002, 0.663]
Reward 4.132931282066625
Current State [[0.1     0.2     0.024   0.1373  0.13723 0.6     0.63    0.      0.0676
  0.241   0.663  ]]
Logits tf.Tensor([[-0.27165085 -0.01581449  0.04697978]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2727185  0.35222724 0.37505427]], shape=(1, 3), dtype=float32)
Selected action 1
[0.23, 0.12, 0.027, 0.15830000000000002, 0.13723, 0.6, 0.79, 0, 0.0055000000000000005, 0.34500000000000003, 1.326]
Reward 12.819936070706802
Current State [[0.23    0.12    0.027   0.1583  0.13723 0.6     0.79    0.      0.0055
  0.345   1.326  ]]
Logits tf.Tensor([[-0.497997   -0.07354405  0.03367034]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23637749 0.361363   0.4022595 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.07, 0.025, 0.1154, 0.13723, 0.6, 0.65, 0, 0.031, 0.315, 0.647]
Reward 4.59746155153267
Current State [[0.07    0.07    0.025   0.1154  0.13723 0.6     0.65    0.      0.031
  0.315   0.647  ]]
Logits tf.Tensor([[-0.30299017 -0.04993146  0.05598972]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2688297  0.34624162 0.38492867]], shape=(1, 3), dtype=float32)
Selected action 1
[0.11, 0.12, 0.028, 0.15, 0.13723, 0.6, 0.65, 0, 0.031, 0.315, 0.647]
Reward 4.59746155153267
Current State [[0.11    0.12    0.028   0.15    0.13723 0.6     0.65    0.      0.031
  0.315   0.647  ]]
Logits tf.Tensor([[-0.3026166  -0.02789142  0.04691118]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26776868 0.35242882 0.37980247]], shape=(1, 3), dtype=float32)
Selected action 1
[0.1, 0.12, 0.023, 0.1529, 0.13723, 0.6, 0.72, 0, 0.0062, 0.35, 0.465]
Reward 10.286068451253936
Current State [[0.1     0.12    0.023   0.1529  0.13723 0.6     0.72    0.      0.0062
  0.35    0.465  ]]
Logits tf.Tensor([[-0.2644917  -0.02345346  0.03729497]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.27587405 0.35106897 0.37305695]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.07, 0.028, 0.1226, 0.13723, 0.6, 0.61, 0, 0.0087, 0.33399999999999996, 1.06]
Reward 7.119809507935895
Current State [[0.07    0.07    0.028   0.1226  0.13723 0.6     0.61    0.      0.0087
  0.334   1.06   ]]
Logits tf.Tensor([[-0.39540744 -0.09639309  0.06482293]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2542609  0.3428782  0.40286088]], shape=(1, 3), dtype=float32)
Selected action 1
[0.13, 0.12, 0.031, 0.1415, 0.13723, 0.6, 0.53, 0, 0.0126, 0.277, 1.2189999999999999]
Reward 5.5350547786363675
Current State [[0.13    0.12    0.031   0.1415  0.13723 0.6     0.53    0.      0.0126
  0.277   1.219  ]]
Logits tf.Tensor([[-0.40833122 -0.08103153  0.05783465]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2511876  0.3484517  0.40036067]], shape=(1, 3), dtype=float32)
Selected action 0
[0.34, 0.2, 0.027, 0.1596, 0.13723, 0.6, 0.75, 0, 0.009000000000000001, 0.325, 1.0470000000000002]
Reward 7.971510945170486
Current State [[0.34    0.2     0.027   0.1596  0.13723 0.6     0.75    0.      0.009
  0.325   1.047  ]]
Logits tf.Tensor([[-0.44880378  0.00770731  0.02152531]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23928724 0.37772855 0.38298425]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.07, 0.031, 0.1375, 0.13723, 0.6, 0.75, 0, 0.009000000000000001, 0.325, 1.0470000000000002]
Reward 7.971510945170486
Current State [[0.07    0.07    0.031   0.1375  0.13723 0.6     0.75    0.      0.009
  0.325   1.047  ]]
Logits tf.Tensor([[-0.3995123  -0.08602577  0.06297803]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25276712 0.34583268 0.40140018]], shape=(1, 3), dtype=float32)
Selected action 1
[0.13, 0.12, 0.03, 0.15880000000000002, 0.13723, 0.6, 0.5, 0, 0.042, 0.318, 1.488]
Reward 4.235441627016061
Current State [[0.13    0.12    0.03    0.1588  0.13723 0.6     0.5     0.      0.042
  0.318   1.488  ]]
Logits tf.Tensor([[-0.4567169  -0.14462599  0.05906746]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24744935 0.33808485 0.41446576]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.07, 0.031, 0.1226, 0.13723, 0.6, 0.78, 0, 0.0358, 0.42400000000000004, 0.52]
Reward 4.6298714842225515
Current State [[0.04    0.07    0.031   0.1226  0.13723 0.6     0.78    0.      0.0358
  0.424   0.52   ]]
Logits tf.Tensor([[-0.27306446 -0.06711937  0.04833358]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.27718183 0.34056938 0.38224882]], shape=(1, 3), dtype=float32)
Selected action 0
[0.16, 0.2, 0.025, 0.1774, 0.13723, 0.6, 0.6, 0, 0.0166, 0.348, 1.3699999999999999]
Reward 5.273515782581244
Current State [[0.16    0.2     0.025   0.1774  0.13723 0.6     0.6     0.      0.0166
  0.348   1.37   ]]
Logits tf.Tensor([[-0.44479278 -0.08089161  0.04081423]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24605736 0.3540598  0.39988285]], shape=(1, 3), dtype=float32)
Selected action 2
[0.09, 0.07, 0.037, 0.1415, 0.13723, 0.6, 0.6, 0, 0.0166, 0.348, 1.3699999999999999]
Reward 5.273515782581244
Episode: 31 | Average Reward: 233 | Episode Reward: 183 | Loss: 193.358 | Steps: 19 | Worker: 0
Current State [[ 6.33858914e-03 -3.61743603e-03 -1.50619090e-03 -1.67199417e-03
  -9.97622904e-03 -9.45338402e-06  4.91557933e-03  2.52891382e-03
  -6.91921091e-03  2.22296312e-03  6.21266136e-03]]
Logits tf.Tensor([[-0.01091913  0.01797342 -0.03338531]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3325465  0.34229475 0.32515875]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.07, 0.035, 0.138, 0.13723, 0.6, 0.5, 0, 0.016, 0.236, 2.116]
Reward 5.043005018754547
Current State [[0.07    0.07    0.035   0.138   0.13723 0.6     0.5     0.      0.016
  0.236   2.116  ]]
Logits tf.Tensor([[-0.55916965 -0.3020785   0.0919402 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23748283 0.30710402 0.4554132 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.3, 0.2, 0.029, 0.1865, 0.13723, 0.6, 0.6, 0, 0.016200000000000003, 0.321, 1.582]
Reward 5.321756413256982
Current State [[0.3     0.2     0.029   0.1865  0.13723 0.6     0.6     0.      0.0162
  0.321   1.582  ]]
Logits tf.Tensor([[-0.49955958 -0.09956576  0.03545212]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23813584 0.35525477 0.4066094 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.07, 0.031, 0.136, 0.13723, 0.6, 0.59, 0, 0.2876, 0.317, 1.9129999999999998]
Reward 3.8652655818603865
Current State [[0.07    0.07    0.031   0.136   0.13723 0.6     0.59    0.      0.2876
  0.317   1.913  ]]
Logits tf.Tensor([[-0.50038487 -0.29170877  0.08966067]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24776293 0.3052553  0.44698182]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.07, 0.027, 0.134, 0.13723, 0.6, 0.59, 0, 0.2876, 0.317, 1.9129999999999998]
Reward 3.8652655818603865
Current State [[0.03    0.07    0.027   0.134   0.13723 0.6     0.59    0.      0.2876
  0.317   1.913  ]]
Logits tf.Tensor([[-0.49309742 -0.30334583  0.09379917]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24954163 0.30168316 0.4487753 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.2, 0.021, 0.14909999999999998, 0.13723, 0.6, 0.54, 0, 0.013300000000000001, 0.385, 0.8619999999999999]
Reward 5.49133453079852
Current State [[0.05    0.2     0.021   0.1491  0.13723 0.6     0.54    0.      0.0133
  0.385   0.862  ]]
Logits tf.Tensor([[-0.32077447 -0.06525993  0.06376918]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26595253 0.3433782  0.39066932]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.07, 0.039, 0.1321, 0.13723, 0.6, 0.8, 0, 0.0078000000000000005, 0.353, 0.316]
Reward 9.308124805661413
Current State [[0.07    0.07    0.039   0.1321  0.13723 0.6     0.8     0.      0.0078
  0.353   0.316  ]]
Logits tf.Tensor([[-0.22673193 -0.03687372  0.03864576]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.28465685 0.3441724  0.3711707 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.07, 0.036, 0.1306, 0.13723, 0.6, 0.82, 0, 0.0027, 0.29900000000000004, 1.09]
Reward 31.94685057429185
Current State [[0.06    0.07    0.036   0.1306  0.13723 0.6     0.82    0.      0.0027
  0.299   1.09   ]]
Logits tf.Tensor([[-0.40411425 -0.09015909  0.06633752]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25191802 0.3448325  0.4032495 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.17, 0.2, 0.029, 0.1776, 0.13723, 0.6, 0.82, 0, 0.0027, 0.29900000000000004, 1.09]
Reward 31.94685057429185
Current State [[0.17    0.2     0.029   0.1776  0.13723 0.6     0.82    0.      0.0027
  0.299   1.09   ]]
Logits tf.Tensor([[-0.4098879  -0.03091362  0.03856423]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24834405 0.36277738 0.38887858]], shape=(1, 3), dtype=float32)
Selected action 0
[0.12, 0.2, 0.031, 0.2038, 0.13723, 0.6, 0.77, 0, 0.0042, 0.296, 1.8670000000000002]
Reward 16.692957872351148
Current State [[0.12    0.2     0.031   0.2038  0.13723 0.6     0.77    0.      0.0042
  0.296   1.867  ]]
Logits tf.Tensor([[-0.51967144 -0.16094199  0.04905654]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23823543 0.34103626 0.42072836]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.07, 0.032, 0.15209999999999999, 0.13723, 0.6, 0.82, 0, 0.009300000000000001, 0.323, 1.968]
Reward 8.249716853473371
Current State [[0.06    0.07    0.032   0.1521  0.13723 0.6     0.82    0.      0.0093
  0.323   1.968  ]]
Logits tf.Tensor([[-0.5811393  -0.23758306  0.0673096 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2313463  0.32618734 0.4424664 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.04, 0.12, 0.032, 0.15369999999999998, 0.13723, 0.6, 0.49, 0, 0.4073, 0.24500000000000002, 2.34]
Reward 3.8351705460082126
Current State [[0.04    0.12    0.032   0.1537  0.13723 0.6     0.49    0.      0.4073
  0.245   2.34   ]]
Logits tf.Tensor([[-0.4935826  -0.39109227  0.10995885]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25403216 0.28144896 0.46451893]], shape=(1, 3), dtype=float32)
Selected action 1
[0.16, 0.12, 0.035, 0.1442, 0.13723, 0.6, 0.77, 0, 0.0026, 0.309, 1.435]
Reward 31.126800958364154
Current State [[0.16    0.12    0.035   0.1442  0.13723 0.6     0.77    0.      0.0026
  0.309   1.435  ]]
Logits tf.Tensor([[-0.48625442 -0.09931628  0.04950895]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23916478 0.35216188 0.40867335]], shape=(1, 3), dtype=float32)
Selected action 1
[0.06, 0.12, 0.033, 0.168, 0.13723, 0.6, 0.77, 0, 0.0026, 0.309, 1.435]
Reward 31.126800958364154
Current State [[0.06    0.12    0.033   0.168   0.13723 0.6     0.77    0.      0.0026
  0.309   1.435  ]]
Logits tf.Tensor([[-0.46174937 -0.12164028  0.05438335]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24505982 0.34433377 0.41060638]], shape=(1, 3), dtype=float32)
Selected action 0
[0.2, 0.2, 0.027, 0.1904, 0.13723, 0.6, 0.78, 0, 0.0019, 0.308, 1.51]
Reward 41.66366255076153
Current State [[0.2     0.2     0.027   0.1904  0.13723 0.6     0.78    0.      0.0019
  0.308   1.51   ]]
Logits tf.Tensor([[-0.4897228  -0.07915305  0.03655251]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23807864 0.3589456  0.40297574]], shape=(1, 3), dtype=float32)
Selected action 1
[0.11, 0.12, 0.029, 0.1596, 0.13723, 0.6, 0.63, 0, 0.1148, 0.282, 1.8210000000000002]
Reward 3.9903551711166765
Current State [[0.11    0.12    0.029   0.1596  0.13723 0.6     0.63    0.      0.1148
  0.282   1.821  ]]
Logits tf.Tensor([[-0.5025115  -0.21355     0.07496859]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24291988 0.3243078  0.4327723 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.07, 0.032, 0.1212, 0.13723, 0.6, 0.79, 0, 0.0002, 0.302, 1.034]
Reward 49.999999999994046
Current State [[8.0000e-02 7.0000e-02 3.2000e-02 1.2120e-01 1.3723e-01 6.0000e-01
  7.9000e-01 0.0000e+00 2.0000e-04 3.0200e-01 1.0340e+00]]
Logits tf.Tensor([[-0.39855522 -0.08067068  0.06516634]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25225785 0.3466572  0.40108496]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.07, 0.04, 0.1415, 0.13723, 0.6, 0.66, 0, 0.038, 0.268, 1.1019999999999999]
Reward 4.445523812867536
Current State [[0.05    0.07    0.04    0.1415  0.13723 0.6     0.66    0.      0.038
  0.268   1.102  ]]
Logits tf.Tensor([[-0.37984613 -0.09318238  0.07044007]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25636178 0.3414678  0.40217036]], shape=(1, 3), dtype=float32)
Selected action 0
[0.18, 0.2, 0.029, 0.2, 0.13723, 0.6, 0.66, 0, 0.038, 0.268, 1.1019999999999999]
Reward 4.445523812867536
Current State [[0.18    0.2     0.029   0.2     0.13723 0.6     0.66    0.      0.038
  0.268   1.102  ]]
Logits tf.Tensor([[-0.3878147  -0.02798717  0.04193173]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25189233 0.36098245 0.38712522]], shape=(1, 3), dtype=float32)
Selected action 0
[0.12, 0.2, 0.028, 0.2039, 0.13723, 0.6, 0.84, 0, 0.0479, 0.262, 1.496]
Reward 4.451983995351445
Current State [[0.12    0.2     0.028   0.2039  0.13723 0.6     0.84    0.      0.0479
  0.262   1.496  ]]
Logits tf.Tensor([[-0.45517653 -0.09348391  0.04508714]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24480322 0.3514781  0.4037187 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.19, 0.2, 0.026, 0.19, 0.13723, 0.6, 0.82, 0, 0.0079, 0.329, 1.441]
Reward 9.409756014761166
Episode: 32 | Average Reward: 234 | Episode Reward: 306 | Loss: 980.55 | Steps: 19 | Worker: 0
Current State [[ 0.0095021   0.00070616  0.00357113  0.00022606  0.00019429  0.00294656
   0.00433758  0.00249577 -0.00665359  0.00350285  0.00238483]]
Logits tf.Tensor([[-0.00691362  0.0188068  -0.03046441]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.33302492 0.34170157 0.32527357]], shape=(1, 3), dtype=float32)
Selected action 1
[0.12, 0.12, 0.032, 0.15369999999999998, 0.13723, 0.6, 0.82, 0, 0.0365, 0.315, 2.066]
Reward 4.664919787553397
Current State [[0.12    0.12    0.032   0.1537  0.13723 0.6     0.82    0.      0.0365
  0.315   2.066  ]]
Logits tf.Tensor([[-0.57135683 -0.24326241  0.06766018]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23348461 0.32415137 0.44236407]], shape=(1, 3), dtype=float32)
Selected action 0
[0.13, 0.2, 0.029, 0.15580000000000002, 0.13723, 0.6, 0.83, 0, 0.0479, 0.313, 2.086]
Reward 4.448727537540262
Current State [[0.13    0.2     0.029   0.1558  0.13723 0.6     0.83    0.      0.0479
  0.313   2.086  ]]
Logits tf.Tensor([[-0.5455835  -0.22637425  0.06115373]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23750286 0.32681325 0.43568385]], shape=(1, 3), dtype=float32)
Selected action 1
[0.11, 0.12, 0.035, 0.1566, 0.13723, 0.6, 0.83, 0, 0.0479, 0.313, 2.086]
Reward 4.448727537540262
Current State [[0.11    0.12    0.035   0.1566  0.13723 0.6     0.83    0.      0.0479
  0.313   2.086  ]]
Logits tf.Tensor([[-0.5709546  -0.24944863  0.06854156]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23393297 0.32264113 0.44342595]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.07, 0.032, 0.1321, 0.13723, 0.6, 0.73, 0, 0.0043, 0.32599999999999996, 1.6179999999999999]
Reward 15.612674660204851
Current State [[0.04    0.07    0.032   0.1321  0.13723 0.6     0.73    0.      0.0043
  0.326   1.618  ]]
Logits tf.Tensor([[-0.49696323 -0.18519124  0.0644727 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24277553 0.3315933  0.42563117]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.07, 0.032, 0.1388, 0.13723, 0.6, 0.77, 0, 0.005, 0.28300000000000003, 1.56]
Reward 13.946507649910133
Current State [[0.05    0.07    0.032   0.1388  0.13723 0.6     0.77    0.      0.005
  0.283   1.56   ]]
Logits tf.Tensor([[-0.48099408 -0.16323873  0.06246814]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24414073 0.33545914 0.42040017]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.07, 0.028, 0.146, 0.13723, 0.6, 0.66, 0, 0.0055000000000000005, 0.23399999999999999, 2.2920000000000003]
Reward 10.784327648931335
Current State [[0.08    0.07    0.028   0.146   0.13723 0.6     0.66    0.      0.0055
  0.234   2.292  ]]
Logits tf.Tensor([[-0.5924552  -0.32642123  0.08675664]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23380317 0.30506158 0.4611353 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.07, 0.043, 0.1333, 0.13723, 0.6, 0.66, 0, 0.0055000000000000005, 0.23399999999999999, 2.2920000000000003]
Reward 10.784327648931335
Current State [[0.07    0.07    0.043   0.1333  0.13723 0.6     0.66    0.      0.0055
  0.234   2.292  ]]
Logits tf.Tensor([[-0.58753616 -0.32798085  0.09073066]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23436695 0.30382243 0.46181062]], shape=(1, 3), dtype=float32)
Selected action 1
[0.07, 0.12, 0.031, 0.1566, 0.13723, 0.6, 0.54, 0, 0.09630000000000001, 0.23700000000000002, 1.7260000000000002]
Reward 3.9932120317300828
Current State [[0.07    0.12    0.031   0.1566  0.13723 0.6     0.54    0.      0.0963
  0.237   1.726  ]]
Logits tf.Tensor([[-0.45104614 -0.21333218  0.08534857]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25137138 0.31882596 0.42980266]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.07, 0.035, 0.118, 0.13723, 0.6, 0.67, 0, 0.0049, 0.32999999999999996, 1.7850000000000001]
Reward 12.261336986612212
Current State [[0.07    0.07    0.035   0.118   0.13723 0.6     0.67    0.      0.0049
  0.33    1.785  ]]
Logits tf.Tensor([[-0.53068787 -0.22783136  0.0755192 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23882398 0.32330084 0.43787515]], shape=(1, 3), dtype=float32)
Selected action 1
[0.13, 0.12, 0.026, 0.15380000000000002, 0.13723, 0.6, 0.67, 0, 0.0049, 0.32999999999999996, 1.7850000000000001]
Reward 12.261336986612212
Current State [[0.13    0.12    0.026   0.1538  0.13723 0.6     0.67    0.      0.0049
  0.33    1.785  ]]
Logits tf.Tensor([[-0.5271316  -0.19520116  0.06277622]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23823829 0.3320222  0.4297395 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.14, 0.12, 0.03, 0.1673, 0.13723, 0.6, 0.71, 0, 0.0032, 0.27799999999999997, 1.226]
Reward 21.506556353120594
Current State [[0.14    0.12    0.03    0.1673  0.13723 0.6     0.71    0.      0.0032
  0.278   1.226  ]]
Logits tf.Tensor([[-0.42613283 -0.07723872  0.04927724]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24837482 0.35207108 0.39955407]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.07, 0.032, 0.1385, 0.13723, 0.6, 0.76, 0, 0.0058, 0.274, 1.082]
Reward 11.629432376453366
Current State [[0.07    0.07    0.032   0.1385  0.13723 0.6     0.76    0.      0.0058
  0.274   1.082  ]]
Logits tf.Tensor([[-0.39180028 -0.08912745  0.06578301]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25421217 0.34406894 0.40171885]], shape=(1, 3), dtype=float32)
Selected action 2
[0.09, 0.07, 0.032, 0.1255, 0.13723, 0.6, 0.58, 0, 0.08869999999999999, 0.286, 0.991]
Reward 4.029993952666229
Current State [[0.09    0.07    0.032   0.1255  0.13723 0.6     0.58    0.      0.0887
  0.286   0.991  ]]
Logits tf.Tensor([[-0.3506259  -0.08679071  0.07259867]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2611791  0.34003258 0.39878836]], shape=(1, 3), dtype=float32)
Selected action 0
[0.27, 0.2, 0.027, 0.192, 0.13723, 0.6, 0.58, 0, 0.08869999999999999, 0.286, 0.991]
Reward 4.029993952666229
Current State [[0.27    0.2     0.027   0.192   0.13723 0.6     0.58    0.      0.0887
  0.286   0.991  ]]
Logits tf.Tensor([[-0.372024   -0.01306134  0.03700101]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2539881  0.36367112 0.3823408 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.09, 0.07, 0.028, 0.1313, 0.13723, 0.6, 0.52, 0, 0.034, 0.5650000000000001, 1.275]
Reward 4.366466710617809
Current State [[0.09    0.07    0.028   0.1313  0.13723 0.6     0.52    0.      0.034
  0.565   1.275  ]]
Logits tf.Tensor([[-0.47309995 -0.19241819  0.06208886]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24802801 0.32839707 0.42357495]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.07, 0.033, 0.1288, 0.13723, 0.6, 0.34, 0, 0.222, 0.32799999999999996, 1.139]
Reward 3.846734546663213
Current State [[0.06    0.07    0.033   0.1288  0.13723 0.6     0.34    0.      0.222
  0.328   1.139  ]]
Logits tf.Tensor([[-0.3241468  -0.17063344  0.08099637]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2728185  0.3180855  0.40909603]], shape=(1, 3), dtype=float32)
Selected action 2
[0.12, 0.07, 0.033, 0.1431, 0.13723, 0.6, 0.68, 0, 0.003, 0.275, 1.3699999999999999]
Reward 21.841039314362828
Current State [[0.12    0.07    0.033   0.1431  0.13723 0.6     0.68    0.      0.003
  0.275   1.37   ]]
Logits tf.Tensor([[-0.45515844 -0.11695594  0.05925631]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24539374 0.3441462  0.4104601 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.07, 0.031, 0.13269999999999998, 0.13723, 0.6, 0.68, 0, 0.003, 0.275, 1.3699999999999999]
Reward 21.841039314362828
Current State [[0.05    0.07    0.031   0.1327  0.13723 0.6     0.68    0.      0.003
  0.275   1.37   ]]
Logits tf.Tensor([[-0.4384836  -0.13375989  0.06450173]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24938273 0.3382254  0.4123919 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.06, 0.12, 0.022, 0.149, 0.13723, 0.6, 0.62, 0, 0.0060999999999999995, 0.31, 1.183]
Reward 9.244232431016746
Current State [[0.06    0.12    0.022   0.149   0.13723 0.6     0.62    0.      0.0061
  0.31    1.183  ]]
Logits tf.Tensor([[-0.39668578 -0.10461216  0.06103484]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2551236  0.3416619  0.40321448]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.07, 0.024, 0.128, 0.13723, 0.6, 0.69, 0, 0.0051, 0.34900000000000003, 0.96]
Reward 12.147781645793911
Episode: 33 | Average Reward: 234 | Episode Reward: 207 | Loss: 400.346 | Steps: 19 | Worker: 0
Current State [[ 0.00181459  0.00311805  0.0083735   0.00417025  0.00680175  0.00929531
   0.00146171 -0.00295754  0.00535238 -0.00095875 -0.00188486]]
Logits tf.Tensor([[-0.00092503  0.0195131  -0.02458595]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.33363748 0.34052658 0.32583597]], shape=(1, 3), dtype=float32)
Selected action 1
[0.07, 0.12, 0.024, 0.1333, 0.13723, 0.6, 0.73, 0, 0.0038, 0.324, 0.162]
Reward 17.772220335832028
Current State [[0.07    0.12    0.024   0.1333  0.13723 0.6     0.73    0.      0.0038
  0.324   0.162  ]]
Logits tf.Tensor([[-0.1723887  -0.03319696  0.03105081]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2963002  0.34055102 0.3631488 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.17, 0.2, 0.024, 0.1784, 0.13723, 0.6, 0.73, 0, 0.0038, 0.324, 0.162]
Reward 17.772220335832028
Current State [[0.17    0.2     0.024   0.1784  0.13723 0.6     0.73    0.      0.0038
  0.324   0.162  ]]
Logits tf.Tensor([[-0.17659903 -0.00958193  0.00331278]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2959555  0.34975266 0.35429183]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.07, 0.031, 0.1235, 0.13723, 0.6, 0.77, 0, 0.0087, 0.294, 0.5730000000000001]
Reward 8.293646605835841
Current State [[0.06    0.07    0.031   0.1235  0.13723 0.6     0.77    0.      0.0087
  0.294   0.573  ]]
Logits tf.Tensor([[-0.2876039  -0.05096386  0.05022676]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.27256215 0.34533212 0.3821057 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.21, 0.2, 0.026, 0.1837, 0.13723, 0.6, 0.73, 0, 0.0039000000000000003, 0.317, 1.2289999999999999]
Reward 17.33840651245309
Current State [[0.21    0.2     0.026   0.1837  0.13723 0.6     0.73    0.      0.0039
  0.317   1.229  ]]
Logits tf.Tensor([[-0.4303637  -0.05434548  0.03827982]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24665175 0.3592418  0.39410642]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.07, 0.032, 0.12079999999999999, 0.13723, 0.6, 0.77, 0, 0.012, 0.36, 1.04]
Reward 6.7507726618198465
Current State [[0.08    0.07    0.032   0.1208  0.13723 0.6     0.77    0.      0.012
  0.36    1.04   ]]
Logits tf.Tensor([[-0.3960131  -0.10505408  0.06877606]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25449255 0.34043714 0.40507033]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.07, 0.027, 0.1389, 0.13723, 0.6, 0.77, 0, 0.012, 0.36, 1.04]
Reward 6.7507726618198465
Current State [[0.07    0.07    0.027   0.1389  0.13723 0.6     0.77    0.      0.012
  0.36    1.04   ]]
Logits tf.Tensor([[-0.39488724 -0.10670736  0.06731948]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25499988 0.34016913 0.40483102]], shape=(1, 3), dtype=float32)
Selected action 1
[0.09, 0.12, 0.026, 0.1566, 0.13723, 0.6, 0.69, 0, 0.008, 0.28700000000000003, 1.6199999999999999]
Reward 8.139245494389819
Current State [[0.09    0.12    0.026   0.1566  0.13723 0.6     0.69    0.      0.008
  0.287   1.62   ]]
Logits tf.Tensor([[-0.4723887  -0.167117    0.06476089]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24581401 0.33356807 0.42061788]], shape=(1, 3), dtype=float32)
Selected action 1
[0.17, 0.12, 0.028, 0.149, 0.13723, 0.6, 0.68, 0, 0.0097, 0.324, 1.386]
Reward 7.130503380450983
Current State [[0.17    0.12    0.028   0.149   0.13723 0.6     0.68    0.      0.0097
  0.324   1.386  ]]
Logits tf.Tensor([[-0.4623934  -0.11253582  0.05284915]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24432495 0.34666425 0.40901086]], shape=(1, 3), dtype=float32)
Selected action 1
[0.13, 0.12, 0.026, 0.156, 0.13723, 0.6, 0.69, 0, 0.0151, 0.304, 0.48200000000000004]
Reward 5.746542193188645
Current State [[0.13    0.12    0.026   0.156   0.13723 0.6     0.69    0.      0.0151
  0.304   0.482  ]]
Logits tf.Tensor([[-0.266315   -0.01753367  0.04023469]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.27463543 0.35220942 0.37315515]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.07, 0.028, 0.1157, 0.13723, 0.6, 0.69, 0, 0.0121, 0.33799999999999997, 1.207]
Reward 6.3404705046673175
Current State [[0.06    0.07    0.028   0.1157  0.13723 0.6     0.69    0.      0.0121
  0.338   1.207  ]]
Logits tf.Tensor([[-0.41567084 -0.13257302  0.07016537]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25298724 0.3357735  0.41123927]], shape=(1, 3), dtype=float32)
Selected action 1
[0.11, 0.12, 0.026, 0.12830000000000003, 0.13723, 0.6, 0.69, 0, 0.0121, 0.33799999999999997, 1.207]
Reward 6.3404705046673175
Current State [[0.11    0.12    0.026   0.1283  0.13723 0.6     0.69    0.      0.0121
  0.338   1.207  ]]
Logits tf.Tensor([[-0.41829568 -0.10751565  0.06018615]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25137553 0.3429992  0.4056253 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.08, 0.2, 0.022, 0.1396, 0.13723, 0.6, 0.79, 0, 0.0042, 0.315, 0.89]
Reward 17.712431825376417
Current State [[0.08    0.2     0.022   0.1396  0.13723 0.6     0.79    0.      0.0042
  0.315   0.89   ]]
Logits tf.Tensor([[-0.33499748 -0.06112619  0.04647987]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26458582 0.34794238 0.38747177]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.07, 0.031, 0.1321, 0.13723, 0.6, 0.85, 0, 0.0178, 0.323, 0.589]
Reward 5.833970335738068
Current State [[0.07    0.07    0.031   0.1321  0.13723 0.6     0.85    0.      0.0178
  0.323   0.589  ]]
Logits tf.Tensor([[-0.29958713 -0.05732335  0.04411975]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2714223  0.34582737 0.3827503 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.13, 0.12, 0.024, 0.152, 0.13723, 0.6, 0.73, 0, 0.0060999999999999995, 0.377, 0.262]
Reward 10.578790286897485
Current State [[0.13    0.12    0.024   0.152   0.13723 0.6     0.73    0.      0.0061
  0.377   0.262  ]]
Logits tf.Tensor([[-0.20789932 -0.02775108  0.02761163]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.28877112 0.34577307 0.36545584]], shape=(1, 3), dtype=float32)
Selected action 1
[0.08, 0.12, 0.029, 0.1275, 0.13723, 0.6, 0.73, 0, 0.0060999999999999995, 0.377, 0.262]
Reward 10.578790286897485
Current State [[0.08    0.12    0.029   0.1275  0.13723 0.6     0.73    0.      0.0061
  0.377   0.262  ]]
Logits tf.Tensor([[-0.19514842 -0.03938073  0.03895608]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29134718 0.3404551  0.3681977 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.14, 0.2, 0.025, 0.14809999999999998, 0.13723, 0.6, 0.76, 0, 0.0209, 0.371, 0.5309999999999999]
Reward 5.27904672923931
Current State [[0.14    0.2     0.025   0.1481  0.13723 0.6     0.76    0.      0.0209
  0.371   0.531  ]]
Logits tf.Tensor([[-0.27146864 -0.02100297  0.03229015]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.27475804 0.35296068 0.37228128]], shape=(1, 3), dtype=float32)
Selected action 1
[0.11, 0.12, 0.024, 0.15, 0.13723, 0.6, 0.87, 0, 0.0383, 0.316, 1.6039999999999999]
Reward 4.669708251881534
Current State [[0.11    0.12    0.024   0.15    0.13723 0.6     0.87    0.      0.0383
  0.316   1.604  ]]
Logits tf.Tensor([[-0.49407396 -0.15526839  0.05391989]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24195209 0.33952424 0.4185237 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.09, 0.12, 0.023, 0.1686, 0.13723, 0.6, 0.72, 0, 0.0265, 0.40499999999999997, 1.401]
Reward 4.864029412306106
Current State [[0.09    0.12    0.023   0.1686  0.13723 0.6     0.72    0.      0.0265
  0.405   1.401  ]]
Logits tf.Tensor([[-0.46140137 -0.14613461  0.05317729]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24730691 0.33896503 0.41372803]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.07, 0.039, 0.1245, 0.13723, 0.6, 0.56, 0, 0.014199999999999999, 0.518, 1.499]
Reward 5.436263686127711
Current State [[0.07    0.07    0.039   0.1245  0.13723 0.6     0.56    0.      0.0142
  0.518   1.499  ]]
Logits tf.Tensor([[-0.50368464 -0.2240144   0.06807496]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24425542 0.3230751  0.4326695 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.23, 0.2, 0.028, 0.206, 0.13723, 0.6, 0.56, 0, 0.014199999999999999, 0.518, 1.499]
Reward 5.436263686127711
Episode: 34 | Average Reward: 233 | Episode Reward: 178 | Loss: 205.278 | Steps: 19 | Worker: 0
Current State [[-0.00575699 -0.0075203  -0.008132   -0.00435136 -0.00253426  0.00070126
  -0.00199143  0.00296319  0.00719836  0.00471044  0.00730194]]
Logits tf.Tensor([[-0.00525538  0.01500308 -0.02731298]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3334835  0.34030825 0.3262082 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.1, 0.07, 0.038, 0.1365, 0.13723, 0.6, 0.65, 0, 0.0078000000000000005, 0.41, 1.716]
Reward 8.020577166044388
Current State [[0.1     0.07    0.038   0.1365  0.13723 0.6     0.65    0.      0.0078
  0.41    1.716  ]]
Logits tf.Tensor([[-0.5358349  -0.22961296  0.06865172]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23874347 0.32428136 0.43697512]], shape=(1, 3), dtype=float32)
Selected action 1
[0.14, 0.12, 0.033, 0.1755, 0.13723, 0.6, 0.6, 0, 0.0088, 0.318, 1.226]
Reward 6.972729473853874
Current State [[0.14    0.12    0.033   0.1755  0.13723 0.6     0.6     0.      0.0088
  0.318   1.226  ]]
Logits tf.Tensor([[-0.41286013 -0.09701324  0.05447964]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25206926 0.34569287 0.40223786]], shape=(1, 3), dtype=float32)
Selected action 0
[0.1, 0.2, 0.025, 0.13019999999999998, 0.13723, 0.6, 0.52, 0, 0.016399999999999998, 0.333, 1.859]
Reward 5.069104037341042
Current State [[0.1     0.2     0.025   0.1302  0.13723 0.6     0.52    0.      0.0164
  0.333   1.859  ]]
Logits tf.Tensor([[-0.48522764 -0.24248178  0.08536338]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24727641 0.3152143  0.43750924]], shape=(1, 3), dtype=float32)
Selected action 0
[0.25, 0.2, 0.026, 0.21630000000000002, 0.13723, 0.6, 0.52, 0, 0.016399999999999998, 0.333, 1.859]
Reward 5.069104037341042
Current State [[0.25    0.2     0.026   0.2163  0.13723 0.6     0.52    0.      0.0164
  0.333   1.859  ]]
Logits tf.Tensor([[-0.51127696 -0.19535598  0.05516255]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2419255  0.3318061  0.42626843]], shape=(1, 3), dtype=float32)
Selected action 1
[0.09, 0.12, 0.035, 0.175, 0.13723, 0.6, 0.36, 0, 0.12140000000000001, 0.45199999999999996, 0.207]
Reward 3.897499040167073
Current State [[0.09    0.12    0.035   0.175   0.13723 0.6     0.36    0.      0.1214
  0.452   0.207  ]]
Logits tf.Tensor([[-0.13852872 -0.06143194  0.04745274]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30445603 0.32885715 0.36668682]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.07, 0.035, 0.151, 0.13723, 0.6, 0.59, 0, 0.0078000000000000005, 0.322, 1.975]
Reward 7.475241523098554
Current State [[0.05    0.07    0.035   0.151   0.13723 0.6     0.59    0.      0.0078
  0.322   1.975  ]]
Logits tf.Tensor([[-0.54683423 -0.2960515   0.08503672]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24002932 0.3084451  0.45152557]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.07, 0.034, 0.12830000000000003, 0.13723, 0.6, 0.54, 0, 0.0311, 0.294, 1.599]
Reward 4.450849600504953
Current State [[0.06    0.07    0.034   0.1283  0.13723 0.6     0.54    0.      0.0311
  0.294   1.599  ]]
Logits tf.Tensor([[-0.46089587 -0.21590917  0.08731768]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24951573 0.31878236 0.43170196]], shape=(1, 3), dtype=float32)
Selected action 1
[0.13, 0.12, 0.033, 0.16040000000000001, 0.13723, 0.6, 0.54, 0, 0.0311, 0.294, 1.599]
Reward 4.450849600504953
Current State [[0.13    0.12    0.033   0.1604  0.13723 0.6     0.54    0.      0.0311
  0.294   1.599  ]]
Logits tf.Tensor([[-0.45628712 -0.18227486  0.07374571]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24911447 0.32764304 0.4232425 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.1, 0.12, 0.035, 0.154, 0.13723, 0.6, 0.77, 0, 0.0006, 0.253, 2.029]
Reward 49.997859307238066
Current State [[1.0000e-01 1.2000e-01 3.5000e-02 1.5400e-01 1.3723e-01 6.0000e-01
  7.7000e-01 0.0000e+00 6.0000e-04 2.5300e-01 2.0290e+00]]
Logits tf.Tensor([[-0.5333184  -0.2480752   0.08306523]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2391027  0.31802705 0.44287023]], shape=(1, 3), dtype=float32)
Selected action 1
[0.15, 0.12, 0.034, 0.166, 0.13723, 0.6, 0.83, 0, 0.009899999999999999, 0.327, 1.655]
Reward 7.955709079827022
Current State [[0.15    0.12    0.034   0.166   0.13723 0.6     0.83    0.      0.0099
  0.327   1.655  ]]
Logits tf.Tensor([[-0.5132708  -0.15731774  0.05387351]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23861991 0.3406396  0.42074051]], shape=(1, 3), dtype=float32)
Selected action 1
[0.11, 0.12, 0.03, 0.1438, 0.13723, 0.6, 0.76, 0, 0.019299999999999998, 0.274, 1.6989999999999998]
Reward 5.4291033560361734
Current State [[0.11    0.12    0.03    0.1438  0.13723 0.6     0.76    0.      0.0193
  0.274   1.699  ]]
Logits tf.Tensor([[-0.4828582  -0.17991273  0.06859469]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24452189 0.33104366 0.42443448]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.07, 0.032, 0.134, 0.13723, 0.6, 0.76, 0, 0.019299999999999998, 0.274, 1.6989999999999998]
Reward 5.4291033560361734
Current State [[0.04    0.07    0.032   0.134   0.13723 0.6     0.76    0.      0.0193
  0.274   1.699  ]]
Logits tf.Tensor([[-0.48601988 -0.2096497   0.07654056]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24548936 0.3236374  0.43087327]], shape=(1, 3), dtype=float32)
Selected action 0
[0.23, 0.2, 0.03, 0.2019, 0.13723, 0.6, 0.83, 0, 0.0025, 0.325, 1.01]
Reward 34.83490726337667
Current State [[0.23    0.2     0.03    0.2019  0.13723 0.6     0.83    0.      0.0025
  0.325   1.01   ]]
Logits tf.Tensor([[-0.40957367 -0.02517683  0.03239105]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24847876 0.36494777 0.3865735 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.24, 0.2, 0.025, 0.1938, 0.13723, 0.6, 0.83, 0, 0.0058, 0.327, 1.8199999999999998]
Reward 12.707612084166481
Current State [[0.24    0.2     0.025   0.1938  0.13723 0.6     0.83    0.      0.0058
  0.327   1.82   ]]
Logits tf.Tensor([[-0.5360548  -0.15228951  0.04343676]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23513192 0.34512687 0.41974118]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.07, 0.032, 0.13269999999999998, 0.13723, 0.6, 0.92, 0, 0.0085, 0.354, 0.35]
Reward 9.763909601088496
Current State [[0.06    0.07    0.032   0.1327  0.13723 0.6     0.92    0.      0.0085
  0.354   0.35   ]]
Logits tf.Tensor([[-0.24417269 -0.05907413  0.03352896]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2838144  0.3415244  0.37466124]], shape=(1, 3), dtype=float32)
Selected action 0
[0.16, 0.2, 0.027, 0.1824, 0.13723, 0.6, 0.92, 0, 0.0085, 0.354, 0.35]
Reward 9.763909601088496
Current State [[0.16    0.2     0.027   0.1824  0.13723 0.6     0.92    0.      0.0085
  0.354   0.35   ]]
Logits tf.Tensor([[-2.4457654e-01 -2.0910703e-02  6.9261063e-05]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.28346103 0.35451138 0.3620276 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.07, 0.032, 0.1385, 0.13723, 0.6, 0.78, 0, 0.0018, 0.33999999999999997, 0.5349999999999999]
Reward 43.51670934313265
Current State [[0.08    0.07    0.032   0.1385  0.13723 0.6     0.78    0.      0.0018
  0.34    0.535  ]]
Logits tf.Tensor([[-0.285959   -0.05044516  0.04787314]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2730847  0.34560478 0.38131055]], shape=(1, 3), dtype=float32)
Selected action 0
[0.23, 0.2, 0.028, 0.2275, 0.13723, 0.6, 0.68, 0, 0.0028000000000000004, 0.244, 2.071]
Reward 24.633497605517444
Current State [[0.23    0.2     0.028   0.2275  0.13723 0.6     0.68    0.      0.0028
  0.244   2.071  ]]
Logits tf.Tensor([[-0.5330505  -0.206286    0.06651574]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23765367 0.32950088 0.43284544]], shape=(1, 3), dtype=float32)
Selected action 1
[0.13, 0.12, 0.03, 0.1346, 0.13723, 0.6, 0.84, 0, 0.0452, 0.267, 1.5050000000000001]
Reward 4.495160566267918
Current State [[0.13    0.12    0.03    0.1346  0.13723 0.6     0.84    0.      0.0452
  0.267   1.505  ]]
Logits tf.Tensor([[-0.4607031  -0.13499461  0.06121084]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24568446 0.34027582 0.41403973]], shape=(1, 3), dtype=float32)
Selected action 1
[0.13, 0.12, 0.035, 0.1712, 0.13723, 0.6, 0.78, 0, 0.0072, 0.319, 1.085]
Reward 9.690592650798235
Episode: 35 | Average Reward: 233 | Episode Reward: 263 | Loss: 749.179 | Steps: 19 | Worker: 0
Current State [[-0.00160014  0.00774933  0.00630632  0.0017715   0.00742079  0.00632361
  -0.00829209 -0.00314483  0.00799461  0.00487263  0.0018076 ]]
Logits tf.Tensor([[ 0.00091094  0.01828159 -0.02529717]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.33426318 0.3401203  0.32561657]], shape=(1, 3), dtype=float32)
Selected action 0
[0.18, 0.2, 0.032, 0.1925, 0.13723, 0.6, 0.78, 0, 0.0072, 0.319, 1.085]
Reward 9.690592650798235
Current State [[0.18    0.2     0.032   0.1925  0.13723 0.6     0.78    0.      0.0072
  0.319   1.085  ]]
Logits tf.Tensor([[-0.39691702 -0.0479006   0.04276614]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2518963  0.35710642 0.39099726]], shape=(1, 3), dtype=float32)
Selected action 0
[0.24, 0.2, 0.026, 0.1736, 0.13723, 0.6, 0.72, 0, 0.0294, 0.371, 2.048]
Reward 4.751381507771302
Current State [[0.24    0.2     0.026   0.1736  0.13723 0.6     0.72    0.      0.0294
  0.371   2.048  ]]
Logits tf.Tensor([[-0.56070876 -0.22345756  0.05787782]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2348855  0.329096   0.43601856]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.07, 0.035, 0.14709999999999998, 0.13723, 0.6, 0.63, 0, 0.0305, 0.329, 1.169]
Reward 4.581248315212197
Current State [[0.08    0.07    0.035   0.1471  0.13723 0.6     0.63    0.      0.0305
  0.329   1.169  ]]
Logits tf.Tensor([[-0.3946418  -0.12455506  0.06600759]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25672746 0.33633304 0.40693948]], shape=(1, 3), dtype=float32)
Selected action 1
[0.13, 0.12, 0.034, 0.1608, 0.13723, 0.6, 0.63, 0, 0.0305, 0.329, 1.169]
Reward 4.581248315212197
Current State [[0.13    0.12    0.034   0.1608  0.13723 0.6     0.63    0.      0.0305
  0.329   1.169  ]]
Logits tf.Tensor([[-0.39665636 -0.09840678  0.05631251]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25507125 0.343708   0.40122077]], shape=(1, 3), dtype=float32)
Selected action 2
[0.1, 0.07, 0.033, 0.1519, 0.13723, 0.6, 0.5, 0, 0.032799999999999996, 0.225, 1.779]
Reward 4.36121488669712
Current State [[0.1     0.07    0.033   0.1519  0.13723 0.6     0.5     0.      0.0328
  0.225   1.779  ]]
Logits tf.Tensor([[-0.4726173  -0.24230842  0.08937402]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24918075 0.3137158  0.43710345]], shape=(1, 3), dtype=float32)
Selected action 0
[0.26, 0.2, 0.028, 0.2077, 0.13723, 0.6, 0.67, 0, 0.0064, 0.23900000000000002, 2.436]
Reward 9.583746457273913
Current State [[0.26    0.2     0.028   0.2077  0.13723 0.6     0.67    0.      0.0064
  0.239   2.436  ]]
Logits tf.Tensor([[-0.58968043 -0.28922543  0.06917819]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23347801 0.3153058  0.4512162 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.07, 0.035, 0.1235, 0.13723, 0.6, 0.75, 0, 0.0638, 0.314, 1.7550000000000001]
Reward 4.224031413590306
Current State [[0.04    0.07    0.035   0.1235  0.13723 0.6     0.75    0.      0.0638
  0.314   1.755  ]]
Logits tf.Tensor([[-0.49306187 -0.23709695  0.07651528]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24635233 0.31821513 0.43543255]], shape=(1, 3), dtype=float32)
Selected action 0
[0.17, 0.2, 0.028, 0.21280000000000002, 0.13723, 0.6, 0.75, 0, 0.0638, 0.314, 1.7550000000000001]
Reward 4.224031413590306
Current State [[0.17    0.2     0.028   0.2128  0.13723 0.6     0.75    0.      0.0638
  0.314   1.755  ]]
Logits tf.Tensor([[-0.48010847 -0.16053851  0.04707717]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2456584  0.33815756 0.41618404]], shape=(1, 3), dtype=float32)
Selected action 0
[0.13, 0.2, 0.026, 0.1712, 0.13723, 0.6, 0.68, 0, 0.0466, 0.383, 1.548]
Reward 4.340002958783782
Current State [[0.13    0.2     0.026   0.1712  0.13723 0.6     0.68    0.      0.0466
  0.383   1.548  ]]
Logits tf.Tensor([[-0.45546582 -0.14596596  0.05029117]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24869537 0.33890796 0.4123967 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.13, 0.12, 0.03, 0.15830000000000002, 0.13723, 0.6, 0.77, 0, 0.075, 0.29900000000000004, 2.197]
Reward 4.168874082379509
Current State [[0.13    0.12    0.03    0.1583  0.13723 0.6     0.77    0.      0.075
  0.299   2.197  ]]
Logits tf.Tensor([[-0.5650154  -0.29719165  0.08008586]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2373438  0.3102361  0.45242006]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.07, 0.033, 0.15209999999999999, 0.13723, 0.6, 0.52, 0, 0.0455, 0.34500000000000003, 1.075]
Reward 4.215858462737795
Current State [[0.07    0.07    0.033   0.1521  0.13723 0.6     0.52    0.      0.0455
  0.345   1.075  ]]
Logits tf.Tensor([[-0.36829558 -0.12276895  0.06963001]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26124778 0.33395153 0.4048007 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.2, 0.2, 0.029, 0.1923, 0.13723, 0.6, 0.52, 0, 0.0455, 0.34500000000000003, 1.075]
Reward 4.215858462737795
Current State [[0.2     0.2     0.029   0.1923  0.13723 0.6     0.52    0.      0.0455
  0.345   1.075  ]]
Logits tf.Tensor([[-0.37048054 -0.05802894  0.04536204]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25757137 0.35204127 0.39038733]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.07, 0.032, 0.144, 0.13723, 0.6, 0.75, 0, 0.0032, 0.343, 0.739]
Reward 22.978020566371704
Current State [[0.06    0.07    0.032   0.144   0.13723 0.6     0.75    0.      0.0032
  0.343   0.739  ]]
Logits tf.Tensor([[-0.3241077  -0.0760491   0.05730815]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26695916 0.3421175  0.39092332]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.07, 0.031, 0.12079999999999999, 0.13723, 0.6, 0.69, 0, 0.0060999999999999995, 0.266, 1.338]
Reward 10.250908436554509
Current State [[0.04    0.07    0.031   0.1208  0.13723 0.6     0.69    0.      0.0061
  0.266   1.338  ]]
Logits tf.Tensor([[-0.41628042 -0.14581712  0.07143911]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25386062 0.33270252 0.4134369 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.16, 0.2, 0.025, 0.1431, 0.13723, 0.6, 0.43, 0, 0.36829999999999996, 0.354, 1.809]
Reward 3.833770413044355
Current State [[0.16    0.2     0.025   0.1431  0.13723 0.6     0.43    0.      0.3683
  0.354   1.809  ]]
Logits tf.Tensor([[-0.3984319  -0.27307883  0.0744714 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26750877 0.30323422 0.42925695]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.07, 0.031, 0.144, 0.13723, 0.6, 0.43, 0, 0.36829999999999996, 0.354, 1.809]
Reward 3.833770413044355
Current State [[0.07    0.07    0.031   0.144   0.13723 0.6     0.43    0.      0.3683
  0.354   1.809  ]]
Logits tf.Tensor([[-0.42492306 -0.32562086  0.08949727]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26475558 0.29239607 0.44284835]], shape=(1, 3), dtype=float32)
Selected action 0
[0.24, 0.2, 0.027, 0.224, 0.13723, 0.6, 0.4, 0, 0.10890000000000001, 0.284, 0.606]
Reward 3.9240484697474027
Current State [[0.24    0.2     0.027   0.224   0.13723 0.6     0.4     0.      0.1089
  0.284   0.606  ]]
Logits tf.Tensor([[-0.26031226  0.00474934  0.03131936]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.27456528 0.35789895 0.36753577]], shape=(1, 3), dtype=float32)
Selected action 0
[0.18, 0.2, 0.025, 0.152, 0.13723, 0.6, 0.8, 0, 0.0109, 0.409, 1.585]
Reward 7.2903765498817625
Current State [[0.18    0.2     0.025   0.152   0.13723 0.6     0.8     0.      0.0109
  0.409   1.585  ]]
Logits tf.Tensor([[-0.49857417 -0.13634911  0.04123284]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24083629 0.3459667  0.41319698]], shape=(1, 3), dtype=float32)
Selected action 1
[0.11, 0.12, 0.026, 0.175, 0.13723, 0.6, 0.8, 0, 0.0109, 0.409, 1.585]
Reward 7.2903765498817625
Current State [[0.11    0.12    0.026   0.175   0.13723 0.6     0.8     0.      0.0109
  0.409   1.585  ]]
Logits tf.Tensor([[-0.5035394  -0.16977161  0.04841489]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24196306 0.33783337 0.42020357]], shape=(1, 3), dtype=float32)
Selected action 2
[0.11, 0.07, 0.032, 0.1288, 0.13723, 0.6, 0.84, 0, 0.004699999999999999, 0.374, 0.9470000000000001]
Reward 16.61397378731258
Episode: 36 | Average Reward: 232 | Episode Reward: 138 | Loss: 177.619 | Steps: 19 | Worker: 0
Current State [[ 0.00308478 -0.00747874 -0.00157498  0.00539411  0.00379877  0.00515405
   0.00830494  0.00304334  0.00880994 -0.00579631  0.00325392]]
Logits tf.Tensor([[-0.00442419  0.02038679 -0.02193211]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3324727  0.34082487 0.32670248]], shape=(1, 3), dtype=float32)
Selected action 0
[0.13, 0.2, 0.024, 0.16540000000000002, 0.13723, 0.6, 0.76, 0, 0.0024, 0.28700000000000003, 0.741]
Reward 33.61822340703285
Current State [[0.13    0.2     0.024   0.1654  0.13723 0.6     0.76    0.      0.0024
  0.287   0.741  ]]
Logits tf.Tensor([[-0.30998877 -0.03085445  0.03633651]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2676769  0.35386482 0.37845832]], shape=(1, 3), dtype=float32)
Selected action 0
[0.19, 0.2, 0.025, 0.1633, 0.13723, 0.6, 0.78, 0, 0.0034999999999999996, 0.29300000000000004, 0.532]
Reward 21.664287851703847
Current State [[0.19    0.2     0.025   0.1633  0.13723 0.6     0.78    0.      0.0035
  0.293   0.532  ]]
Logits tf.Tensor([[-0.28533435 -0.00418974  0.01839862]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2717722  0.3600017  0.36822608]], shape=(1, 3), dtype=float32)
Selected action 1
[0.04, 0.12, 0.026, 0.152, 0.13723, 0.6, 0.78, 0, 0.0034999999999999996, 0.29300000000000004, 0.532]
Reward 21.664287851703847
Current State [[0.04    0.12    0.026   0.152   0.13723 0.6     0.78    0.      0.0035
  0.293   0.532  ]]
Logits tf.Tensor([[-0.2632096  -0.05139488  0.04299348]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.27822784 0.34386703 0.3779052 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.21, 0.2, 0.026, 0.1596, 0.13723, 0.6, 0.82, 0, 0.0040999999999999995, 0.35, 1.2429999999999999]
Reward 18.782413657268087
Current State [[0.21    0.2     0.026   0.1596  0.13723 0.6     0.82    0.      0.0041
  0.35    1.243  ]]
Logits tf.Tensor([[-0.4371141  -0.07399585  0.0386412 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24709448 0.35527387 0.39763165]], shape=(1, 3), dtype=float32)
Selected action 0
[0.22, 0.2, 0.025, 0.1981, 0.13723, 0.6, 0.63, 0, 0.015700000000000002, 0.40499999999999997, 1.342]
Reward 5.452863786195365
Current State [[0.22    0.2     0.025   0.1981  0.13723 0.6     0.63    0.      0.0157
  0.405   1.342  ]]
Logits tf.Tensor([[-0.44552153 -0.09657442  0.03319041]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24804245 0.35161856 0.40033904]], shape=(1, 3), dtype=float32)
Selected action 0
[0.1, 0.2, 0.023, 0.18, 0.13723, 0.6, 0.49, 0, 0.0341, 0.358, 1.277]
Reward 4.3328341964829535
Current State [[0.1     0.2     0.023   0.18    0.13723 0.6     0.49    0.      0.0341
  0.358   1.277  ]]
Logits tf.Tensor([[-0.3769702  -0.11920147  0.05372319]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2609356  0.33766097 0.40140346]], shape=(1, 3), dtype=float32)
Selected action 1
[0.16, 0.12, 0.031, 0.1529, 0.13723, 0.6, 0.71, 0, 0.0144, 0.346, 0.8009999999999999]
Reward 5.948920370702304
Current State [[0.16    0.12    0.031   0.1529  0.13723 0.6     0.71    0.      0.0144
  0.346   0.801  ]]
Logits tf.Tensor([[-0.3456338  -0.0517205   0.04934284]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26136842 0.35066953 0.38796207]], shape=(1, 3), dtype=float32)
Selected action 0
[0.19, 0.2, 0.027, 0.18080000000000002, 0.13723, 0.6, 0.71, 0, 0.0144, 0.346, 0.8009999999999999]
Reward 5.948920370702304
Current State [[0.19    0.2     0.027   0.1808  0.13723 0.6     0.71    0.      0.0144
  0.346   0.801  ]]
Logits tf.Tensor([[-0.3402979  -0.02817746  0.03959897]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26120213 0.3568855  0.38191244]], shape=(1, 3), dtype=float32)
Selected action 1
[0.05, 0.12, 0.029, 0.1755, 0.13723, 0.6, 0.57, 0, 0.008, 0.28700000000000003, 0.316]
Reward 7.206789255555286
Current State [[0.05    0.12    0.029   0.1755  0.13723 0.6     0.57    0.      0.008
  0.287   0.316  ]]
Logits tf.Tensor([[-0.19527546 -0.02941303  0.05234053]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.28890222 0.3410233  0.37007448]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.07, 0.033, 0.1438, 0.13723, 0.6, 0.71, 0, 0.0076, 0.351, 0.784]
Reward 8.696815713236234
Current State [[0.07    0.07    0.033   0.1438  0.13723 0.6     0.71    0.      0.0076
  0.351   0.784  ]]
Logits tf.Tensor([[-0.3300268  -0.08350796  0.06111003]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26608312 0.34047022 0.3934467 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.07, 0.032, 0.1135, 0.13723, 0.6, 0.67, 0, 0.01, 0.306, 0.808]
Reward 6.908678104080295
Current State [[0.05    0.07    0.032   0.1135  0.13723 0.6     0.67    0.      0.01
  0.306   0.808  ]]
Logits tf.Tensor([[-0.32041755 -0.08888289  0.07092416]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26741567 0.3370863  0.3954981 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.07, 0.031, 0.1453, 0.13723, 0.6, 0.67, 0, 0.01, 0.306, 0.808]
Reward 6.908678104080295
Current State [[0.07    0.07    0.031   0.1453  0.13723 0.6     0.67    0.      0.01
  0.306   0.808  ]]
Logits tf.Tensor([[-0.3278893  -0.07901823  0.06515519]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2656705  0.3407428  0.39358667]], shape=(1, 3), dtype=float32)
Selected action 0
[0.18, 0.2, 0.026, 0.1774, 0.13723, 0.6, 0.61, 0, 0.025, 0.271, 0.792]
Reward 4.744482141997391
Current State [[0.18    0.2     0.026   0.1774  0.13723 0.6     0.61    0.      0.025
  0.271   0.792  ]]
Logits tf.Tensor([[-0.31820464 -0.0188752   0.04789767]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2637787  0.3558253  0.38039598]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.07, 0.022, 0.1231, 0.13723, 0.6, 0.74, 0, 0.0062, 0.4, 0.32]
Reward 10.769774718779617
Current State [[0.05    0.07    0.022   0.1231  0.13723 0.6     0.74    0.      0.0062
  0.4     0.32   ]]
Logits tf.Tensor([[-0.21177714 -0.06100988  0.05162663]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2886771  0.33565238 0.37567052]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.07, 0.03, 0.12040000000000001, 0.13723, 0.6, 0.66, 0, 0.0176, 0.34500000000000003, 0.7030000000000001]
Reward 5.337460844501389
Current State [[0.08    0.07    0.03    0.1204  0.13723 0.6     0.66    0.      0.0176
  0.345   0.703  ]]
Logits tf.Tensor([[-0.30971247 -0.07409212  0.06235585]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26907572 0.34056747 0.39035678]], shape=(1, 3), dtype=float32)
Selected action 0
[0.11, 0.2, 0.025, 0.156, 0.13723, 0.6, 0.66, 0, 0.0176, 0.34500000000000003, 0.7030000000000001]
Reward 5.337460844501389
Current State [[0.11    0.2     0.025   0.156   0.13723 0.6     0.66    0.      0.0176
  0.345   0.703  ]]
Logits tf.Tensor([[-0.29302058 -0.04503917  0.0490854 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.27105078 0.34733424 0.38161495]], shape=(1, 3), dtype=float32)
Selected action 1
[0.06, 0.12, 0.026, 0.15919999999999998, 0.13723, 0.6, 0.66, 0, 0.1175, 0.319, 1.241]
Reward 3.995819411329085
Current State [[0.06    0.12    0.026   0.1592  0.13723 0.6     0.66    0.      0.1175
  0.319   1.241  ]]
Logits tf.Tensor([[-0.3702422  -0.13698265  0.06803304]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26227856 0.3311815  0.40654   ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.2, 0.12, 0.027, 0.1904, 0.13723, 0.6, 0.82, 0, 0.0054, 0.362, 1.457]
Reward 13.524486121348234
Current State [[0.2     0.12    0.027   0.1904  0.13723 0.6     0.82    0.      0.0054
  0.362   1.457  ]]
Logits tf.Tensor([[-0.49419498 -0.12370432  0.0373408 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24096452 0.34902388 0.41001162]], shape=(1, 3), dtype=float32)
Selected action 0
[0.26, 0.2, 0.031, 0.18819999999999998, 0.13723, 0.6, 0.64, 0, 0.0109, 0.389, 0.514]
Reward 6.415932660477069
Current State [[0.26    0.2     0.031   0.1882  0.13723 0.6     0.64    0.      0.0109
  0.389   0.514  ]]
Logits tf.Tensor([[-0.2827641   0.00562739  0.0241056 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.27075005 0.36125627 0.36799368]], shape=(1, 3), dtype=float32)
Selected action 1
[0.06, 0.12, 0.032, 0.16040000000000001, 0.13723, 0.6, 0.64, 0, 0.0109, 0.389, 0.514]
Reward 6.415932660477069
Episode: 37 | Average Reward: 232 | Episode Reward: 203 | Loss: 212.009 | Steps: 19 | Worker: 0
Current State [[ 0.0075696   0.003302   -0.00352508  0.0061646   0.00352241 -0.00301443
   0.00322834  0.00321344  0.00880906  0.00492369  0.00206565]]
Logits tf.Tensor([[-0.00348473  0.01619467 -0.03098499]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.334141   0.3407818  0.32507724]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.07, 0.037, 0.1296, 0.13723, 0.6, 0.61, 0, 0.0147, 0.41, 1.543]
Reward 5.519851412911293
Current State [[0.06    0.07    0.037   0.1296  0.13723 0.6     0.61    0.      0.0147
  0.41    1.543  ]]
Logits tf.Tensor([[-0.46967405 -0.21657689  0.06632153]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25017777 0.3222311  0.42759112]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.07, 0.033, 0.12409999999999999, 0.13723, 0.6, 0.57, 0, 0.024, 0.319, 1.53]
Reward 4.719285969612157
Current State [[0.07    0.07    0.033   0.1241  0.13723 0.6     0.57    0.      0.024
  0.319   1.53   ]]
Logits tf.Tensor([[-0.44271132 -0.20333861  0.07195367]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2535799  0.32216114 0.42425898]], shape=(1, 3), dtype=float32)
Selected action 1
[0.09, 0.12, 0.027, 0.149, 0.13723, 0.6, 0.36, 0, 0.1649, 0.25, 1.8199999999999998]
Reward 3.870042151491103
Current State [[0.09    0.12    0.027   0.149   0.13723 0.6     0.36    0.      0.1649
  0.25    1.82   ]]
Logits tf.Tensor([[-0.41440704 -0.28727743  0.08736753]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26404637 0.29984158 0.43611208]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.07, 0.032, 0.1385, 0.13723, 0.6, 0.36, 0, 0.1649, 0.25, 1.8199999999999998]
Reward 3.870042151491103
Current State [[0.04    0.07    0.032   0.1385  0.13723 0.6     0.36    0.      0.1649
  0.25    1.82   ]]
Logits tf.Tensor([[-0.42384467 -0.31263876  0.09460564]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2633625 0.2943405 0.442297 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.09, 0.07, 0.036, 0.13269999999999998, 0.13723, 0.6, 0.6, 0, 0.032799999999999996, 0.29500000000000004, 1.761]
Reward 4.488070531768454
Current State [[0.09    0.07    0.036   0.1327  0.13723 0.6     0.6     0.      0.0328
  0.295   1.761  ]]
Logits tf.Tensor([[-0.4819633  -0.24499515  0.07840197]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2488359  0.3153748  0.43578932]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.07, 0.032, 0.1275, 0.13723, 0.6, 0.61, 0, 0.0219, 0.29100000000000004, 2.3760000000000003]
Reward 4.884948413537489
Current State [[0.04    0.07    0.032   0.1275  0.13723 0.6     0.61    0.      0.0219
  0.291   2.376  ]]
Logits tf.Tensor([[-0.5767919  -0.40046534  0.08653248]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24189281 0.2885364  0.4695708 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.07, 0.04, 0.16269999999999998, 0.13723, 0.6, 0.61, 0, 0.0219, 0.29100000000000004, 2.3760000000000003]
Reward 4.884948413537489
Current State [[0.07    0.07    0.04    0.1627  0.13723 0.6     0.61    0.      0.0219
  0.291   2.376  ]]
Logits tf.Tensor([[-0.58457464 -0.38562787  0.07920904]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24025503 0.29313925 0.46660572]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.07, 0.034, 0.1259, 0.13723, 0.6, 0.83, 0, 0.0109, 0.252, 1.2029999999999998]
Reward 7.485502141635418
Current State [[0.07    0.07    0.034   0.1259  0.13723 0.6     0.83    0.      0.0109
  0.252   1.203  ]]
Logits tf.Tensor([[-0.39223292 -0.12351609  0.06551486]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25714907 0.33642417 0.40642673]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.07, 0.037, 0.1519, 0.13723, 0.6, 0.83, 0, 0.0109, 0.252, 1.2029999999999998]
Reward 7.485502141635418
Current State [[0.08    0.07    0.037   0.1519  0.13723 0.6     0.83    0.      0.0109
  0.252   1.203  ]]
Logits tf.Tensor([[-0.39626464 -0.11735251  0.06171194]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25624183 0.33867258 0.40508556]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.07, 0.042, 0.14709999999999998, 0.13723, 0.6, 0.68, 0, 0.0134, 0.277, 1.9620000000000002]
Reward 5.997230992221896
Current State [[0.07    0.07    0.042   0.1471  0.13723 0.6     0.68    0.      0.0134
  0.277   1.962  ]]
Logits tf.Tensor([[-0.5147143  -0.27881256  0.07801173]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.245401   0.31068996 0.44390905]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.07, 0.03, 0.1154, 0.13723, 0.6, 0.66, 0, 0.002, 0.28300000000000003, 1.173]
Reward 34.866771807122944
Current State [[0.06    0.07    0.03    0.1154  0.13723 0.6     0.66    0.      0.002
  0.283   1.173  ]]
Logits tf.Tensor([[-0.38127315 -0.12915832  0.06920769]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25934887 0.33371556 0.4069356 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.13, 0.12, 0.034, 0.1472, 0.13723, 0.6, 0.85, 0, 0.0021, 0.322, 1.068]
Reward 40.758707722047326
Current State [[0.13    0.12    0.034   0.1472  0.13723 0.6     0.85    0.      0.0021
  0.322   1.068  ]]
Logits tf.Tensor([[-0.3890215  -0.08741707  0.05153269]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.256043   0.34617686 0.39778018]], shape=(1, 3), dtype=float32)
Selected action 0
[0.24, 0.2, 0.032, 0.2, 0.13723, 0.6, 0.85, 0, 0.0021, 0.322, 1.068]
Reward 40.758707722047326
Current State [[0.24    0.2     0.032   0.2     0.13723 0.6     0.85    0.      0.0021
  0.322   1.068  ]]
Logits tf.Tensor([[-0.4089311  -0.03759978  0.02638885]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25030532 0.36285844 0.38683623]], shape=(1, 3), dtype=float32)
Selected action 0
[0.19, 0.2, 0.027, 0.1941, 0.13723, 0.6, 0.78, 0, 0.022400000000000003, 0.317, 2.4699999999999998]
Reward 5.197685643865438
Current State [[0.19    0.2     0.027   0.1941  0.13723 0.6     0.78    0.      0.0224
  0.317   2.47   ]]
Logits tf.Tensor([[-0.5944827  -0.32431716  0.05949034]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23621966 0.3094906  0.45428973]], shape=(1, 3), dtype=float32)
Selected action 1
[0.14, 0.12, 0.031, 0.17, 0.13723, 0.6, 0.68, 0, 0.0363, 0.32999999999999996, 1.107]
Reward 4.507375962753591
Current State [[0.14    0.12    0.031   0.17    0.13723 0.6     0.68    0.      0.0363
  0.33    1.107  ]]
Logits tf.Tensor([[-0.3828778  -0.09501413  0.0516638 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25787613 0.3438973  0.3982265 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.1, 0.2, 0.028, 0.17880000000000001, 0.13723, 0.6, 0.67, 0, 0.08869999999999999, 0.317, 1.08]
Reward 4.064817174252236
Current State [[0.1     0.2     0.028   0.1788  0.13723 0.6     0.67    0.      0.0887
  0.317   1.08   ]]
Logits tf.Tensor([[-0.33341095 -0.08622465  0.05743197]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2660534  0.34065944 0.39328712]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.07, 0.033, 0.117, 0.13723, 0.6, 0.75, 0, 0.0434, 0.269, 1.436]
Reward 4.447200112492983
Current State [[0.08    0.07    0.033   0.117   0.13723 0.6     0.75    0.      0.0434
  0.269   1.436  ]]
Logits tf.Tensor([[-0.42550445 -0.15928374  0.06472722]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25395423 0.3314161  0.41462964]], shape=(1, 3), dtype=float32)
Selected action 2
[0.1, 0.07, 0.032, 0.1358, 0.13723, 0.6, 0.75, 0, 0.0434, 0.269, 1.436]
Reward 4.447200112492983
Current State [[0.1     0.07    0.032   0.1358  0.13723 0.6     0.75    0.      0.0434
  0.269   1.436  ]]
Logits tf.Tensor([[-0.43225437 -0.151673    0.06134756]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25239104 0.33414033 0.4134686 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.15, 0.12, 0.031, 0.15469999999999998, 0.13723, 0.6, 0.56, 0, 0.03, 0.23900000000000002, 2.1550000000000002]
Reward 4.5046471658092635
Current State [[0.15    0.12    0.031   0.1547  0.13723 0.6     0.56    0.      0.03
  0.239   2.155  ]]
Logits tf.Tensor([[-0.5209659  -0.3042622   0.08072961]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24587017 0.30536488 0.4487649 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.07, 0.032, 0.132, 0.13723, 0.6, 0.71, 0, 0.0075, 0.313, 1.103]
Reward 8.759130886707128
Episode: 38 | Average Reward: 232 | Episode Reward: 205 | Loss: 447.356 | Steps: 19 | Worker: 0
Current State [[-0.00565523  0.00505226  0.00146762 -0.00889264 -0.00582923 -0.00445535
   0.00925414 -0.00044275  0.00851737 -0.00145846 -0.0038344 ]]
Logits tf.Tensor([[ 0.00558024  0.01253219 -0.02842947]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3362997  0.3386458  0.32505453]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.07, 0.037, 0.15830000000000002, 0.13723, 0.6, 0.71, 0, 0.0075, 0.313, 1.103]
Reward 8.759130886707128
Current State [[0.08    0.07    0.037   0.1583  0.13723 0.6     0.71    0.      0.0075
  0.313   1.103  ]]
Logits tf.Tensor([[-0.37473032 -0.11887807  0.06260066]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26040784 0.3363328  0.40325937]], shape=(1, 3), dtype=float32)
Selected action 0
[0.14, 0.2, 0.027, 0.216, 0.13723, 0.6, 0.65, 0, 0.2047, 0.272, 1.5070000000000001]
Reward 3.904889619881049
Current State [[0.14    0.2     0.027   0.216   0.13723 0.6     0.65    0.      0.2047
  0.272   1.507  ]]
Logits tf.Tensor([[-0.36095977 -0.14754342  0.04764072]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26719317 0.33075845 0.40204835]], shape=(1, 3), dtype=float32)
Selected action 1
[0.13, 0.12, 0.034, 0.1596, 0.13723, 0.6, 0.84, 0, 0.0040999999999999995, 0.344, 1.918]
Reward 19.689009846706416
Current State [[0.13    0.12    0.034   0.1596  0.13723 0.6     0.84    0.      0.0041
  0.344   1.918  ]]
Logits tf.Tensor([[-0.52774173 -0.23183803  0.05343851]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24198493 0.32531023 0.43270484]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.07, 0.032, 0.124, 0.13723, 0.6, 0.7, 0, 0.0013, 0.31, 1.1380000000000001]
Reward 46.96294481903284
Current State [[0.08    0.07    0.032   0.124   0.13723 0.6     0.7     0.      0.0013
  0.31    1.138  ]]
Logits tf.Tensor([[-0.38268465 -0.1276495   0.06642833]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25924006 0.3345511  0.40620887]], shape=(1, 3), dtype=float32)
Selected action 1
[0.04, 0.12, 0.034, 0.1608, 0.13723, 0.6, 0.7, 0, 0.0013, 0.31, 1.1380000000000001]
Reward 46.96294481903284
Current State [[0.04    0.12    0.034   0.1608  0.13723 0.6     0.7     0.      0.0013
  0.31    1.138  ]]
Logits tf.Tensor([[-0.36318183 -0.12387268  0.0648897 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2628351  0.33389816 0.4032668 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.08, 0.12, 0.035, 0.16419999999999998, 0.13723, 0.6, 0.77, 0, 0.0053, 0.29300000000000004, 1.706]
Reward 12.958937124275005
Current State [[0.08    0.12    0.035   0.1642  0.13723 0.6     0.77    0.      0.0053
  0.293   1.706  ]]
Logits tf.Tensor([[-0.46410346 -0.19619747  0.05782128]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2504701 0.3274206 0.4221093]], shape=(1, 3), dtype=float32)
Selected action 1
[0.04, 0.12, 0.034, 0.18130000000000002, 0.13723, 0.6, 0.89, 0, 0.0037, 0.312, 0.354]
Reward 23.554700498093602
Current State [[0.04    0.12    0.034   0.1813  0.13723 0.6     0.89    0.      0.0037
  0.312   0.354  ]]
Logits tf.Tensor([[-0.22488092 -0.05610115  0.0261959 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.28824523 0.3412418  0.37051293]], shape=(1, 3), dtype=float32)
Selected action 0
[0.23, 0.2, 0.031, 0.2288, 0.13723, 0.6, 0.59, 0, 0.0073, 0.259, 2.25]
Reward 7.847867447061666
Current State [[0.23    0.2     0.031   0.2288  0.13723 0.6     0.59    0.      0.0073
  0.259   2.25   ]]
Logits tf.Tensor([[-0.5362449  -0.2774869   0.06164186]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24309649 0.31488785 0.44201562]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.07, 0.03, 0.15919999999999998, 0.13723, 0.6, 0.81, 0, 0.0079, 0.307, 2.472]
Reward 9.29560410282777
Current State [[0.03    0.07    0.03    0.1592  0.13723 0.6     0.81    0.      0.0079
  0.307   2.472  ]]
Logits tf.Tensor([[-0.60823905 -0.40239865  0.07727423]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23734097 0.29158694 0.47107205]], shape=(1, 3), dtype=float32)
Selected action 0
[0.19, 0.2, 0.026, 0.1981, 0.13723, 0.6, 0.81, 0, 0.0079, 0.307, 2.472]
Reward 9.29560410282777
Current State [[0.19    0.2     0.026   0.1981  0.13723 0.6     0.81    0.      0.0079
  0.307   2.472  ]]
Logits tf.Tensor([[-0.5909377  -0.3243134   0.06063675]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23673633 0.3090711  0.4541926 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.18, 0.2, 0.024, 0.194, 0.13723, 0.6, 0.77, 0, 0.013300000000000001, 0.392, 1.303]
Reward 6.378009476756634
Current State [[0.18    0.2     0.024   0.194   0.13723 0.6     0.77    0.      0.0133
  0.392   1.303  ]]
Logits tf.Tensor([[-0.42912364 -0.10443021  0.03470939]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25165057 0.3481854  0.40016407]], shape=(1, 3), dtype=float32)
Selected action 2
[0.09, 0.07, 0.037, 0.1264, 0.13723, 0.6, 0.85, 0, 0.0031, 0.353, 0.614]
Reward 27.835252322475974
Current State [[0.09    0.07    0.037   0.1264  0.13723 0.6     0.85    0.      0.0031
  0.353   0.614  ]]
Logits tf.Tensor([[-0.29400814 -0.07066566  0.04420628]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.27377084 0.34228164 0.38394752]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.07, 0.03, 0.15280000000000002, 0.13723, 0.6, 0.85, 0, 0.0031, 0.353, 0.614]
Reward 27.835252322475974
Current State [[0.08    0.07    0.03    0.1528  0.13723 0.6     0.85    0.      0.0031
  0.353   0.614  ]]
Logits tf.Tensor([[-0.29549995 -0.07119494  0.04026454]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2739379  0.34282032 0.3832417 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.2, 0.2, 0.026, 0.1765, 0.13723, 0.6, 0.76, 0, 0.0025, 0.23700000000000002, 1.9620000000000002]
Reward 32.39673079632506
Current State [[0.2     0.2     0.026   0.1765  0.13723 0.6     0.76    0.      0.0025
  0.237   1.962  ]]
Logits tf.Tensor([[-0.4810695  -0.1985491   0.06014093]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24724606 0.3279642  0.42478976]], shape=(1, 3), dtype=float32)
Selected action 1
[0.12, 0.12, 0.023, 0.1569, 0.13723, 0.6, 0.52, 0, 0.0383, 0.386, 1.552]
Reward 4.296044481539277
Current State [[0.12    0.12    0.023   0.1569  0.13723 0.6     0.52    0.      0.0383
  0.386   1.552  ]]
Logits tf.Tensor([[-0.44844788 -0.20560004  0.0600534 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25395718 0.32376355 0.42227927]], shape=(1, 3), dtype=float32)
Selected action 0
[0.14, 0.2, 0.025, 0.1358, 0.13723, 0.6, 0.57, 0, 0.012, 0.377, 0.8800000000000001]
Reward 5.849458792912101
Current State [[0.14    0.2     0.025   0.1358  0.13723 0.6     0.57    0.      0.012
  0.377   0.88   ]]
Logits tf.Tensor([[-0.32251284 -0.07031045  0.05952994]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2665152  0.3429668  0.39051798]], shape=(1, 3), dtype=float32)
Selected action 1
[0.15, 0.12, 0.032, 0.1462, 0.13723, 0.6, 0.81, 0, 0.004699999999999999, 0.454, 0.16]
Reward 15.783091330584393
Current State [[0.15    0.12    0.032   0.1462  0.13723 0.6     0.81    0.      0.0047
  0.454   0.16   ]]
Logits tf.Tensor([[-0.16616991 -0.06221633  0.01462193]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30232352 0.33544275 0.3622337 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.07, 0.027, 0.1396, 0.13723, 0.6, 0.81, 0, 0.004699999999999999, 0.454, 0.16]
Reward 15.783091330584393
Current State [[0.08    0.07    0.027   0.1396  0.13723 0.6     0.81    0.      0.0047
  0.454   0.16   ]]
Logits tf.Tensor([[-0.16445398 -0.07914747  0.03173818]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3024976  0.32943526 0.36806718]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.07, 0.031, 0.1388, 0.13723, 0.6, 0.7, 0, 0.0044, 0.269, 1.333]
Reward 14.360933610242336
Current State [[0.04    0.07    0.031   0.1388  0.13723 0.6     0.7     0.      0.0044
  0.269   1.333  ]]
Logits tf.Tensor([[-0.4001728  -0.15532804  0.06640557]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2582677  0.32991707 0.4118153 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.07, 0.025, 0.11109999999999999, 0.13723, 0.6, 0.79, 0, 0.0092, 0.337, 0.538]
Reward 8.107132408064627
Episode: 39 | Average Reward: 233 | Episode Reward: 347 | Loss: 917.441 | Steps: 19 | Worker: 0
Current State [[-0.00293184  0.0044577   0.00240034  0.0090128   0.00637984 -0.0089714
  -0.00897874 -0.00192502  0.00386285 -0.00579682 -0.00255664]]
Logits tf.Tensor([[ 0.00425361  0.01575651 -0.02759038]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3355449  0.33942693 0.32502818]], shape=(1, 3), dtype=float32)
Selected action 0
[0.11, 0.2, 0.025, 0.1694, 0.13723, 0.6, 0.79, 0, 0.0092, 0.337, 0.538]
Reward 8.107132408064627
Current State [[0.11    0.2     0.025   0.1694  0.13723 0.6     0.79    0.      0.0092
  0.337   0.538  ]]
Logits tf.Tensor([[-0.2520236  -0.04313213  0.0292984 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2811207  0.34642816 0.3724512 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.07, 0.029, 0.1377, 0.13723, 0.6, 0.72, 0, 0.0034000000000000002, 0.343, 0.355]
Reward 20.096512820960562
Current State [[0.07    0.07    0.029   0.1377  0.13723 0.6     0.72    0.      0.0034
  0.343   0.355  ]]
Logits tf.Tensor([[-0.21362253 -0.05673899  0.0515888 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.28788862 0.3367892  0.37532222]], shape=(1, 3), dtype=float32)
Selected action 1
[0.12, 0.12, 0.025, 0.1551, 0.13723, 0.6, 0.63, 0, 0.1351, 0.308, 1.176]
Reward 3.9585450096430863
Current State [[0.12    0.12    0.025   0.1551  0.13723 0.6     0.63    0.      0.1351
  0.308   1.176  ]]
Logits tf.Tensor([[-0.34752423 -0.12643373  0.06252526]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26635918 0.33226615 0.40137464]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.07, 0.032, 0.1188, 0.13723, 0.6, 0.63, 0, 0.008, 0.304, 0.761]
Reward 7.662685493669419
Current State [[0.08    0.07    0.032   0.1188  0.13723 0.6     0.63    0.      0.008
  0.304   0.761  ]]
Logits tf.Tensor([[-0.30149233 -0.08478506  0.06683621]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.27120134 0.33682677 0.39197186]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.2, 0.024, 0.1623, 0.13723, 0.6, 0.63, 0, 0.008, 0.304, 0.761]
Reward 7.662685493669419
Current State [[0.05    0.2     0.024   0.1623  0.13723 0.6     0.63    0.      0.008
  0.304   0.761  ]]
Logits tf.Tensor([[-0.2676287 -0.0699425  0.0571013]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.27760527 0.33828422 0.38411048]], shape=(1, 3), dtype=float32)
Selected action 0
[0.17, 0.2, 0.023, 0.2021, 0.13723, 0.6, 0.66, 0, 0.002, 0.371, 1.52]
Reward 35.004333810220274
Current State [[0.17    0.2     0.023   0.2021  0.13723 0.6     0.66    0.      0.002
  0.371   1.52   ]]
Logits tf.Tensor([[-0.44189286 -0.14047618  0.0367731 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25216275 0.34086668 0.4069705 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.14, 0.2, 0.025, 0.18630000000000002, 0.13723, 0.6, 0.68, 0, 0.0070999999999999995, 0.29, 0.568]
Reward 8.819344572338396
Current State [[0.14    0.2     0.025   0.1863  0.13723 0.6     0.68    0.      0.0071
  0.29    0.568  ]]
Logits tf.Tensor([[-0.25439602 -0.02337101  0.03341321]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.27828845 0.3506131  0.37109846]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.07, 0.028, 0.12240000000000001, 0.13723, 0.6, 0.82, 0, 0.013000000000000001, 0.344, 1.08]
Reward 6.672619393187612
Current State [[0.08    0.07    0.028   0.1224  0.13723 0.6     0.82    0.      0.013
  0.344   1.08   ]]
Logits tf.Tensor([[-0.37656707 -0.13017006  0.06653857]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26062405 0.3334444  0.4059316 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.19, 0.2, 0.026, 0.1906, 0.13723, 0.6, 0.82, 0, 0.013000000000000001, 0.344, 1.08]
Reward 6.672619393187612
Current State [[0.19    0.2     0.026   0.1906  0.13723 0.6     0.82    0.      0.013
  0.344   1.08   ]]
Logits tf.Tensor([[-0.38186067 -0.0691082   0.03713411]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2572271  0.35167652 0.3910964 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.16, 0.2, 0.025, 0.1392, 0.13723, 0.6, 0.58, 0, 0.015, 0.298, 0.63]
Reward 5.380233182912765
Current State [[0.16    0.2     0.025   0.1392  0.13723 0.6     0.58    0.      0.015
  0.298   0.63   ]]
Logits tf.Tensor([[-0.26532692 -0.02701166  0.04922484]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2748193  0.34877574 0.37640497]], shape=(1, 3), dtype=float32)
Selected action 0
[0.16, 0.2, 0.026, 0.1776, 0.13723, 0.6, 0.54, 0, 0.037599999999999995, 0.32999999999999996, 0.782]
Reward 4.324217924208777
Current State [[0.16    0.2     0.026   0.1776  0.13723 0.6     0.54    0.      0.0376
  0.33    0.782  ]]
Logits tf.Tensor([[-0.29112798 -0.04879965  0.05376456]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.27129307 0.34568503 0.38302192]], shape=(1, 3), dtype=float32)
Selected action 0
[0.2, 0.2, 0.026, 0.1667, 0.13723, 0.6, 0.64, 0, 0.1616, 0.29, 1.111]
Reward 3.9352400431791708
Current State [[0.2     0.2     0.026   0.1667  0.13723 0.6     0.64    0.      0.1616
  0.29    1.111  ]]
Logits tf.Tensor([[-0.33021814 -0.08110738  0.05278718]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26669723 0.3421417  0.39116108]], shape=(1, 3), dtype=float32)
Selected action 1
[0.11, 0.12, 0.025, 0.1346, 0.13723, 0.6, 0.65, 0, 0.1563, 0.32599999999999996, 1.408]
Reward 3.942150677133654
Current State [[0.11    0.12    0.025   0.1346  0.13723 0.6     0.65    0.      0.1563
  0.326   1.408  ]]
Logits tf.Tensor([[-0.38189736 -0.17738865  0.06633089]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26368123 0.3235163  0.41280246]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.07, 0.031, 0.13019999999999998, 0.13723, 0.6, 0.65, 0, 0.1563, 0.32599999999999996, 1.408]
Reward 3.942150677133654
Current State [[0.08    0.07    0.031   0.1302  0.13723 0.6     0.65    0.      0.1563
  0.326   1.408  ]]
Logits tf.Tensor([[-0.38852698 -0.19763684  0.07375725]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26329488 0.31867275 0.41803232]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.07, 0.035, 0.134, 0.13723, 0.6, 0.82, 0, 0.004699999999999999, 0.317, 0.978]
Reward 16.17218296380479
Current State [[0.07    0.07    0.035   0.134   0.13723 0.6     0.82    0.      0.0047
  0.317   0.978  ]]
Logits tf.Tensor([[-0.35330173 -0.11378561  0.06283392]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2640804  0.3355496  0.40037006]], shape=(1, 3), dtype=float32)
Selected action 1
[0.15, 0.12, 0.025, 0.151, 0.13723, 0.6, 0.43, 0, 0.17980000000000002, 0.24300000000000002, 2.027]
Reward 3.877445996709345
Current State [[0.15    0.12    0.025   0.151   0.13723 0.6     0.43    0.      0.1798
  0.243   2.027  ]]
Logits tf.Tensor([[-0.4502153  -0.32285336  0.09005687]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25958505 0.294844   0.44557098]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.07, 0.032, 0.1346, 0.13723, 0.6, 0.74, 0, 0.052199999999999996, 0.40599999999999997, 0.51]
Reward 4.316917808371238
Current State [[0.06    0.07    0.032   0.1346  0.13723 0.6     0.74    0.      0.0522
  0.406   0.51   ]]
Logits tf.Tensor([[-0.24442415 -0.08775651  0.05580486]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2841091  0.33229595 0.383595  ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.07, 0.029, 0.12830000000000003, 0.13723, 0.6, 0.74, 0, 0.052199999999999996, 0.40599999999999997, 0.51]
Reward 4.316917808371238
Current State [[0.04    0.07    0.029   0.1283  0.13723 0.6     0.74    0.      0.0522
  0.406   0.51   ]]
Logits tf.Tensor([[-0.24018848 -0.09351847  0.05716406]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.28536683 0.33044672 0.38418645]], shape=(1, 3), dtype=float32)
Selected action 2
[0.09, 0.07, 0.032, 0.1308, 0.13723, 0.6, 0.6, 0, 0.0159, 0.354, 1.405]
Reward 5.3403830173693905
Current State [[0.09    0.07    0.032   0.1308  0.13723 0.6     0.6     0.      0.0159
  0.354   1.405  ]]
Logits tf.Tensor([[-0.42731702 -0.18434246  0.06487235]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25569367 0.32601866 0.4182877 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.13, 0.12, 0.028, 0.151, 0.13723, 0.6, 0.51, 0, 0.019799999999999998, 0.23900000000000002, 2.447]
Reward 4.8018741267930345
Episode: 40 | Average Reward: 232 | Episode Reward: 165 | Loss: 175.899 | Steps: 19 | Worker: 0
Current State [[ 0.0064023   0.00800828 -0.00569476 -0.00014191 -0.00449173  0.00257177
  -0.00471388 -0.00569231 -0.00591914  0.00440969 -0.00628833]]
Logits tf.Tensor([[-0.00017768  0.01113517 -0.03083153]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3354367 0.339253  0.3253103]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.07, 0.034, 0.1296, 0.13723, 0.6, 0.62, 0, 0.0155, 0.356, 1.844]
Reward 5.4695358887984575
Current State [[0.08    0.07    0.034   0.1296  0.13723 0.6     0.62    0.      0.0155
  0.356   1.844  ]]
Logits tf.Tensor([[-0.501299   -0.29001683  0.07377116]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24922018 0.30785197 0.4429279 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.12, 0.2, 0.024, 0.1519, 0.13723, 0.6, 0.62, 0, 0.0155, 0.356, 1.844]
Reward 5.4695358887984575
Current State [[0.12    0.2     0.024   0.1519  0.13723 0.6     0.62    0.      0.0155
  0.356   1.844  ]]
Logits tf.Tensor([[-0.46136636 -0.24418591  0.06306629]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25431907 0.31600884 0.42967212]], shape=(1, 3), dtype=float32)
Selected action 1
[0.07, 0.12, 0.03, 0.162, 0.13723, 0.6, 0.65, 0, 0.0146, 0.475, 1.6059999999999999]
Reward 5.690689202319402
Current State [[0.07    0.12    0.03    0.162   0.13723 0.6     0.65    0.      0.0146
  0.475   1.606  ]]
Logits tf.Tensor([[-0.46893778 -0.23587336  0.05552429]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2530356  0.31944805 0.42751628]], shape=(1, 3), dtype=float32)
Selected action 0
[0.21, 0.2, 0.027, 0.1904, 0.13723, 0.6, 0.58, 0, 0.0072, 0.441, 0.959]
Reward 7.708421464440496
Current State [[0.21    0.2     0.027   0.1904  0.13723 0.6     0.58    0.      0.0072
  0.441   0.959  ]]
Logits tf.Tensor([[-0.35773167 -0.08146204  0.04267834]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26242313 0.34592703 0.39164984]], shape=(1, 3), dtype=float32)
Selected action 0
[0.18, 0.2, 0.031, 0.1731, 0.13723, 0.6, 0.9, 0, 0.004, 0.357, 1.072]
Reward 21.65627281585726
Current State [[0.18    0.2     0.031   0.1731  0.13723 0.6     0.9     0.      0.004
  0.357   1.072  ]]
Logits tf.Tensor([[-0.37504092 -0.08139838  0.0347675 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2598865  0.34858692 0.39152658]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.07, 0.036, 0.117, 0.13723, 0.6, 0.83, 0, 0.017, 0.327, 1.67]
Reward 5.885009814040332
Current State [[0.08    0.07    0.036   0.117   0.13723 0.6     0.83    0.      0.017
  0.327   1.67   ]]
Logits tf.Tensor([[-0.47196427 -0.22180988  0.06037362]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25080678 0.32209206 0.42710114]], shape=(1, 3), dtype=float32)
Selected action 1
[0.13, 0.12, 0.036, 0.1714, 0.13723, 0.6, 0.83, 0, 0.017, 0.327, 1.67]
Reward 5.885009814040332
Current State [[0.13    0.12    0.036   0.1714  0.13723 0.6     0.83    0.      0.017
  0.327   1.67   ]]
Logits tf.Tensor([[-0.47109637 -0.18828522  0.04666833]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24968001 0.33128905 0.419031  ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.09, 0.07, 0.032, 0.1352, 0.13723, 0.6, 0.72, 0, 0.0014000000000000002, 0.28900000000000003, 1.94]
Reward 46.718870794547406
Current State [[9.0000e-02 7.0000e-02 3.2000e-02 1.3520e-01 1.3723e-01 6.0000e-01
  7.2000e-01 0.0000e+00 1.4000e-03 2.8900e-01 1.9400e+00]]
Logits tf.Tensor([[-0.5041574  -0.28487754  0.07582647]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24806574 0.30888644 0.44304782]], shape=(1, 3), dtype=float32)
Selected action 2
[0.09, 0.07, 0.034, 0.1519, 0.13723, 0.6, 0.61, 0, 0.0108, 0.261, 2.166]
Reward 6.310630764983402
Current State [[0.09    0.07    0.034   0.1519  0.13723 0.6     0.61    0.      0.0108
  0.261   2.166  ]]
Logits tf.Tensor([[-0.5256983  -0.34741253  0.08237004]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.248013   0.2964169  0.45557004]], shape=(1, 3), dtype=float32)
Selected action 1
[0.11, 0.12, 0.035, 0.16469999999999999, 0.13723, 0.6, 0.61, 0, 0.0108, 0.261, 2.166]
Reward 6.310630764983402
Current State [[0.11    0.12    0.035   0.1647  0.13723 0.6     0.61    0.      0.0108
  0.261   2.166  ]]
Logits tf.Tensor([[-0.51185185 -0.32781154  0.0790074 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24952568 0.2999459  0.45052838]], shape=(1, 3), dtype=float32)
Selected action 0
[0.22, 0.2, 0.026, 0.1846, 0.13723, 0.6, 0.69, 0, 0.0037, 0.255, 1.768]
Reward 17.263027989638573
Current State [[0.22    0.2     0.026   0.1846  0.13723 0.6     0.69    0.      0.0037
  0.255   1.768  ]]
Logits tf.Tensor([[-0.445895   -0.17214946  0.05323769]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25238684 0.33185843 0.41575477]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.07, 0.04, 0.1431, 0.13723, 0.6, 0.84, 0, 0.005, 0.329, 1.4869999999999999]
Reward 15.285668892476991
Current State [[0.07    0.07    0.04    0.1431  0.13723 0.6     0.84    0.      0.005
  0.329   1.487  ]]
Logits tf.Tensor([[-0.43947166 -0.18948942  0.05878552]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25446245 0.32673046 0.41880712]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.07, 0.037, 0.12040000000000001, 0.13723, 0.6, 0.68, 0, 0.0026, 0.272, 1.504]
Reward 26.873572064182493
Current State [[0.07    0.07    0.037   0.1204  0.13723 0.6     0.68    0.      0.0026
  0.272   1.504  ]]
Logits tf.Tensor([[-0.42113736 -0.18953855  0.06932765]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25682583 0.32375824 0.41941598]], shape=(1, 3), dtype=float32)
Selected action 1
[0.12, 0.12, 0.031, 0.1566, 0.13723, 0.6, 0.68, 0, 0.0026, 0.272, 1.504]
Reward 26.873572064182493
Current State [[0.12    0.12    0.031   0.1566  0.13723 0.6     0.68    0.      0.0026
  0.272   1.504  ]]
Logits tf.Tensor([[-0.41837743 -0.1623769   0.05854302]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25622246 0.33097622 0.41280136]], shape=(1, 3), dtype=float32)
Selected action 1
[0.07, 0.12, 0.032, 0.16, 0.13723, 0.6, 0.52, 0, 0.0048, 0.308, 1.548]
Reward 9.751528848677324
Current State [[0.07    0.12    0.032   0.16    0.13723 0.6     0.52    0.      0.0048
  0.308   1.548  ]]
Logits tf.Tensor([[-0.411692   -0.2070425   0.07067016]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25994343 0.31897524 0.42108136]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.07, 0.039, 0.134, 0.13723, 0.6, 0.98, 0, 0.0054, 0.313, 0.24700000000000003]
Reward 16.682654238791486
Current State [[0.08    0.07    0.039   0.134   0.13723 0.6     0.98    0.      0.0054
  0.313   0.247  ]]
Logits tf.Tensor([[-0.20884271 -0.06727857  0.01667976]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29368132 0.3383427  0.36797598]], shape=(1, 3), dtype=float32)
Selected action 1
[0.03, 0.12, 0.033, 0.14809999999999998, 0.13723, 0.6, 0.68, 0, 0.0027, 0.25, 1.9129999999999998]
Reward 25.294994980848223
Current State [[0.03    0.12    0.033   0.1481  0.13723 0.6     0.68    0.      0.0027
  0.25    1.913  ]]
Logits tf.Tensor([[-0.45767874 -0.2783144   0.08082002]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25576174 0.30600777 0.43823048]], shape=(1, 3), dtype=float32)
Selected action 0
[0.34, 0.2, 0.032, 0.21130000000000002, 0.13723, 0.6, 0.68, 0, 0.0027, 0.25, 1.9129999999999998]
Reward 25.294994980848223
Current State [[0.34    0.2     0.032   0.2113  0.13723 0.6     0.68    0.      0.0027
  0.25    1.913  ]]
Logits tf.Tensor([[-0.48670173 -0.17598335  0.04790244]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24562918 0.33513767 0.41923314]], shape=(1, 3), dtype=float32)
Selected action 0
[0.2, 0.2, 0.026, 0.21730000000000002, 0.13723, 0.6, 0.9, 0, 0.0007000000000000001, 0.341, 0.16799999999999998]
Reward 49.99640536283262
Current State [[2.0000e-01 2.0000e-01 2.6000e-02 2.1730e-01 1.3723e-01 6.0000e-01
  9.0000e-01 0.0000e+00 7.0000e-04 3.4100e-01 1.6800e-01]]
Logits tf.Tensor([[-0.18242523 -0.03519715 -0.0178686 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2996265 0.3471527 0.3532208]], shape=(1, 3), dtype=float32)
Selected action 1
[0.11, 0.12, 0.03, 0.15309999999999999, 0.13723, 0.6, 0.81, 0, 0.0152, 0.304, 1.108]
Reward 6.114318266639387
Episode: 41 | Average Reward: 233 | Episode Reward: 336 | Loss: 1221.779 | Steps: 19 | Worker: 0
Current State [[ 0.00717785  0.0077632   0.00270284 -0.00194785 -0.00448343  0.00134539
   0.00868218 -0.00786129  0.00138508 -0.00567002 -0.00261341]]
Logits tf.Tensor([[ 0.00150702  0.01288273 -0.02400614]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.33486813 0.33869922 0.32643265]], shape=(1, 3), dtype=float32)
Selected action 1
[0.11, 0.12, 0.031, 0.1434, 0.13723, 0.6, 0.74, 0, 0.0679, 0.319, 0.9039999999999999]
Reward 4.194490922668774
Current State [[0.11    0.12    0.031   0.1434  0.13723 0.6     0.74    0.      0.0679
  0.319   0.904  ]]
Logits tf.Tensor([[-0.31098595 -0.10079867  0.05690509]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.27184302 0.33542958 0.3927274 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.2, 0.2, 0.029, 0.17859999999999998, 0.13723, 0.6, 0.76, 0, 0.0678, 0.24, 2.21]
Reward 4.205321152619328
Current State [[0.2     0.2     0.029   0.1786  0.13723 0.6     0.76    0.      0.0678
  0.24    2.21   ]]
Logits tf.Tensor([[-0.48457012 -0.28577557  0.06735673]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2527469  0.30833387 0.43891925]], shape=(1, 3), dtype=float32)
Selected action 0
[0.2, 0.2, 0.029, 0.2075, 0.13723, 0.6, 0.76, 0, 0.0678, 0.24, 2.21]
Reward 4.205321152619328
Current State [[0.2     0.2     0.029   0.2075  0.13723 0.6     0.76    0.      0.0678
  0.24    2.21   ]]
Logits tf.Tensor([[-0.4875696  -0.2810481   0.06238785]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25236127 0.31025144 0.4373873 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.1, 0.2, 0.028, 0.188, 0.13723, 0.6, 0.8, 0, 0.0004, 0.311, 2.2399999999999998]
Reward 49.99999970189831
Current State [[1.0000e-01 2.0000e-01 2.8000e-02 1.8800e-01 1.3723e-01 6.0000e-01
  8.0000e-01 0.0000e+00 4.0000e-04 3.1100e-01 2.2400e+00]]
Logits tf.Tensor([[-0.5122996  -0.3136672   0.05810099]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2507077  0.30579656 0.44349578]], shape=(1, 3), dtype=float32)
Selected action 2
[0.09, 0.07, 0.028, 0.12079999999999999, 0.13723, 0.6, 0.85, 0, 0.0025, 0.335, 1.907]
Reward 35.51572967354545
Current State [[0.09    0.07    0.028   0.1208  0.13723 0.6     0.85    0.      0.0025
  0.335   1.907  ]]
Logits tf.Tensor([[-0.5077155  -0.27385327  0.05949187]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24833573 0.3137649  0.43789932]], shape=(1, 3), dtype=float32)
Selected action 2
[0.09, 0.07, 0.042, 0.124, 0.13723, 0.6, 0.5, 0, 0.1447, 0.26, 1.754]
Reward 3.916069695167362
Current State [[0.09    0.07    0.042   0.124   0.13723 0.6     0.5     0.      0.1447
  0.26    1.754  ]]
Logits tf.Tensor([[-0.41337797 -0.28897032  0.09013557]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26406115 0.2990433  0.43689555]], shape=(1, 3), dtype=float32)
Selected action 0
[0.23, 0.2, 0.027, 0.2041, 0.13723, 0.6, 0.5, 0, 0.1447, 0.26, 1.754]
Reward 3.916069695167362
Current State [[0.23    0.2     0.027   0.2041  0.13723 0.6     0.5     0.      0.1447
  0.26    1.754  ]]
Logits tf.Tensor([[-0.39162946 -0.21510597  0.05466487]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2662709  0.3176778  0.41605127]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.07, 0.032, 0.1346, 0.13723, 0.6, 0.97, 0, 0.0233, 0.312, 0.9560000000000001]
Reward 5.541014675032253
Current State [[0.06    0.07    0.032   0.1346  0.13723 0.6     0.97    0.      0.0233
  0.312   0.956  ]]
Logits tf.Tensor([[-0.3336277  -0.1358607   0.04612335]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2716949  0.33110872 0.39719638]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.07, 0.031, 0.1216, 0.13723, 0.6, 0.78, 0, 0.0032, 0.269, 1.7890000000000001]
Reward 23.842058088617122
Current State [[0.03    0.07    0.031   0.1216  0.13723 0.6     0.78    0.      0.0032
  0.269   1.789  ]]
Logits tf.Tensor([[-0.4539839  -0.2595306   0.06951215]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25624174 0.31124318 0.4325151 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.07, 0.031, 0.1451, 0.13723, 0.6, 0.69, 0, 0.0125, 0.28300000000000003, 1.1789999999999998]
Reward 6.254973635986788
Current State [[0.08    0.07    0.031   0.1451  0.13723 0.6     0.69    0.      0.0125
  0.283   1.179  ]]
Logits tf.Tensor([[-0.3638132  -0.14164445  0.06228908]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2645461  0.33036044 0.40509346]], shape=(1, 3), dtype=float32)
Selected action 0
[0.2, 0.2, 0.026, 0.1824, 0.13723, 0.6, 0.69, 0, 0.0125, 0.28300000000000003, 1.1789999999999998]
Reward 6.254973635986788
Current State [[0.2     0.2     0.026   0.1824  0.13723 0.6     0.69    0.      0.0125
  0.283   1.179  ]]
Logits tf.Tensor([[-0.3643555  -0.07712585  0.03773302]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2612553  0.34818283 0.39056194]], shape=(1, 3), dtype=float32)
Selected action 1
[0.12, 0.12, 0.032, 0.1571, 0.13723, 0.6, 0.87, 0, 0.0104, 0.308, 1.114]
Reward 7.972199477404272
Current State [[0.12    0.12    0.032   0.1571  0.13723 0.6     0.87    0.      0.0104
  0.308   1.114  ]]
Logits tf.Tensor([[-0.36695075 -0.11516975  0.0499457 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2629116  0.33818695 0.3989014 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.2, 0.023, 0.144, 0.13723, 0.6, 0.83, 0, 0.0059, 0.306, 1.5859999999999999]
Reward 12.585305183773313
Current State [[0.05    0.2     0.023   0.144   0.13723 0.6     0.83    0.      0.0059
  0.306   1.586  ]]
Logits tf.Tensor([[-0.40242442 -0.18723592  0.0508901 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2622184  0.32517588 0.41260564]], shape=(1, 3), dtype=float32)
Selected action 1
[0.09, 0.12, 0.025, 0.152, 0.13723, 0.6, 0.6, 0, 0.2271, 0.46799999999999997, 0.612]
Reward 3.8867030915746157
Current State [[0.09    0.12    0.025   0.152   0.13723 0.6     0.6     0.      0.2271
  0.468   0.612  ]]
Logits tf.Tensor([[-0.22327277 -0.12201384  0.06629945]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2904934  0.3214493  0.38805732]], shape=(1, 3), dtype=float32)
Selected action 0
[0.13, 0.2, 0.024, 0.1776, 0.13723, 0.6, 0.54, 0, 0.0231, 0.36, 0.633]
Reward 4.700597330618425
Current State [[0.13    0.2     0.024   0.1776  0.13723 0.6     0.54    0.      0.0231
  0.36    0.633  ]]
Logits tf.Tensor([[-0.24934742 -0.05360243  0.05025616]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.28046238 0.34110305 0.37843457]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.07, 0.022, 0.125, 0.13723, 0.6, 0.54, 0, 0.0231, 0.36, 0.633]
Reward 4.700597330618425
Current State [[0.07    0.07    0.022   0.125   0.13723 0.6     0.54    0.      0.0231
  0.36    0.633  ]]
Logits tf.Tensor([[-0.2629411  -0.09276079  0.06861848]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.27943438 0.33127463 0.38929096]], shape=(1, 3), dtype=float32)
Selected action 0
[0.19, 0.2, 0.026, 0.18080000000000002, 0.13723, 0.6, 0.69, 0, 0.003, 0.286, 1.1640000000000001]
Reward 22.581028096571252
Current State [[0.19    0.2     0.026   0.1808  0.13723 0.6     0.69    0.      0.003
  0.286   1.164  ]]
Logits tf.Tensor([[-0.362631   -0.07799072  0.03887979]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26154977 0.34767386 0.39077634]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.07, 0.029, 0.1377, 0.13723, 0.6, 0.72, 0, 0.1272, 0.333, 1.423]
Reward 3.9970643810599573
Current State [[0.07    0.07    0.029   0.1377  0.13723 0.6     0.72    0.      0.1272
  0.333   1.423  ]]
Logits tf.Tensor([[-0.38728476 -0.20180802  0.06625991]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2647132  0.31865966 0.41662714]], shape=(1, 3), dtype=float32)
Selected action 0
[0.16, 0.2, 0.024, 0.1529, 0.13723, 0.6, 0.62, 0, 0.0086, 0.307, 0.975]
Reward 7.209978015693317
Current State [[0.16    0.2     0.024   0.1529  0.13723 0.6     0.62    0.      0.0086
  0.307   0.975  ]]
Logits tf.Tensor([[-0.32196462 -0.07375559  0.05140731]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26778406 0.34322628 0.3889897 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.12, 0.12, 0.026, 0.18, 0.13723, 0.6, 0.62, 0, 0.0086, 0.307, 0.975]
Reward 7.209978015693317
Episode: 42 | Average Reward: 233 | Episode Reward: 222 | Loss: 352.185 | Steps: 19 | Worker: 0
Current State [[ 0.00156782  0.00029181  0.00388404  0.00590334 -0.00792492 -0.00242849
  -0.00893779 -0.00414442 -0.00626237  0.00871525 -0.00738595]]
Logits tf.Tensor([[ 0.00114463  0.00919289 -0.03043858]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.33590963 0.33862403 0.32546633]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.2, 0.021, 0.134, 0.13723, 0.6, 0.8, 0, 0.0009, 0.34900000000000003, 0.19]
Reward 49.90985637202677
Current State [[0.04    0.2     0.021   0.134   0.13723 0.6     0.8     0.      0.0009
  0.349   0.19   ]]
Logits tf.Tensor([[-0.1364206  -0.07174687  0.01811939]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30922112 0.32988048 0.36089844]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.07, 0.028, 0.1462, 0.13723, 0.6, 0.76, 0, 0.0069, 0.29100000000000004, 0.499]
Reward 9.917947091335929
Current State [[0.07    0.07    0.028   0.1462  0.13723 0.6     0.76    0.      0.0069
  0.291   0.499  ]]
Logits tf.Tensor([[-0.23465058 -0.07457597  0.04050292]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.28650576 0.33624274 0.37725154]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.07, 0.027, 0.1333, 0.13723, 0.6, 0.74, 0, 0.0043, 0.315, 1.2189999999999999]
Reward 15.754332428276813
Current State [[0.08    0.07    0.027   0.1333  0.13723 0.6     0.74    0.      0.0043
  0.315   1.219  ]]
Logits tf.Tensor([[-0.37141788 -0.16085823  0.05856828]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2651391  0.32727942 0.40758145]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.07, 0.033, 0.1321, 0.13723, 0.6, 0.74, 0, 0.0043, 0.315, 1.2189999999999999]
Reward 15.754332428276813
Current State [[0.06    0.07    0.033   0.1321  0.13723 0.6     0.74    0.      0.0043
  0.315   1.219  ]]
Logits tf.Tensor([[-0.36476684 -0.16521853  0.06149893]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26649764 0.32535392 0.40814847]], shape=(1, 3), dtype=float32)
Selected action 0
[0.24, 0.2, 0.027, 0.2385, 0.13723, 0.6, 0.75, 0, 0.0060999999999999995, 0.28700000000000003, 1.2449999999999999]
Reward 11.08384031520046
Current State [[0.24    0.2     0.027   0.2385  0.13723 0.6     0.75    0.      0.0061
  0.287   1.245  ]]
Logits tf.Tensor([[-0.38417757 -0.0797381   0.02185065]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2592884  0.35156    0.38915163]], shape=(1, 3), dtype=float32)
Selected action 1
[0.1, 0.12, 0.025, 0.2204, 0.13723, 0.6, 0.75, 0, 0.0060999999999999995, 0.28700000000000003, 1.2449999999999999]
Reward 11.08384031520046
Current State [[0.1     0.12    0.025   0.2204  0.13723 0.6     0.75    0.      0.0061
  0.287   1.245  ]]
Logits tf.Tensor([[-0.36953846 -0.13589297  0.0438506 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26489156 0.33461013 0.40049833]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.07, 0.024, 0.2122, 0.13723, 0.6, 0.62, 0, 0.04, 0.34900000000000003, 0.799]
Reward 4.3701977678379915
Current State [[0.08    0.07    0.024   0.2122  0.13723 0.6     0.62    0.      0.04
  0.349   0.799  ]]
Logits tf.Tensor([[-0.2929732  -0.10842207  0.05480127]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.27635062 0.33236092 0.3912884 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.12, 0.2, 0.024, 0.2647, 0.13723, 0.6, 0.62, 0, 0.04, 0.34900000000000003, 0.799]
Reward 4.3701977678379915
Current State [[0.12    0.2     0.024   0.2647  0.13723 0.6     0.62    0.      0.04
  0.349   0.799  ]]
Logits tf.Tensor([[-0.27117994 -0.07209975  0.03912008]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.27900898 0.34046903 0.38052198]], shape=(1, 3), dtype=float32)
Selected action 1
[0.11, 0.12, 0.024, 0.2396, 0.13723, 0.6, 0.68, 0, 0.010700000000000001, 0.279, 1.1400000000000001]
Reward 6.714943289448537
Current State [[0.11    0.12    0.024   0.2396  0.13723 0.6     0.68    0.      0.0107
  0.279   1.14   ]]
Logits tf.Tensor([[-0.34700933 -0.11764384  0.04227054]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26782948 0.33687636 0.39529422]], shape=(1, 3), dtype=float32)
Selected action 0
[0.17, 0.2, 0.027, 0.2327, 0.13723, 0.6, 0.68, 0, 0.010700000000000001, 0.279, 1.1400000000000001]
Reward 6.714943289448537
Current State [[0.17    0.2     0.027   0.2327  0.13723 0.6     0.68    0.      0.0107
  0.279   1.14   ]]
Logits tf.Tensor([[-0.33994344 -0.08159694  0.03341043]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2668527  0.34551752 0.3876298 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.07, 0.027, 0.216, 0.13723, 0.6, 0.8, 0, 0.004, 0.327, 1.508]
Reward 18.9862679643784
Current State [[0.07    0.07    0.027   0.216   0.13723 0.6     0.8     0.      0.004
  0.327   1.508  ]]
Logits tf.Tensor([[-0.42718145 -0.20070395  0.04407379]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2593241  0.32523763 0.4154382 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.07, 0.029, 0.228, 0.13723, 0.6, 0.8, 0, 0.004, 0.327, 1.508]
Reward 18.9862679643784
Current State [[0.07    0.07    0.029   0.228   0.13723 0.6     0.8     0.      0.004
  0.327   1.508  ]]
Logits tf.Tensor([[-0.42762002 -0.1993171   0.04303189]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25923502 0.32571998 0.41504502]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.07, 0.033, 0.2039, 0.13723, 0.6, 0.44, 0, 0.0171, 0.28700000000000003, 1.0150000000000001]
Reward 4.789375312611153
Current State [[0.08    0.07    0.033   0.2039  0.13723 0.6     0.44    0.      0.0171
  0.287   1.015  ]]
Logits tf.Tensor([[-0.30117235 -0.12359275  0.05380632]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.276207   0.3298804  0.39391267]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.07, 0.032, 0.2077, 0.13723, 0.6, 0.44, 0, 0.0171, 0.28700000000000003, 1.0150000000000001]
Reward 4.789375312611153
Current State [[0.07    0.07    0.032   0.2077  0.13723 0.6     0.44    0.      0.0171
  0.287   1.015  ]]
Logits tf.Tensor([[-0.29840356 -0.12568897  0.05378513]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.27695432 0.32916766 0.39387804]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.07, 0.035, 0.1321, 0.13723, 0.6, 0.55, 0, 0.1974, 0.253, 0.922]
Reward 3.891079860868113
Current State [[0.06    0.07    0.035   0.1321  0.13723 0.6     0.55    0.      0.1974
  0.253   0.922  ]]
Logits tf.Tensor([[-0.2452406  -0.12961005  0.07638758]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.28555498 0.3205586  0.39388648]], shape=(1, 3), dtype=float32)
Selected action 0
Traceback (most recent call last):
  File "/home/kaiser/Git/drl-a3c/A3C/agent.py", line 387, in <module>
    main()
  File "/home/kaiser/Git/drl-a3c/A3C/agent.py", line 375, in main
    train(env, global_model)
  File "/home/kaiser/Git/drl-a3c/A3C/agent.py", line 84, in train
    reward = res_queue.get()
  File "/usr/lib/python3.8/queue.py", line 170, in get
    self.not_empty.wait()
  File "/usr/lib/python3.8/threading.py", line 302, in wait
    waiter.acquire()
KeyboardInterrupt
[0.22, 0.2, 0.026, 0.2471, 0.13723, 0.6, 0.55, 0, 0.1974, 0.253, 0.922]
Reward 3.891079860868113
Current State [[0.22    0.2     0.026   0.2471  0.13723 0.6     0.55    0.      0.1974
  0.253   0.922  ]]
Logits tf.Tensor([[-0.25951853 -0.06665945  0.03443516]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.28133878 0.3411829  0.37747836]], shape=(1, 3), dtype=float32)
Selected action 1

Process finished with exit code 137 (interrupted by signal 9: SIGKILL)
