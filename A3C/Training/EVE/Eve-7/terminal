/home/kaiser/Git/drl-a3c/venv/bin/python /home/kaiser/Git/drl-a3c/A3C/agent.py --train --num-workers 1
2022-01-27 11:38:16.245709: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
Namespace(gamma=0.99, lr=0.001, max_eps=200, num_workers=1, train=True, update_freq=20)
/home/kaiser/Git/drl-a3c/venv/lib/python3.8/site-packages/gym/logger.py:30: UserWarning: WARN: Box bound precision lowered by casting to float32
  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))
-------------------------------------
TRAINING INFORMATION
Environment name: A3C.envs.eve:Eve-v0
Number of states: 11. Number of actions: 3
Training episodes: 200
-------------------------------------
2022-01-27 11:38:24.685531: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2022-01-27 11:38:24.692198: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2022-01-27 11:38:24.742306: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-01-27 11:38:24.743033: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2022-01-27 11:38:24.743093: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-01-27 11:38:24.758315: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-01-27 11:38:24.758709: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2022-01-27 11:38:24.766386: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-01-27 11:38:24.770002: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-01-27 11:38:24.799689: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2022-01-27 11:38:24.803851: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2022-01-27 11:38:24.805285: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-01-27 11:38:24.805487: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-01-27 11:38:24.806081: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-01-27 11:38:24.806823: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2022-01-27 11:38:24.807373: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-01-27 11:38:24.808175: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2022-01-27 11:38:24.808275: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-01-27 11:38:24.808607: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2022-01-27 11:38:24.808632: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-01-27 11:38:24.808652: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-01-27 11:38:24.808661: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2022-01-27 11:38:24.808670: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-01-27 11:38:24.808679: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-01-27 11:38:24.808687: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2022-01-27 11:38:24.808695: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2022-01-27 11:38:24.808704: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-01-27 11:38:24.808751: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-01-27 11:38:24.809125: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-01-27 11:38:24.809423: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2022-01-27 11:38:24.809717: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-01-27 11:38:25.620114: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2022-01-27 11:38:25.620151: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2022-01-27 11:38:25.620157: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2022-01-27 11:38:25.620798: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-01-27 11:38:25.621145: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-01-27 11:38:25.621438: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-01-27 11:38:25.621718: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9999 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5)
2022-01-27 11:38:25.753120: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-01-27 11:38:26.529705: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
Starting worker 0
Probs tf.Tensor([[0.3332841  0.3333662  0.33334973]], shape=(1, 3), dtype=float32)
Selected action 2
[0.12, 0.3, 0.19, 0.248, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.30350018 0.38769644 0.30880344]], shape=(1, 3), dtype=float32)
Selected action 0
[0.06, 0.075, 0.32, 0.196, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.30997798 0.39300358 0.29701847]], shape=(1, 3), dtype=float32)
Selected action 1
[0.16, 0.15, 0.23, 0.248, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.30801186 0.38615417 0.305834  ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.2, 0.15, 0.28, 0.252, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.30921495 0.3859957  0.30478933]], shape=(1, 3), dtype=float32)
Selected action 0
[0.06, 0.075, 0.33, 0.208, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 0 | Average Reward: 43 | Episode Reward: 43 | Loss: 89.647 | Steps: 4 | Worker: 0
Saving best model to ./Training/, episode score: 43.41875337791373
Probs tf.Tensor([[0.33390322 0.33294624 0.33315054]], shape=(1, 3), dtype=float32)
Selected action 0
[0.08, 0.075, 0.33, 0.233, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.360545   0.31585985 0.32359517]], shape=(1, 3), dtype=float32)
Selected action 0
[0.08, 0.075, 0.33, 0.178, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.35775262 0.31676546 0.32548195]], shape=(1, 3), dtype=float32)
Selected action 0
[0.06, 0.075, 0.3, 0.169, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.3578753  0.31652212 0.32560265]], shape=(1, 3), dtype=float32)
Selected action 1
[0.13, 0.15, 0.3, 0.249, 0.125, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.35977393 0.31721568 0.32301033]], shape=(1, 3), dtype=float32)
Selected action 2
[0.33, 0.3, 0.3, 0.242, 0.125, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 1 | Average Reward: 43 | Episode Reward: 37 | Loss: 111.105 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 37.49359088466956
Probs tf.Tensor([[0.33586305 0.33184257 0.3322944 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.3, 0.3, 0.27, 0.231, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.3620499  0.31887    0.31908005]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.075, 0.35, 0.165, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.36403197 0.31317464 0.32279336]], shape=(1, 3), dtype=float32)
Selected action 0
[0.07, 0.075, 0.34, 0.167, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.36438534 0.31347367 0.32214102]], shape=(1, 3), dtype=float32)
Selected action 0
[0.09, 0.075, 0.35, 0.143, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.36298856 0.31437173 0.32263973]], shape=(1, 3), dtype=float32)
Selected action 0
[0.07, 0.075, 0.35, 0.142, 0.125, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 2 | Average Reward: 43 | Episode Reward: 31 | Loss: 38.586 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 31.54442839142539
Probs tf.Tensor([[0.33661816 0.3315121  0.33186978]], shape=(1, 3), dtype=float32)
Selected action 0
[0.03, 0.075, 0.32, 0.181, 0.129, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.37440762 0.30791602 0.31767642]], shape=(1, 3), dtype=float32)
Selected action 0
[0.07, 0.075, 0.41, 0.172, 0.13, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.37252194 0.30890602 0.31857198]], shape=(1, 3), dtype=float32)
Selected action 0
[0.11, 0.075, 0.34, 0.124, 0.13, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.37133467 0.31038448 0.31828085]], shape=(1, 3), dtype=float32)
Selected action 1
[0.13, 0.15, 0.37, 0.206, 0.131, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.37344807 0.30905262 0.3174993 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.09, 0.075, 0.32, 0.183, 0.131, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 3 | Average Reward: 43 | Episode Reward: 25 | Loss: 43.425 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 25.571265898181217
Probs tf.Tensor([[0.33936033 0.33086744 0.3297722 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.13, 0.15, 0.25, 0.215, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.38528326 0.30495968 0.3097571 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.13, 0.3, 0.25, 0.21, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.38064435 0.30643997 0.3129157 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.08, 0.075, 0.33, 0.175, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.38403293 0.304561   0.3114061 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.17, 0.3, 0.26, 0.232, 0.125, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.3821338  0.30668202 0.31118423]], shape=(1, 3), dtype=float32)
Selected action 2
[0.09, 0.3, 0.22, 0.22, 0.125, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 4 | Average Reward: 43 | Episode Reward: 61 | Loss: 229.568 | Steps: 4 | Worker: 0
Saving best model to ./Training/, episode score: 61.91010340493704
Probs tf.Tensor([[0.3393515  0.3299946  0.33065394]], shape=(1, 3), dtype=float32)
Selected action 1
[0.17, 0.15, 0.26, 0.194, 0.121, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.3889395  0.2990713  0.31198916]], shape=(1, 3), dtype=float32)
Selected action 2
[0.31, 0.3, 0.31, 0.243, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.38841453 0.3004317  0.31115383]], shape=(1, 3), dtype=float32)
Selected action 0
[0.09, 0.075, 0.33, 0.188, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.38952076 0.29774615 0.31273308]], shape=(1, 3), dtype=float32)
Selected action 2
[0.2, 0.3, 0.2, 0.231, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.3869087 0.3003485 0.3127428]], shape=(1, 3), dtype=float32)
Selected action 2
[0.18, 0.3, 0.25, 0.227, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 5 | Average Reward: 43 | Episode Reward: 62 | Loss: 230.251 | Steps: 4 | Worker: 0
Saving best model to ./Training/, episode score: 62.032940911692876
Probs tf.Tensor([[0.34097874 0.32835376 0.33066753]], shape=(1, 3), dtype=float32)
Selected action 1
[0.17, 0.15, 0.3, 0.172, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.3897838 0.2921217 0.3180945]], shape=(1, 3), dtype=float32)
Selected action 2
[0.09, 0.3, 0.26, 0.206, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.38747874 0.29184398 0.32067728]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.075, 0.28, 0.122, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.3884324  0.29228273 0.31928486]], shape=(1, 3), dtype=float32)
Selected action 2
[0.1, 0.3, 0.25, 0.226, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.3889388  0.29153222 0.31952894]], shape=(1, 3), dtype=float32)
Selected action 2
[0.15, 0.3, 0.29, 0.218, 0.125, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 6 | Average Reward: 43 | Episode Reward: 62 | Loss: 230.897 | Steps: 4 | Worker: 0
Saving best model to ./Training/, episode score: 62.1557784184487
Probs tf.Tensor([[0.34123132 0.32836092 0.33040774]], shape=(1, 3), dtype=float32)
Selected action 0
[0.12, 0.075, 0.29, 0.171, 0.121, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.39250565 0.2844543  0.3230401 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.08, 0.075, 0.4, 0.172, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.39068794 0.28413883 0.32517323]], shape=(1, 3), dtype=float32)
Selected action 1
[0.06, 0.15, 0.36, 0.179, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.38945073 0.28383738 0.32671192]], shape=(1, 3), dtype=float32)
Selected action 1
[0.06, 0.15, 0.35, 0.121, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.38599348 0.28565246 0.328354  ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.11, 0.15, 0.37, 0.198, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 7 | Average Reward: 43 | Episode Reward: 37 | Loss: 102.804 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 37.94261592520452
Probs tf.Tensor([[0.3405879  0.32711732 0.33229476]], shape=(1, 3), dtype=float32)
Selected action 1
[0.16, 0.15, 0.27, 0.237, 0.128, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.39427242 0.2793301  0.3263974 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.06, 0.075, 0.33, 0.188, 0.129, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.3914511  0.2808473  0.32770166]], shape=(1, 3), dtype=float32)
Selected action 2
[0.23, 0.3, 0.27, 0.244, 0.13, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.39153367 0.2799456  0.32852075]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.3, 0.22, 0.26, 0.13, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.3910103  0.2799221  0.32906756]], shape=(1, 3), dtype=float32)
Selected action 2
[0.33, 0.3, 0.28, 0.262, 0.131, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 8 | Average Reward: 43 | Episode Reward: 62 | Loss: 257.401 | Steps: 4 | Worker: 0
Saving best model to ./Training/, episode score: 62.40145343196035
Probs tf.Tensor([[0.33937782 0.33008507 0.3305371 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.14, 0.15, 0.3, 0.172, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.38821158 0.2770588  0.33472958]], shape=(1, 3), dtype=float32)
Selected action 0
[0.08, 0.075, 0.42, 0.177, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.38813254 0.277154   0.3347134 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.31, 0.3, 0.22, 0.26, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.39139873 0.2761618  0.3324395 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.18, 0.15, 0.27, 0.202, 0.125, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.3906019  0.27634844 0.33304965]], shape=(1, 3), dtype=float32)
Selected action 0
[0.1, 0.075, 0.39, 0.194, 0.125, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 9 | Average Reward: 43 | Episode Reward: 44 | Loss: 108.4 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 44.20029093871618
Probs tf.Tensor([[0.34050658 0.32896847 0.33052498]], shape=(1, 3), dtype=float32)
Selected action 1
[0.07, 0.15, 0.25, 0.188, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.38775462 0.2737186  0.33852682]], shape=(1, 3), dtype=float32)
Selected action 0
[0.08, 0.075, 0.29, 0.174, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.3887807  0.2741647  0.33705458]], shape=(1, 3), dtype=float32)
Selected action 0
[0.03, 0.075, 0.28, 0.186, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.3888638 0.2742377 0.3368985]], shape=(1, 3), dtype=float32)
Selected action 0
[0.08, 0.075, 0.27, 0.131, 0.125, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.3867336  0.2753105  0.33795595]], shape=(1, 3), dtype=float32)
Selected action 2
[0.24, 0.3, 0.19, 0.248, 0.125, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 10 | Average Reward: 43 | Episode Reward: 38 | Loss: 88.98 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 38.167128445472
Probs tf.Tensor([[0.33999074 0.3287357  0.33127356]], shape=(1, 3), dtype=float32)
Selected action 0
[0.08, 0.075, 0.28, 0.204, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.3912548  0.2693869  0.33935827]], shape=(1, 3), dtype=float32)
Selected action 0
[0.07, 0.075, 0.3, 0.194, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.39031526 0.26962852 0.3400562 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.08, 0.15, 0.33, 0.131, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.38434952 0.27066505 0.3449854 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.34, 0.3, 0.31, 0.124, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.38306066 0.26974434 0.34719497]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.3, 0.33, 0.198, 0.125, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 11 | Average Reward: 43 | Episode Reward: 50 | Loss: 196.811 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 50.50596595222784
Probs tf.Tensor([[0.341409  0.3272677 0.3313233]], shape=(1, 3), dtype=float32)
Selected action 0
[0.07, 0.075, 0.32, 0.122, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.38599932 0.26778182 0.3462189 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.07, 0.075, 0.33, 0.18, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.38905668 0.26613888 0.34480447]], shape=(1, 3), dtype=float32)
Selected action 1
[0.17, 0.15, 0.28, 0.206, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.39052412 0.2640815  0.34539437]], shape=(1, 3), dtype=float32)
Selected action 0
[0.07, 0.075, 0.29, 0.192, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.3902373  0.26602837 0.34373432]], shape=(1, 3), dtype=float32)
Selected action 1
[0.16, 0.15, 0.32, 0.182, 0.125, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 12 | Average Reward: 43 | Episode Reward: 32 | Loss: 70.101 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 32.172803458983665
Probs tf.Tensor([[0.34080797 0.32844573 0.33074626]], shape=(1, 3), dtype=float32)
Selected action 2
[0.29, 0.3, 0.27, 0.259, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.39136422 0.25878236 0.34985343]], shape=(1, 3), dtype=float32)
Selected action 1
[0.17, 0.15, 0.34, 0.247, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.39273143 0.25975516 0.34751347]], shape=(1, 3), dtype=float32)
Selected action 0
[0.08, 0.075, 0.39, 0.127, 0.125, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.38577715 0.26447308 0.34974974]], shape=(1, 3), dtype=float32)
Selected action 1
[0.13, 0.15, 0.29, 0.21, 0.125, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.39033633 0.26155382 0.3481098 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.37, 0.3, 0.29, 0.259, 0.125, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 13 | Average Reward: 43 | Episode Reward: 56 | Loss: 170.895 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 56.85964096573949
Probs tf.Tensor([[0.34120265 0.326699   0.3320983 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.22, 0.3, 0.26, 0.241, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.388639   0.25843024 0.35293072]], shape=(1, 3), dtype=float32)
Selected action 2
[0.33, 0.3, 0.29, 0.269, 0.126, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.39133227 0.25683087 0.35183683]], shape=(1, 3), dtype=float32)
Selected action 2
[0.25, 0.3, 0.28, 0.241, 0.127, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.38879243 0.25793537 0.3532722 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.18, 0.3, 0.25, 0.206, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.38592252 0.25998858 0.35408884]], shape=(1, 3), dtype=float32)
Selected action 0
[0.07, 0.075, 0.44, 0.171, 0.125, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 14 | Average Reward: 44 | Episode Reward: 69 | Loss: 235.285 | Steps: 4 | Worker: 0
Saving best model to ./Training/, episode score: 69.30647847249533
Probs tf.Tensor([[0.3412063  0.32907116 0.32972252]], shape=(1, 3), dtype=float32)
Selected action 2
[0.15, 0.3, 0.26, 0.218, 0.129, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.38441256 0.2572169  0.3583705 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.08, 0.075, 0.33, 0.184, 0.13, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.38747832 0.2599026  0.35261908]], shape=(1, 3), dtype=float32)
Selected action 0
[0.1, 0.075, 0.36, 0.124, 0.131, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.38395432 0.26115698 0.35488874]], shape=(1, 3), dtype=float32)
Selected action 0
[0.06, 0.075, 0.33, 0.172, 0.132, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.3865718  0.26051238 0.3529159 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.13, 0.15, 0.27, 0.217, 0.132, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 15 | Average Reward: 43 | Episode Reward: 38 | Loss: 67.101 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 38.54131597925115
Probs tf.Tensor([[0.34078935 0.32644802 0.33276263]], shape=(1, 3), dtype=float32)
Selected action 2
[0.3, 0.3, 0.2, 0.257, 0.121, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.38814932 0.2535112  0.35833952]], shape=(1, 3), dtype=float32)
Selected action 2
[0.09, 0.3, 0.24, 0.211, 0.126, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.38284016 0.25589254 0.36126733]], shape=(1, 3), dtype=float32)
Selected action 1
[0.15, 0.15, 0.26, 0.23, 0.127, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.3896091  0.25523785 0.35515296]], shape=(1, 3), dtype=float32)
Selected action 2
[0.1, 0.3, 0.24, 0.172, 0.128, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.38059807 0.25715992 0.36224207]], shape=(1, 3), dtype=float32)
Selected action 2
[0.12, 0.3, 0.25, 0.206, 0.128, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 16 | Average Reward: 44 | Episode Reward: 75 | Loss: 310.377 | Steps: 4 | Worker: 0
Saving best model to ./Training/, episode score: 75.76815348600697
Probs tf.Tensor([[0.33948305 0.32820225 0.3323147 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.15, 0.15, 0.26, 0.202, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.38541836 0.25421923 0.3603624 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.12, 0.3, 0.26, 0.222, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.38122362 0.25295746 0.36581895]], shape=(1, 3), dtype=float32)
Selected action 2
[0.26, 0.3, 0.3, 0.206, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.3812698  0.25163952 0.3670907 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.21, 0.3, 0.27, 0.206, 0.125, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.3811393  0.25248644 0.36637422]], shape=(1, 3), dtype=float32)
Selected action 2
[0.19, 0.3, 0.28, 0.216, 0.125, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 17 | Average Reward: 44 | Episode Reward: 75 | Loss: 343.43 | Steps: 4 | Worker: 0
Saving best model to ./Training/, episode score: 75.9149909927628
Probs tf.Tensor([[0.33878875 0.32729986 0.33391142]], shape=(1, 3), dtype=float32)
Selected action 2
[0.24, 0.3, 0.27, 0.216, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.37737298 0.24908325 0.37354377]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.075, 0.3, 0.169, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.380523   0.25495294 0.364524  ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.07, 0.075, 0.37, 0.192, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.3808773  0.2532571  0.36586562]], shape=(1, 3), dtype=float32)
Selected action 0
[0.06, 0.075, 0.36, 0.168, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.37965405 0.25419977 0.36614615]], shape=(1, 3), dtype=float32)
Selected action 1
[0.08, 0.15, 0.29, 0.175, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 18 | Average Reward: 44 | Episode Reward: 38 | Loss: 67.651 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 38.76582849951863
Probs tf.Tensor([[0.33855864 0.3277799  0.33366147]], shape=(1, 3), dtype=float32)
Selected action 1
[0.08, 0.15, 0.33, 0.227, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.3780581  0.2492141  0.37272784]], shape=(1, 3), dtype=float32)
Selected action 1
[0.13, 0.15, 0.28, 0.133, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.37431416 0.2513759  0.37430996]], shape=(1, 3), dtype=float32)
Selected action 2
[0.22, 0.3, 0.29, 0.255, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.3762658  0.24499737 0.37873685]], shape=(1, 3), dtype=float32)
Selected action 1
[0.13, 0.15, 0.32, 0.253, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.3802818  0.24761912 0.37209907]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.075, 0.32, 0.181, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 19 | Average Reward: 44 | Episode Reward: 51 | Loss: 138.933 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 51.296666006274464
Probs tf.Tensor([[0.33802363 0.3256789  0.3362974 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.08, 0.075, 0.36, 0.123, 0.121, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.37199765 0.2516734  0.37632897]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.3, 0.32, 0.123, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.36345002 0.25026825 0.38628176]], shape=(1, 3), dtype=float32)
Selected action 2
[0.1, 0.3, 0.37, 0.194, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.36767846 0.24602914 0.3862924 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.07, 0.15, 0.34, 0.194, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.37303934 0.24899147 0.37796915]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.3, 0.31, 0.19, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 20 | Average Reward: 44 | Episode Reward: 63 | Loss: 261.58 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 63.87550351303028
Probs tf.Tensor([[0.33724573 0.32220837 0.34054586]], shape=(1, 3), dtype=float32)
Selected action 2
[0.13, 0.3, 0.25, 0.235, 0.129, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.3664499  0.2449758  0.38857433]], shape=(1, 3), dtype=float32)
Selected action 0
[0.11, 0.075, 0.25, 0.178, 0.13, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.37265176 0.24929598 0.37805223]], shape=(1, 3), dtype=float32)
Selected action 2
[0.1, 0.3, 0.25, 0.229, 0.13, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.3657684  0.24567068 0.38856086]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.075, 0.22, 0.135, 0.13, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.3706944  0.2520338  0.37727183]], shape=(1, 3), dtype=float32)
Selected action 0
[0.09, 0.075, 0.3, 0.18, 0.131, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 21 | Average Reward: 44 | Episode Reward: 45 | Loss: 90.151 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 45.24234101978612
Probs tf.Tensor([[0.3360354  0.32724148 0.33672306]], shape=(1, 3), dtype=float32)
Selected action 0
[0.07, 0.075, 0.33, 0.142, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.36665377 0.24886943 0.38447684]], shape=(1, 3), dtype=float32)
Selected action 2
[0.1, 0.3, 0.3, 0.138, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.357165   0.2461989  0.39663613]], shape=(1, 3), dtype=float32)
Selected action 0
[0.1, 0.075, 0.35, 0.188, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.36871094 0.246742   0.38454708]], shape=(1, 3), dtype=float32)
Selected action 0
[0.07, 0.075, 0.32, 0.173, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.36834338 0.24802335 0.38363323]], shape=(1, 3), dtype=float32)
Selected action 0
[0.12, 0.075, 0.38, 0.196, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 22 | Average Reward: 44 | Episode Reward: 32 | Loss: 54.452 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 32.80117852654194
Probs tf.Tensor([[0.33633682 0.3253909  0.33827227]], shape=(1, 3), dtype=float32)
Selected action 2
[0.24, 0.3, 0.27, 0.212, 0.128, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.36027592 0.24003513 0.3996889 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.12, 0.3, 0.26, 0.227, 0.129, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.36084926 0.2413398  0.39781097]], shape=(1, 3), dtype=float32)
Selected action 1
[0.17, 0.15, 0.26, 0.192, 0.13, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.36541814 0.24302673 0.39155513]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.075, 0.32, 0.196, 0.13, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.36758506 0.24564835 0.3867666 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.09, 0.075, 0.29, 0.177, 0.131, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 23 | Average Reward: 44 | Episode Reward: 51 | Loss: 109.677 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 51.69201603329776
Probs tf.Tensor([[0.3358033 0.3244151 0.3397816]], shape=(1, 3), dtype=float32)
Selected action 0
[0.09, 0.075, 0.34, 0.186, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.36577693 0.24307121 0.39115185]], shape=(1, 3), dtype=float32)
Selected action 2
[0.34, 0.3, 0.26, 0.255, 0.125, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.36108086 0.23564932 0.40326986]], shape=(1, 3), dtype=float32)
Selected action 2
[1.36, 0.3, 0.2, 0.0, 0.097, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.373005   0.23396355 0.39303142]], shape=(1, 3), dtype=float32)
Selected action 1
[0.16, 0.15, 0.37, 0.226, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.364396   0.23900609 0.3965979 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.08, 0.075, 0.31, 0.185, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 24 | Average Reward: 44 | Episode Reward: 51 | Loss: 154.322 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 51.79085354005359
Probs tf.Tensor([[0.33616784 0.32312608 0.34070608]], shape=(1, 3), dtype=float32)
Selected action 0
[0.11, 0.075, 0.38, 0.162, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.3624691  0.24127845 0.3962524 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.3, 0.32, 0.171, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.35379922 0.2398853  0.4063155 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.07, 0.075, 0.37, 0.175, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.3631783  0.24175602 0.39506567]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.3, 0.34, 0.194, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.35474342 0.23864833 0.40660825]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.3, 0.36, 0.131, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 25 | Average Reward: 44 | Episode Reward: 58 | Loss: 224.475 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 58.18969104680942
Probs tf.Tensor([[0.33675367 0.3252721  0.33797425]], shape=(1, 3), dtype=float32)
Selected action 0
[0.09, 0.075, 0.35, 0.19, 0.128, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.3626187  0.23840667 0.39897463]], shape=(1, 3), dtype=float32)
Selected action 1
[0.12, 0.15, 0.28, 0.218, 0.129, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.36172044 0.23678716 0.40149245]], shape=(1, 3), dtype=float32)
Selected action 2
[0.23, 0.3, 0.28, 0.208, 0.129, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.3544727  0.2340092  0.41151807]], shape=(1, 3), dtype=float32)
Selected action 0
[0.16, 0.075, 0.33, 0.208, 0.13, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.36395296 0.23668167 0.39936534]], shape=(1, 3), dtype=float32)
Selected action 2
[0.19, 0.3, 0.26, 0.24, 0.131, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 26 | Average Reward: 45 | Episode Reward: 51 | Loss: 176.759 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 51.988528553565246
Probs tf.Tensor([[0.336212   0.32204136 0.34174663]], shape=(1, 3), dtype=float32)
Selected action 2
[0.17, 0.3, 0.25, 0.196, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.35217038 0.23342769 0.4144019 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.09, 0.075, 0.29, 0.208, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.36300117 0.23621364 0.40078518]], shape=(1, 3), dtype=float32)
Selected action 2
[0.17, 0.3, 0.25, 0.167, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.35053772 0.23446146 0.4150008 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.23, 0.3, 0.28, 0.212, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.3527475 0.2315907 0.4156618]], shape=(1, 3), dtype=float32)
Selected action 1
[0.18, 0.15, 0.26, 0.234, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 27 | Average Reward: 45 | Episode Reward: 64 | Loss: 229.871 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 64.73536606032107
Probs tf.Tensor([[0.33659202 0.32001433 0.34339365]], shape=(1, 3), dtype=float32)
Selected action 1
[0.17, 0.15, 0.27, 0.245, 0.13, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.35886165 0.23074415 0.4103942 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.08, 0.15, 0.24, 0.204, 0.131, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.3576151  0.23390733 0.40847751]], shape=(1, 3), dtype=float32)
Selected action 0
[0.09, 0.075, 0.32, 0.128, 0.133, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.35605502 0.23606758 0.40787745]], shape=(1, 3), dtype=float32)
Selected action 2
[0.27, 0.3, 0.27, 0.207, 0.133, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.34977344 0.22932853 0.420898  ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.16, 0.15, 0.25, 0.224, 0.133, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 28 | Average Reward: 45 | Episode Reward: 52 | Loss: 157.571 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 52.1862035670769
Probs tf.Tensor([[0.3361023  0.3213563  0.34254137]], shape=(1, 3), dtype=float32)
Selected action 1
[0.16, 0.15, 0.31, 0.204, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.35383087 0.23088072 0.41528845]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.075, 0.31, 0.192, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.35712436 0.23428154 0.40859407]], shape=(1, 3), dtype=float32)
Selected action 2
[0.19, 0.3, 0.2, 0.259, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.35081378 0.22946121 0.419725  ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.12, 0.15, 0.32, 0.192, 0.125, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.35316455 0.23172848 0.41510692]], shape=(1, 3), dtype=float32)
Selected action 2
[0.14, 0.3, 0.31, 0.232, 0.125, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 29 | Average Reward: 45 | Episode Reward: 58 | Loss: 215.726 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 58.63304107383273
Probs tf.Tensor([[0.3365124 0.3186963 0.3447913]], shape=(1, 3), dtype=float32)
Selected action 2
[0.24, 0.3, 0.2, 0.232, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.34618166 0.22973034 0.42408803]], shape=(1, 3), dtype=float32)
Selected action 0
[0.08, 0.075, 0.35, 0.169, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.35229623 0.23336636 0.41433746]], shape=(1, 3), dtype=float32)
Selected action 2
[0.25, 0.3, 0.16, 0.258, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.34773833 0.22979052 0.42247114]], shape=(1, 3), dtype=float32)
Selected action 0
[0.09, 0.075, 0.33, 0.154, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.35204184 0.23389481 0.41406336]], shape=(1, 3), dtype=float32)
Selected action 0
[0.1, 0.075, 0.33, 0.188, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 30 | Average Reward: 45 | Episode Reward: 46 | Loss: 92.539 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 46.02387858058856
Probs tf.Tensor([[0.3355309  0.3200944  0.34437466]], shape=(1, 3), dtype=float32)
Selected action 0
[0.07, 0.075, 0.36, 0.145, 0.121, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.34947658 0.2330588  0.4174646 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.07, 0.075, 0.35, 0.194, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.35191903 0.23167686 0.41640407]], shape=(1, 3), dtype=float32)
Selected action 0
[0.51, 0.075, 0.3, 0.187, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.35164967 0.22894008 0.41941023]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.3, 0.36, 0.142, 0.125, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.33950555 0.23068358 0.42981085]], shape=(1, 3), dtype=float32)
Selected action 0
[0.06, 0.075, 0.31, 0.116, 0.125, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 31 | Average Reward: 45 | Episode Reward: 33 | Loss: 76.257 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 33.366716087344386
Probs tf.Tensor([[0.33529934 0.31827518 0.34642547]], shape=(1, 3), dtype=float32)
Selected action 2
[0.26, 0.3, 0.27, 0.231, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.34341547 0.2259568  0.43062767]], shape=(1, 3), dtype=float32)
Selected action 2
[0.29, 0.3, 0.21, 0.26, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.34496439 0.2260723  0.42896333]], shape=(1, 3), dtype=float32)
Selected action 0
[0.2, 0.3, 0.21, 0.246, 0.125, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.34508464 0.22731146 0.42760393]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.3, 0.24, 0.21, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.34396076 0.23030184 0.42573735]], shape=(1, 3), dtype=float32)
Selected action 0
[0.12, 0.075, 0.27, 0.165, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 32 | Average Reward: 45 | Episode Reward: 58 | Loss: 157.318 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 58.96555359410022
Probs tf.Tensor([[0.33584896 0.3201792  0.34397185]], shape=(1, 3), dtype=float32)
Selected action 1
[0.13, 0.15, 0.25, 0.212, 0.127, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.3505568  0.22673523 0.422708  ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.15, 0.3, 0.25, 0.235, 0.128, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.34455615 0.22508983 0.430354  ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.14, 0.15, 0.28, 0.185, 0.128, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.34871176 0.2268806  0.4244076 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.12, 0.3, 0.24, 0.238, 0.128, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.34493166 0.2256746  0.4293937 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.09, 0.075, 0.29, 0.14, 0.129, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 33 | Average Reward: 45 | Episode Reward: 59 | Loss: 181.53 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 59.07639110085604
Probs tf.Tensor([[0.33644244 0.32012647 0.34343106]], shape=(1, 3), dtype=float32)
Selected action 2
[0.21, 0.3, 0.2, 0.224, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.34400576 0.22453487 0.4314593 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.25, 0.3, 0.2, 0.26, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.34532943 0.22287267 0.43179786]], shape=(1, 3), dtype=float32)
Selected action 2
[0.12, 0.3, 0.24, 0.192, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.3425355  0.22553854 0.431926  ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.17, 0.3, 0.25, 0.21, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.34307626 0.22411674 0.432807  ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.15, 0.3, 0.26, 0.25, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 34 | Average Reward: 46 | Episode Reward: 84 | Loss: 386.714 | Steps: 4 | Worker: 0
Saving best model to ./Training/, episode score: 84.81922860761188
Probs tf.Tensor([[0.3357698  0.31740022 0.34683   ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.07, 0.075, 0.26, 0.185, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.35108998 0.22498345 0.42392656]], shape=(1, 3), dtype=float32)
Selected action 1
[0.12, 0.15, 0.35, 0.26, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.34835312 0.21985085 0.43179604]], shape=(1, 3), dtype=float32)
Selected action 0
[0.11, 0.075, 0.42, 0.182, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.3472457  0.22227623 0.4304781 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.15, 0.3, 0.26, 0.24, 0.125, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.3421043  0.22031403 0.43758172]], shape=(1, 3), dtype=float32)
Selected action 1
[0.12, 0.15, 0.32, 0.231, 0.125, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 35 | Average Reward: 46 | Episode Reward: 46 | Loss: 144.692 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 46.458066114367696
Probs tf.Tensor([[0.33524576 0.3197455  0.34500876]], shape=(1, 3), dtype=float32)
Selected action 2
[0.2, 0.3, 0.25, 0.228, 0.125, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.33891195 0.21871327 0.4423748 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.17, 0.15, 0.34, 0.253, 0.126, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.3454139  0.21770842 0.43687767]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.075, 0.32, 0.134, 0.127, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.34520772 0.22471532 0.43007696]], shape=(1, 3), dtype=float32)
Selected action 0
[0.02, 0.075, 0.31, 0.127, 0.128, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.34540516 0.22557135 0.4290235 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.25, 0.3, 0.28, 0.252, 0.128, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 36 | Average Reward: 46 | Episode Reward: 52 | Loss: 135.826 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 52.976903621123526
Probs tf.Tensor([[0.33583337 0.31719738 0.34696928]], shape=(1, 3), dtype=float32)
Selected action 2
[0.22, 0.3, 0.27, 0.245, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.33759043 0.2161777  0.4462319 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.06, 0.075, 0.33, 0.186, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.34578252 0.22084297 0.43337452]], shape=(1, 3), dtype=float32)
Selected action 1
[0.14, 0.15, 0.26, 0.185, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.34274203 0.21976246 0.4374955 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.1, 0.075, 0.33, 0.196, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.34588948 0.21985492 0.43425563]], shape=(1, 3), dtype=float32)
Selected action 0
[0.14, 0.075, 0.32, 0.2, 0.125, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 37 | Average Reward: 46 | Episode Reward: 40 | Loss: 65.633 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 40.18774112787935
Probs tf.Tensor([[0.33462894 0.31601173 0.34935936]], shape=(1, 3), dtype=float32)
Selected action 1
[0.14, 0.15, 0.28, 0.164, 0.121, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.34091955 0.21892068 0.44015983]], shape=(1, 3), dtype=float32)
Selected action 1
[0.14, 0.15, 0.26, 0.212, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.3433408  0.21781217 0.438847  ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.12, 0.3, 0.21, 0.149, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.3339641  0.22120045 0.4448354 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.06, 0.075, 0.3, 0.18, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.34573781 0.2203205  0.43394172]], shape=(1, 3), dtype=float32)
Selected action 1
[0.17, 0.15, 0.26, 0.226, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 38 | Average Reward: 46 | Episode Reward: 53 | Loss: 149.184 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 53.174578634635175
Probs tf.Tensor([[0.3355631  0.31729198 0.3471449 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.13, 0.075, 0.29, 0.192, 0.127, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.34485042 0.21856445 0.43658513]], shape=(1, 3), dtype=float32)
Selected action 1
[0.15, 0.15, 0.26, 0.224, 0.128, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.3427661  0.21712503 0.44010887]], shape=(1, 3), dtype=float32)
Selected action 0
[0.09, 0.075, 0.3, 0.148, 0.128, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.34305134 0.22059634 0.4363523 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.1, 0.15, 0.25, 0.225, 0.129, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.34339473 0.21808447 0.4385208 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.15, 0.3, 0.26, 0.214, 0.129, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 39 | Average Reward: 46 | Episode Reward: 46 | Loss: 150.503 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 46.80541614139101
Probs tf.Tensor([[0.33429036 0.3161127  0.34959695]], shape=(1, 3), dtype=float32)
Selected action 1
[0.1, 0.15, 0.23, 0.192, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.3416166  0.22023852 0.4381449 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.1, 0.075, 0.3, 0.135, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.34155074 0.22170147 0.43674776]], shape=(1, 3), dtype=float32)
Selected action 1
[0.17, 0.15, 0.29, 0.163, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.33851913 0.21899259 0.44248828]], shape=(1, 3), dtype=float32)
Selected action 2
[0.13, 0.3, 0.19, 0.261, 0.125, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.33745232 0.21801016 0.44453752]], shape=(1, 3), dtype=float32)
Selected action 0
[0.07, 0.075, 0.34, 0.188, 0.125, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 40 | Average Reward: 46 | Episode Reward: 46 | Loss: 124.157 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 46.892253648146834
Probs tf.Tensor([[0.33502865 0.314765   0.35020635]], shape=(1, 3), dtype=float32)
Selected action 0
[0.09, 0.075, 0.37, 0.169, 0.125, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.34117767 0.22053768 0.43828467]], shape=(1, 3), dtype=float32)
Selected action 2
[0.27, 0.3, 0.26, 0.264, 0.127, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.33459502 0.2154869  0.44991812]], shape=(1, 3), dtype=float32)
Selected action 1
[0.17, 0.15, 0.35, 0.255, 0.128, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.34068975 0.21619616 0.44311413]], shape=(1, 3), dtype=float32)
Selected action 0
[0.08, 0.075, 0.36, 0.124, 0.128, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.33938938 0.22242387 0.43818682]], shape=(1, 3), dtype=float32)
Selected action 0
[0.09, 0.075, 0.37, 0.176, 0.128, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 41 | Average Reward: 46 | Episode Reward: 40 | Loss: 85.028 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 40.487091154902664
Probs tf.Tensor([[0.33485878 0.31724194 0.34789926]], shape=(1, 3), dtype=float32)
Selected action 1
[0.16, 0.15, 0.3, 0.245, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.3416658  0.21833488 0.43999937]], shape=(1, 3), dtype=float32)
Selected action 0
[0.09, 0.075, 0.36, 0.179, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.34198236 0.22118331 0.4368343 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.11, 0.075, 0.34, 0.178, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.34214976 0.22114238 0.43670782]], shape=(1, 3), dtype=float32)
Selected action 1
[0.17, 0.15, 0.3, 0.167, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.3382165  0.22041331 0.4413701 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.09, 0.075, 0.38, 0.19, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 42 | Average Reward: 45 | Episode Reward: 34 | Loss: 57.863 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 34.05792866165849
Probs tf.Tensor([[0.33422944 0.3149537  0.35081682]], shape=(1, 3), dtype=float32)
Selected action 1
[0.15, 0.15, 0.28, 0.187, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.34060434 0.22123876 0.43815687]], shape=(1, 3), dtype=float32)
Selected action 0
[0.07, 0.075, 0.34, 0.186, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.34373355 0.22246552 0.43380094]], shape=(1, 3), dtype=float32)
Selected action 2
[0.25, 0.3, 0.21, 0.24, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.33546057 0.2194427  0.44509673]], shape=(1, 3), dtype=float32)
Selected action 2
[0.15, 0.3, 0.25, 0.258, 0.126, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.3370503  0.21894841 0.4440013 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.07, 0.15, 0.21, 0.15, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 43 | Average Reward: 46 | Episode Reward: 60 | Loss: 220.635 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 60.18476616841431
Probs tf.Tensor([[0.3345859  0.31894314 0.3464709 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.075, 0.21, 0.161, 0.121, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.34645563 0.22731033 0.42623404]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.3, 0.3, 0.215, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.33643234 0.22171447 0.44185323]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.3, 0.33, 0.206, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.33542296 0.2209964  0.44358066]], shape=(1, 3), dtype=float32)
Selected action 1
[0.04, 0.15, 0.27, 0.115, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.339549   0.22678718 0.43366385]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.3, 0.31, 0.171, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 44 | Average Reward: 46 | Episode Reward: 66 | Loss: 280.876 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 66.82360367517015
Probs tf.Tensor([[0.33484122 0.31849387 0.34666494]], shape=(1, 3), dtype=float32)
Selected action 0
[0.06, 0.075, 0.3, 0.141, 0.126, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.34187266 0.22689486 0.4312325 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.13, 0.3, 0.26, 0.21, 0.127, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.33428207 0.22269978 0.4430181 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.08, 0.15, 0.22, 0.185, 0.128, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.34145948 0.22556552 0.43297502]], shape=(1, 3), dtype=float32)
Selected action 2
[0.15, 0.3, 0.25, 0.16, 0.128, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.33186328 0.22465941 0.4434773 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.24, 0.3, 0.27, 0.252, 0.129, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 45 | Average Reward: 46 | Episode Reward: 66 | Loss: 291.314 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 66.94644118192596
Probs tf.Tensor([[0.33488643 0.3191801  0.3459335 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.09, 0.3, 0.23, 0.185, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.3317173  0.22591    0.44237274]], shape=(1, 3), dtype=float32)
Selected action 1
[0.18, 0.15, 0.33, 0.23, 0.125, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.3378371 0.2221082 0.4400547]], shape=(1, 3), dtype=float32)
Selected action 0
[0.08, 0.075, 0.38, 0.129, 0.126, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.33702376 0.22669064 0.4362856 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.23, 0.3, 0.28, 0.257, 0.126, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.3321325  0.22090927 0.44695824]], shape=(1, 3), dtype=float32)
Selected action 2
[0.11, 0.3, 0.25, 0.252, 0.129, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 46 | Average Reward: 46 | Episode Reward: 67 | Loss: 243.365 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 67.0692786886818
Probs tf.Tensor([[0.334454   0.31938046 0.34616557]], shape=(1, 3), dtype=float32)
Selected action 1
[0.13, 0.15, 0.31, 0.208, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.3352465  0.22441946 0.44033408]], shape=(1, 3), dtype=float32)
Selected action 2
[0.24, 0.3, 0.28, 0.244, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.3285831 0.222261  0.449156 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.4, 0.3, 0.27, 0.25, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.3269722  0.22109437 0.45193335]], shape=(1, 3), dtype=float32)
Selected action 0
[0.09, 0.075, 0.31, 0.175, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.33789825 0.22678149 0.4353202 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.26, 0.3, 0.28, 0.263, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 47 | Average Reward: 46 | Episode Reward: 67 | Loss: 242.5 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 67.19211619543763
Probs tf.Tensor([[0.33332473 0.31713966 0.34953558]], shape=(1, 3), dtype=float32)
Selected action 0
[0.1, 0.075, 0.36, 0.198, 0.127, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.33492526 0.22503726 0.4400375 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.32, 0.3, 0.28, 0.244, 0.129, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.324522   0.22131565 0.45416233]], shape=(1, 3), dtype=float32)
Selected action 1
[0.15, 0.15, 0.31, 0.217, 0.129, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.33238214 0.22382429 0.4437935 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.06, 0.075, 0.32, 0.183, 0.13, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.3352992  0.2266647  0.43803608]], shape=(1, 3), dtype=float32)
Selected action 2
[0.24, 0.3, 0.27, 0.253, 0.13, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 48 | Average Reward: 46 | Episode Reward: 54 | Loss: 176.572 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 54.16295370219345
Probs tf.Tensor([[0.3340116  0.32027563 0.3457128 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.23, 0.3, 0.19, 0.249, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.3244264  0.22456531 0.45100823]], shape=(1, 3), dtype=float32)
Selected action 2
[0.29, 0.3, 0.21, 0.245, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.32315654 0.22344466 0.45339882]], shape=(1, 3), dtype=float32)
Selected action 2
[0.16, 0.3, 0.25, 0.222, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.3235781  0.2246394  0.45178255]], shape=(1, 3), dtype=float32)
Selected action 0
[0.07, 0.075, 0.32, 0.134, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.33068815 0.22819509 0.44111675]], shape=(1, 3), dtype=float32)
Selected action 2
[0.14, 0.3, 0.25, 0.204, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 49 | Average Reward: 47 | Episode Reward: 74 | Loss: 266.801 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 74.02579120894929
Probs tf.Tensor([[0.33342323 0.31982297 0.34675378]], shape=(1, 3), dtype=float32)
Selected action 2
[0.29, 0.3, 0.2, 0.225, 0.121, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.31954476 0.22332676 0.45712847]], shape=(1, 3), dtype=float32)
Selected action 0
[0.07, 0.075, 0.34, 0.172, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.3289515  0.22548182 0.4455667 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.1, 0.075, 0.31, 0.178, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.32959273 0.22521764 0.4451896 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.11, 0.075, 0.29, 0.138, 0.125, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.3281903  0.2267322  0.44507745]], shape=(1, 3), dtype=float32)
Selected action 2
[0.27, 0.3, 0.17, 0.255, 0.125, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 50 | Average Reward: 47 | Episode Reward: 47 | Loss: 113.146 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 47.76062871570511
Probs tf.Tensor([[0.33444068 0.32056    0.34499934]], shape=(1, 3), dtype=float32)
Selected action 2
[0.14, 0.3, 0.26, 0.244, 0.125, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.32010952 0.22137418 0.4585163 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.22, 0.15, 0.25, 0.249, 0.127, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.32661858 0.22058035 0.4528011 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.27, 0.3, 0.27, 0.2, 0.128, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.31605008 0.22086135 0.46308863]], shape=(1, 3), dtype=float32)
Selected action 0
[0.03, 0.075, 0.29, 0.179, 0.128, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.32938397 0.22512536 0.44549063]], shape=(1, 3), dtype=float32)
Selected action 0
[0.06, 0.075, 0.29, 0.185, 0.129, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 51 | Average Reward: 47 | Episode Reward: 54 | Loss: 125.99 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 54.45946622246093
Probs tf.Tensor([[0.33365896 0.3170541  0.3492869 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.13, 0.15, 0.33, 0.188, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.3232157  0.2205473  0.45623696]], shape=(1, 3), dtype=float32)
Selected action 2
[0.13, 0.3, 0.33, 0.233, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.3180749  0.2189972  0.46292785]], shape=(1, 3), dtype=float32)
Selected action 1
[0.16, 0.15, 0.28, 0.188, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.32363954 0.22102793 0.45533255]], shape=(1, 3), dtype=float32)
Selected action 1
[0.16, 0.15, 0.31, 0.212, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.3241336  0.21978302 0.45608336]], shape=(1, 3), dtype=float32)
Selected action 2
[0.12, 0.3, 0.27, 0.226, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 52 | Average Reward: 47 | Episode Reward: 67 | Loss: 255.595 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 67.80630372921675
Probs tf.Tensor([[0.33385602 0.31670547 0.34943855]], shape=(1, 3), dtype=float32)
Selected action 2
[0.33, 0.3, 0.28, 0.241, 0.121, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.31398958 0.21743086 0.46857953]], shape=(1, 3), dtype=float32)
Selected action 2
[0.27, 0.3, 0.26, 0.269, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.3161001  0.21771085 0.46618903]], shape=(1, 3), dtype=float32)
Selected action 2
[0.32, 0.3, 0.29, 0.255, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.31444487 0.21687503 0.46868005]], shape=(1, 3), dtype=float32)
Selected action 2
[0.18, 0.3, 0.25, 0.215, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.31548128 0.22085358 0.46366516]], shape=(1, 3), dtype=float32)
Selected action 0
[0.08, 0.075, 0.31, 0.165, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 53 | Average Reward: 47 | Episode Reward: 74 | Loss: 263.623 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 74.5651412359726
Probs tf.Tensor([[0.33297265 0.31637323 0.35065416]], shape=(1, 3), dtype=float32)
Selected action 0
[0.08, 0.075, 0.32, 0.182, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.32295692 0.22122197 0.45582107]], shape=(1, 3), dtype=float32)
Selected action 1
[0.08, 0.15, 0.32, 0.18, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.3192041  0.22083013 0.4599658 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.3, 0.34, 0.131, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.3105381  0.22243413 0.46702772]], shape=(1, 3), dtype=float32)
Selected action 2
[0.1, 0.3, 0.32, 0.119, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.31006572 0.22296727 0.46696705]], shape=(1, 3), dtype=float32)
Selected action 2
[0.1, 0.3, 0.32, 0.182, 0.125, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 54 | Average Reward: 47 | Episode Reward: 68 | Loss: 314.042 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 68.05197874272842
Probs tf.Tensor([[0.33181265 0.31816784 0.3500195 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.14, 0.3, 0.24, 0.177, 0.128, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.3088986  0.22099623 0.4701052 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.15, 0.15, 0.25, 0.204, 0.129, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.31647888 0.21932843 0.4641927 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.2, 0.15, 0.26, 0.2, 0.13, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.3154021  0.21859913 0.46599877]], shape=(1, 3), dtype=float32)
Selected action 0
[0.07, 0.075, 0.27, 0.176, 0.13, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.32035795 0.22139446 0.45824763]], shape=(1, 3), dtype=float32)
Selected action 2
[0.1, 0.3, 0.23, 0.2, 0.13, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 55 | Average Reward: 48 | Episode Reward: 61 | Loss: 185.107 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 61.51481624948425
Probs tf.Tensor([[0.3304137  0.31734127 0.35224503]], shape=(1, 3), dtype=float32)
Selected action 0
[0.06, 0.075, 0.31, 0.15, 0.121, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.3156349  0.22196952 0.46239555]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.3, 0.28, 0.179, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.306679   0.22163743 0.4716835 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.13, 0.3, 0.3, 0.137, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.3035696  0.22135292 0.47507745]], shape=(1, 3), dtype=float32)
Selected action 0
[0.06, 0.075, 0.31, 0.159, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.31586492 0.22160257 0.46253252]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.075, 0.29, 0.144, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 56 | Average Reward: 48 | Episode Reward: 48 | Loss: 122.903 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 48.281653756240075
Probs tf.Tensor([[0.33096668 0.3168762  0.35215715]], shape=(1, 3), dtype=float32)
Selected action 0
[0.09, 0.075, 0.34, 0.179, 0.127, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.31277546 0.21935971 0.4678649 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.09, 0.075, 0.31, 0.165, 0.128, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.31292626 0.2202968  0.46677694]], shape=(1, 3), dtype=float32)
Selected action 1
[0.23, 0.15, 0.27, 0.166, 0.129, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.30746153 0.21876015 0.47377837]], shape=(1, 3), dtype=float32)
Selected action 0
[0.09, 0.075, 0.37, 0.19, 0.13, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.31232458 0.21852422 0.46915114]], shape=(1, 3), dtype=float32)
Selected action 2
[0.31, 0.3, 0.29, 0.24, 0.13, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 57 | Average Reward: 48 | Episode Reward: 41 | Loss: 121.002 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 41.684491262995905
Probs tf.Tensor([[0.33055896 0.31541803 0.35402304]], shape=(1, 3), dtype=float32)
Selected action 0
[0.08, 0.075, 0.35, 0.194, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.3117526  0.21862873 0.46961874]], shape=(1, 3), dtype=float32)
Selected action 1
[0.07, 0.15, 0.28, 0.22, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.3104916  0.21900585 0.47050256]], shape=(1, 3), dtype=float32)
Selected action 0
[0.08, 0.075, 0.33, 0.176, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.3115961  0.2194849  0.46891904]], shape=(1, 3), dtype=float32)
Selected action 2
[0.26, 0.3, 0.27, 0.223, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.30020252 0.21595043 0.48384708]], shape=(1, 3), dtype=float32)
Selected action 2
[0.26, 0.3, 0.27, 0.251, 0.125, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 58 | Average Reward: 48 | Episode Reward: 55 | Loss: 210.648 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 55.15132876975173
Probs tf.Tensor([[0.33052522 0.3154536  0.3540212 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.16, 0.15, 0.33, 0.224, 0.127, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.30628675 0.21615176 0.47756147]], shape=(1, 3), dtype=float32)
Selected action 0
[0.07, 0.075, 0.36, 0.202, 0.128, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.31021553 0.21801451 0.47176993]], shape=(1, 3), dtype=float32)
Selected action 1
[0.14, 0.15, 0.31, 0.241, 0.13, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.30756247 0.21624427 0.4761933 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.07, 0.075, 0.32, 0.161, 0.13, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.3098099  0.21997787 0.47021225]], shape=(1, 3), dtype=float32)
Selected action 2
[0.26, 0.3, 0.26, 0.238, 0.13, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 59 | Average Reward: 48 | Episode Reward: 48 | Loss: 136.527 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 48.542166276507544
Probs tf.Tensor([[0.33199766 0.31340504 0.35459727]], shape=(1, 3), dtype=float32)
Selected action 1
[0.05, 0.15, 0.23, 0.188, 0.126, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.3084824  0.22120424 0.47031337]], shape=(1, 3), dtype=float32)
Selected action 2
[0.01, 0.3, 0.16, 0.115, 0.127, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.30217913 0.22549716 0.47232366]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.075, 0.32, 0.14, 0.128, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.3090031  0.22138946 0.46960744]], shape=(1, 3), dtype=float32)
Selected action 1
[0.18, 0.15, 0.27, 0.178, 0.129, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.3047366  0.21831547 0.4769478 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.3, 0.19, 0.175, 0.129, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 60 | Average Reward: 48 | Episode Reward: 62 | Loss: 209.9 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 62.06900378326338
Probs tf.Tensor([[0.3301733  0.31559128 0.35423535]], shape=(1, 3), dtype=float32)
Selected action 2
[0.21, 0.3, 0.28, 0.246, 0.13, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.2979238 0.2155268 0.4865494]], shape=(1, 3), dtype=float32)
Selected action 1
[0.2, 0.15, 0.24, 0.234, 0.131, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.30604196 0.21714565 0.4768124 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.17, 0.3, 0.26, 0.176, 0.132, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.29700798 0.21905906 0.48393294]], shape=(1, 3), dtype=float32)
Selected action 2
[0.17, 0.3, 0.25, 0.227, 0.132, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.2987069  0.21761163 0.4836815 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.19, 0.3, 0.26, 0.231, 0.133, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 61 | Average Reward: 48 | Episode Reward: 82 | Loss: 369.643 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 82.3758412900192
Probs tf.Tensor([[0.33151463 0.31743488 0.35105047]], shape=(1, 3), dtype=float32)
Selected action 0
[0.13, 0.075, 0.33, 0.164, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.3045976  0.21933196 0.47607046]], shape=(1, 3), dtype=float32)
Selected action 0
[0.07, 0.075, 0.25, 0.184, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.3082856  0.22106133 0.4706531 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.33, 0.3, 0.28, 0.254, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.29407007 0.21333401 0.49259597]], shape=(1, 3), dtype=float32)
Selected action 2
[0.28, 0.3, 0.28, 0.233, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.2940901  0.21473637 0.49117345]], shape=(1, 3), dtype=float32)
Selected action 2
[0.09, 0.3, 0.24, 0.202, 0.125, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 62 | Average Reward: 48 | Episode Reward: 62 | Loss: 278.411 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 62.29067879677504
Probs tf.Tensor([[0.33016655 0.3137431  0.35609034]], shape=(1, 3), dtype=float32)
Selected action 0
[0.06, 0.075, 0.33, 0.172, 0.121, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.30374599 0.2193274  0.47692668]], shape=(1, 3), dtype=float32)
Selected action 1
[0.1, 0.15, 0.38, 0.2, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.29872924 0.21636713 0.48490363]], shape=(1, 3), dtype=float32)
Selected action 0
[0.08, 0.075, 0.38, 0.163, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.3017238  0.21855152 0.4797247 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.08, 0.075, 0.37, 0.149, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.30149275 0.21918178 0.47932547]], shape=(1, 3), dtype=float32)
Selected action 0
[0.07, 0.075, 0.36, 0.151, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 63 | Average Reward: 48 | Episode Reward: 28 | Loss: 40.761 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 28.621516303530864
Probs tf.Tensor([[0.33049795 0.31432876 0.35517332]], shape=(1, 3), dtype=float32)
Selected action 0
[0.06, 0.075, 0.38, 0.218, 0.125, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.30220258 0.2161937  0.4816037 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.26, 0.3, 0.27, 0.251, 0.126, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.29052398 0.2126473  0.49682876]], shape=(1, 3), dtype=float32)
Selected action 2
[0.32, 0.3, 0.26, 0.206, 0.127, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.28858134 0.21315111 0.49826753]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.075, 0.31, 0.167, 0.128, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.30267432 0.21909489 0.47823077]], shape=(1, 3), dtype=float32)
Selected action 2
[0.27, 0.3, 0.28, 0.264, 0.128, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 64 | Average Reward: 48 | Episode Reward: 62 | Loss: 231.561 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 62.5123538102867
Probs tf.Tensor([[0.33006454 0.31370568 0.35622978]], shape=(1, 3), dtype=float32)
Selected action 2
[0.24, 0.3, 0.29, 0.25, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.28863055 0.21076837 0.5006011 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.1, 0.3, 0.24, 0.236, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.29246446 0.21528608 0.49224946]], shape=(1, 3), dtype=float32)
Selected action 2
[0.19, 0.3, 0.26, 0.248, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.29018053 0.2125775  0.497242  ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.11, 0.3, 0.25, 0.204, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.29123452 0.21592657 0.49283883]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.3, 0.24, 0.202, 0.125, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 65 | Average Reward: 49 | Episode Reward: 89 | Loss: 422.31 | Steps: 4 | Worker: 0
Saving best model to ./Training/, episode score: 89.7431913170425
Probs tf.Tensor([[0.3312896  0.31244153 0.35626885]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.075, 0.25, 0.16, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.29975566 0.21610378 0.48414057]], shape=(1, 3), dtype=float32)
Selected action 2
[0.17, 0.3, 0.22, 0.154, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.28587642 0.21405396 0.5000696 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.3, 0.27, 0.198, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.28817934 0.21328764 0.49853304]], shape=(1, 3), dtype=float32)
Selected action 0
[0.09, 0.075, 0.35, 0.127, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.295028   0.21478713 0.49018487]], shape=(1, 3), dtype=float32)
Selected action 0
[0.1, 0.075, 0.29, 0.135, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 66 | Average Reward: 49 | Episode Reward: 49 | Loss: 126.019 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 49.15002882379835
Probs tf.Tensor([[0.33138004 0.3115509  0.35706908]], shape=(1, 3), dtype=float32)
Selected action 2
[0.41, 0.3, 0.22, 0.265, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.28224373 0.20245285 0.51530343]], shape=(1, 3), dtype=float32)
Selected action 2
[0.32, 0.3, 0.21, 0.26, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.28376606 0.20394923 0.5122847 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.15, 0.3, 0.23, 0.157, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.2838653  0.21066342 0.5054713 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.12, 0.075, 0.32, 0.149, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.29347378 0.21068022 0.49584597]], shape=(1, 3), dtype=float32)
Selected action 2
[0.15, 0.3, 0.24, 0.24, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 67 | Average Reward: 49 | Episode Reward: 76 | Loss: 279.584 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 76.45286633055416
Probs tf.Tensor([[0.32971755 0.30778977 0.36249268]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.075, 0.32, 0.186, 0.127, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.29360974 0.20699373 0.4993965 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.2, 0.3, 0.26, 0.245, 0.128, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.2809518  0.20152588 0.5175223 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.07, 0.075, 0.32, 0.133, 0.129, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.2915983  0.20851825 0.49988344]], shape=(1, 3), dtype=float32)
Selected action 2
[0.17, 0.3, 0.25, 0.208, 0.129, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.28117934 0.20375574 0.51506495]], shape=(1, 3), dtype=float32)
Selected action 1
[0.31, 0.15, 0.31, 0.233, 0.127, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 68 | Average Reward: 49 | Episode Reward: 56 | Loss: 189.536 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 56.13970383731001
Probs tf.Tensor([[0.33030006 0.3098043  0.35989562]], shape=(1, 3), dtype=float32)
Selected action 0
[0.09, 0.075, 0.36, 0.12, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.28764784 0.20478074 0.5075714 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.09, 0.3, 0.37, 0.15, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.27683398 0.2015596  0.52160645]], shape=(1, 3), dtype=float32)
Selected action 0
[0.06, 0.075, 0.35, 0.171, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.28989497 0.20360605 0.506499  ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.13, 0.3, 0.37, 0.214, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.27697784 0.19791001 0.52511215]], shape=(1, 3), dtype=float32)
Selected action 0
[0.1, 0.075, 0.37, 0.15, 0.125, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 69 | Average Reward: 49 | Episode Reward: 49 | Loss: 136.091 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 49.41054134406582
Probs tf.Tensor([[0.3315782  0.3074837  0.36093807]], shape=(1, 3), dtype=float32)
Selected action 0
[0.09, 0.075, 0.34, 0.158, 0.121, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.28771245 0.20013323 0.51215434]], shape=(1, 3), dtype=float32)
Selected action 1
[0.17, 0.15, 0.33, 0.165, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.2818501  0.19716065 0.5209893 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.075, 0.35, 0.192, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.2892024  0.19951941 0.5112782 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.3, 0.35, 0.182, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.27700412 0.19754222 0.5254537 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.3, 0.35, 0.124, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 70 | Average Reward: 49 | Episode Reward: 56 | Loss: 216.909 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 56.33737885082165
Probs tf.Tensor([[0.3323174  0.30597597 0.36170658]], shape=(1, 3), dtype=float32)
Selected action 1
[0.2, 0.15, 0.27, 0.235, 0.128, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.28305462 0.19223052 0.5247148 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.15, 0.3, 0.25, 0.206, 0.129, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.27653477 0.19382744 0.5296378 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.12, 0.15, 0.26, 0.173, 0.13, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.28383186 0.1962901  0.5198781 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.18, 0.3, 0.27, 0.224, 0.131, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.27535632 0.19181533 0.53282833]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.3, 0.19, 0.159, 0.131, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 71 | Average Reward: 49 | Episode Reward: 76 | Loss: 336.435 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 76.99221635757748
Probs tf.Tensor([[0.332375   0.30639887 0.3612261 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.21, 0.3, 0.22, 0.262, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.27419707 0.18869962 0.5371033 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.15, 0.15, 0.3, 0.202, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.2800913 0.1912657 0.528643 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.54, 0.3, 0.26, 0.258, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.26760602 0.18161637 0.5507776 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.06, 0.075, 0.27, 0.13, 0.121, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.2860113  0.19785243 0.5161363 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.3, 0.31, 0.184, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 72 | Average Reward: 49 | Episode Reward: 70 | Loss: 242.083 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 70.2630538643333
Probs tf.Tensor([[0.3308642 0.3033181 0.3658177]], shape=(1, 3), dtype=float32)
Selected action 1
[0.15, 0.15, 0.28, 0.174, 0.121, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.27775243 0.19062492 0.53162265]], shape=(1, 3), dtype=float32)
Selected action 0
[0.1, 0.075, 0.32, 0.185, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.28208223 0.19161701 0.5263007 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.12, 0.15, 0.26, 0.192, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.27940932 0.191266   0.5293247 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.44, 0.3, 0.27, 0.229, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.2652453  0.18047568 0.554279  ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.15, 0.3, 0.29, 0.231, 0.125, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 73 | Average Reward: 50 | Episode Reward: 63 | Loss: 253.24 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 63.50989137108913
Probs tf.Tensor([[0.3315487  0.30512387 0.3633274 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.23, 0.15, 0.27, 0.268, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.27540663 0.18439953 0.54019386]], shape=(1, 3), dtype=float32)
Selected action 2
[0.18, 0.3, 0.32, 0.255, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.26689413 0.18309925 0.5500066 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.14, 0.15, 0.32, 0.236, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.27543196 0.18632285 0.5382452 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.24, 0.3, 0.29, 0.277, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.26632106 0.1815885  0.5520904 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.06, 0.075, 0.29, 0.2, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 74 | Average Reward: 50 | Episode Reward: 63 | Loss: 202.416 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 63.620728877844954
Probs tf.Tensor([[0.33222142 0.30491346 0.3628651 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.13, 0.15, 0.28, 0.214, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.27444592 0.187302   0.53825206]], shape=(1, 3), dtype=float32)
Selected action 0
[0.12, 0.075, 0.37, 0.187, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.275396   0.1877033  0.53690076]], shape=(1, 3), dtype=float32)
Selected action 2
[0.42, 0.3, 0.26, 0.256, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.26153955 0.17722116 0.5612393 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.19, 0.3, 0.28, 0.154, 0.125, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.2640822  0.18653105 0.54938674]], shape=(1, 3), dtype=float32)
Selected action 0
[0.08, 0.075, 0.37, 0.211, 0.125, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 75 | Average Reward: 50 | Episode Reward: 56 | Loss: 177.88 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 56.83156638460079
Probs tf.Tensor([[0.33170864 0.30334392 0.36494747]], shape=(1, 3), dtype=float32)
Selected action 0
[0.09, 0.075, 0.36, 0.159, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.27464283 0.18853866 0.53681856]], shape=(1, 3), dtype=float32)
Selected action 2
[0.31, 0.3, 0.29, 0.256, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.2609574  0.17777511 0.5612675 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.1, 0.075, 0.33, 0.186, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.2758151  0.18771555 0.5364694 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.1, 0.3, 0.31, 0.198, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.26517314 0.18528463 0.54954225]], shape=(1, 3), dtype=float32)
Selected action 0
[0.06, 0.075, 0.3, 0.16, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 76 | Average Reward: 50 | Episode Reward: 50 | Loss: 137.986 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 50.01840389135662
Probs tf.Tensor([[0.33044064 0.3020519  0.3675074 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.08, 0.075, 0.27, 0.194, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.2778953  0.18761688 0.53448784]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.075, 0.28, 0.184, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.2782212  0.18855625 0.53322256]], shape=(1, 3), dtype=float32)
Selected action 2
[0.17, 0.3, 0.25, 0.174, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.2643065  0.18423583 0.5514577 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.17, 0.3, 0.27, 0.0, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.26148397 0.1907967  0.54771936]], shape=(1, 3), dtype=float32)
Selected action 2
[0.1, 0.3, 0.24, 0.241, 0.128, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 77 | Average Reward: 50 | Episode Reward: 63 | Loss: 288.649 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 63.953241398112446
Probs tf.Tensor([[0.33105   0.3020276 0.3669224]], shape=(1, 3), dtype=float32)
Selected action 1
[0.12, 0.15, 0.26, 0.226, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.27318242 0.18231912 0.54449844]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.075, 0.32, 0.173, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.2763598  0.18607458 0.5375656 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.09, 0.3, 0.26, 0.222, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.26652256 0.18187854 0.5515989 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.2, 0.3, 0.25, 0.225, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.26345068 0.17905125 0.55749804]], shape=(1, 3), dtype=float32)
Selected action 2
[0.19, 0.3, 0.27, 0.218, 0.131, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 78 | Average Reward: 50 | Episode Reward: 71 | Loss: 312.157 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 71.00007890486826
Probs tf.Tensor([[0.3327075  0.30462313 0.36266938]], shape=(1, 3), dtype=float32)
Selected action 2
[0.15, 0.3, 0.25, 0.184, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.2636272  0.17900671 0.5573661 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.14, 0.3, 0.24, 0.248, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.26499707 0.17719395 0.557809  ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.29, 0.3, 0.27, 0.235, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.25967804 0.17224942 0.5680725 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.11, 0.3, 0.25, 0.25, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.2656686  0.17769995 0.5566315 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.16, 0.15, 0.3, 0.23, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 79 | Average Reward: 51 | Episode Reward: 85 | Loss: 355.751 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 85.0189164116241
Probs tf.Tensor([[0.3313089  0.30153903 0.36715207]], shape=(1, 3), dtype=float32)
Selected action 1
[0.13, 0.15, 0.32, 0.232, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.26787826 0.17474478 0.5573769 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.14, 0.15, 0.34, 0.243, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.2669784  0.17351367 0.55950797]], shape=(1, 3), dtype=float32)
Selected action 1
[0.24, 0.15, 0.31, 0.247, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.26526022 0.17144006 0.5632998 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.47, 0.3, 0.28, 0.235, 0.131, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.25424057 0.16405576 0.58170366]], shape=(1, 3), dtype=float32)
Selected action 2
[0.21, 0.3, 0.22, 0.239, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 80 | Average Reward: 51 | Episode Reward: 71 | Loss: 299.568 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 71.24575391837993
Probs tf.Tensor([[0.3291745  0.30065885 0.37016666]], shape=(1, 3), dtype=float32)
Selected action 1
[0.14, 0.15, 0.29, 0.169, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.2645953  0.17678338 0.5586213 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.27, 0.3, 0.29, 0.258, 0.125, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.25400606 0.1676301  0.57836384]], shape=(1, 3), dtype=float32)
Selected action 0
[0.07, 0.075, 0.32, 0.23, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.27045703 0.176905   0.55263793]], shape=(1, 3), dtype=float32)
Selected action 2
[0.21, 0.3, 0.27, 0.253, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.25633058 0.17039417 0.57327527]], shape=(1, 3), dtype=float32)
Selected action 2
[0.3, 0.3, 0.29, 0.245, 0.127, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 81 | Average Reward: 51 | Episode Reward: 71 | Loss: 282.49 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 71.36859142513575
Probs tf.Tensor([[0.3296254  0.30154294 0.3688317 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.07, 0.075, 0.32, 0.13, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.2658256  0.17959298 0.5545814 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.28, 0.3, 0.25, 0.258, 0.13, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.25184703 0.16677022 0.58138275]], shape=(1, 3), dtype=float32)
Selected action 2
[0.14, 0.3, 0.26, 0.245, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.25571233 0.17172852 0.5725591 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.27, 0.3, 0.24, 0.236, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.2525352  0.16844139 0.5790234 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.3, 0.21, 0.181, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 82 | Average Reward: 51 | Episode Reward: 78 | Loss: 382.499 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 78.47542893189157
Probs tf.Tensor([[0.3290738  0.3030632  0.36786297]], shape=(1, 3), dtype=float32)
Selected action 2
[0.27, 0.3, 0.21, 0.246, 0.121, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.24924515 0.1663594  0.58439547]], shape=(1, 3), dtype=float32)
Selected action 2
[0.14, 0.3, 0.26, 0.206, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.25096732 0.17055233 0.5784803 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.06, 0.075, 0.32, 0.226, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.2634363  0.17375447 0.5628093 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.18, 0.3, 0.25, 0.0, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.24850659 0.17787516 0.5736183 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.08, 0.075, 0.32, 0.176, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 83 | Average Reward: 51 | Episode Reward: 64 | Loss: 179.364 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 64.61826643864741
Probs tf.Tensor([[0.32886478 0.30219397 0.36894125]], shape=(1, 3), dtype=float32)
Selected action 0
[0.1, 0.075, 0.3, 0.234, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.25967705 0.1701266  0.5701964 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.08, 0.075, 0.31, 0.178, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.25928542 0.1726397  0.5680749 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.31, 0.3, 0.28, 0.233, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.24200802 0.1601573  0.59783465]], shape=(1, 3), dtype=float32)
Selected action 0
[0.07, 0.075, 0.31, 0.182, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.2596581  0.17280035 0.56754154]], shape=(1, 3), dtype=float32)
Selected action 2
[0.16, 0.3, 0.27, 0.236, 0.125, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 84 | Average Reward: 51 | Episode Reward: 50 | Loss: 168.816 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 50.71310394540323
Probs tf.Tensor([[0.32706437 0.3009268  0.37200883]], shape=(1, 3), dtype=float32)
Selected action 2
[0.26, 0.3, 0.27, 0.222, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.24168414 0.15964004 0.59867585]], shape=(1, 3), dtype=float32)
Selected action 0
[0.09, 0.075, 0.33, 0.229, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.25689942 0.1671712  0.5759294 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.18, 0.3, 0.26, 0.269, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.24470204 0.16115691 0.594141  ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.08, 0.075, 0.33, 0.2, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.2568436 0.1686223 0.5745341]], shape=(1, 3), dtype=float32)
Selected action 2
[0.3, 0.3, 0.27, 0.242, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 85 | Average Reward: 51 | Episode Reward: 64 | Loss: 208.412 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 64.83994145215905
Probs tf.Tensor([[0.3286675  0.30003142 0.37130108]], shape=(1, 3), dtype=float32)
Selected action 1
[0.13, 0.15, 0.36, 0.167, 0.127, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.24866566 0.1630185  0.58831584]], shape=(1, 3), dtype=float32)
Selected action 2
[0.13, 0.3, 0.25, 0.246, 0.121, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.24559125 0.16096434 0.59344435]], shape=(1, 3), dtype=float32)
Selected action 2
[0.26, 0.3, 0.28, 0.0, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.23960254 0.16570622 0.5946912 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.21, 0.3, 0.28, 0.25, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.24193636 0.15693885 0.6011248 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.22, 0.3, 0.27, 0.231, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 86 | Average Reward: 52 | Episode Reward: 86 | Loss: 414.225 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 86.04677895891489
Probs tf.Tensor([[0.32913414 0.30045128 0.37041458]], shape=(1, 3), dtype=float32)
Selected action 1
[0.2, 0.15, 0.27, 0.235, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.24764581 0.15680334 0.59555084]], shape=(1, 3), dtype=float32)
Selected action 2
[0.19, 0.3, 0.2, 0.252, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.24294208 0.15657158 0.60048634]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.075, 0.33, 0.241, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.25465137 0.16162726 0.5837214 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.18, 0.3, 0.26, 0.167, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.24063464 0.15808712 0.60127825]], shape=(1, 3), dtype=float32)
Selected action 0
[0.2, 0.3, 0.27, 0.233, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 87 | Average Reward: 52 | Episode Reward: 58 | Loss: 159.872 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 58.01761646567073
Probs tf.Tensor([[0.32861882 0.29943496 0.3719462 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.3, 0.25, 0.236, 0.129, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.24318199 0.1563283  0.6004897 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.08, 0.075, 0.22, 0.242, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.2562014  0.16024706 0.5835516 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.11, 0.3, 0.22, 0.218, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.24275438 0.15637839 0.6008673 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.13, 0.075, 0.21, 0.19, 0.121, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.25434345 0.16072185 0.5849347 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.08, 0.075, 0.29, 0.146, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 88 | Average Reward: 52 | Episode Reward: 51 | Loss: 106.398 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 51.060453972426544
Probs tf.Tensor([[0.32914904 0.3006579  0.37019303]], shape=(1, 3), dtype=float32)
Selected action 1
[0.14, 0.15, 0.25, 0.245, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.24844164 0.15259211 0.59896624]], shape=(1, 3), dtype=float32)
Selected action 2
[0.24, 0.3, 0.27, 0.223, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.23625232 0.1463839  0.61736375]], shape=(1, 3), dtype=float32)
Selected action 1
[0.17, 0.15, 0.28, 0.247, 0.127, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.24590616 0.15023787 0.60385597]], shape=(1, 3), dtype=float32)
Selected action 2
[0.19, 0.3, 0.27, 0.2, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.23785987 0.14926308 0.612877  ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.21, 0.3, 0.26, 0.231, 0.127, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 89 | Average Reward: 52 | Episode Reward: 79 | Loss: 350.786 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 79.41929147918236
Probs tf.Tensor([[0.32894185 0.29938442 0.37167373]], shape=(1, 3), dtype=float32)
Selected action 0
[0.06, 0.075, 0.31, 0.21, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.25081596 0.1540034  0.59518063]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.3, 0.3, 0.23, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.23987137 0.14986227 0.6102664 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.09, 0.3, 0.35, 0.219, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.2364893  0.14736149 0.61614925]], shape=(1, 3), dtype=float32)
Selected action 0
[0.02, 0.075, 0.39, 0.233, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.24920495 0.15256815 0.5982269 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.1, 0.3, 0.31, 0.158, 0.125, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 90 | Average Reward: 52 | Episode Reward: 65 | Loss: 244.877 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 65.3941289859382
Probs tf.Tensor([[0.32742834 0.297603   0.37496865]], shape=(1, 3), dtype=float32)
Selected action 0
[0.09, 0.075, 0.38, 0.208, 0.121, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.24536598 0.14842097 0.6062131 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.3, 0.36, 0.168, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.23505817 0.14705436 0.61788744]], shape=(1, 3), dtype=float32)
Selected action 0
[0.07, 0.075, 0.37, 0.16, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.24612638 0.15126802 0.60260564]], shape=(1, 3), dtype=float32)
Selected action 2
[0.14, 0.3, 0.39, 0.172, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.23141685 0.14333373 0.6252494 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.3, 0.34, 0.151, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 91 | Average Reward: 52 | Episode Reward: 65 | Loss: 264.125 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 65.50496649269402
Probs tf.Tensor([[0.32856524 0.29736465 0.3740701 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.19, 0.3, 0.28, 0.243, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.23287815 0.13869214 0.6284297 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.16, 0.3, 0.25, 0.262, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.2352164  0.14015098 0.6246326 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.32, 0.3, 0.29, 0.256, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.22820346 0.13276106 0.63903546]], shape=(1, 3), dtype=float32)
Selected action 2
[0.21, 0.3, 0.25, 0.268, 0.127, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.23328346 0.13780431 0.6289122 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.22, 0.3, 0.26, 0.27, 0.128, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 92 | Average Reward: 53 | Episode Reward: 94 | Loss: 449.667 | Steps: 4 | Worker: 0
Saving best model to ./Training/, episode score: 94.03180399944985
Probs tf.Tensor([[0.3292999  0.2982654  0.37243474]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.075, 0.32, 0.22, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.24507913 0.14432122 0.61059964]], shape=(1, 3), dtype=float32)
Selected action 2
[0.19, 0.3, 0.26, 0.236, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.23032969 0.135559   0.63411134]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.075, 0.37, 0.234, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.2426334  0.14201023 0.6153564 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.22, 0.3, 0.27, 0.243, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.22885066 0.13373922 0.6374101 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.09, 0.3, 0.23, 0.26, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 93 | Average Reward: 53 | Episode Reward: 65 | Loss: 265.307 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 65.72664150620568
Probs tf.Tensor([[0.3281157 0.2950244 0.3768599]], shape=(1, 3), dtype=float32)
Selected action 0
[0.07, 0.075, 0.29, 0.226, 0.128, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.2421547  0.13962002 0.61822534]], shape=(1, 3), dtype=float32)
Selected action 2
[0.13, 0.3, 0.25, 0.244, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.22997954 0.13375075 0.63626975]], shape=(1, 3), dtype=float32)
Selected action 2
[0.13, 0.3, 0.25, 0.233, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.22993183 0.13413773 0.6359304 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.16, 0.15, 0.3, 0.239, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.23443383 0.13388681 0.63167936]], shape=(1, 3), dtype=float32)
Selected action 2
[0.13, 0.3, 0.24, 0.229, 0.129, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 94 | Average Reward: 53 | Episode Reward: 72 | Loss: 317.104 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 72.96547901296151
Probs tf.Tensor([[0.33066323 0.2987976  0.37053913]], shape=(1, 3), dtype=float32)
Selected action 0
[0.06, 0.075, 0.24, 0.192, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.24148738 0.13993168 0.61858094]], shape=(1, 3), dtype=float32)
Selected action 2
[0.12, 0.3, 0.26, 0.231, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.22635059 0.13086756 0.64278185]], shape=(1, 3), dtype=float32)
Selected action 1
[0.22, 0.15, 0.28, 0.244, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.22925177 0.12865253 0.6420957 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.18, 0.3, 0.26, 0.189, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.22417729 0.13021462 0.64560807]], shape=(1, 3), dtype=float32)
Selected action 2
[0.13, 0.3, 0.25, 0.23, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 95 | Average Reward: 53 | Episode Reward: 73 | Loss: 328.885 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 73.08831651971734
Probs tf.Tensor([[0.32661933 0.29150155 0.3818791 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.1, 0.15, 0.29, 0.256, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.22952919 0.12975532 0.6407155 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.15, 0.15, 0.29, 0.233, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.22735406 0.12861894 0.64402705]], shape=(1, 3), dtype=float32)
Selected action 1
[0.2, 0.15, 0.29, 0.24, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.22531451 0.12639311 0.6482924 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.22, 0.15, 0.27, 0.255, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.2253853  0.12574716 0.64886755]], shape=(1, 3), dtype=float32)
Selected action 1
[0.26, 0.15, 0.27, 0.167, 0.13, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 96 | Average Reward: 53 | Episode Reward: 58 | Loss: 181.406 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 58.907154026473165
Probs tf.Tensor([[0.32556176 0.29218045 0.38225776]], shape=(1, 3), dtype=float32)
Selected action 2
[0.21, 0.3, 0.27, 0.22, 0.129, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.2149187  0.1244824  0.66059893]], shape=(1, 3), dtype=float32)
Selected action 2
[0.3, 0.3, 0.29, 0.251, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.21079023 0.11916675 0.670043  ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.1, 0.3, 0.21, 0.235, 0.127, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.22201024 0.13047254 0.6475172 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.25, 0.3, 0.27, 0.226, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.21365339 0.1228264  0.6635203 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.22, 0.3, 0.28, 0.23, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 97 | Average Reward: 54 | Episode Reward: 94 | Loss: 454.251 | Steps: 4 | Worker: 0
Saving best model to ./Training/, episode score: 94.825991533229
Probs tf.Tensor([[0.32674184 0.29356888 0.3796893 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.25, 0.15, 0.28, 0.233, 0.128, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.21568161 0.1242452  0.6600732 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.22, 0.3, 0.27, 0.243, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.20996414 0.12245054 0.6675853 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.3, 0.19, 0.243, 0.13, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.21912262 0.13071528 0.65016216]], shape=(1, 3), dtype=float32)
Selected action 2
[0.23, 0.3, 0.28, 0.233, 0.127, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.2090149  0.12192873 0.6690564 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.13, 0.3, 0.26, 0.243, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 98 | Average Reward: 54 | Episode Reward: 87 | Loss: 424.449 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 87.80882903998483
Probs tf.Tensor([[0.32716447 0.29454878 0.37828675]], shape=(1, 3), dtype=float32)
Selected action 1
[0.09, 0.15, 0.29, 0.236, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.2166742  0.12884563 0.65448016]], shape=(1, 3), dtype=float32)
Selected action 2
[0.17, 0.3, 0.27, 0.231, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.20622522 0.12330712 0.6704677 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.24, 0.15, 0.26, 0.261, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.21153778 0.12295748 0.66550475]], shape=(1, 3), dtype=float32)
Selected action 2
[0.19, 0.3, 0.16, 0.257, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.21067628 0.12563495 0.6636888 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.18, 0.3, 0.26, 0.235, 0.131, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 99 | Average Reward: 54 | Episode Reward: 80 | Loss: 358.095 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 80.76766654674064
Probs tf.Tensor([[0.3252174  0.2938395  0.38094312]], shape=(1, 3), dtype=float32)
Selected action 0
[0.07, 0.075, 0.31, 0.0, 0.128, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.21644196 0.14009884 0.6434592 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.17, 0.3, 0.27, 0.237, 0.128, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.20009466 0.12186816 0.67803717]], shape=(1, 3), dtype=float32)
Selected action 2
[0.09, 0.3, 0.25, 0.21, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.20503603 0.12724808 0.66771585]], shape=(1, 3), dtype=float32)
Selected action 2
[0.12, 0.3, 0.24, 0.198, 0.12, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.20440896 0.12691705 0.668674  ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.14, 0.15, 0.26, 0.251, 0.127, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 100 | Average Reward: 55 | Episode Reward: 73 | Loss: 317.079 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 73.70250405349648
Probs tf.Tensor([[0.3225213  0.2943912  0.38308752]], shape=(1, 3), dtype=float32)
Selected action 1
[0.15, 0.15, 0.25, 0.22, 0.121, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.20455122 0.12687492 0.66857386]], shape=(1, 3), dtype=float32)
Selected action 0
[0.07, 0.075, 0.27, 0.232, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.21122296 0.13055371 0.65822333]], shape=(1, 3), dtype=float32)
Selected action 1
[0.11, 0.15, 0.25, 0.218, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.20629595 0.12854995 0.6651541 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.24, 0.3, 0.28, 0.224, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.19133478 0.1185112  0.690154  ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.29, 0.3, 0.28, 0.242, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 101 | Average Reward: 55 | Episode Reward: 66 | Loss: 268.613 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 66.61334156025231
Probs tf.Tensor([[0.3209781  0.29238096 0.38664097]], shape=(1, 3), dtype=float32)
Selected action 0
[0.07, 0.075, 0.26, 0.235, 0.125, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.20699485 0.1308033  0.6622018 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.37, 0.3, 0.29, 0.245, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.18155576 0.11180262 0.7066417 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.16, 0.15, 0.29, 0.233, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.19717489 0.12443665 0.6783884 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.3, 0.3, 0.29, 0.25, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.18377778 0.11451571 0.7017065 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.25, 0.3, 0.29, 0.262, 0.128, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 102 | Average Reward: 55 | Episode Reward: 73 | Loss: 332.539 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 73.94817906700813
Probs tf.Tensor([[0.32024947 0.29251638 0.38723415]], shape=(1, 3), dtype=float32)
Selected action 1
[0.13, 0.15, 0.33, 0.0, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.19455433 0.13469411 0.6707516 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.17, 0.3, 0.28, 0.263, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.18429047 0.12006814 0.6956414 ]], shape=(1, 3), dtype=float32)
Selected action 2
[1.44, 0.3, 0.2, 0.0, 0.093, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.17576143 0.10871777 0.7155208 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.23, 0.3, 0.28, 0.246, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.18194544 0.1180839  0.69997066]], shape=(1, 3), dtype=float32)
Selected action 1
[0.16, 0.15, 0.31, 0.242, 0.121, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 103 | Average Reward: 55 | Episode Reward: 81 | Loss: 345.635 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 81.30701657376395
Probs tf.Tensor([[0.32154238 0.29755786 0.38089976]], shape=(1, 3), dtype=float32)
Selected action 1
[0.19, 0.15, 0.31, 0.233, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.18520378 0.12343097 0.6913653 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.08, 0.075, 0.35, 0.229, 0.126, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.1924048  0.12836693 0.67922825]], shape=(1, 3), dtype=float32)
Selected action 1
[0.24, 0.075, 0.26, 0.246, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.18975826 0.12458275 0.68565893]], shape=(1, 3), dtype=float32)
Selected action 2
[0.37, 0.3, 0.28, 0.233, 0.127, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.1724162  0.11321066 0.7143731 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.26, 0.3, 0.26, 0.254, 0.126, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 104 | Average Reward: 55 | Episode Reward: 66 | Loss: 269.517 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 66.94585408051978
Probs tf.Tensor([[0.3213319  0.29975128 0.37891683]], shape=(1, 3), dtype=float32)
Selected action 2
[0.17, 0.3, 0.23, 0.245, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.17841782 0.12445848 0.6971237 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.13, 0.3, 0.23, 0.0, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.18505943 0.13652653 0.67841405]], shape=(1, 3), dtype=float32)
Selected action 2
[0.14, 0.3, 0.24, 0.191, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.18007752 0.12761237 0.6923101 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.08, 0.075, 0.33, 0.225, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.19000278 0.1306621  0.6793351 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.23, 0.075, 0.27, 0.233, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 105 | Average Reward: 55 | Episode Reward: 81 | Loss: 303.784 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 81.5766915872756
Probs tf.Tensor([[0.3213296  0.30169424 0.37697616]], shape=(1, 3), dtype=float32)
Selected action 2
[0.16, 0.3, 0.26, 0.25, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.17399122 0.12419412 0.70181465]], shape=(1, 3), dtype=float32)
Selected action 2
[0.17, 0.3, 0.26, 0.221, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.17390965 0.12487426 0.7012161 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.1, 0.075, 0.25, 0.212, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.1900809  0.13400334 0.6759158 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.1, 0.075, 0.33, 0.167, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.18648781 0.13282312 0.6806891 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.14, 0.15, 0.25, 0.228, 0.127, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 106 | Average Reward: 56 | Episode Reward: 74 | Loss: 251.313 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 74.43952909403144
Probs tf.Tensor([[0.3201146  0.30181867 0.3780667 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.06, 0.075, 0.28, 0.222, 0.121, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.18781255 0.1352977  0.6768898 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.23, 0.075, 0.28, 0.253, 0.127, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.17897141 0.1267617  0.69426686]], shape=(1, 3), dtype=float32)
Selected action 0
[0.37, 0.075, 0.29, 0.2, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.17430662 0.12336916 0.7023242 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.06, 0.075, 0.26, 0.237, 0.121, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.18870811 0.13546646 0.6758255 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.07, 0.15, 0.37, 0.222, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 107 | Average Reward: 55 | Episode Reward: 30 | Loss: 54.73 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 30.858366600787274
Probs tf.Tensor([[0.3178627  0.30091748 0.3812199 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.3, 0.15, 0.36, 0.253, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.16735002 0.12055881 0.7120912 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.21, 0.3, 0.24, 0.237, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.16936766 0.12552367 0.70510864]], shape=(1, 3), dtype=float32)
Selected action 2
[0.38, 0.3, 0.29, 0.249, 0.126, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.1606352  0.11566307 0.7237018 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.09, 0.075, 0.35, 0.213, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.18170612 0.13323729 0.6850566 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.08, 0.075, 0.39, 0.217, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 108 | Average Reward: 55 | Episode Reward: 60 | Loss: 155.834 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 60.093204107543094
Probs tf.Tensor([[0.3180186  0.30099145 0.38098997]], shape=(1, 3), dtype=float32)
Selected action 0
[0.08, 0.075, 0.35, 0.231, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.18173814 0.13431564 0.68394625]], shape=(1, 3), dtype=float32)
Selected action 0
[0.06, 0.075, 0.36, 0.227, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.18220684 0.13493949 0.6828537 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.27, 0.3, 0.27, 0.235, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.16564548 0.12310575 0.71124876]], shape=(1, 3), dtype=float32)
Selected action 2
[0.26, 0.3, 0.28, 0.241, 0.119, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.16559488 0.12304433 0.7113608 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.17, 0.3, 0.25, 0.254, 0.131, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 109 | Average Reward: 56 | Episode Reward: 67 | Loss: 305.925 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 67.50004161429892
Probs tf.Tensor([[0.3196926  0.30272675 0.37758064]], shape=(1, 3), dtype=float32)
Selected action 1
[0.13, 0.15, 0.29, 0.226, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.17846325 0.1335909  0.68794584]], shape=(1, 3), dtype=float32)
Selected action 0
[0.22, 0.075, 0.27, 0.238, 0.125, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.179182   0.13169855 0.6891194 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.14, 0.075, 0.25, 0.149, 0.12, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.18554232 0.13965024 0.6748074 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.2, 0.15, 0.27, 0.224, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.17619093 0.1313101  0.6924989 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.14, 0.15, 0.25, 0.226, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 110 | Average Reward: 55 | Episode Reward: 45 | Loss: 107.283 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 45.65087912105475
Probs tf.Tensor([[0.31762904 0.30229345 0.38007748]], shape=(1, 3), dtype=float32)
Selected action 2
[0.16, 0.3, 0.11, 0.257, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.17942552 0.13622618 0.6843482 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.12, 0.15, 0.24, 0.194, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.18322212 0.13903695 0.67774093]], shape=(1, 3), dtype=float32)
Selected action 1
[0.08, 0.15, 0.23, 0.225, 0.125, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.18522006 0.13991673 0.67486316]], shape=(1, 3), dtype=float32)
Selected action 1
[0.09, 0.15, 0.24, 0.136, 0.126, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.18537365 0.1427658  0.6718606 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.3, 0.22, 0.178, 0.126, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 111 | Average Reward: 56 | Episode Reward: 75 | Loss: 275.094 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 75.05371662781057
Probs tf.Tensor([[0.319779   0.30436787 0.37585312]], shape=(1, 3), dtype=float32)
Selected action 2
[0.09, 0.3, 0.26, 0.226, 0.121, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.17653841 0.13846168 0.68499994]], shape=(1, 3), dtype=float32)
Selected action 1
[0.16, 0.15, 0.24, 0.2, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.18265934 0.14060986 0.6767308 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.13, 0.3, 0.25, 0.206, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.1754551  0.1376516  0.68689334]], shape=(1, 3), dtype=float32)
Selected action 2
[0.1, 0.3, 0.24, 0.198, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.17739743 0.13976304 0.6828396 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.17, 0.3, 0.26, 0.25, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 112 | Average Reward: 56 | Episode Reward: 89 | Loss: 415.19 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 89.8645541345664
Probs tf.Tensor([[0.3185573  0.3062297  0.37521306]], shape=(1, 3), dtype=float32)
Selected action 2
[0.34, 0.3, 0.21, 0.244, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.16911325 0.13128853 0.6995982 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.29, 0.3, 0.26, 0.21, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.16896953 0.13294695 0.6980835 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.22, 0.3, 0.29, 0.256, 0.125, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.16948639 0.13328785 0.6972258 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.21, 0.3, 0.29, 0.266, 0.127, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.16965765 0.13331352 0.6970288 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.16, 0.15, 0.28, 0.216, 0.128, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 113 | Average Reward: 56 | Episode Reward: 75 | Loss: 282.35 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 75.29939164132225
Probs tf.Tensor([[0.318295  0.3086345 0.3730705]], shape=(1, 3), dtype=float32)
Selected action 2
[0.16, 0.3, 0.28, 0.262, 0.132, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.17291133 0.1396334  0.68745524]], shape=(1, 3), dtype=float32)
Selected action 2
[0.21, 0.3, 0.27, 0.231, 0.126, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.1719462  0.139042   0.68901175]], shape=(1, 3), dtype=float32)
Selected action 2
[0.36, 0.3, 0.27, 0.246, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.16661645 0.13162999 0.70175356]], shape=(1, 3), dtype=float32)
Selected action 2
[0.16, 0.3, 0.27, 0.26, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.17382734 0.14039044 0.68578225]], shape=(1, 3), dtype=float32)
Selected action 2
[0.27, 0.3, 0.28, 0.246, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 114 | Average Reward: 57 | Episode Reward: 97 | Loss: 470.047 | Steps: 4 | Worker: 0
Saving best model to ./Training/, episode score: 97.52622914807804
Probs tf.Tensor([[0.31969815 0.30930108 0.3710007 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.14, 0.15, 0.32, 0.245, 0.121, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.17951803 0.14586802 0.6746139 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.17, 0.3, 0.32, 0.251, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.17047238 0.14046654 0.6890611 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.27, 0.075, 0.27, 0.225, 0.128, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.18074559 0.14432567 0.6749288 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.23, 0.3, 0.23, 0.22, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.1726958  0.14214039 0.6851638 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.19, 0.3, 0.27, 0.24, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 115 | Average Reward: 57 | Episode Reward: 75 | Loss: 300.746 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 75.5450666548339
Probs tf.Tensor([[0.3163367  0.30820295 0.37546033]], shape=(1, 3), dtype=float32)
Selected action 2
[0.13, 0.3, 0.23, 0.242, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.17595527 0.1476842  0.67636055]], shape=(1, 3), dtype=float32)
Selected action 2
[0.16, 0.3, 0.26, 0.273, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.17285398 0.14380696 0.6833391 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.17, 0.3, 0.25, 0.236, 0.126, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.17320442 0.1450812  0.68171436]], shape=(1, 3), dtype=float32)
Selected action 2
[0.1, 0.3, 0.24, 0.237, 0.134, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.1763305  0.14858162 0.67508787]], shape=(1, 3), dtype=float32)
Selected action 2
[0.09, 0.3, 0.24, 0.233, 0.134, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 116 | Average Reward: 57 | Episode Reward: 97 | Loss: 472.658 | Steps: 4 | Worker: 0
Saving best model to ./Training/, episode score: 97.84390416158972
Probs tf.Tensor([[0.31367743 0.30582806 0.3804945 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.32, 0.3, 0.19, 0.256, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.16850269 0.13971382 0.6917835 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.24, 0.3, 0.27, 0.254, 0.126, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.16755995 0.14039822 0.69204175]], shape=(1, 3), dtype=float32)
Selected action 2
[0.23, 0.3, 0.26, 0.214, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.16898607 0.14282282 0.6881911 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.1, 0.15, 0.25, 0.183, 0.127, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.18300667 0.15425795 0.66273534]], shape=(1, 3), dtype=float32)
Selected action 2
[0.11, 0.3, 0.21, 0.249, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 117 | Average Reward: 57 | Episode Reward: 90 | Loss: 388.309 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 90.59874166834555
Probs tf.Tensor([[0.31517074 0.30854023 0.376289  ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.18, 0.3, 0.19, 0.216, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.17191073 0.14812993 0.67995936]], shape=(1, 3), dtype=float32)
Selected action 0
[0.31, 0.075, 0.27, 0.194, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.17541361 0.14588618 0.6787002 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.39, 0.3, 0.28, 0.217, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.16031708 0.13485862 0.70482427]], shape=(1, 3), dtype=float32)
Selected action 2
[0.1, 0.3, 0.24, 0.252, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.17238839 0.1487941  0.6788175 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.3, 0.3, 0.3, 0.256, 0.125, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 118 | Average Reward: 58 | Episode Reward: 83 | Loss: 364.542 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 83.32957917510139
Probs tf.Tensor([[0.31305    0.3085612  0.37838876]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.075, 0.32, 0.234, 0.125, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.18163681 0.15407836 0.6642849 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.17, 0.3, 0.26, 0.257, 0.125, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.16615795 0.14389665 0.6899454 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.25, 0.3, 0.26, 0.216, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.16376667 0.14156595 0.69466746]], shape=(1, 3), dtype=float32)
Selected action 2
[0.45, 0.3, 0.31, 0.24, 0.125, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.15474492 0.1298712  0.7153838 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.34, 0.3, 0.28, 0.242, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 119 | Average Reward: 58 | Episode Reward: 83 | Loss: 410.642 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 83.4644166818572
Probs tf.Tensor([[0.31405693 0.30860162 0.37734148]], shape=(1, 3), dtype=float32)
Selected action 0
[0.1, 0.075, 0.33, 0.223, 0.126, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.175493   0.15009028 0.6744167 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.14, 0.075, 0.26, 0.264, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.17661206 0.14927568 0.67411226]], shape=(1, 3), dtype=float32)
Selected action 2
[0.29, 0.3, 0.28, 0.232, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.15819149 0.13679835 0.7050102 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.17, 0.3, 0.24, 0.256, 0.126, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.16411859 0.1432226  0.6926588 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.25, 0.3, 0.28, 0.239, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 120 | Average Reward: 58 | Episode Reward: 76 | Loss: 361.197 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 76.15925418861302
Probs tf.Tensor([[0.31209886 0.30657458 0.3813266 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.08, 0.075, 0.3, 0.155, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.17608698 0.15400806 0.669905  ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.16, 0.3, 0.27, 0.24, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.1603561  0.14214149 0.69750243]], shape=(1, 3), dtype=float32)
Selected action 2
[0.19, 0.3, 0.26, 0.25, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.15951236 0.14065833 0.69982934]], shape=(1, 3), dtype=float32)
Selected action 2
[0.16, 0.3, 0.25, 0.159, 0.127, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.16243064 0.14598964 0.69157976]], shape=(1, 3), dtype=float32)
Selected action 2
[0.29, 0.3, 0.27, 0.214, 0.128, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 121 | Average Reward: 58 | Episode Reward: 83 | Loss: 412.691 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 83.73409169536886
Probs tf.Tensor([[0.31200626 0.30536884 0.38262495]], shape=(1, 3), dtype=float32)
Selected action 1
[0.13, 0.15, 0.25, 0.266, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.16655383 0.14541796 0.6880282 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.19, 0.3, 0.25, 0.234, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.1565479  0.13961042 0.7038417 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.2, 0.3, 0.26, 0.254, 0.125, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.15528035 0.13786468 0.70685494]], shape=(1, 3), dtype=float32)
Selected action 2
[0.13, 0.3, 0.25, 0.236, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.15904583 0.14259523 0.69835895]], shape=(1, 3), dtype=float32)
Selected action 2
[0.16, 0.3, 0.24, 0.239, 0.126, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 122 | Average Reward: 59 | Episode Reward: 91 | Loss: 444.163 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 91.33292920212469
Probs tf.Tensor([[0.3083528  0.3032759  0.38837126]], shape=(1, 3), dtype=float32)
Selected action 2
[0.34, 0.3, 0.22, 0.24, 0.121, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.1477823  0.13041453 0.72180325]], shape=(1, 3), dtype=float32)
Selected action 0
[0.1, 0.075, 0.27, 0.221, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.16773465 0.14719388 0.68507147]], shape=(1, 3), dtype=float32)
Selected action 2
[0.19, 0.3, 0.26, 0.251, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.15141918 0.13579819 0.7127827 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.2, 0.3, 0.26, 0.255, 0.128, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.15074052 0.13497332 0.71428615]], shape=(1, 3), dtype=float32)
Selected action 2
[0.12, 0.3, 0.24, 0.204, 0.128, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 123 | Average Reward: 59 | Episode Reward: 84 | Loss: 367.164 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 84.0037667088805
Probs tf.Tensor([[0.31013274 0.30673265 0.3831346 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.17, 0.15, 0.28, 0.206, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.15605493 0.13917157 0.70477355]], shape=(1, 3), dtype=float32)
Selected action 2
[0.18, 0.3, 0.27, 0.259, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.14741941 0.1325882  0.71999234]], shape=(1, 3), dtype=float32)
Selected action 2
[0.35, 0.3, 0.27, 0.267, 0.125, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.1407155  0.12381695 0.7354676 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.34, 0.3, 0.31, 0.242, 0.125, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.13966626 0.12374236 0.73659134]], shape=(1, 3), dtype=float32)
Selected action 2
[0.21, 0.3, 0.26, 0.258, 0.126, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 124 | Average Reward: 59 | Episode Reward: 91 | Loss: 444.825 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 91.62660421563633
Probs tf.Tensor([[0.30920985 0.3036418  0.3871484 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.09, 0.15, 0.3, 0.193, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.1547248  0.13956395 0.70571125]], shape=(1, 3), dtype=float32)
Selected action 2
[0.13, 0.3, 0.29, 0.202, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.14512683 0.13311271 0.72176045]], shape=(1, 3), dtype=float32)
Selected action 2
[0.15, 0.3, 0.29, 0.249, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.14342648 0.13017248 0.726401  ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.18, 0.3, 0.31, 0.206, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.14202242 0.12954174 0.7284359 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.12, 0.15, 0.28, 0.252, 0.125, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 125 | Average Reward: 60 | Episode Reward: 84 | Loss: 358.87 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 84.27344172239216
Probs tf.Tensor([[0.30626455 0.3023419  0.39139354]], shape=(1, 3), dtype=float32)
Selected action 0
[0.09, 0.075, 0.4, 0.18, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.14996858 0.13568194 0.71434945]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.3, 0.36, 0.189, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.14011185 0.13071333 0.72917485]], shape=(1, 3), dtype=float32)
Selected action 2
[0.11, 0.3, 0.37, 0.23, 0.125, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.13748114 0.12703764 0.73548126]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.3, 0.33, 0.159, 0.125, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.14386597 0.13520196 0.720932  ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.3, 0.33, 0.161, 0.125, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 126 | Average Reward: 60 | Episode Reward: 84 | Loss: 414.465 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 84.408279229148
Probs tf.Tensor([[0.30729422 0.3027186  0.38998714]], shape=(1, 3), dtype=float32)
Selected action 1
[0.12, 0.15, 0.25, 0.188, 0.126, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.1467959  0.13419257 0.7190115 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.28, 0.3, 0.27, 0.233, 0.127, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.13035655 0.11867733 0.7509661 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.16, 0.3, 0.26, 0.192, 0.128, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.13635154 0.12676169 0.7368868 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.07, 0.075, 0.28, 0.165, 0.128, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.15258947 0.13862391 0.70878667]], shape=(1, 3), dtype=float32)
Selected action 2
[0.16, 0.3, 0.24, 0.194, 0.128, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 127 | Average Reward: 60 | Episode Reward: 77 | Loss: 286.283 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 77.01911673590382
Probs tf.Tensor([[0.30501872 0.3034183  0.39156297]], shape=(1, 3), dtype=float32)
Selected action 2
[0.17, 0.3, 0.23, 0.237, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.13290416 0.12258502 0.7445109 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.3, 0.3, 0.22, 0.255, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.1277701  0.11568932 0.75654054]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.3, 0.23, 0.208, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.13816296 0.1291247  0.7327123 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.14, 0.3, 0.25, 0.226, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.13340764 0.12379085 0.74280155]], shape=(1, 3), dtype=float32)
Selected action 2
[0.21, 0.3, 0.27, 0.188, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 128 | Average Reward: 60 | Episode Reward: 99 | Loss: 481.627 | Steps: 4 | Worker: 0
Saving best model to ./Training/, episode score: 99.74995424265964
Probs tf.Tensor([[0.2995573  0.29802543 0.40241724]], shape=(1, 3), dtype=float32)
Selected action 1
[0.11, 0.15, 0.27, 0.206, 0.132, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.13715951 0.12600599 0.73683447]], shape=(1, 3), dtype=float32)
Selected action 2
[0.18, 0.3, 0.25, 0.216, 0.133, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.12696698 0.11782897 0.7552041 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.08, 0.075, 0.32, 0.14, 0.134, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.14187624 0.13057218 0.7275516 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.22, 0.3, 0.27, 0.225, 0.134, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.12409551 0.11457247 0.761332  ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.06, 0.075, 0.32, 0.2, 0.135, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 129 | Average Reward: 60 | Episode Reward: 62 | Loss: 170.66 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 62.168791749415476
Probs tf.Tensor([[0.30053666 0.29756862 0.40189478]], shape=(1, 3), dtype=float32)
Selected action 2
[0.38, 0.3, 0.27, 0.253, 0.126, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.11486787 0.10300063 0.78213155]], shape=(1, 3), dtype=float32)
Selected action 2
[0.26, 0.3, 0.3, 0.23, 0.128, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.11822421 0.10821468 0.7735611 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.08, 0.075, 0.36, 0.183, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.13616568 0.12429492 0.7395394 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.16, 0.15, 0.34, 0.246, 0.125, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.12765099 0.1159803  0.75636876]], shape=(1, 3), dtype=float32)
Selected action 2
[0.21, 0.3, 0.27, 0.237, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 130 | Average Reward: 61 | Episode Reward: 77 | Loss: 263.159 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 77.3876292561713
Probs tf.Tensor([[0.30040756 0.2991853  0.40040714]], shape=(1, 3), dtype=float32)
Selected action 0
[0.08, 0.075, 0.38, 0.222, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.13208222 0.11959327 0.7483245 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.12, 0.3, 0.25, 0.244, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.12421419 0.11458656 0.7611993 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.33, 0.3, 0.28, 0.246, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.11433306 0.10293087 0.7827361 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.26, 0.3, 0.28, 0.273, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.11621851 0.10509513 0.77868634]], shape=(1, 3), dtype=float32)
Selected action 2
[0.22, 0.3, 0.27, 0.238, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 131 | Average Reward: 61 | Episode Reward: 85 | Loss: 416.725 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 85.08246676292711
Probs tf.Tensor([[0.29785824 0.2971833  0.4049584 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.11, 0.3, 0.28, 0.27, 0.13, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.11969238 0.10973879 0.77056885]], shape=(1, 3), dtype=float32)
Selected action 2
[0.27, 0.3, 0.22, 0.256, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.11652787 0.10491445 0.7785576 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.06, 0.075, 0.33, 0.225, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.13288455 0.11970731 0.74740815]], shape=(1, 3), dtype=float32)
Selected action 1
[0.11, 0.15, 0.25, 0.222, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.13038903 0.11822361 0.7513873 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.15, 0.24, 0.0, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 132 | Average Reward: 61 | Episode Reward: 77 | Loss: 264.486 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 77.63330426968295
Probs tf.Tensor([[0.29906103 0.29766694 0.4032721 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.08, 0.075, 0.29, 0.196, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.13290116 0.1197671  0.7473318 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.14, 0.3, 0.27, 0.236, 0.125, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.11808244 0.10815164 0.77376586]], shape=(1, 3), dtype=float32)
Selected action 2
[0.2, 0.3, 0.24, 0.2, 0.127, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.11783137 0.10773933 0.77442926]], shape=(1, 3), dtype=float32)
Selected action 2
[0.19, 0.3, 0.27, 0.239, 0.119, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.11614443 0.10566802 0.7781875 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.1, 0.3, 0.25, 0.233, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 133 | Average Reward: 61 | Episode Reward: 85 | Loss: 418.897 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 85.35214177643878
Probs tf.Tensor([[0.29854602 0.2966448  0.40480915]], shape=(1, 3), dtype=float32)
Selected action 2
[0.15, 0.3, 0.26, 0.229, 0.126, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.11605851 0.10578676 0.7781548 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.16, 0.3, 0.27, 0.251, 0.127, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.11458628 0.1039541  0.7814596 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.06, 0.075, 0.26, 0.146, 0.128, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.13438836 0.12173527 0.7438764 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.17, 0.15, 0.32, 0.218, 0.128, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.11982664 0.1078569  0.77231646]], shape=(1, 3), dtype=float32)
Selected action 0
[0.07, 0.075, 0.3, 0.182, 0.129, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 134 | Average Reward: 61 | Episode Reward: 62 | Loss: 143.326 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 62.66297928319461
Probs tf.Tensor([[0.2983082 0.2945519 0.4071399]], shape=(1, 3), dtype=float32)
Selected action 1
[0.2, 0.15, 0.28, 0.231, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.11942641 0.10600541 0.77456814]], shape=(1, 3), dtype=float32)
Selected action 2
[0.19, 0.3, 0.25, 0.245, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.11360534 0.10201126 0.7843834 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.13, 0.3, 0.25, 0.216, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.1167786  0.10620371 0.77701765]], shape=(1, 3), dtype=float32)
Selected action 2
[0.37, 0.3, 0.29, 0.255, 0.125, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.10463785 0.09158373 0.80377847]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.075, 0.35, 0.187, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 135 | Average Reward: 61 | Episode Reward: 78 | Loss: 283.805 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 78.00181678995042
Probs tf.Tensor([[0.301306   0.29745755 0.4012365 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.34, 0.3, 0.29, 0.251, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.10536411 0.09170843 0.8029275 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.25, 0.3, 0.27, 0.247, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.10961545 0.09672853 0.79365605]], shape=(1, 3), dtype=float32)
Selected action 2
[0.26, 0.3, 0.27, 0.259, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.10902438 0.09584329 0.79513234]], shape=(1, 3), dtype=float32)
Selected action 2
[0.15, 0.3, 0.26, 0.2, 0.125, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.11524257 0.10392871 0.7808288 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.2, 0.3, 0.26, 0.256, 0.128, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 136 | Average Reward: 62 | Episode Reward: 101 | Loss: 485.597 | Steps: 4 | Worker: 0
Saving best model to ./Training/, episode score: 101.02065429670628
Probs tf.Tensor([[0.30121094 0.29625553 0.40253356]], shape=(1, 3), dtype=float32)
Selected action 2
[0.28, 0.3, 0.3, 0.262, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.10545062 0.09155992 0.8029895 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.25, 0.3, 0.25, 0.276, 0.126, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.10839651 0.09417021 0.7974333 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.19, 0.3, 0.22, 0.266, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.1126155  0.09876789 0.7886166 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.24, 0.3, 0.28, 0.244, 0.127, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.10808125 0.09471453 0.7972042 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.15, 0.3, 0.25, 0.244, 0.126, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 137 | Average Reward: 62 | Episode Reward: 85 | Loss: 317.119 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 85.8914918034621
Probs tf.Tensor([[0.29835078 0.2942124  0.40743685]], shape=(1, 3), dtype=float32)
Selected action 2
[0.14, 0.3, 0.26, 0.253, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.11206161 0.09808609 0.7898524 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.075, 0.32, 0.231, 0.133, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.12498838 0.10863405 0.76637757]], shape=(1, 3), dtype=float32)
Selected action 2
[0.13, 0.3, 0.25, 0.231, 0.134, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.11298855 0.09946281 0.7875487 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.16, 0.3, 0.26, 0.256, 0.131, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.11073866 0.09664237 0.79261893]], shape=(1, 3), dtype=float32)
Selected action 2
[0.17, 0.3, 0.27, 0.249, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 138 | Average Reward: 62 | Episode Reward: 86 | Loss: 374.358 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 86.02632931021793
Probs tf.Tensor([[0.2945828  0.28880742 0.41660973]], shape=(1, 3), dtype=float32)
Selected action 1
[0.11, 0.15, 0.23, 0.24, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.12231565 0.10454639 0.773138  ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.11, 0.3, 0.27, 0.257, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.11211722 0.09690263 0.79098016]], shape=(1, 3), dtype=float32)
Selected action 2
[0.12, 0.3, 0.24, 0.224, 0.128, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.11371873 0.09871034 0.7875709 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.17, 0.3, 0.25, 0.221, 0.129, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.1111849  0.09590904 0.79290605]], shape=(1, 3), dtype=float32)
Selected action 2
[0.2, 0.3, 0.26, 0.237, 0.129, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 139 | Average Reward: 63 | Episode Reward: 93 | Loss: 454.965 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 93.82916681697377
Probs tf.Tensor([[0.29531208 0.2914813  0.41320664]], shape=(1, 3), dtype=float32)
Selected action 1
[0.12, 0.15, 0.27, 0.194, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.1194922  0.10187163 0.77863616]], shape=(1, 3), dtype=float32)
Selected action 2
[0.16, 0.3, 0.27, 0.237, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.10914165 0.09272594 0.7981324 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.3, 0.25, 0.242, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.1133578  0.09727214 0.78937006]], shape=(1, 3), dtype=float32)
Selected action 2
[0.21, 0.3, 0.28, 0.178, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.10812984 0.092289   0.7995811 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.12, 0.15, 0.29, 0.249, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 140 | Average Reward: 63 | Episode Reward: 86 | Loss: 366.684 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 86.29600432372958
Probs tf.Tensor([[0.29600173 0.29058275 0.41341552]], shape=(1, 3), dtype=float32)
Selected action 1
[0.16, 0.15, 0.29, 0.171, 0.125, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.11575522 0.09821492 0.7860299 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.16, 0.3, 0.26, 0.263, 0.127, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.10749709 0.09032436 0.80217856]], shape=(1, 3), dtype=float32)
Selected action 2
[0.22, 0.3, 0.3, 0.2, 0.129, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.10473507 0.08836935 0.80689555]], shape=(1, 3), dtype=float32)
Selected action 2
[0.24, 0.3, 0.28, 0.244, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.10403678 0.08664386 0.8093194 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.075, 0.3, 0.182, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 141 | Average Reward: 63 | Episode Reward: 78 | Loss: 285.915 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 78.7388418304854
Probs tf.Tensor([[0.2961143  0.29028362 0.41360205]], shape=(1, 3), dtype=float32)
Selected action 1
[0.11, 0.15, 0.28, 0.212, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.11680233 0.09818409 0.78501356]], shape=(1, 3), dtype=float32)
Selected action 2
[0.15, 0.3, 0.29, 0.218, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.10697868 0.09014997 0.80287135]], shape=(1, 3), dtype=float32)
Selected action 2
[0.1, 0.3, 0.29, 0.226, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.10877273 0.09222356 0.7990037 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.13, 0.3, 0.28, 0.21, 0.125, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.1084095  0.09177171 0.79981875]], shape=(1, 3), dtype=float32)
Selected action 2
[0.16, 0.3, 0.32, 0.226, 0.125, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 142 | Average Reward: 63 | Episode Reward: 94 | Loss: 456.599 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 94.26967933724123
Probs tf.Tensor([[0.2965967  0.29213378 0.4112695 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.07, 0.075, 0.27, 0.19, 0.126, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.1224675  0.10246754 0.77506495]], shape=(1, 3), dtype=float32)
Selected action 2
[0.17, 0.3, 0.25, 0.248, 0.127, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.10580102 0.0876578  0.80654114]], shape=(1, 3), dtype=float32)
Selected action 2
[0.2, 0.3, 0.26, 0.272, 0.128, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.10348138 0.08486964 0.81164896]], shape=(1, 3), dtype=float32)
Selected action 2
[0.09, 0.3, 0.24, 0.224, 0.128, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.11006685 0.09280463 0.79712856]], shape=(1, 3), dtype=float32)
Selected action 0
[0.08, 0.075, 0.28, 0.185, 0.128, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 143 | Average Reward: 63 | Episode Reward: 71 | Loss: 259.261 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 71.26851684399706
Probs tf.Tensor([[0.2952372  0.29171094 0.41305184]], shape=(1, 3), dtype=float32)
Selected action 0
[0.08, 0.075, 0.27, 0.176, 0.127, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.12139376 0.10090548 0.7777008 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.11, 0.3, 0.25, 0.204, 0.128, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.10843877 0.0906186  0.80094266]], shape=(1, 3), dtype=float32)
Selected action 1
[0.06, 0.15, 0.21, 0.156, 0.128, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.12209919 0.10259267 0.7753082 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.1, 0.075, 0.29, 0.184, 0.129, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.11891644 0.09860215 0.78248143]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.075, 0.31, 0.172, 0.13, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 144 | Average Reward: 63 | Episode Reward: 48 | Loss: 100.716 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 48.19535435075289
Probs tf.Tensor([[0.29461163 0.2905591  0.4148292 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.08, 0.075, 0.31, 0.194, 0.127, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.11866204 0.09748204 0.7838559 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.22, 0.3, 0.26, 0.247, 0.128, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.1025396  0.08239567 0.8150647 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.19, 0.3, 0.26, 0.173, 0.129, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.10559996 0.08673571 0.8076643 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.27, 0.3, 0.27, 0.228, 0.129, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.10061927 0.08047586 0.8189049 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.23, 0.3, 0.27, 0.202, 0.129, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 145 | Average Reward: 63 | Episode Reward: 86 | Loss: 424.919 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 86.97019185750871
Probs tf.Tensor([[0.2950267 0.2891403 0.415833 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.06, 0.075, 0.31, 0.16, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.1203879  0.09882955 0.7807826 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.3, 0.34, 0.172, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.10705458 0.0890731  0.80387235]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.3, 0.36, 0.192, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.10595366 0.08791788 0.80612844]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.3, 0.31, 0.152, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.10900591 0.09107609 0.799918  ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.11, 0.3, 0.37, 0.152, 0.125, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 146 | Average Reward: 64 | Episode Reward: 87 | Loss: 426.347 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 87.10502936426455
Probs tf.Tensor([[0.29618365 0.28910318 0.4147132 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.2, 0.3, 0.25, 0.247, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.10246223 0.08072446 0.8168133 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.28, 0.3, 0.28, 0.264, 0.125, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.09745519 0.07536202 0.82718277]], shape=(1, 3), dtype=float32)
Selected action 0
[0.07, 0.075, 0.39, 0.186, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.11374458 0.09196687 0.7942886 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.18, 0.3, 0.26, 0.246, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.10272112 0.08125749 0.81602144]], shape=(1, 3), dtype=float32)
Selected action 2
[0.4, 0.3, 0.29, 0.246, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 147 | Average Reward: 64 | Episode Reward: 87 | Loss: 341.75 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 87.23986687102038
Probs tf.Tensor([[0.29736972 0.28907275 0.4135575 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.14, 0.15, 0.28, 0.229, 0.126, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.11035562 0.08651729 0.8031271 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.19, 0.3, 0.26, 0.254, 0.128, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.10139626 0.07865912 0.8199446 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.27, 0.3, 0.29, 0.243, 0.129, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.09717718 0.07443561 0.82838726]], shape=(1, 3), dtype=float32)
Selected action 2
[0.17, 0.3, 0.25, 0.254, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.10283508 0.08008074 0.8170842 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.35, 0.3, 0.29, 0.233, 0.125, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 148 | Average Reward: 64 | Episode Reward: 87 | Loss: 384.738 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 87.3747043777762
Probs tf.Tensor([[0.29417056 0.28790402 0.41792536]], shape=(1, 3), dtype=float32)
Selected action 2
[0.16, 0.3, 0.26, 0.206, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.10353748 0.0812008  0.8152617 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.26, 0.3, 0.27, 0.249, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.09808683 0.07469019 0.827223  ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.31, 0.15, 0.27, 0.162, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.10525192 0.08070297 0.81404513]], shape=(1, 3), dtype=float32)
Selected action 2
[0.19, 0.3, 0.28, 0.237, 0.125, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.10046998 0.0777733  0.8217568 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.14, 0.3, 0.26, 0.204, 0.126, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 149 | Average Reward: 64 | Episode Reward: 95 | Loss: 418.207 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 95.29754188453202
Probs tf.Tensor([[0.29329768 0.28630984 0.4203925 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.14, 0.15, 0.25, 0.214, 0.125, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.11118522 0.08706386 0.80175096]], shape=(1, 3), dtype=float32)
Selected action 2
[0.11, 0.3, 0.25, 0.222, 0.126, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.10477759 0.08274338 0.812479  ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.18, 0.3, 0.27, 0.171, 0.127, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.10242278 0.08080408 0.8167731 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.16, 0.3, 0.26, 0.196, 0.127, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.10300877 0.08109677 0.8158945 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.13, 0.3, 0.25, 0.204, 0.127, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 150 | Average Reward: 65 | Episode Reward: 95 | Loss: 461.692 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 95.44437939128785
Probs tf.Tensor([[0.29253143 0.2855066  0.4219619 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.09, 0.3, 0.22, 0.215, 0.127, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.1060067  0.08433093 0.8096624 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.11, 0.075, 0.32, 0.148, 0.128, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.11325836 0.09051765 0.79622394]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.3, 0.23, 0.185, 0.128, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.10709476 0.08609705 0.8068082 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.16, 0.3, 0.25, 0.214, 0.129, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.10171732 0.07994609 0.8183366 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.2, 0.3, 0.26, 0.244, 0.129, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 151 | Average Reward: 65 | Episode Reward: 87 | Loss: 380.836 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 87.77921689804369
Probs tf.Tensor([[0.2985542  0.29247698 0.4089688 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.09, 0.075, 0.35, 0.175, 0.127, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.11097595 0.08825202 0.8007721 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.08, 0.075, 0.28, 0.174, 0.128, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.11542534 0.09166533 0.7929093 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.18, 0.3, 0.26, 0.248, 0.129, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.09874891 0.0764984  0.8247527 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.29, 0.3, 0.27, 0.263, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.09408019 0.07109894 0.83482087]], shape=(1, 3), dtype=float32)
Selected action 0
[0.07, 0.075, 0.4, 0.19, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 152 | Average Reward: 65 | Episode Reward: 56 | Loss: 176.717 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 56.61805440479951
Probs tf.Tensor([[0.29147935 0.28496847 0.42355216]], shape=(1, 3), dtype=float32)
Selected action 2
[0.29, 0.3, 0.28, 0.227, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.094851   0.07160665 0.8335424 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.06, 0.075, 0.32, 0.168, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.11484441 0.0908874  0.7942682 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.21, 0.3, 0.26, 0.226, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.0987298  0.07572909 0.8255411 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.19, 0.3, 0.27, 0.242, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.09860146 0.0756418  0.8257567 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.14, 0.15, 0.33, 0.151, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 153 | Average Reward: 65 | Episode Reward: 80 | Loss: 297.537 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 80.21289191155533
Probs tf.Tensor([[0.2958702  0.2895404  0.41458938]], shape=(1, 3), dtype=float32)
Selected action 1
[0.15, 0.15, 0.34, 0.22, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.10535755 0.08101774 0.8136247 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.11, 0.3, 0.24, 0.217, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.10487437 0.08159622 0.81352943]], shape=(1, 3), dtype=float32)
Selected action 1
[0.07, 0.15, 0.33, 0.189, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.11007263 0.08645643 0.80347097]], shape=(1, 3), dtype=float32)
Selected action 2
[0.2, 0.3, 0.27, 0.224, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.09975891 0.07616693 0.8240741 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.24, 0.3, 0.26, 0.26, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 154 | Average Reward: 65 | Episode Reward: 88 | Loss: 387.94 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 88.18372941831116
Probs tf.Tensor([[0.2933664  0.28622696 0.42040658]], shape=(1, 3), dtype=float32)
Selected action 1
[0.06, 0.15, 0.25, 0.192, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.1158745  0.09101383 0.79311174]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.3, 0.21, 0.194, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.10921481 0.08600149 0.8047837 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.3, 0.24, 0.171, 0.125, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.10902771 0.08664074 0.80433154]], shape=(1, 3), dtype=float32)
Selected action 0
[0.09, 0.075, 0.3, 0.172, 0.125, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.1162226  0.09103612 0.79274136]], shape=(1, 3), dtype=float32)
Selected action 2
[0.09, 0.3, 0.25, 0.186, 0.126, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 155 | Average Reward: 65 | Episode Reward: 80 | Loss: 295.703 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 80.45856692506699
Probs tf.Tensor([[0.2966051  0.28986028 0.41353455]], shape=(1, 3), dtype=float32)
Selected action 0
[0.08, 0.075, 0.29, 0.185, 0.128, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.11793924 0.09201586 0.7900449 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.22, 0.3, 0.27, 0.222, 0.129, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.10104237 0.07682633 0.82213134]], shape=(1, 3), dtype=float32)
Selected action 2
[0.16, 0.3, 0.24, 0.238, 0.129, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.1043613  0.07999872 0.81564003]], shape=(1, 3), dtype=float32)
Selected action 2
[0.16, 0.3, 0.27, 0.221, 0.13, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.10325323 0.07946686 0.8172799 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.11, 0.3, 0.26, 0.208, 0.131, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 156 | Average Reward: 66 | Episode Reward: 88 | Loss: 430.661 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 88.4534044318228
Probs tf.Tensor([[0.29644847 0.29033557 0.41321597]], shape=(1, 3), dtype=float32)
Selected action 2
[0.12, 0.3, 0.24, 0.2, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.10783997 0.08382522 0.8083348 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.11, 0.3, 0.24, 0.174, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.10892274 0.08534408 0.80573314]], shape=(1, 3), dtype=float32)
Selected action 2
[0.17, 0.3, 0.26, 0.162, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.10585336 0.08225825 0.8118884 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.33, 0.3, 0.28, 0.26, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.09639988 0.07084123 0.8327589 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.21, 0.3, 0.27, 0.267, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 157 | Average Reward: 66 | Episode Reward: 104 | Loss: 502.348 | Steps: 4 | Worker: 0
Saving best model to ./Training/, episode score: 104.35624193857865
Probs tf.Tensor([[0.29718477 0.2905868  0.4122284 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.1, 0.075, 0.38, 0.172, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.11273773 0.08774042 0.79952186]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.3, 0.37, 0.208, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.10334784 0.08097869 0.8156735 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.3, 0.35, 0.192, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.10428505 0.08189649 0.81381845]], shape=(1, 3), dtype=float32)
Selected action 2
[0.09, 0.3, 0.38, 0.143, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.10293752 0.08130833 0.8157542 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.3, 0.33, 0.12, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 158 | Average Reward: 66 | Episode Reward: 88 | Loss: 431.106 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 88.72307944533448
Probs tf.Tensor([[0.29356343 0.28781185 0.41862476]], shape=(1, 3), dtype=float32)
Selected action 1
[0.15, 0.15, 0.35, 0.214, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.10636433 0.08111669 0.81251895]], shape=(1, 3), dtype=float32)
Selected action 2
[0.29, 0.3, 0.28, 0.261, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.09667803 0.07113125 0.8321907 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.19, 0.3, 0.26, 0.242, 0.125, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.1017065  0.07670795 0.8215855 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.12, 0.3, 0.22, 0.243, 0.125, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.10639494 0.08135679 0.8122483 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.11, 0.3, 0.25, 0.232, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 159 | Average Reward: 66 | Episode Reward: 96 | Loss: 464.74 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 96.76591695209031
Probs tf.Tensor([[0.29519156 0.2899365  0.41487187]], shape=(1, 3), dtype=float32)
Selected action 2
[0.19, 0.3, 0.27, 0.233, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.10019433 0.07556789 0.8242378 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.19, 0.3, 0.26, 0.243, 0.128, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.10016775 0.07536153 0.82447076]], shape=(1, 3), dtype=float32)
Selected action 2
[0.17, 0.3, 0.26, 0.274, 0.129, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.10003123 0.07499631 0.82497245]], shape=(1, 3), dtype=float32)
Selected action 1
[0.22, 0.15, 0.3, 0.224, 0.13, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.10408552 0.07799375 0.81792074]], shape=(1, 3), dtype=float32)
Selected action 2
[0.14, 0.3, 0.25, 0.215, 0.13, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 160 | Average Reward: 67 | Episode Reward: 96 | Loss: 411.322 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 96.91275445884614
Probs tf.Tensor([[0.2971209  0.29088572 0.4119934 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.06, 0.075, 0.31, 0.198, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.11407369 0.08842549 0.7975008 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.11, 0.3, 0.22, 0.178, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.10590801 0.08258972 0.8115023 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.19, 0.3, 0.28, 0.211, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.09882241 0.07528587 0.8258917 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.22, 0.3, 0.26, 0.22, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.09848724 0.07442496 0.82708776]], shape=(1, 3), dtype=float32)
Selected action 2
[0.15, 0.3, 0.26, 0.232, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 161 | Average Reward: 67 | Episode Reward: 89 | Loss: 433.649 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 89.12759196560197
Probs tf.Tensor([[0.29206392 0.28601494 0.42192113]], shape=(1, 3), dtype=float32)
Selected action 2
[0.36, 0.3, 0.2, 0.22, 0.121, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.09481376 0.0699565  0.8352297 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.19, 0.3, 0.19, 0.256, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.1004694 0.0759891 0.8235415]], shape=(1, 3), dtype=float32)
Selected action 2
[0.13, 0.3, 0.25, 0.164, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.10223878 0.07993187 0.8178293 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.17, 0.3, 0.22, 0.223, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.10058333 0.07697935 0.8224373 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.16, 0.3, 0.25, 0.21, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 162 | Average Reward: 67 | Episode Reward: 105 | Loss: 503.741 | Steps: 4 | Worker: 0
Saving best model to ./Training/, episode score: 105.15042947235779
Probs tf.Tensor([[0.29322925 0.2882737  0.41849706]], shape=(1, 3), dtype=float32)
Selected action 1
[0.19, 0.15, 0.25, 0.189, 0.126, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.10352403 0.07945369 0.81702226]], shape=(1, 3), dtype=float32)
Selected action 2
[0.17, 0.3, 0.26, 0.233, 0.128, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.09572571 0.07326914 0.83100516]], shape=(1, 3), dtype=float32)
Selected action 2
[0.12, 0.3, 0.24, 0.212, 0.128, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.0992246  0.07704293 0.82373244]], shape=(1, 3), dtype=float32)
Selected action 2
[0.23, 0.3, 0.26, 0.256, 0.129, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.09289365 0.06987009 0.8372362 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.24, 0.3, 0.27, 0.26, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 163 | Average Reward: 68 | Episode Reward: 97 | Loss: 468.222 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 97.35326697911361
Probs tf.Tensor([[0.29392073 0.28787982 0.41819948]], shape=(1, 3), dtype=float32)
Selected action 0
[0.09, 0.075, 0.32, 0.171, 0.129, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.1055982  0.08288309 0.8115187 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.31, 0.3, 0.28, 0.248, 0.13, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.0866542  0.06451011 0.84883565]], shape=(1, 3), dtype=float32)
Selected action 2
[0.33, 0.3, 0.28, 0.226, 0.13, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.08653048 0.06449991 0.84896964]], shape=(1, 3), dtype=float32)
Selected action 2
[0.28, 0.3, 0.29, 0.262, 0.131, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.08682033 0.06480087 0.8483788 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.23, 0.3, 0.26, 0.251, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 164 | Average Reward: 68 | Episode Reward: 89 | Loss: 432.166 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 89.53210448586945
Probs tf.Tensor([[0.2947533  0.2889421  0.41630453]], shape=(1, 3), dtype=float32)
Selected action 2
[0.26, 0.3, 0.32, 0.247, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.08410806 0.06340286 0.85248905]], shape=(1, 3), dtype=float32)
Selected action 2
[0.14, 0.3, 0.26, 0.262, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.09082694 0.06985572 0.8393174 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.25, 0.3, 0.26, 0.241, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.0874091  0.0661241  0.84646684]], shape=(1, 3), dtype=float32)
Selected action 1
[0.14, 0.15, 0.31, 0.204, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.09660967 0.07498031 0.8284101 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.19, 0.3, 0.26, 0.191, 0.125, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 165 | Average Reward: 68 | Episode Reward: 97 | Loss: 412.841 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 97.64694199262527
Probs tf.Tensor([[0.2911791 0.2851976 0.4236233]], shape=(1, 3), dtype=float32)
Selected action 2
[0.23, 0.3, 0.28, 0.23, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.08499022 0.06532353 0.8496862 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.3, 0.23, 0.214, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.09382211 0.07452793 0.83164996]], shape=(1, 3), dtype=float32)
Selected action 2
[0.19, 0.3, 0.26, 0.169, 0.125, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.08895022 0.06987168 0.84117806]], shape=(1, 3), dtype=float32)
Selected action 2
[0.11, 0.3, 0.24, 0.198, 0.125, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.09216456 0.07295465 0.83488077]], shape=(1, 3), dtype=float32)
Selected action 2
[0.18, 0.3, 0.26, 0.211, 0.125, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 166 | Average Reward: 69 | Episode Reward: 105 | Loss: 506.1 | Steps: 4 | Worker: 0
Saving best model to ./Training/, episode score: 105.78577949938109
Probs tf.Tensor([[0.28907803 0.28603676 0.42488515]], shape=(1, 3), dtype=float32)
Selected action 2
[0.25, 0.3, 0.19, 0.233, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.08561414 0.06603995 0.8483459 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.23, 0.3, 0.19, 0.247, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.08586622 0.06627145 0.8478623 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.2, 0.3, 0.13, 0.258, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.08977856 0.06955037 0.8406711 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.08, 0.075, 0.31, 0.188, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.09801715 0.07803182 0.82395107]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.3, 0.24, 0.225, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 167 | Average Reward: 69 | Episode Reward: 89 | Loss: 328.184 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 89.93661700613693
Probs tf.Tensor([[0.28903735 0.28555074 0.42541185]], shape=(1, 3), dtype=float32)
Selected action 0
[0.1, 0.075, 0.27, 0.173, 0.13, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.09705684 0.07746466 0.8254785 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.3, 0.23, 0.2, 0.132, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.08940084 0.07221638 0.8383828 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.1, 0.075, 0.27, 0.121, 0.133, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.09851997 0.079593   0.821887  ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.2, 0.3, 0.27, 0.235, 0.133, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.08081726 0.06309128 0.85609144]], shape=(1, 3), dtype=float32)
Selected action 1
[0.14, 0.15, 0.28, 0.21, 0.133, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 168 | Average Reward: 69 | Episode Reward: 66 | Loss: 216.147 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 66.02345451289276
Probs tf.Tensor([[0.28948766 0.28473085 0.4257815 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.33, 0.3, 0.3, 0.261, 0.128, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.07343188 0.05577197 0.87079614]], shape=(1, 3), dtype=float32)
Selected action 2
[0.19, 0.3, 0.28, 0.254, 0.13, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.0791439  0.06182797 0.8590281 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.14, 0.15, 0.33, 0.218, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.08622605 0.06816076 0.8456132 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.2, 0.3, 0.26, 0.257, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.07989629 0.0622499  0.8578538 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.38, 0.3, 0.28, 0.272, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 169 | Average Reward: 69 | Episode Reward: 98 | Loss: 425.142 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 98.23429201964859
Probs tf.Tensor([[0.28963527 0.28621417 0.42415056]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.075, 0.32, 0.165, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.09478008 0.07719239 0.82802755]], shape=(1, 3), dtype=float32)
Selected action 2
[0.09, 0.3, 0.37, 0.192, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.07937108 0.06466783 0.8559611 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.09, 0.3, 0.36, 0.214, 0.125, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.07921107 0.06421889 0.85657007]], shape=(1, 3), dtype=float32)
Selected action 0
[0.08, 0.075, 0.37, 0.152, 0.125, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.09089419 0.07419351 0.83491236]], shape=(1, 3), dtype=float32)
Selected action 2
[0.1, 0.3, 0.36, 0.162, 0.126, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 170 | Average Reward: 69 | Episode Reward: 74 | Loss: 268.382 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 74.2611295264044
Probs tf.Tensor([[0.28861013 0.28449517 0.42689475]], shape=(1, 3), dtype=float32)
Selected action 1
[0.17, 0.15, 0.33, 0.231, 0.121, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.08320071 0.06610278 0.85069656]], shape=(1, 3), dtype=float32)
Selected action 0
[0.08, 0.075, 0.36, 0.196, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.08972008 0.07265734 0.83762264]], shape=(1, 3), dtype=float32)
Selected action 0
[0.03, 0.075, 0.25, 0.168, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.09908786 0.08081464 0.82009745]], shape=(1, 3), dtype=float32)
Selected action 2
[0.3, 0.3, 0.25, 0.25, 0.125, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.07557356 0.05872989 0.86569655]], shape=(1, 3), dtype=float32)
Selected action 2
[0.15, 0.3, 0.24, 0.239, 0.125, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 171 | Average Reward: 69 | Episode Reward: 66 | Loss: 224.678 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 66.31996703316022
Probs tf.Tensor([[0.28673095 0.2818341  0.431435  ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.24, 0.3, 0.28, 0.222, 0.121, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.07781731 0.06132619 0.86085653]], shape=(1, 3), dtype=float32)
Selected action 2
[0.13, 0.3, 0.26, 0.223, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.08262205 0.0663157  0.85106224]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.3, 0.23, 0.233, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.08731816 0.07095862 0.84172314]], shape=(1, 3), dtype=float32)
Selected action 2
[0.12, 0.3, 0.23, 0.238, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.08400936 0.06729905 0.8486915 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.13, 0.3, 0.26, 0.244, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 172 | Average Reward: 69 | Episode Reward: 106 | Loss: 508.641 | Steps: 4 | Worker: 0
Saving best model to ./Training/, episode score: 106.73880453991603
Probs tf.Tensor([[0.28609473 0.28188083 0.4320245 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.26, 0.3, 0.26, 0.223, 0.127, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.077765   0.06084127 0.86139375]], shape=(1, 3), dtype=float32)
Selected action 2
[0.13, 0.3, 0.21, 0.248, 0.121, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.08447657 0.06716058 0.8483628 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.14, 0.3, 0.25, 0.196, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.08353647 0.06709293 0.8493706 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.25, 0.3, 0.27, 0.232, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.07753947 0.06065293 0.86180764]], shape=(1, 3), dtype=float32)
Selected action 2
[0.12, 0.3, 0.24, 0.17, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 173 | Average Reward: 70 | Episode Reward: 106 | Loss: 508.896 | Steps: 4 | Worker: 0
Saving best model to ./Training/, episode score: 106.89764204667188
Probs tf.Tensor([[0.28764388 0.28175765 0.43059844]], shape=(1, 3), dtype=float32)
Selected action 0
[0.07, 0.075, 0.32, 0.148, 0.13, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.09353888 0.07578311 0.83067805]], shape=(1, 3), dtype=float32)
Selected action 2
[0.25, 0.3, 0.27, 0.255, 0.131, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.07605143 0.05899128 0.8649573 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.17, 0.3, 0.25, 0.215, 0.132, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.080865   0.06413701 0.85499805]], shape=(1, 3), dtype=float32)
Selected action 2
[0.1, 0.3, 0.21, 0.19, 0.133, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.08611311 0.06947804 0.8444089 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.35, 0.3, 0.3, 0.237, 0.133, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 174 | Average Reward: 70 | Episode Reward: 90 | Loss: 436.851 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 90.8804795534277
Probs tf.Tensor([[0.28459194 0.27795914 0.43744892]], shape=(1, 3), dtype=float32)
Selected action 0
[0.07, 0.075, 0.38, 0.169, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.08909938 0.0716382  0.8392625 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.3, 0.34, 0.178, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.08104928 0.06580352 0.85314715]], shape=(1, 3), dtype=float32)
Selected action 1
[0.11, 0.15, 0.37, 0.158, 0.125, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.08459548 0.06802163 0.8473829 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.09, 0.3, 0.35, 0.188, 0.125, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.07915223 0.06379966 0.85704815]], shape=(1, 3), dtype=float32)
Selected action 2
[0.12, 0.3, 0.35, 0.158, 0.125, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 175 | Average Reward: 70 | Episode Reward: 82 | Loss: 361.494 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 82.91531706018354
Probs tf.Tensor([[0.28565887 0.27954566 0.43479547]], shape=(1, 3), dtype=float32)
Selected action 2
[0.24, 0.3, 0.27, 0.259, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.07512077 0.0581517  0.8667275 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.26, 0.3, 0.25, 0.252, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.07551587 0.05833755 0.86614656]], shape=(1, 3), dtype=float32)
Selected action 2
[0.29, 0.3, 0.27, 0.255, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.07354382 0.05648958 0.8699666 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.22, 0.3, 0.27, 0.216, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.07700153 0.06037961 0.86261886]], shape=(1, 3), dtype=float32)
Selected action 2
[0.41, 0.3, 0.27, 0.246, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 176 | Average Reward: 70 | Episode Reward: 107 | Loss: 508.132 | Steps: 4 | Worker: 0
Saving best model to ./Training/, episode score: 107.37415456693935
Probs tf.Tensor([[0.28800696 0.28135037 0.4306426 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.09, 0.075, 0.31, 0.143, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.09096019 0.07340019 0.83563966]], shape=(1, 3), dtype=float32)
Selected action 2
[0.17, 0.3, 0.25, 0.224, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.07835554 0.06191956 0.85972494]], shape=(1, 3), dtype=float32)
Selected action 0
[0.08, 0.075, 0.3, 0.177, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.0908538  0.07280014 0.8363461 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.11, 0.3, 0.26, 0.177, 0.125, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.08130166 0.06558658 0.8531118 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.14, 0.3, 0.26, 0.212, 0.125, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 177 | Average Reward: 71 | Episode Reward: 75 | Loss: 289.759 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 75.03699207369519
Probs tf.Tensor([[0.2853716  0.27770332 0.43692505]], shape=(1, 3), dtype=float32)
Selected action 0
[0.11, 0.075, 0.26, 0.202, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.090507   0.07144442 0.8380486 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.3, 0.29, 0.175, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.08063997 0.06514451 0.8542155 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.3, 0.3, 0.16, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.08167635 0.06654696 0.8517767 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.3, 0.28, 0.149, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.08258722 0.06732897 0.85008377]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.3, 0.27, 0.14, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 178 | Average Reward: 71 | Episode Reward: 91 | Loss: 439.313 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 91.41982958045101
Probs tf.Tensor([[0.28583804 0.2768492  0.43731278]], shape=(1, 3), dtype=float32)
Selected action 1
[0.19, 0.15, 0.27, 0.216, 0.131, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.08145477 0.06325514 0.85529006]], shape=(1, 3), dtype=float32)
Selected action 2
[0.15, 0.3, 0.26, 0.212, 0.131, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.07734998 0.06090054 0.8617495 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.18, 0.3, 0.26, 0.216, 0.132, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.07611406 0.05956816 0.86431783]], shape=(1, 3), dtype=float32)
Selected action 1
[0.16, 0.15, 0.26, 0.215, 0.132, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.08308326 0.06486478 0.8520519 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.12, 0.3, 0.25, 0.186, 0.133, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 179 | Average Reward: 71 | Episode Reward: 91 | Loss: 383.384 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 91.55466708720685
Probs tf.Tensor([[0.28767207 0.27803946 0.4342885 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.3, 0.21, 0.252, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.08117349 0.06427511 0.8545514 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.27, 0.3, 0.27, 0.264, 0.125, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.07098176 0.0543121  0.87470615]], shape=(1, 3), dtype=float32)
Selected action 2
[0.33, 0.3, 0.29, 0.255, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.06842549 0.05191314 0.8796613 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.28, 0.3, 0.28, 0.253, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.07056139 0.05403424 0.87540436]], shape=(1, 3), dtype=float32)
Selected action 2
[0.16, 0.3, 0.23, 0.268, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 180 | Average Reward: 71 | Episode Reward: 108 | Loss: 511.009 | Steps: 4 | Worker: 0
Saving best model to ./Training/, episode score: 108.00950459396267
Probs tf.Tensor([[0.28551555 0.27548197 0.43900254]], shape=(1, 3), dtype=float32)
Selected action 2
[0.13, 0.3, 0.25, 0.204, 0.128, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.07730545 0.0615379  0.86115664]], shape=(1, 3), dtype=float32)
Selected action 2
[0.24, 0.3, 0.28, 0.221, 0.129, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.07149924 0.05567959 0.8728212 ]], shape=(1, 3), dtype=float32)
Selected action 2
[1.07, 0.3, 0.2, 0.0, 0.115, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.05731983 0.04417817 0.898502  ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.26, 0.3, 0.28, 0.266, 0.127, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.06973615 0.05358985 0.87667406]], shape=(1, 3), dtype=float32)
Selected action 2
[0.34, 0.3, 0.29, 0.263, 0.128, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 181 | Average Reward: 72 | Episode Reward: 108 | Loss: 510.459 | Steps: 4 | Worker: 0
Saving best model to ./Training/, episode score: 108.16834210071852
Probs tf.Tensor([[0.28317988 0.27438343 0.44243667]], shape=(1, 3), dtype=float32)
Selected action 1
[0.17, 0.15, 0.33, 0.233, 0.128, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.07588185 0.05940004 0.86471814]], shape=(1, 3), dtype=float32)
Selected action 2
[0.28, 0.3, 0.27, 0.25, 0.129, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.06839747 0.05269295 0.8789095 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.13, 0.3, 0.25, 0.214, 0.13, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.07548864 0.06009882 0.8644126 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.17, 0.3, 0.27, 0.236, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.07277609 0.05728444 0.86993945]], shape=(1, 3), dtype=float32)
Selected action 2
[0.18, 0.3, 0.26, 0.223, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 182 | Average Reward: 72 | Episode Reward: 100 | Loss: 473.105 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 100.14317960747431
Probs tf.Tensor([[0.2842065  0.2754536  0.44033986]], shape=(1, 3), dtype=float32)
Selected action 1
[0.01, 0.15, 0.16, 0.113, 0.127, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.094087   0.0769996  0.82891333]], shape=(1, 3), dtype=float32)
Selected action 2
[0.24, 0.3, 0.27, 0.234, 0.128, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.06856278 0.05355256 0.8778847 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.21, 0.3, 0.27, 0.21, 0.129, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.07018735 0.05538709 0.8744256 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.1, 0.3, 0.24, 0.2, 0.13, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.0757753  0.06101666 0.8632081 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.06, 0.15, 0.24, 0.151, 0.13, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 183 | Average Reward: 72 | Episode Reward: 92 | Loss: 383.876 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 92.09401711423016
Probs tf.Tensor([[0.28136307 0.27277052 0.44586635]], shape=(1, 3), dtype=float32)
Selected action 1
[0.12, 0.15, 0.25, 0.213, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.07938091 0.06373677 0.85688233]], shape=(1, 3), dtype=float32)
Selected action 2
[0.17, 0.3, 0.26, 0.226, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.07051779 0.05642492 0.8730573 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.17, 0.3, 0.26, 0.237, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.07018515 0.05602639 0.8737885 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.17, 0.3, 0.24, 0.25, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.07073981 0.05629345 0.87296677]], shape=(1, 3), dtype=float32)
Selected action 2
[0.11, 0.3, 0.24, 0.157, 0.125, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 184 | Average Reward: 72 | Episode Reward: 100 | Loss: 475.526 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 100.43685462098598
Probs tf.Tensor([[0.28240708 0.27404624 0.44354665]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.075, 0.29, 0.173, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.08359731 0.0686113  0.8477914 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.19, 0.3, 0.34, 0.196, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.06554654 0.0532842  0.88116926]], shape=(1, 3), dtype=float32)
Selected action 1
[0.09, 0.15, 0.36, 0.167, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.07485036 0.06176136 0.8633883 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.3, 0.33, 0.119, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.07299099 0.06167519 0.8653338 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.3, 0.34, 0.212, 0.125, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 185 | Average Reward: 73 | Episode Reward: 84 | Loss: 363.439 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 84.14369212774183
Probs tf.Tensor([[0.2819045  0.27574894 0.4423466 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.075, 0.33, 0.131, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.08190954 0.06903657 0.84905386]], shape=(1, 3), dtype=float32)
Selected action 2
[0.27, 0.3, 0.25, 0.268, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.06367564 0.05107331 0.88525105]], shape=(1, 3), dtype=float32)
Selected action 2
[0.2, 0.3, 0.24, 0.257, 0.127, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.06665664 0.05417704 0.87916636]], shape=(1, 3), dtype=float32)
Selected action 2
[0.22, 0.3, 0.28, 0.249, 0.128, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.06442036 0.05232872 0.8832509 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.3, 0.3, 0.27, 0.256, 0.128, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 186 | Average Reward: 73 | Episode Reward: 92 | Loss: 439.148 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 92.49852963449763
Probs tf.Tensor([[0.28104553 0.27457416 0.44438034]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.075, 0.32, 0.192, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.078836  0.0662614 0.8549026]], shape=(1, 3), dtype=float32)
Selected action 2
[0.22, 0.3, 0.25, 0.263, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.0642266  0.05268231 0.88309115]], shape=(1, 3), dtype=float32)
Selected action 2
[0.31, 0.3, 0.29, 0.262, 0.125, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.05960227 0.04827401 0.8921237 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.18, 0.3, 0.26, 0.252, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.06553272 0.05422239 0.8802449 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.3, 0.3, 0.28, 0.252, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 187 | Average Reward: 73 | Episode Reward: 92 | Loss: 438.29 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 92.63336714125347
Probs tf.Tensor([[0.2838412  0.27782816 0.4383306 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.18, 0.3, 0.27, 0.206, 0.125, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.06480576 0.0547293  0.880465  ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.23, 0.3, 0.26, 0.226, 0.126, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.062963   0.05254121 0.88449585]], shape=(1, 3), dtype=float32)
Selected action 2
[0.22, 0.3, 0.27, 0.2, 0.126, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.06354533 0.05340615 0.88304853]], shape=(1, 3), dtype=float32)
Selected action 0
[0.1, 0.075, 0.31, 0.188, 0.127, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.07554817 0.06390017 0.8605517 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.21, 0.3, 0.28, 0.257, 0.128, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 188 | Average Reward: 73 | Episode Reward: 92 | Loss: 331.196 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 92.76820464800929
Probs tf.Tensor([[0.2817772  0.27508304 0.4431398 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.3, 0.21, 0.204, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.07083798 0.06100985 0.86815214]], shape=(1, 3), dtype=float32)
Selected action 0
[0.07, 0.075, 0.31, 0.168, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.0767439  0.06559104 0.857665  ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.22, 0.3, 0.26, 0.233, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.06236979 0.052284   0.88534623]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.3, 0.23, 0.2, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.06955315 0.05989994 0.870547  ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.17, 0.3, 0.25, 0.239, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 189 | Average Reward: 73 | Episode Reward: 92 | Loss: 390.677 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 92.90304215476513
Probs tf.Tensor([[0.27844515 0.27123818 0.45031664]], shape=(1, 3), dtype=float32)
Selected action 2
[0.23, 0.3, 0.23, 0.24, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.0628329  0.05238332 0.8847838 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.09, 0.075, 0.27, 0.165, 0.121, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.07769717 0.06606263 0.85624015]], shape=(1, 3), dtype=float32)
Selected action 2
[0.11, 0.3, 0.32, 0.198, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.06417742 0.05510245 0.8807202 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.075, 0.35, 0.196, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.07436896 0.06329712 0.8623339 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.15, 0.3, 0.32, 0.2, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 190 | Average Reward: 73 | Episode Reward: 76 | Loss: 229.197 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 76.47787966152094
Probs tf.Tensor([[0.2831716  0.27679175 0.44003662]], shape=(1, 3), dtype=float32)
Selected action 2
[0.28, 0.3, 0.28, 0.236, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.05977289 0.04907592 0.89115125]], shape=(1, 3), dtype=float32)
Selected action 2
[0.14, 0.3, 0.26, 0.243, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.06511657 0.05451977 0.8803637 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.13, 0.15, 0.31, 0.171, 0.125, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.0709142  0.05987068 0.8692151 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.27, 0.3, 0.32, 0.231, 0.125, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.05852384 0.04823659 0.8932396 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.57, 0.3, 0.31, 0.265, 0.126, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 191 | Average Reward: 74 | Episode Reward: 101 | Loss: 431.488 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 101.46471716827678
Probs tf.Tensor([[0.28225207 0.2752395  0.44250846]], shape=(1, 3), dtype=float32)
Selected action 0
[0.09, 0.075, 0.38, 0.167, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.07329508 0.06198424 0.86472064]], shape=(1, 3), dtype=float32)
Selected action 2
[0.1, 0.3, 0.36, 0.164, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.06491379 0.05565276 0.87943345]], shape=(1, 3), dtype=float32)
Selected action 0
[0.09, 0.075, 0.34, 0.184, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.07465741 0.06280483 0.86253774]], shape=(1, 3), dtype=float32)
Selected action 0
[0.08, 0.075, 0.35, 0.131, 0.125, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.07607993 0.06486306 0.85905707]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.3, 0.35, 0.128, 0.125, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 192 | Average Reward: 73 | Episode Reward: 60 | Loss: 152.387 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 60.0915546750326
Probs tf.Tensor([[0.28266054 0.27302662 0.4443129 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.08, 0.075, 0.41, 0.178, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.07342476 0.06153461 0.86504066]], shape=(1, 3), dtype=float32)
Selected action 2
[0.13, 0.3, 0.26, 0.247, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.06746322 0.05597517 0.87656164]], shape=(1, 3), dtype=float32)
Selected action 1
[0.16, 0.15, 0.34, 0.176, 0.125, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.07029451 0.05848433 0.8712212 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.17, 0.3, 0.26, 0.252, 0.125, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.06581667 0.05421576 0.87996763]], shape=(1, 3), dtype=float32)
Selected action 2
[0.24, 0.3, 0.26, 0.233, 0.125, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 193 | Average Reward: 74 | Episode Reward: 85 | Loss: 362.226 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 85.12639218178845
Probs tf.Tensor([[0.28644952 0.27620053 0.43734995]], shape=(1, 3), dtype=float32)
Selected action 2
[0.13, 0.3, 0.25, 0.198, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.07077186 0.05919556 0.8700326 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.22, 0.3, 0.27, 0.248, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.06528671 0.05331998 0.8813933 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.17, 0.3, 0.26, 0.175, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.06942415 0.05799922 0.87257665]], shape=(1, 3), dtype=float32)
Selected action 2
[0.09, 0.3, 0.22, 0.214, 0.125, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.07316835 0.06133531 0.8654963 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.07, 0.15, 0.23, 0.212, 0.125, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 194 | Average Reward: 74 | Episode Reward: 101 | Loss: 419.807 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 101.90522968854425
Probs tf.Tensor([[0.2881613  0.27809596 0.4337427 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.24, 0.3, 0.28, 0.246, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.06569497 0.05377799 0.88052696]], shape=(1, 3), dtype=float32)
Selected action 2
[0.27, 0.3, 0.2, 0.253, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.06782424 0.0550767  0.8770991 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.3, 0.23, 0.198, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.07714425 0.06579738 0.8570584 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.09, 0.075, 0.31, 0.183, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.08065012 0.06732429 0.8520256 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.18, 0.3, 0.27, 0.186, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 195 | Average Reward: 74 | Episode Reward: 93 | Loss: 331.351 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 93.7120671953001
Probs tf.Tensor([[0.28913522 0.2792076  0.43165717]], shape=(1, 3), dtype=float32)
Selected action 1
[0.14, 0.15, 0.25, 0.155, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.08080918 0.06765559 0.8515352 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.17, 0.3, 0.24, 0.206, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.07261416 0.06050382 0.8668821 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.2, 0.3, 0.28, 0.177, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.07042165 0.05881923 0.8707591 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.16, 0.3, 0.3, 0.215, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.06997604 0.05838495 0.8716391 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.13, 0.3, 0.27, 0.224, 0.125, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 196 | Average Reward: 74 | Episode Reward: 102 | Loss: 480.497 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 102.19890470205591
Probs tf.Tensor([[0.28479236 0.2754342  0.43977344]], shape=(1, 3), dtype=float32)
Selected action 2
[0.33, 0.3, 0.28, 0.262, 0.131, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.06434043 0.05185481 0.88380474]], shape=(1, 3), dtype=float32)
Selected action 2
[0.29, 0.3, 0.28, 0.253, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.06628902 0.05381618 0.8798948 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.22, 0.3, 0.27, 0.247, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.06944551 0.0570357  0.87351876]], shape=(1, 3), dtype=float32)
Selected action 2
[0.27, 0.3, 0.3, 0.257, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.06611398 0.05381894 0.88006705]], shape=(1, 3), dtype=float32)
Selected action 2
[0.23, 0.3, 0.27, 0.269, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 197 | Average Reward: 75 | Episode Reward: 110 | Loss: 513.712 | Steps: 4 | Worker: 0
Saving best model to ./Training/, episode score: 110.70974220881175
Probs tf.Tensor([[0.28267404 0.27357134 0.44375464]], shape=(1, 3), dtype=float32)
Selected action 0
[0.07, 0.075, 0.37, 0.167, 0.122, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.08232518 0.06922874 0.84844613]], shape=(1, 3), dtype=float32)
Selected action 2
[0.11, 0.3, 0.37, 0.202, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.07066336 0.0597695  0.86956716]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.3, 0.3, 0.196, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.07709571 0.06598097 0.8569234 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.07, 0.15, 0.37, 0.124, 0.125, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.08000261 0.0684621  0.8515353 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.075, 0.37, 0.145, 0.125, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 198 | Average Reward: 75 | Episode Reward: 68 | Loss: 199.629 | Steps: 4 | Worker: 0
Saving actual model to ./Training/, episode score: 68.98857971556757
Probs tf.Tensor([[0.2858884  0.27519482 0.4389168 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.2, 0.3, 0.21, 0.258, 0.123, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.07397108 0.06081045 0.86521846]], shape=(1, 3), dtype=float32)
Selected action 2
[0.21, 0.3, 0.26, 0.255, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.07140791 0.05872538 0.86986667]], shape=(1, 3), dtype=float32)
Selected action 2
[0.21, 0.3, 0.27, 0.224, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.07180355 0.05943526 0.8687611 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.3, 0.23, 0.211, 0.124, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Probs tf.Tensor([[0.0796307  0.06744465 0.8529247 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.0, 0.3, 0.17, 0.077, 0.125, 0.2, 0.83, 0.025, 0.032, 0.275, 0.008]
Episode: 199 | Average Reward: 75 | Episode Reward: 111 | Loss: 518.12 | Steps: 4 | Worker: 0
Saving best model to ./Training/, episode score: 111.02741722232341
------------TRAINING DONE------------

Process finished with exit code 0
