32
3.358333
Reward 16.75683060270072
Episode: 42 | Average Reward: 284 | Episode Reward: 321 | Loss: 579.307 | Steps: 19 | Worker: 0
Current State [[-8.30436297e-03 -4.63132129e-03  4.48880926e-04 -8.47128499e-03
  -1.15588575e-05 -5.72331614e-03  6.11621054e-03 -6.32427749e-03
  -2.41769637e-03 -3.81728628e-03]]
Logits tf.Tensor([[ 0.01654455 -0.00433745 -0.00276272]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3378136  0.3308325  0.33135387]], shape=(1, 3), dtype=float32)
Selected action 1
[0.05, 0.08, 0.33, 0.169, 0.151, 0.87, 0.033, 0.004, 0.536, 0.14]
0.870038
3.6255949999999997
Reward 10.72439478799669
Current State [[0.05  0.08  0.33  0.169 0.151 0.87  0.033 0.004 0.536 0.14 ]]
Logits tf.Tensor([[ 0.05149702 -0.13345712  0.37523904]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.31119365 0.25864625 0.4301601 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.31, 0.15, 0.29, 0.16, 0.151, 0.74, 0.02, 0.002, 0.625, 0.07]
0.7449615
1.8196426666666667
Reward 17.50069014861522
Current State [[0.31  0.15  0.29  0.16  0.151 0.74  0.02  0.002 0.625 0.07 ]]
Logits tf.Tensor([[ 0.01436368 -0.18387464  0.40288812]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30349222 0.24891654 0.44759122]], shape=(1, 3), dtype=float32)
Selected action 1
[0.08, 0.08, 0.34, 0.155, 0.151, 0.89, 0.043, 0.001, 0.6599999999999999, 0.16]
0.8898405
1.4523806666666668
Reward 12.577501097400264
Current State [[0.08  0.08  0.34  0.155 0.151 0.89  0.043 0.001 0.66  0.16 ]]
Logits tf.Tensor([[ 0.043026   -0.15641505  0.41128346]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30633473 0.2509459  0.44271928]], shape=(1, 3), dtype=float32)
Selected action 2
[0.15, 0.15, 0.3, 0.181, 0.151, 0.89, 0.043, 0.001, 0.6599999999999999, 0.16]
0.8898405
1.4523806666666668
Reward 18.577501097400265
Current State [[0.15  0.15  0.3   0.181 0.151 0.89  0.043 0.001 0.66  0.16 ]]
Logits tf.Tensor([[ 0.03259504 -0.1831316   0.42538926]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3042224  0.24518973 0.45058793]], shape=(1, 3), dtype=float32)
Selected action 0
[0.02, 0.04, 0.31, 0.146, 0.151, 0.91, 0.037, 0.002, 0.714, 0.16]
0.9115423333333333
1.8738091666666663
Reward 5.889456435063541
Current State [[0.02  0.04  0.31  0.146 0.151 0.91  0.037 0.002 0.714 0.16 ]]
Logits tf.Tensor([[ 0.05167605 -0.14716882  0.41585082]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3068423  0.25151163 0.44164607]], shape=(1, 3), dtype=float32)
Selected action 2
[0.16, 0.15, 0.26, 0.144, 0.151, 0.84, 0.031, 0.002, 0.678, 0.13]
0.841414
2.1869053333333337
Reward 17.381175465806496
Current State [[0.16  0.15  0.26  0.144 0.151 0.84  0.031 0.002 0.678 0.13 ]]
Logits tf.Tensor([[ 0.03231316 -0.18732205  0.41839156]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3054357  0.24520731 0.449357  ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.06, 0.08, 0.33, 0.157, 0.151, 0.97, 0.056, 0.001, 0.429, 0.1]
0.9653619999999999
0.8059521666666666
Reward 16.68967140657505
Current State [[0.06  0.08  0.33  0.157 0.151 0.97  0.056 0.001 0.429 0.1  ]]
Logits tf.Tensor([[ 0.02907789 -0.14557788  0.35973507]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30944148 0.25985226 0.4307062 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.19, 0.15, 0.28, 0.18, 0.151, 0.97, 0.056, 0.001, 0.429, 0.1]
0.9653619999999999
0.8059521666666666
Reward 22.68967140657505
Current State [[0.19  0.15  0.28  0.18  0.151 0.97  0.056 0.001 0.429 0.1  ]]
Logits tf.Tensor([[-0.00285506 -0.18071415  0.37267497]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3036908  0.25420752 0.44210172]], shape=(1, 3), dtype=float32)
Selected action 2
[0.15, 0.15, 0.3, 0.164, 0.151, 0.95, 0.076, 0.001, 0.379, 0.12]
0.9488315
1.1833334999999998
Reward 19.735216815951116
Current State [[0.15  0.15  0.3   0.164 0.151 0.95  0.076 0.001 0.379 0.12 ]]
Logits tf.Tensor([[-0.0074079  -0.17631659  0.3595981 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30413693 0.2568698  0.43899325]], shape=(1, 3), dtype=float32)
Selected action 2
[0.17, 0.15, 0.27, 0.165, 0.151, 0.98, 0.056, 0.0, 0.361, 0.11]
0.975298
0.3672616666666667
Reward 38.94101478490344
Current State [[0.17  0.15  0.27  0.165 0.151 0.98  0.056 0.    0.361 0.11 ]]
Logits tf.Tensor([[-0.00893875 -0.18200755  0.35232502]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30522963 0.25672245 0.4380479 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.15, 0.15, 0.29, 0.143, 0.151, 0.89, 0.074, 0.003, 0.362, 0.18]
0.8867720000000001
2.6035716666666664
Reward 17.17279646586052
Current State [[0.15  0.15  0.29  0.143 0.151 0.89  0.074 0.003 0.362 0.18 ]]
Logits tf.Tensor([[-0.00591203 -0.18219732  0.34491757]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30687803 0.25728    0.43584204]], shape=(1, 3), dtype=float32)
Selected action 2
[0.16, 0.15, 0.3, 0.173, 0.151, 0.89, 0.074, 0.003, 0.362, 0.18]
0.8867720000000001
2.6035716666666664
Reward 17.17279646586052
Current State [[0.16  0.15  0.3   0.173 0.151 0.89  0.074 0.003 0.362 0.18 ]]
Logits tf.Tensor([[-0.00337286 -0.1783023   0.34557858]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30702192 0.2577499  0.43522823]], shape=(1, 3), dtype=float32)
Selected action 1
[0.07, 0.08, 0.31, 0.173, 0.151, 0.92, 0.081, 0.001, 0.377, 0.16]
0.920615
0.9773809999999999
Reward 14.696118479001107
Current State [[0.07  0.08  0.31  0.173 0.151 0.92  0.081 0.001 0.377 0.16 ]]
Logits tf.Tensor([[ 0.01360026 -0.14817372  0.33699885]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30936292 0.26315445 0.42748263]], shape=(1, 3), dtype=float32)
Selected action 0
[0.02, 0.04, 0.36, 0.143, 0.151, 0.89, 0.049, 0.001, 0.45999999999999996, 0.2]
0.8919978333333334
0.8672620000000001
Reward 9.335901590831229
Current State [[0.02  0.04  0.36  0.143 0.151 0.89  0.049 0.001 0.46  0.2  ]]
Logits tf.Tensor([[ 0.04704796 -0.13036269  0.3490549 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.313479   0.26251853 0.42400247]], shape=(1, 3), dtype=float32)
Selected action 1
[0.12, 0.08, 0.35, 0.139, 0.151, 0.82, 0.042, 0.003, 0.502, 0.23]
0.82026
2.5940475000000003
Reward 11.060774719370063
Current State [[0.12  0.08  0.35  0.139 0.151 0.82  0.042 0.003 0.502 0.23 ]]
Logits tf.Tensor([[ 0.03500709 -0.15778837  0.35749426]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.31199226 0.2572846  0.43072313]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.33, 0.147, 0.151, 0.82, 0.042, 0.003, 0.502, 0.23]
0.82026
2.5940475000000003
Reward 5.0607747193700625
Current State [[0.04  0.04  0.33  0.147 0.151 0.82  0.042 0.003 0.502 0.23 ]]
Logits tf.Tensor([[ 0.04828468 -0.13158198  0.34617525]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.31422862 0.26250085 0.4232705 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.1, 0.15, 0.25, 0.167, 0.151, 0.86, 0.039, 0.001, 0.475, 0.15]
0.8572088333333334
0.9023805
Reward 20.75389213646754
Current State [[0.1   0.15  0.25  0.167 0.151 0.86  0.039 0.001 0.475 0.15 ]]
Logits tf.Tensor([[ 0.02949258 -0.15866964  0.36852148]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3093998  0.25633165 0.43426856]], shape=(1, 3), dtype=float32)
Selected action 2
[0.21, 0.15, 0.28, 0.204, 0.151, 0.97, 0.078, 0.002, 0.368, 0.07]
0.9680328333333335
2.2029761666666663
Reward 17.649386808210604
Current State [[0.21  0.15  0.28  0.204 0.151 0.97  0.078 0.002 0.368 0.07 ]]
Logits tf.Tensor([[-0.02097714 -0.17713612  0.35591027]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30182636 0.25818926 0.4399844 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.12, 0.15, 0.26, 0.135, 0.151, 0.94, 0.036, 0.001, 0.37, 0.15]
0.9430073333333334
1.185119
Reward 19.695269469313082
Current State [[0.12  0.15  0.26  0.135 0.151 0.94  0.036 0.001 0.37  0.15 ]]
Logits tf.Tensor([[ 0.00945988 -0.17726089  0.3469243 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30949548 0.25678077 0.43372378]], shape=(1, 3), dtype=float32)
Selected action 2
[0.09, 0.15, 0.25, 0.188, 0.151, 0.94, 0.036, 0.001, 0.37, 0.15]
0.9430073333333334
1.185119
Reward 19.695269469313082
Episode: 43 | Average Reward: 285 | Episode Reward: 332 | Loss: 946.235 | Steps: 19 | Worker: 0
Current State [[ 0.00781806  0.00853891  0.00045432  0.00474408  0.00995395  0.00480049
  -0.00573138 -0.00606048 -0.00888509  0.0007708 ]]
Logits tf.Tensor([[ 0.01356409 -0.0091101   0.00164866]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3371844  0.32962504 0.33319056]], shape=(1, 3), dtype=float32)
Selected action 1
[0.06, 0.08, 0.3, 0.16, 0.151, 0.96, 0.053, 0.0, 0.40599999999999997, 0.12]
0.9620274999999999
0.1196425
Reward 55.80460719744242
Current State [[0.06  0.08  0.3   0.16  0.151 0.96  0.053 0.    0.406 0.12 ]]
Logits tf.Tensor([[ 0.02283442 -0.14755312  0.3533585 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30911565 0.26068896 0.4301954 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.04, 0.37, 0.123, 0.151, 0.86, 0.034, 0.001, 0.507, 0.13]
0.8570198333333331
1.1821430000000002
Reward 7.245904201823559
Current State [[0.05  0.04  0.37  0.123 0.151 0.86  0.034 0.001 0.507 0.13 ]]
Logits tf.Tensor([[ 0.04433442 -0.12831938  0.3651466 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.31059027 0.26133963 0.42807004]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.37, 0.165, 0.151, 0.86, 0.034, 0.001, 0.507, 0.13]
0.8570198333333331
1.1821430000000002
Reward 7.245904201823559
Current State [[0.04  0.04  0.37  0.165 0.151 0.86  0.034 0.001 0.507 0.13 ]]
Logits tf.Tensor([[ 0.0487732  -0.11807203  0.36487195]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3107427  0.26299104 0.42626616]], shape=(1, 3), dtype=float32)
Selected action 1
[0.05, 0.08, 0.31, 0.159, 0.151, 0.86, 0.038, 0.002, 0.499, 0.18]
0.860142
2.2904756666666657
Reward 11.337055197330805
Current State [[0.05  0.08  0.31  0.159 0.151 0.86  0.038 0.002 0.499 0.18 ]]
Logits tf.Tensor([[ 0.04340245 -0.1391073   0.36700076]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.31101602 0.25913122 0.42985272]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.15, 0.29, 0.165, 0.151, 0.96, 0.047, 0.001, 0.514, 0.26]
0.9591878333333335
0.7821431666666666
Reward 22.931725279125125
Current State [[0.06  0.15  0.29  0.165 0.151 0.96  0.047 0.001 0.514 0.26 ]]
Logits tf.Tensor([[ 0.0348691  -0.17948122  0.40121603]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30773765 0.24836448 0.44389787]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.33, 0.132, 0.151, 0.9, 0.05, 0.0, 0.41200000000000003, 0.17]
0.9038173333333333
0.32202433333333336
Reward 28.80366113159429
Current State [[0.04  0.04  0.33  0.132 0.151 0.9   0.05  0.    0.412 0.17 ]]
Logits tf.Tensor([[ 0.03117885 -0.13737224  0.33889863]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.31199226 0.26359853 0.42440918]], shape=(1, 3), dtype=float32)
Selected action 1
[0.07, 0.08, 0.29, 0.152, 0.151, 0.9, 0.05, 0.0, 0.41200000000000003, 0.17]
0.9038173333333333
0.32202433333333336
Reward 34.80366113159429
Current State [[0.07  0.08  0.29  0.152 0.151 0.9   0.05  0.    0.412 0.17 ]]
Logits tf.Tensor([[ 0.02348671 -0.14922267  0.34551403]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.31043324 0.26119298 0.4283738 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.03, 0.04, 0.31, 0.125, 0.151, 0.96, 0.052, 0.001, 0.421, 0.12]
0.9581136666666666
0.6863098333333333
Reward 12.449900750676491
Current State [[0.03  0.04  0.31  0.125 0.151 0.96  0.052 0.001 0.421 0.12 ]]
Logits tf.Tensor([[ 0.03131711 -0.14168067  0.34808546]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3111558  0.26172543 0.42711875]], shape=(1, 3), dtype=float32)
Selected action 2
[0.15, 0.15, 0.3, 0.176, 0.151, 0.95, 0.024, 0.001, 0.41100000000000003, 0.03]
0.9486471666666667
1.430357166666667
Reward 18.871651642253063
Current State [[0.15  0.15  0.3   0.176 0.151 0.95  0.024 0.001 0.411 0.03 ]]
Logits tf.Tensor([[ 0.01348078 -0.15822208  0.3705568 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30568197 0.25745434 0.43686372]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.04, 0.35, 0.156, 0.151, 0.95, 0.024, 0.001, 0.41100000000000003, 0.03]
0.9486471666666667
1.430357166666667
Reward 6.871651642253064
Current State [[0.05  0.04  0.35  0.156 0.151 0.95  0.024 0.001 0.411 0.03 ]]
Logits tf.Tensor([[ 0.04201173 -0.12067017  0.3453818 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3120829  0.26522723 0.42268994]], shape=(1, 3), dtype=float32)
Selected action 2
[0.13, 0.15, 0.26, 0.169, 0.151, 0.71, 0.034, 0.005, 0.633, 0.16]
0.7107361666666666
4.88631
Reward 16.335257785471253
Current State [[0.13  0.15  0.26  0.169 0.151 0.71  0.034 0.005 0.633 0.16 ]]
Logits tf.Tensor([[ 0.03286795 -0.17014289  0.3890003 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30825517 0.25161925 0.44012564]], shape=(1, 3), dtype=float32)
Selected action 1
[0.09, 0.08, 0.29, 0.138, 0.151, 0.93, 0.041, 0.001, 0.409, 0.12]
0.9309349999999998
1.0720235000000002
Reward 14.180499609087398
Current State [[0.09  0.08  0.29  0.138 0.151 0.93  0.041 0.001 0.409 0.12 ]]
Logits tf.Tensor([[ 0.02002873 -0.15341865  0.34797454]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30970538 0.26038828 0.42990628]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.32, 0.152, 0.151, 0.93, 0.041, 0.001, 0.409, 0.12]
0.9309349999999998
1.0720235000000002
Reward 8.180499609087398
Current State [[0.04  0.04  0.32  0.152 0.151 0.93  0.041 0.001 0.409 0.12 ]]
Logits tf.Tensor([[ 0.03552613 -0.13167146  0.3397691 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.31234083 0.26425046 0.42340872]], shape=(1, 3), dtype=float32)
Selected action 2
[0.1, 0.15, 0.26, 0.185, 0.151, 0.86, 0.026, 0.002, 0.476, 0.11]
0.8633283333333334
1.7833324999999998
Reward 17.87722992359618
Current State [[0.1   0.15  0.26  0.185 0.151 0.86  0.026 0.002 0.476 0.11 ]]
Logits tf.Tensor([[ 0.03344923 -0.14849101  0.37427276]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3086652  0.25731912 0.43401572]], shape=(1, 3), dtype=float32)
Selected action 1
[0.09, 0.08, 0.34, 0.19, 0.151, 0.89, 0.025, 0.002, 0.417, 0.11]
0.8924544999999999
2.1196426666666666
Reward 11.557934337900095
Current State [[0.09  0.08  0.34  0.19  0.151 0.89  0.025 0.002 0.417 0.11 ]]
Logits tf.Tensor([[ 0.03574827 -0.1301144   0.34766102]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3112164  0.2636509  0.42513266]], shape=(1, 3), dtype=float32)
Selected action 1
[0.07, 0.08, 0.32, 0.142, 0.151, 0.76, 0.023, 0.005, 0.905, 0.13]
0.7596218333333332
4.672024333333334
Reward 10.403583216817935
Current State [[0.07  0.08  0.32  0.142 0.151 0.76  0.023 0.005 0.905 0.13 ]]
Logits tf.Tensor([[ 0.03178622 -0.17262189  0.48535028]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29506868 0.24051921 0.46441206]], shape=(1, 3), dtype=float32)
Selected action 1
[0.08, 0.08, 0.3, 0.169, 0.151, 0.76, 0.023, 0.005, 0.905, 0.13]
0.7596218333333332
4.672024333333334
Reward 10.403583216817935
Current State [[0.08  0.08  0.3   0.169 0.151 0.76  0.023 0.005 0.905 0.13 ]]
Logits tf.Tensor([[ 0.03165279 -0.17233782  0.48452842]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29513338 0.24067244 0.46419424]], shape=(1, 3), dtype=float32)
Selected action 2
[0.16, 0.15, 0.27, 0.206, 0.151, 0.66, 0.017, 0.005, 0.8130000000000001, 0.14]
0.6627055
4.963691
Reward 16.28820013040449
Current State [[0.16  0.15  0.27  0.206 0.151 0.66  0.017 0.005 0.813 0.14 ]]
Logits tf.Tensor([[ 0.02783646 -0.17812148  0.4511688 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29931974 0.24360655 0.45707372]], shape=(1, 3), dtype=float32)
Selected action 0
[0.02, 0.04, 0.31, 0.115, 0.151, 0.93, 0.042, 0.001, 0.458, 0.11]
0.932274
0.566666
Reward 14.921255337686434
Current State [[0.02  0.04  0.31  0.115 0.151 0.93  0.042 0.001 0.458 0.11 ]]
Logits tf.Tensor([[ 0.04089318 -0.13496035  0.3550695 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.31173313 0.2614633  0.42680353]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.32, 0.14, 0.151, 0.93, 0.042, 0.001, 0.458, 0.11]
0.932274
0.566666
Reward 14.921255337686434
Episode: 44 | Average Reward: 285 | Episode Reward: 341 | Loss: 759.747 | Steps: 19 | Worker: 0
Current State [[ 0.00224247 -0.00886771  0.0085952   0.00951905  0.00548723  0.00422672
   0.00033916  0.00260981 -0.00449014 -0.00786889]]
Logits tf.Tensor([[ 0.01536248 -0.00864914 -0.00204637]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.33795017 0.3299321  0.33211777]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.32, 0.141, 0.151, 0.81, 0.035, 0.002, 0.553, 0.11]
0.8059781666666667
2.327976
Reward 5.198898834729074
Current State [[0.04  0.04  0.32  0.141 0.151 0.81  0.035 0.002 0.553 0.11 ]]
Logits tf.Tensor([[ 0.0428012  -0.12179157  0.36694574]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30949345 0.2625244  0.42798212]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.04, 0.32, 0.124, 0.151, 0.86, 0.02, 0.001, 0.61, 0.08]
0.8647534999999998
1.3642861666666668
Reward 6.699394455748128
Current State [[0.05  0.04  0.32  0.124 0.151 0.86  0.02  0.001 0.61  0.08 ]]
Logits tf.Tensor([[ 0.04662589 -0.13065225  0.39117253]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30779678 0.25779423 0.434409  ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.07, 0.08, 0.25, 0.152, 0.151, 0.95, 0.037, 0.0, 0.409, 0.02]
0.9450445000000001
0.2184533333333333
Reward 49.064646715989376
Current State [[0.07  0.08  0.25  0.152 0.151 0.95  0.037 0.    0.409 0.02 ]]
Logits tf.Tensor([[ 0.02476765 -0.13913937  0.34922996]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30939564 0.26262152 0.42798287]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.38, 0.142, 0.151, 0.95, 0.037, 0.0, 0.409, 0.02]
0.9450445000000001
0.2184533333333333
Reward 43.064646715989376
Current State [[0.04  0.04  0.38  0.142 0.151 0.95  0.037 0.    0.409 0.02 ]]
Logits tf.Tensor([[ 0.03670259 -0.11960027  0.35307723]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30984265 0.26500848 0.42514881]], shape=(1, 3), dtype=float32)
Selected action 2
[0.16, 0.15, 0.26, 0.175, 0.151, 0.74, 0.017, 0.003, 0.588, 0.09]
0.7406896666666668
2.6940471666666665
Reward 16.87610876174717
Current State [[0.16  0.15  0.26  0.175 0.151 0.74  0.017 0.003 0.588 0.09 ]]
Logits tf.Tensor([[ 0.03134187 -0.15954357  0.38630775]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30746913 0.25403938 0.43849155]], shape=(1, 3), dtype=float32)
Selected action 2
[0.13, 0.15, 0.27, 0.175, 0.151, 0.85, 0.028, 0.001, 0.425, 0.1]
0.851176
0.8184518333333334
Reward 21.423236321636526
Current State [[0.13  0.15  0.27  0.175 0.151 0.85  0.028 0.001 0.425 0.1  ]]
Logits tf.Tensor([[ 0.01865422 -0.15161392  0.36050284]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.307599   0.2594409  0.43296015]], shape=(1, 3), dtype=float32)
Selected action 2
[0.14, 0.15, 0.26, 0.152, 0.151, 0.93, 0.043, 0.001, 0.45099999999999996, 0.13]
0.9325741666666667
0.675
Reward 24.315329170923945
Current State [[0.14  0.15  0.26  0.152 0.151 0.93  0.043 0.001 0.451 0.13 ]]
Logits tf.Tensor([[ 0.00874153 -0.17624018  0.3792964 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30490988 0.25341654 0.44167358]], shape=(1, 3), dtype=float32)
Selected action 1
[0.09, 0.08, 0.29, 0.18, 0.151, 0.93, 0.043, 0.001, 0.45099999999999996, 0.13]
0.9325741666666667
0.675
Reward 18.315329170923945
Current State [[0.09  0.08  0.29  0.18  0.151 0.93  0.043 0.001 0.451 0.13 ]]
Logits tf.Tensor([[ 0.02649926 -0.14604431  0.36214837]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30860674 0.25969926 0.43169397]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.04, 0.36, 0.151, 0.151, 0.84, 0.021, 0.001, 0.522, 0.07]
0.8444258333333333
1.0982139999999998
Reward 7.522399476627939
Current State [[0.05  0.04  0.36  0.151 0.151 0.84  0.021 0.001 0.522 0.07 ]]
Logits tf.Tensor([[ 0.04704677 -0.11494584  0.36886594]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3095896  0.2632897  0.42712072]], shape=(1, 3), dtype=float32)
Selected action 1
[0.07, 0.08, 0.31, 0.124, 0.151, 0.76, 0.014, 0.005, 0.567, 0.07]
0.7642555000000001
5.444047666666666
Reward 10.315222297410465
Current State [[0.07  0.08  0.31  0.124 0.151 0.76  0.014 0.005 0.567 0.07 ]]
Logits tf.Tensor([[ 0.04435909 -0.12982507  0.37243113]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30974796 0.26023233 0.43001968]], shape=(1, 3), dtype=float32)
Selected action 2
[0.16, 0.15, 0.28, 0.192, 0.151, 0.76, 0.014, 0.005, 0.567, 0.07]
0.7642555000000001
5.444047666666666
Reward 16.315222297410465
Current State [[0.16  0.15  0.28  0.192 0.151 0.76  0.014 0.005 0.567 0.07 ]]
Logits tf.Tensor([[ 0.03337364 -0.15108132  0.385656  ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3073266  0.25555968 0.4371137 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.04, 0.33, 0.143, 0.151, 0.95, 0.039, 0.001, 0.477, 0.14]
0.9547058333333333
0.9505959999999999
Reward 9.15356166543562
Current State [[0.05  0.04  0.33  0.143 0.151 0.95  0.039 0.001 0.477 0.14 ]]
Logits tf.Tensor([[ 0.03901781 -0.13965403  0.36586985]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3102722  0.25950554 0.43022227]], shape=(1, 3), dtype=float32)
Selected action 0
[0.03, 0.04, 0.32, 0.121, 0.151, 0.86, 0.029, 0.002, 0.541, 0.13]
0.8625944999999999
1.7994051666666664
Reward 5.852732349371893
Current State [[0.03  0.04  0.32  0.121 0.151 0.86  0.029 0.002 0.541 0.13 ]]
Logits tf.Tensor([[ 0.04719514 -0.12871227  0.37138876]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.31040376 0.26033425 0.429262  ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.12, 0.08, 0.31, 0.143, 0.151, 0.72, 0.022, 0.006, 0.5509999999999999, 0.1]
0.7249264999999999
6.447618833333333
Reward 10.206285893953002
Current State [[0.12  0.08  0.31  0.143 0.151 0.72  0.022 0.006 0.551 0.1  ]]
Logits tf.Tensor([[ 0.03266036 -0.13644087  0.359984  ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3094372  0.261296   0.42926684]], shape=(1, 3), dtype=float32)
Selected action 1
[0.07, 0.08, 0.33, 0.182, 0.151, 0.72, 0.022, 0.006, 0.5509999999999999, 0.1]
0.7249264999999999
6.447618833333333
Reward 10.206285893953002
Current State [[0.07  0.08  0.33  0.182 0.151 0.72  0.022 0.006 0.551 0.1  ]]
Logits tf.Tensor([[ 0.04391722 -0.11900927  0.36137035]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.31024313 0.26359922 0.42615768]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.15, 0.24, 0.169, 0.151, 0.87, 0.036, 0.001, 0.523, 0.11]
0.8661911666666667
1.0488096666666666
Reward 19.893783946573077
Current State [[0.07  0.15  0.24  0.169 0.151 0.87  0.036 0.001 0.523 0.11 ]]
Logits tf.Tensor([[ 0.03414165 -0.15374954  0.39084455]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3070012  0.25441337 0.4385854 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.15, 0.25, 0.135, 0.151, 0.94, 0.022, 0.002, 0.434, 0.1]
0.9392138333333333
1.6529761666666662
Reward 18.327549902997443
Current State [[0.06  0.15  0.25  0.135 0.151 0.94  0.022 0.002 0.434 0.1  ]]
Logits tf.Tensor([[ 0.02994046 -0.16115616  0.37295935]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3090953  0.25532904 0.43557566]], shape=(1, 3), dtype=float32)
Selected action 2
[0.15, 0.15, 0.27, 0.158, 0.151, 0.81, 0.046, 0.006, 0.438, 0.15]
0.8095490000000001
5.8827378333333336
Reward 16.3043157515968
Current State [[0.15  0.15  0.27  0.158 0.151 0.81  0.046 0.006 0.438 0.15 ]]
Logits tf.Tensor([[ 0.01104718 -0.16344419  0.35910457]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30710664 0.257934   0.43495932]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.33, 0.165, 0.151, 0.81, 0.046, 0.006, 0.438, 0.15]
0.8095490000000001
5.8827378333333336
Reward 4.304315751596801
Current State [[0.04  0.04  0.33  0.165 0.151 0.81  0.046 0.006 0.438 0.15 ]]
Logits tf.Tensor([[ 0.03968779 -0.11614956  0.33501354]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.31257206 0.2674674  0.41996056]], shape=(1, 3), dtype=float32)
Selected action 1
[0.05, 0.08, 0.27, 0.19, 0.151, 0.74, 0.021, 0.007, 0.602, 0.05]
0.7449511666666666
7.244643333333332
Reward 10.169429462556112
Episode: 45 | Average Reward: 286 | Episode Reward: 323 | Loss: 708.086 | Steps: 19 | Worker: 0
Current State [[-0.00656735  0.0002534  -0.00581245  0.00183803  0.00088145 -0.0014727
  -0.00715962  0.00416231  0.00342772  0.00655463]]
Logits tf.Tensor([[ 0.02175921 -0.00622305 -0.00223018]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.33913228 0.32977414 0.33109352]], shape=(1, 3), dtype=float32)
Selected action 1
[0.09, 0.08, 0.32, 0.143, 0.151, 0.81, 0.03, 0.002, 0.748, 0.13]
0.8063163333333333
1.5684526666666667
Reward 12.034479723338722
Current State [[0.09  0.08  0.32  0.143 0.151 0.81  0.03  0.002 0.748 0.13 ]]
Logits tf.Tensor([[ 0.03263599 -0.15871     0.4305409 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30170017 0.24915808 0.44914177]], shape=(1, 3), dtype=float32)
Selected action 2
[0.13, 0.15, 0.28, 0.216, 0.151, 0.81, 0.03, 0.002, 0.748, 0.13]
0.8063163333333333
1.5684526666666667
Reward 18.03447972333872
Current State [[0.13  0.15  0.28  0.216 0.151 0.81  0.03  0.002 0.748 0.13 ]]
Logits tf.Tensor([[ 0.0368361  -0.17220895  0.4419635 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30203703 0.24506038 0.4529026 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.16, 0.15, 0.28, 0.192, 0.151, 0.79, 0.035, 0.002, 0.6950000000000001, 0.16]
0.7946308333333332
1.6017858333333332
Reward 17.939653336172466
Current State [[0.16  0.15  0.28  0.192 0.151 0.79  0.035 0.002 0.695 0.16 ]]
Logits tf.Tensor([[ 0.02827683 -0.18132822  0.4228953 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30351573 0.24612224 0.4503621 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.03, 0.04, 0.35, 0.159, 0.151, 0.92, 0.036, 0.001, 0.659, 0.1]
0.9152980000000001
0.675596
Reward 12.068353029123694
Current State [[0.03  0.04  0.35  0.159 0.151 0.92  0.036 0.001 0.659 0.1  ]]
Logits tf.Tensor([[ 0.04680638 -0.13195714  0.41643038]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30455363 0.25469932 0.44074708]], shape=(1, 3), dtype=float32)
Selected action 1
[0.05, 0.08, 0.32, 0.134, 0.151, 0.67, 0.029, 0.005, 0.791, 0.16]
0.6715509999999999
5.105357000000001
Reward 10.280474860897328
Current State [[0.05  0.08  0.32  0.134 0.151 0.67  0.029 0.005 0.791 0.16 ]]
Logits tf.Tensor([[ 0.0286104  -0.15788533  0.4348516 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30020773 0.24913102 0.4506612 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.02, 0.04, 0.32, 0.142, 0.151, 0.67, 0.029, 0.005, 0.791, 0.16]
0.6715509999999999
5.105357000000001
Reward 4.2804748608973275
Current State [[0.02  0.04  0.32  0.142 0.151 0.67  0.029 0.005 0.791 0.16 ]]
Logits tf.Tensor([[ 0.03050485 -0.14574406  0.42985404]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30036676 0.25183025 0.44780302]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.04, 0.4, 0.155, 0.151, 0.88, 0.037, 0.002, 0.751, 0.17]
0.8773748333333332
1.770238
Reward 5.937218836527889
Current State [[0.05  0.04  0.4   0.155 0.151 0.88  0.037 0.002 0.751 0.17 ]]
Logits tf.Tensor([[ 0.04424611 -0.14876246  0.43720895]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30249515 0.24939963 0.4481052 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.43, 0.115, 0.151, 0.9, 0.038, 0.001, 0.5509999999999999, 0.03]
0.8961689999999999
0.5952386666666667
Reward 13.501823743435237
Current State [[0.04  0.04  0.43  0.115 0.151 0.9   0.038 0.001 0.551 0.03 ]]
Logits tf.Tensor([[ 0.04048222 -0.12387533  0.39779955]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3050708  0.25883383 0.43609545]], shape=(1, 3), dtype=float32)
Selected action 2
[0.09, 0.15, 0.29, 0.172, 0.151, 0.84, 0.039, 0.002, 0.48200000000000004, 0.14]
0.8436548333333334
2.1505951666666663
Reward 17.417480454344936
Current State [[0.09  0.15  0.29  0.172 0.151 0.84  0.039 0.002 0.482 0.14 ]]
Logits tf.Tensor([[ 0.02991275 -0.14969459  0.37957352]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30729666 0.25677654 0.4359268 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.32, 0.186, 0.151, 0.84, 0.039, 0.002, 0.48200000000000004, 0.14]
0.8436548333333334
2.1505951666666663
Reward 5.417480454344937
Current State [[0.04  0.04  0.32  0.186 0.151 0.84  0.039 0.002 0.482 0.14 ]]
Logits tf.Tensor([[ 0.04239014 -0.11493422  0.3515373 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3108786  0.26562303 0.42349836]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.38, 0.147, 0.151, 0.83, 0.058, 0.002, 0.43200000000000005, 0.15]
0.8288751666666667
1.9833335000000003
Reward 5.542540563971629
Current State [[0.04  0.04  0.38  0.147 0.151 0.83  0.058 0.002 0.432 0.15 ]]
Logits tf.Tensor([[ 0.03397033 -0.11833693  0.34360465]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.31039986 0.26654795 0.42305222]], shape=(1, 3), dtype=float32)
Selected action 0
[0.03, 0.04, 0.38, 0.133, 0.151, 0.78, 0.064, 0.005, 0.441, 0.14]
0.7848215
5.215476333333333
Reward 4.3551940723415985
Current State [[0.03  0.04  0.38  0.133 0.151 0.78  0.064 0.005 0.441 0.14 ]]
Logits tf.Tensor([[ 0.03430577 -0.11435433  0.3391661 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3107233  0.2678006  0.42147613]], shape=(1, 3), dtype=float32)
Selected action 1
[0.07, 0.08, 0.26, 0.16, 0.151, 0.78, 0.064, 0.005, 0.441, 0.14]
0.7848215
5.215476333333333
Reward 10.355194072341598
Current State [[0.07  0.08  0.26  0.16  0.151 0.78  0.064 0.005 0.441 0.14 ]]
Logits tf.Tensor([[ 0.02192639 -0.1319356   0.33861667]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30960062 0.2654486  0.4249508 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.1, 0.15, 0.27, 0.169, 0.151, 0.9, 0.048, 0.002, 0.462, 0.17]
0.8964655000000001
2.202976
Reward 17.48862916969358
Current State [[0.1   0.15  0.27  0.169 0.151 0.9   0.048 0.002 0.462 0.17 ]]
Logits tf.Tensor([[ 0.01940095 -0.16477783  0.3801713 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3061642  0.25466344 0.43917233]], shape=(1, 3), dtype=float32)
Selected action 2
[0.19, 0.15, 0.28, 0.148, 0.151, 0.9, 0.063, 0.006, 0.393, 0.2]
0.8996218333333332
6.217261833333333
Reward 16.332260904763466
Current State [[0.19  0.15  0.28  0.148 0.151 0.9   0.063 0.006 0.393 0.2  ]]
Logits tf.Tensor([[-0.01268514 -0.19066215  0.35922927]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30418524 0.2545914  0.44122338]], shape=(1, 3), dtype=float32)
Selected action 0
[0.06, 0.04, 0.34, 0.119, 0.151, 0.93, 0.056, 0.002, 0.362, 0.16]
0.9344818333333335
2.244642333333333
Reward 5.53464256842505
Current State [[0.06  0.04  0.34  0.119 0.151 0.93  0.056 0.002 0.362 0.16 ]]
Logits tf.Tensor([[ 0.01534186 -0.14560655  0.33100373]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3103178  0.26418474 0.42549738]], shape=(1, 3), dtype=float32)
Selected action 2
[0.12, 0.15, 0.24, 0.135, 0.151, 0.93, 0.056, 0.002, 0.362, 0.16]
0.9344818333333335
2.244642333333333
Reward 17.53464256842505
Current State [[0.12  0.15  0.24  0.135 0.151 0.93  0.056 0.002 0.362 0.16 ]]
Logits tf.Tensor([[-0.00533034 -0.18002309  0.35083342]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3060391  0.2569856  0.43697527]], shape=(1, 3), dtype=float32)
Selected action 2
[0.18, 0.15, 0.29, 0.19, 0.151, 0.96, 0.067, 0.003, 0.341, 0.09]
0.9561758333333333
2.8589281666666664
Reward 17.144364247585628
Current State [[0.18  0.15  0.29  0.19  0.151 0.96  0.067 0.003 0.341 0.09 ]]
Logits tf.Tensor([[-0.01879507 -0.17268859  0.35408124]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30218166 0.25907946 0.43873894]], shape=(1, 3), dtype=float32)
Selected action 1
[0.08, 0.08, 0.3, 0.12, 0.151, 0.96, 0.039, 0.0, 0.393, 0.12]
0.9602786666666668
0.3982138333333333
Reward 29.894033105385827
Current State [[0.08  0.08  0.3   0.12  0.151 0.96  0.039 0.    0.393 0.12 ]]
Logits tf.Tensor([[ 0.01623676 -0.15677454  0.35048994]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30883026 0.2597658  0.43140396]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.37, 0.141, 0.151, 0.92, 0.052, 0.0, 0.44299999999999995, 0.18]
0.9186896666666667
0.44404816666666663
Reward 19.693142000117643
Episode: 46 | Average Reward: 285 | Episode Reward: 260 | Loss: 592.256 | Steps: 19 | Worker: 0
Current State [[ 0.00392495  0.00431258 -0.00344857  0.00405556  0.00083375  0.00675433
  -0.00010085  0.0064797  -0.00545884  0.00147063]]
Logits tf.Tensor([[ 0.01729003 -0.00941997 -0.00198513]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.33846068 0.32954007 0.33199927]], shape=(1, 3), dtype=float32)
Selected action 0
[0.06, 0.04, 0.33, 0.142, 0.151, 0.92, 0.052, 0.0, 0.44299999999999995, 0.18]
0.9186896666666667
0.44404816666666663
Reward 19.693142000117643
Current State [[0.06  0.04  0.33  0.142 0.151 0.92  0.052 0.    0.443 0.18 ]]
Logits tf.Tensor([[ 0.0289687  -0.14281763  0.35222125]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3101955 0.261234  0.4285705]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.04, 0.37, 0.174, 0.151, 0.8, 0.025, 0.003, 0.621, 0.09]
0.796761
3.0357143333333334
Reward 4.82149420547388
Current State [[0.05  0.04  0.37  0.174 0.151 0.8   0.025 0.003 0.621 0.09 ]]
Logits tf.Tensor([[ 0.04695758 -0.11816339  0.3896621 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30707404 0.26033464 0.4325913 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.03, 0.04, 0.33, 0.123, 0.151, 0.87, 0.037, 0.002, 0.49800000000000005, 0.18]
0.8658541666666667
1.7374998333333336
Reward 5.9514024377333365
Current State [[0.03  0.04  0.33  0.123 0.151 0.87  0.037 0.002 0.498 0.18 ]]
Logits tf.Tensor([[ 0.04462   -0.1327031  0.3613152]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.31151742 0.2608987  0.42758387]], shape=(1, 3), dtype=float32)
Selected action 2
[0.23, 0.15, 0.3, 0.173, 0.151, 0.87, 0.037, 0.002, 0.49800000000000005, 0.18]
0.8658541666666667
1.7374998333333336
Reward 17.951402437733336
Current State [[0.23  0.15  0.3   0.173 0.151 0.87  0.037 0.002 0.498 0.18 ]]
Logits tf.Tensor([[ 0.0054973  -0.18534465  0.3855307 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30408108 0.251251   0.44466794]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.33, 0.117, 0.151, 1.0, 0.046, 0.001, 0.46299999999999997, 0.21]
0.9983556666666668
0.5791664999999999
Reward 15.7567573866181
Current State [[0.04  0.04  0.33  0.117 0.151 1.    0.046 0.001 0.463 0.21 ]]
Logits tf.Tensor([[ 0.03332736 -0.15891583  0.3676183 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.31036088 0.25608066 0.43355846]], shape=(1, 3), dtype=float32)
Selected action 1
[0.07, 0.08, 0.32, 0.14, 0.151, 0.75, 0.039, 0.003, 0.546, 0.16]
0.7477556666666667
2.5047618333333332
Reward 10.980944337193428
Current State [[0.07  0.08  0.32  0.14  0.151 0.75  0.039 0.003 0.546 0.16 ]]
Logits tf.Tensor([[ 0.03590034 -0.13783082  0.3637805 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.309737   0.26034102 0.42992195]], shape=(1, 3), dtype=float32)
Selected action 2
[0.25, 0.15, 0.31, 0.173, 0.151, 0.75, 0.039, 0.003, 0.546, 0.16]
0.7477556666666667
2.5047618333333332
Reward 16.980944337193428
Current State [[0.25  0.15  0.31  0.173 0.151 0.75  0.039 0.003 0.546 0.16 ]]
Logits tf.Tensor([[ 0.0101691  -0.18348606  0.3787312 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30584812 0.25200114 0.4421507 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.04, 0.36, 0.145, 0.151, 0.98, 0.051, 0.001, 0.422, 0.25]
0.9761391666666666
1.017262
Reward 8.82367491765273
Current State [[0.05  0.04  0.36  0.145 0.151 0.98  0.051 0.001 0.422 0.25 ]]
Logits tf.Tensor([[ 0.03109747 -0.15494822  0.35454345]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.31132114 0.25846994 0.43020895]], shape=(1, 3), dtype=float32)
Selected action 2
[0.21, 0.15, 0.31, 0.149, 0.151, 0.89, 0.039, 0.001, 0.48600000000000004, 0.08]
0.894954
1.2160715000000002
Reward 19.3141205937911
Current State [[0.21  0.15  0.31  0.149 0.151 0.89  0.039 0.001 0.486 0.08 ]]
Logits tf.Tensor([[ 0.00375122 -0.17635722  0.389132  ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30253947 0.25267482 0.44478568]], shape=(1, 3), dtype=float32)
Selected action 2
[0.17, 0.15, 0.29, 0.174, 0.151, 0.89, 0.039, 0.001, 0.48600000000000004, 0.08]
0.894954
1.2160715000000002
Reward 19.3141205937911
Current State [[0.17  0.15  0.29  0.174 0.151 0.89  0.039 0.001 0.486 0.08 ]]
Logits tf.Tensor([[ 0.01270596 -0.16378921  0.38774627]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30365115 0.25452125 0.44182763]], shape=(1, 3), dtype=float32)
Selected action 2
[0.13, 0.15, 0.26, 0.196, 0.151, 0.85, 0.047, 0.002, 0.45999999999999996, 0.22]
0.8492509999999999
2.1744045
Reward 17.40916872401315
Current State [[0.13  0.15  0.26  0.196 0.151 0.85  0.047 0.002 0.46  0.22 ]]
Logits tf.Tensor([[ 0.01668322 -0.16680013  0.36782008]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30740404 0.25587258 0.43672332]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.04, 0.35, 0.164, 0.151, 0.93, 0.048, 0.002, 0.404, 0.15]
0.9250435000000002
2.048809666666666
Reward 5.710216438536592
Current State [[0.05  0.04  0.35  0.164 0.151 0.93  0.048 0.002 0.404 0.15 ]]
Logits tf.Tensor([[ 0.03162794 -0.13241696  0.34255177]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3111979  0.26411486 0.42468718]], shape=(1, 3), dtype=float32)
Selected action 2
[0.09, 0.15, 0.26, 0.128, 0.151, 0.81, 0.029, 0.001, 0.53, 0.08]
0.8130666666666665
1.3999999999999997
Reward 18.397327634334076
Current State [[0.09  0.15  0.26  0.128 0.151 0.81  0.029 0.001 0.53  0.08 ]]
Logits tf.Tensor([[ 0.03376301 -0.15359458  0.38668424]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30746847 0.2549366  0.43759498]], shape=(1, 3), dtype=float32)
Selected action 2
[0.14, 0.15, 0.27, 0.183, 0.151, 0.81, 0.029, 0.001, 0.53, 0.08]
0.8130666666666665
1.3999999999999997
Reward 18.397327634334076
Current State [[0.14  0.15  0.27  0.183 0.151 0.81  0.029 0.001 0.53  0.08 ]]
Logits tf.Tensor([[ 0.02700134 -0.15090893  0.3858472 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30593264 0.25607097 0.43799645]], shape=(1, 3), dtype=float32)
Selected action 2
[0.12, 0.15, 0.26, 0.19, 0.151, 0.97, 0.028, 0.001, 0.425, 0.11]
0.9656651666666666
0.507738
Reward 29.738886078899846
Current State [[0.12  0.15  0.26  0.19  0.151 0.97  0.028 0.001 0.425 0.11 ]]
Logits tf.Tensor([[ 0.01776427 -0.16467625  0.37391958]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30664843 0.25550997 0.4378416 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.08, 0.08, 0.33, 0.172, 0.151, 0.72, 0.027, 0.019, 0.549, 0.14]
0.7162895000000002
19.09999966666667
Reward 9.92646950738961
Current State [[0.08  0.08  0.33  0.172 0.151 0.72  0.027 0.019 0.549 0.14 ]]
Logits tf.Tensor([[ 0.04392895 -0.13008496  0.35505524]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.31198847 0.26215926 0.42585224]], shape=(1, 3), dtype=float32)
Selected action 2
[0.13, 0.15, 0.26, 0.196, 0.151, 0.72, 0.027, 0.019, 0.549, 0.14]
0.7162895000000002
19.09999966666667
Reward 15.92646950738961
Current State [[0.13  0.15  0.26  0.196 0.151 0.72  0.027 0.019 0.549 0.14 ]]
Logits tf.Tensor([[ 0.03588225 -0.15543592  0.36720893]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.31068596 0.2565861  0.43272796]], shape=(1, 3), dtype=float32)
Selected action 2
[0.12, 0.15, 0.26, 0.183, 0.151, 0.74, 0.023, 0.003, 0.8130000000000001, 0.15]
0.7370925
2.7226195
Reward 16.857629001251595
Current State [[0.12  0.15  0.26  0.183 0.151 0.74  0.023 0.003 0.813 0.15 ]]
Logits tf.Tensor([[ 0.03259541 -0.18388343  0.45725963]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29990166 0.24152568 0.4585727 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.34, 0.147, 0.151, 0.94, 0.042, 0.0, 0.449, 0.14]
0.9378768333333333
0.4904766666666667
Reward 17.856693736504113
Current State [[0.04  0.04  0.34  0.147 0.151 0.94  0.042 0.    0.449 0.14 ]]
Logits tf.Tensor([[ 0.03756578 -0.13402154  0.3573213 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3106441  0.26166382 0.42769206]], shape=(1, 3), dtype=float32)
Selected action 1
[0.08, 0.08, 0.26, 0.123, 0.151, 0.81, 0.035, 0.002, 0.554, 0.11]
0.8074501666666666
2.362499833333333
Reward 11.178269606586447
Episode: 47 | Average Reward: 286 | Episode Reward: 300 | Loss: 804.144 | Steps: 19 | Worker: 0
Current State [[-0.00615035 -0.00105343 -0.00101543  0.00462565  0.00050332  0.00020439
  -0.00568637 -0.00013142  0.00396693  0.00815955]]
Logits tf.Tensor([[ 0.02226955 -0.00672965 -0.00165546]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3392388  0.32954243 0.33121884]], shape=(1, 3), dtype=float32)
Selected action 2
[0.11, 0.15, 0.25, 0.187, 0.151, 0.81, 0.035, 0.002, 0.554, 0.11]
0.8074501666666666
2.362499833333333
Reward 17.178269606586447
Current State [[0.11  0.15  0.25  0.187 0.151 0.81  0.035 0.002 0.554 0.11 ]]
Logits tf.Tensor([[ 0.03179677 -0.1567338   0.39099786]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30671456 0.25401342 0.43927196]], shape=(1, 3), dtype=float32)
Selected action 1
[0.07, 0.08, 0.24, 0.152, 0.151, 0.93, 0.023, 0.0, 0.481, 0.09]
0.9300798333333333
0.3339285
Reward 34.54184390201832
Current State [[0.07  0.08  0.24  0.152 0.151 0.93  0.023 0.    0.481 0.09 ]]
Logits tf.Tensor([[ 0.03933964 -0.14783436  0.36647028]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.31091797 0.2578441  0.43123788]], shape=(1, 3), dtype=float32)
Selected action 1
[0.08, 0.08, 0.31, 0.141, 0.151, 0.99, 0.038, 0.0, 0.393, 0.03]
0.9851448333333334
0.17976166666666668
Reward 53.583769747521565
Current State [[0.08  0.08  0.31  0.141 0.151 0.99  0.038 0.    0.393 0.03 ]]
Logits tf.Tensor([[ 0.02176083 -0.14765002  0.35673708]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.308445   0.26037756 0.4311775 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.12, 0.15, 0.25, 0.147, 0.151, 0.99, 0.038, 0.0, 0.393, 0.03]
0.9851448333333334
0.17976166666666668
Reward 59.583769747521565
Current State [[0.12  0.15  0.25  0.147 0.151 0.99  0.038 0.    0.393 0.03 ]]
Logits tf.Tensor([[ 0.0072914  -0.17080793  0.37023377]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3053983  0.25557542 0.43902624]], shape=(1, 3), dtype=float32)
Selected action 1
[0.07, 0.08, 0.28, 0.161, 0.151, 0.88, 0.021, 0.001, 0.45899999999999996, 0.1]
0.8767838333333334
1.1476191666666666
Reward 13.491101577304438
Current State [[0.07  0.08  0.28  0.161 0.151 0.88  0.021 0.001 0.459 0.1  ]]
Logits tf.Tensor([[ 0.04093446 -0.13688776  0.3567245 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3116786 0.2609034 0.427418 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.04, 0.37, 0.135, 0.151, 0.75, 0.026, 0.003, 0.549, 0.13]
0.7546746666666666
2.579166666666667
Reward 4.954414776225144
Current State [[0.05  0.04  0.37  0.135 0.151 0.75  0.026 0.003 0.549 0.13 ]]
Logits tf.Tensor([[ 0.04605938 -0.12216222  0.36213487]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.31085828 0.262727   0.4264148 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.09, 0.08, 0.33, 0.14, 0.151, 0.74, 0.031, 0.003, 0.637, 0.13]
0.7413051666666668
2.522022833333333
Reward 10.960348587318034
Current State [[0.09  0.08  0.33  0.14  0.151 0.74  0.031 0.003 0.637 0.13 ]]
Logits tf.Tensor([[ 0.03592684 -0.14733267  0.38874778]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30716038 0.255727   0.43711266]], shape=(1, 3), dtype=float32)
Selected action 2
[0.14, 0.15, 0.27, 0.184, 0.151, 0.74, 0.031, 0.003, 0.637, 0.13]
0.7413051666666668
2.522022833333333
Reward 16.960348587318034
Current State [[0.14  0.15  0.27  0.184 0.151 0.74  0.031 0.003 0.637 0.13 ]]
Logits tf.Tensor([[ 0.03250839 -0.16918601  0.40004444]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30660585 0.25060263 0.44279155]], shape=(1, 3), dtype=float32)
Selected action 2
[0.15, 0.15, 0.27, 0.169, 0.151, 0.94, 0.031, 0.001, 0.44000000000000006, 0.13]
0.9408920000000001
0.5244046666666667
Reward 28.52648609149636
Current State [[0.15  0.15  0.27  0.169 0.151 0.94  0.031 0.001 0.44  0.13 ]]
Logits tf.Tensor([[ 0.01379167 -0.17553538  0.37719488]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3062101  0.2533937  0.44039616]], shape=(1, 3), dtype=float32)
Selected action 2
[0.13, 0.15, 0.26, 0.185, 0.151, 0.95, 0.033, 0.001, 0.466, 0.12]
0.9522826666666668
1.263689833333333
Reward 19.424921875010067
Current State [[0.13  0.15  0.26  0.185 0.151 0.95  0.033 0.001 0.466 0.12 ]]
Logits tf.Tensor([[ 0.02052916 -0.17005952  0.3859972 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3060293  0.2529248  0.44104588]], shape=(1, 3), dtype=float32)
Selected action 0
[0.02, 0.04, 0.31, 0.115, 0.151, 0.98, 0.035, 0.001, 0.471, 0.14]
0.9817756666666667
0.9232133333333333
Reward 9.603877757836536
Current State [[0.02  0.04  0.31  0.115 0.151 0.98  0.035 0.001 0.471 0.14 ]]
Logits tf.Tensor([[ 0.04360709 -0.14652836  0.3667268 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.31169373 0.25772303 0.43058324]], shape=(1, 3), dtype=float32)
Selected action 1
[0.07, 0.08, 0.27, 0.153, 0.151, 0.98, 0.035, 0.001, 0.471, 0.14]
0.9817756666666667
0.9232133333333333
Reward 15.603877757836536
Current State [[0.07  0.08  0.27  0.153 0.151 0.98  0.035 0.001 0.471 0.14 ]]
Logits tf.Tensor([[ 0.03372071 -0.15939066  0.3730731 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3097483  0.25535342 0.43489835]], shape=(1, 3), dtype=float32)
Selected action 1
[0.07, 0.08, 0.3, 0.149, 0.151, 0.93, 0.033, 0.001, 0.487, 0.11]
0.9288803333333334
1.2898808333333336
Reward 13.21595193459796
Current State [[0.07  0.08  0.3   0.149 0.151 0.93  0.033 0.001 0.487 0.11 ]]
Logits tf.Tensor([[ 0.03862683 -0.14743577  0.37545484]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30952856 0.2569773  0.43349415]], shape=(1, 3), dtype=float32)
Selected action 2
[0.19, 0.15, 0.28, 0.154, 0.151, 0.91, 0.028, 0.002, 0.434, 0.09]
0.9113140000000001
2.021429
Reward 17.706796655004503
Current State [[0.19  0.15  0.28  0.154 0.151 0.91  0.028 0.002 0.434 0.09 ]]
Logits tf.Tensor([[ 0.00563409 -0.17635027  0.37266356]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30515206 0.25437915 0.44046882]], shape=(1, 3), dtype=float32)
Selected action 1
[0.07, 0.08, 0.3, 0.151, 0.151, 0.9, 0.038, 0.001, 0.48200000000000004, 0.11]
0.9011385
1.0023813333333331
Reward 14.392078719683006
Current State [[0.07  0.08  0.3   0.151 0.151 0.9   0.038 0.001 0.482 0.11 ]]
Logits tf.Tensor([[ 0.03671185 -0.14334312  0.37067068]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30943373 0.25844657 0.43211973]], shape=(1, 3), dtype=float32)
Selected action 2
[0.13, 0.15, 0.26, 0.18, 0.151, 0.9, 0.038, 0.001, 0.48200000000000004, 0.11]
0.9011385
1.0023813333333331
Reward 20.392078719683006
Current State [[0.13  0.15  0.26  0.18  0.151 0.9   0.038 0.001 0.482 0.11 ]]
Logits tf.Tensor([[ 0.02150593 -0.16394162  0.38572252]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30579934 0.2540374  0.44016328]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.04, 0.37, 0.154, 0.151, 0.95, 0.044, 0.001, 0.48600000000000004, 0.15]
0.95394
1.2910713333333335
Reward 7.3324732677173
Current State [[0.05  0.04  0.37  0.154 0.151 0.95  0.044 0.001 0.486 0.15 ]]
Logits tf.Tensor([[ 0.041804   -0.13783778  0.37400547]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30963558 0.25872204 0.4316424 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.09, 0.15, 0.26, 0.138, 0.151, 0.75, 0.039, 0.006, 0.5469999999999999, 0.15]
0.7475796666666666
5.8809525
Reward 16.26320772392502
Current State [[0.09  0.15  0.26  0.138 0.151 0.75  0.039 0.006 0.547 0.15 ]]
Logits tf.Tensor([[ 0.03215205 -0.16294171  0.3785578 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3089534  0.25419378 0.43685278]], shape=(1, 3), dtype=float32)
Selected action 1
[0.07, 0.08, 0.29, 0.14, 0.151, 0.89, 0.031, 0.003, 0.54, 0.06]
0.8898033333333335
3.1196425000000003
Reward 10.921580358584645
Current State [[0.07  0.08  0.29  0.14  0.151 0.89  0.031 0.003 0.54  0.06 ]]
Logits tf.Tensor([[ 0.039681   -0.14097978  0.38533556]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30791658 0.25702363 0.4350598 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.1, 0.08, 0.31, 0.183, 0.151, 0.89, 0.031, 0.003, 0.54, 0.06]
0.8898033333333335
3.1196425000000003
Reward 10.921580358584645
Episode: 48 | Average Reward: 287 | Episode Reward: 395 | Loss: 946.568 | Steps: 19 | Worker: 0
Current State [[ 0.00861675  0.00093482 -0.00246745  0.00103866 -0.00717891  0.00676507
  -0.00074771  0.00535551 -0.00915759  0.00126432]]
Logits tf.Tensor([[ 0.01705689 -0.00950188 -0.00480595]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.33873445 0.32985646 0.3314091 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.03, 0.04, 0.42, 0.159, 0.151, 0.83, 0.03, 0.001, 0.724, 0.12]
0.8273848333333335
1.0648811666666667
Reward 7.574089427994577
Current State [[0.03  0.04  0.42  0.159 0.151 0.83  0.03  0.001 0.724 0.12 ]]
Logits tf.Tensor([[ 0.04964578 -0.13324386  0.42869762]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30360448 0.25286007 0.44353545]], shape=(1, 3), dtype=float32)
Selected action 2
[0.13, 0.15, 0.25, 0.14, 0.151, 0.69, 0.031, 0.003, 0.738, 0.16]
0.6930569999999998
3.4113094999999998
Reward 16.569269156542305
Current State [[0.13  0.15  0.25  0.14  0.151 0.69  0.031 0.003 0.738 0.16 ]]
Logits tf.Tensor([[ 0.03026718 -0.18481259  0.42212602]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30430228 0.24541283 0.45028487]], shape=(1, 3), dtype=float32)
Selected action 2
[0.15, 0.15, 0.26, 0.174, 0.151, 0.69, 0.031, 0.003, 0.738, 0.16]
0.6930569999999998
3.4113094999999998
Reward 16.569269156542305
Current State [[0.15  0.15  0.26  0.174 0.151 0.69  0.031 0.003 0.738 0.16 ]]
Logits tf.Tensor([[ 0.02949233 -0.18121748  0.42279133]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30377868 0.24606347 0.45015785]], shape=(1, 3), dtype=float32)
Selected action 0
[0.02, 0.04, 0.3, 0.155, 0.151, 0.85, 0.039, 0.005, 0.5509999999999999, 0.11]
0.8524011666666667
5.337500333333334
Reward 4.391995506319473
Current State [[0.02  0.04  0.3   0.155 0.151 0.85  0.039 0.005 0.551 0.11 ]]
Logits tf.Tensor([[ 0.04476358 -0.1221315   0.3706366 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30945113 0.26188493 0.42866394]], shape=(1, 3), dtype=float32)
Selected action 1
[0.09, 0.08, 0.32, 0.14, 0.151, 0.66, 0.027, 0.006, 0.8140000000000001, 0.17]
0.661996
5.8910713333333335
Reward 10.20605304579814
Current State [[0.09  0.08  0.32  0.14  0.151 0.66  0.027 0.006 0.814 0.17 ]]
Logits tf.Tensor([[ 0.02775926 -0.16989635  0.44372502]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29971647 0.24596308 0.45432043]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.28, 0.122, 0.151, 0.66, 0.027, 0.006, 0.8140000000000001, 0.17]
0.661996
5.8910713333333335
Reward 4.206053045798138
Current State [[0.04  0.04  0.28  0.122 0.151 0.66  0.027 0.006 0.814 0.17 ]]
Logits tf.Tensor([[ 0.02691061 -0.16201892  0.43725014]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29983437 0.24821636 0.45194924]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.42, 0.156, 0.151, 0.95, 0.04, 0.001, 0.736, 0.2]
0.9525625000000001
0.9964284999999999
Reward 8.797558830135491
Current State [[0.04  0.04  0.42  0.156 0.151 0.95  0.04  0.001 0.736 0.2  ]]
Logits tf.Tensor([[ 0.04944777 -0.15466852  0.4453897 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3029247  0.24699493 0.45008034]], shape=(1, 3), dtype=float32)
Selected action 1
[0.08, 0.08, 0.34, 0.157, 0.151, 0.91, 0.04, 0.001, 0.532, 0.01]
0.9140566666666667
0.5476189999999999
Reward 21.173237975792976
Current State [[0.08  0.08  0.34  0.157 0.151 0.91  0.04  0.001 0.532 0.01 ]]
Logits tf.Tensor([[ 0.03350218 -0.1332192   0.39273658]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30500194 0.25816444 0.43683368]], shape=(1, 3), dtype=float32)
Selected action 2
[0.16, 0.15, 0.3, 0.137, 0.151, 0.9, 0.051, 0.001, 0.434, 0.15]
0.9023278333333334
0.6511908333333333
Reward 24.353115252353653
Current State [[0.16  0.15  0.3   0.137 0.151 0.9   0.051 0.001 0.434 0.15 ]]
Logits tf.Tensor([[ 0.00265289 -0.1794372   0.37553346]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3043735  0.25370333 0.44192323]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.32, 0.142, 0.151, 0.9, 0.051, 0.001, 0.434, 0.15]
0.9023278333333334
0.6511908333333333
Reward 12.353115252353653
Current State [[0.04  0.04  0.32  0.142 0.151 0.9   0.051 0.001 0.434 0.15 ]]
Logits tf.Tensor([[ 0.03263351 -0.13322301  0.3468955 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.31090504 0.26338872 0.4257062 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.02, 0.04, 0.36, 0.151, 0.151, 0.81, 0.057, 0.004, 0.44299999999999995, 0.16]
0.8071521666666667
3.682737666666667
Reward 4.63616274969264
Current State [[0.02  0.04  0.36  0.151 0.151 0.81  0.057 0.004 0.443 0.16 ]]
Logits tf.Tensor([[ 0.03987459 -0.11526391  0.34170997]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.31165898 0.26687253 0.42146847]], shape=(1, 3), dtype=float32)
Selected action 1
[0.08, 0.08, 0.36, 0.128, 0.151, 0.74, 0.07, 0.004, 0.43200000000000005, 0.21]
0.7394149999999999
3.9535704999999997
Reward 10.502701563199015
Current State [[0.08  0.08  0.36  0.128 0.151 0.74  0.07  0.004 0.432 0.21 ]]
Logits tf.Tensor([[ 0.02397397 -0.14223202  0.33745965]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3110364  0.26340798 0.42555565]], shape=(1, 3), dtype=float32)
Selected action 2
[0.11, 0.15, 0.25, 0.168, 0.151, 0.74, 0.07, 0.004, 0.43200000000000005, 0.21]
0.7394149999999999
3.9535704999999997
Reward 16.502701563199015
Current State [[0.11  0.15  0.25  0.168 0.151 0.74  0.07  0.004 0.432 0.21 ]]
Logits tf.Tensor([[ 0.00991515 -0.16136631  0.3451219 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30856448 0.25999162 0.4314439 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.16, 0.15, 0.29, 0.18, 0.151, 0.96, 0.048, 0.0, 0.40599999999999997, 0.14]
0.9622208333333333
0.46666650000000004
Reward 31.609719772044496
Current State [[0.16  0.15  0.29  0.18  0.151 0.96  0.048 0.    0.406 0.14 ]]
Logits tf.Tensor([[ 0.00115536 -0.17638741  0.37252012]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3042254  0.25473556 0.44103912]], shape=(1, 3), dtype=float32)
Selected action 2
[0.16, 0.15, 0.3, 0.176, 0.151, 0.98, 0.054, 0.0, 0.42800000000000005, 0.17]
0.9770078333333334
0.42559483333333326
Reward 34.454217012350455
Current State [[0.16  0.15  0.3   0.176 0.151 0.98  0.054 0.    0.428 0.17 ]]
Logits tf.Tensor([[ 0.00140075 -0.18405534  0.38324058]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30342543 0.25206318 0.4445114 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.21, 0.15, 0.27, 0.124, 0.151, 0.96, 0.053, 0.0, 0.39, 0.17]
0.9590403333333334
0.16726116666666666
Reward 60.104311245416376
Current State [[0.21  0.15  0.27  0.124 0.151 0.96  0.053 0.    0.39  0.17 ]]
Logits tf.Tensor([[-0.01983058 -0.20339641  0.36681134]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30263355 0.251881   0.4454854 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.06, 0.04, 0.35, 0.153, 0.151, 0.88, 0.063, 0.001, 0.381, 0.08]
0.8770736666666666
1.0345235
Reward 8.0406220324228
Current State [[0.06  0.04  0.35  0.153 0.151 0.88  0.063 0.001 0.381 0.08 ]]
Logits tf.Tensor([[ 0.0215218  -0.12252368  0.33330417]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30943412 0.26792303 0.42264286]], shape=(1, 3), dtype=float32)
Selected action 1
[0.03, 0.08, 0.32, 0.177, 0.151, 0.88, 0.063, 0.001, 0.381, 0.08]
0.8770736666666666
1.0345235
Reward 14.0406220324228
Current State [[0.03  0.08  0.32  0.177 0.151 0.88  0.063 0.001 0.381 0.08 ]]
Logits tf.Tensor([[ 0.02677896 -0.12124048  0.34163263]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30936065 0.26679704 0.42384225]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.4, 0.138, 0.151, 0.94, 0.038, 0.001, 0.421, 0.11]
0.9383098333333333
0.6136903333333332
Reward 13.733693046725056
Current State [[0.04  0.04  0.4   0.138 0.151 0.94  0.038 0.001 0.421 0.11 ]]
Logits tf.Tensor([[ 0.03798673 -0.12736703  0.35563058]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.31041625 0.2631069  0.4264768 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.34, 0.136, 0.151, 0.9, 0.046, 0.001, 0.471, 0.16]
0.9041773333333333
0.8660716666666667
Reward 9.453980704448991
Episode: 49 | Average Reward: 287 | Episode Reward: 329 | Loss: 1096.565 | Steps: 19 | Worker: 0
Current State [[-0.00466111 -0.0010347   0.00166054 -0.00732071  0.00673227  0.00700566
   0.00109802  0.00109385 -0.00058265 -0.00556247]]
Logits tf.Tensor([[ 0.01841193 -0.00685679 -0.00175155]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3383996  0.32995582 0.3316446 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.07, 0.08, 0.31, 0.167, 0.151, 0.9, 0.046, 0.001, 0.471, 0.16]
0.9041773333333333
0.8660716666666667
Reward 15.453980704448991
Current State [[0.07  0.08  0.31  0.167 0.151 0.9   0.046 0.001 0.471 0.16 ]]
Logits tf.Tensor([[ 0.03445881 -0.14293003  0.36597353]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30954665 0.2592311  0.4312222 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.07, 0.08, 0.29, 0.155, 0.151, 0.87, 0.038, 0.003, 0.472, 0.16]
0.8656495
3.1077378333333328
Reward 10.892021615414802
Current State [[0.07  0.08  0.29  0.155 0.151 0.87  0.038 0.003 0.472 0.16 ]]
Logits tf.Tensor([[ 0.03676376 -0.14212659  0.35912266]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.31088942 0.25996497 0.42914557]], shape=(1, 3), dtype=float32)
Selected action 2
[0.16, 0.15, 0.28, 0.154, 0.151, 0.89, 0.038, 0.001, 0.487, 0.18]
0.8900978333333334
1.311904666666667
Reward 18.96256442457453
Current State [[0.16  0.15  0.28  0.154 0.151 0.89  0.038 0.001 0.487 0.18 ]]
Logits tf.Tensor([[ 0.01618298 -0.1782934   0.38475695]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3059098  0.251845   0.44224513]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.04, 0.39, 0.16, 0.151, 0.89, 0.038, 0.001, 0.487, 0.18]
0.8900978333333334
1.311904666666667
Reward 6.962564424574529
Current State [[0.05  0.04  0.39  0.16  0.151 0.89  0.038 0.001 0.487 0.18 ]]
Logits tf.Tensor([[ 0.04691065 -0.12669776  0.36515218]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.31100968 0.2614428  0.42754757]], shape=(1, 3), dtype=float32)
Selected action 2
[0.1, 0.15, 0.26, 0.188, 0.151, 0.76, 0.031, 0.004, 0.562, 0.11]
0.7554535
3.698214333333333
Reward 16.573882565606354
Current State [[0.1   0.15  0.26  0.188 0.151 0.76  0.031 0.004 0.562 0.11 ]]
Logits tf.Tensor([[ 0.03476186 -0.14955026  0.382564  ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30791703 0.25608724 0.43599576]], shape=(1, 3), dtype=float32)
Selected action 1
[0.08, 0.08, 0.34, 0.152, 0.151, 0.9, 0.051, 0.001, 0.409, 0.18]
0.901249
0.9446428333333334
Reward 14.783695044955287
Current State [[0.08  0.08  0.34  0.152 0.151 0.9   0.051 0.001 0.409 0.18 ]]
Logits tf.Tensor([[ 0.02427802 -0.14771028  0.34980744]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3099091  0.26094005 0.42915085]], shape=(1, 3), dtype=float32)
Selected action 1
[0.06, 0.08, 0.28, 0.142, 0.151, 0.96, 0.053, 0.001, 0.413, 0.13]
0.958676
0.6690485
Reward 18.797697579211146
Current State [[0.06  0.08  0.28  0.142 0.151 0.96  0.053 0.001 0.413 0.13 ]]
Logits tf.Tensor([[ 0.02160328 -0.15320173  0.35396317]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30922654 0.25963297 0.43114048]], shape=(1, 3), dtype=float32)
Selected action 2
[0.16, 0.15, 0.3, 0.185, 0.151, 0.96, 0.053, 0.001, 0.413, 0.13]
0.958676
0.6690485
Reward 24.797697579211146
Current State [[0.16  0.15  0.3   0.185 0.151 0.96  0.053 0.001 0.413 0.13 ]]
Logits tf.Tensor([[ 0.00212542 -0.1736625   0.37453443]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30394933 0.25495145 0.44109926]], shape=(1, 3), dtype=float32)
Selected action 2
[0.15, 0.15, 0.28, 0.181, 0.151, 0.98, 0.027, 0.001, 0.369, 0.03]
0.9841213333333335
0.5970241666666667
Reward 26.954632879187308
Current State [[0.15  0.15  0.28  0.181 0.151 0.98  0.027 0.001 0.369 0.03 ]]
Logits tf.Tensor([[ 0.00566061 -0.16100687  0.36016023]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3056283  0.25870857 0.43566313]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.41, 0.121, 0.151, 0.87, 0.05, 0.003, 0.449, 0.22]
0.8738421666666666
3.1476195000000002
Reward 4.887934190763558
Current State [[0.04  0.04  0.41  0.121 0.151 0.87  0.05  0.003 0.449 0.22 ]]
Logits tf.Tensor([[ 0.04022383 -0.1338006   0.35297337]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.31177363 0.261976   0.42625037]], shape=(1, 3), dtype=float32)
Selected action 2
[0.17, 0.15, 0.27, 0.145, 0.151, 0.83, 0.052, 0.002, 0.509, 0.22]
0.8318248333333333
2.4470233333333327
Reward 17.169713617843264
Current State [[0.17  0.15  0.27  0.145 0.151 0.83  0.052 0.002 0.509 0.22 ]]
Logits tf.Tensor([[ 0.01019884 -0.18790904  0.37901193]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30615696 0.2511348  0.44270825]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.33, 0.163, 0.151, 0.83, 0.052, 0.002, 0.509, 0.22]
0.8318248333333333
2.4470233333333327
Reward 5.169713617843265
Current State [[0.04  0.04  0.33  0.163 0.151 0.83  0.052 0.002 0.509 0.22 ]]
Logits tf.Tensor([[ 0.03997538 -0.13079047  0.3560519 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3110658  0.26223436 0.42669988]], shape=(1, 3), dtype=float32)
Selected action 2
[0.22, 0.15, 0.28, 0.192, 0.151, 0.69, 0.028, 0.002, 0.585, 0.11]
0.6883061666666667
2.4351185
Reward 16.910198069660005
Current State [[0.22  0.15  0.28  0.192 0.151 0.69  0.028 0.002 0.585 0.11 ]]
Logits tf.Tensor([[ 0.02355117 -0.16588181  0.38084725]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30704165 0.2540549  0.43890345]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.38, 0.119, 0.151, 0.96, 0.028, 0.001, 0.426, 0.11]
0.9649223333333334
0.5315481666666666
Reward 16.760717755572813
Current State [[0.04  0.04  0.38  0.119 0.151 0.96  0.028 0.001 0.426 0.11 ]]
Logits tf.Tensor([[ 0.03981682 -0.1337266   0.35498512]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3114129  0.2617988  0.42678827]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.32, 0.148, 0.151, 0.96, 0.028, 0.001, 0.426, 0.11]
0.9649223333333334
0.5315481666666666
Reward 16.760717755572813
Current State [[0.04  0.04  0.32  0.148 0.151 0.96  0.028 0.001 0.426 0.11 ]]
Logits tf.Tensor([[ 0.04081789 -0.132422    0.3480471 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3124425  0.26274413 0.4248133 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.4, 0.131, 0.151, 0.66, 0.019, 0.009, 0.931, 0.13]
0.6582106666666668
8.9083335
Reward 4.060150313473014
Current State [[0.04  0.04  0.4   0.131 0.151 0.66  0.019 0.009 0.931 0.13 ]]
Logits tf.Tensor([[ 0.02839967 -0.15591335  0.49073982]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29244375 0.2432183  0.46433792]], shape=(1, 3), dtype=float32)
Selected action 1
[0.08, 0.08, 0.25, 0.129, 0.151, 0.62, 0.015, 0.008, 0.798, 0.12]
0.6180091666666667
7.921428500000001
Reward 10.075584951071246
Current State [[0.08  0.08  0.25  0.129 0.151 0.62  0.015 0.008 0.798 0.12 ]]
Logits tf.Tensor([[ 0.02848955 -0.16104646  0.43578997]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30029142 0.24844398 0.4512646 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.07, 0.08, 0.23, 0.137, 0.151, 0.62, 0.015, 0.008, 0.798, 0.12]
0.6180091666666667
7.921428500000001
Reward 10.075584951071246
Current State [[0.07  0.08  0.23  0.137 0.151 0.62  0.015 0.008 0.798 0.12 ]]
Logits tf.Tensor([[ 0.02899469 -0.16103642  0.4363532 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30032048 0.24834503 0.45133448]], shape=(1, 3), dtype=float32)
Selected action 2
[0.12, 0.15, 0.27, 0.18, 0.151, 0.93, 0.044, 0.001, 0.471, 0.12]
0.9281256666666666
0.6303571666666666
Reward 25.177294720466705
Current State [[0.12  0.15  0.27  0.18  0.151 0.93  0.044 0.001 0.471 0.12 ]]
Logits tf.Tensor([[ 0.01946753 -0.16447893  0.38574377]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30540562 0.2540915  0.4405029 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.36, 0.132, 0.151, 0.91, 0.036, 0.001, 0.45899999999999996, 0.14]
0.9069754999999999
0.7017856666666666
Reward 11.50614373533065
Episode: 50 | Average Reward: 287 | Episode Reward: 292 | Loss: 681.956 | Steps: 19 | Worker: 0
Current State [[ 0.00381869  0.00055513 -0.00164724 -0.00170042  0.00631741  0.00544783
   0.00273547 -0.0081259   0.00554734 -0.009452  ]]
Logits tf.Tensor([[ 0.01643183 -0.00709005  0.00162654]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.33760333 0.32975492 0.3326418 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.02, 0.04, 0.31, 0.138, 0.151, 0.82, 0.019, 0.002, 0.607, 0.07]
0.815754
2.1482143333333332
Reward 5.357139930477525
Current State [[0.02  0.04  0.31  0.138 0.151 0.82  0.019 0.002 0.607 0.07 ]]
Logits tf.Tensor([[ 0.05058408 -0.11855458  0.38098258]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3090317  0.2609438  0.43002453]], shape=(1, 3), dtype=float32)
Selected action 1
[0.11, 0.08, 0.24, 0.157, 0.151, 0.82, 0.019, 0.002, 0.607, 0.07]
0.815754
2.1482143333333332
Reward 11.357139930477526
Current State [[0.11  0.08  0.24  0.157 0.151 0.82  0.019 0.002 0.607 0.07 ]]
Logits tf.Tensor([[ 0.03495594 -0.14274082  0.38085496]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30764914 0.2575627  0.43478817]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.15, 0.22, 0.156, 0.151, 0.99, 0.038, 0.0, 0.39, 0.02]
0.9875716666666666
0.18154716666666668
Reward 59.488846279563745
Current State [[0.06  0.15  0.22  0.156 0.151 0.99  0.038 0.    0.39  0.02 ]]
Logits tf.Tensor([[ 0.02096637 -0.15510432  0.3621949 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30814427 0.25839704 0.43345872]], shape=(1, 3), dtype=float32)
Selected action 2
[0.1, 0.15, 0.25, 0.127, 0.151, 0.94, 0.023, 0.001, 0.425, 0.08]
0.9377808333333333
1.4910715000000003
Reward 18.670902945382384
Current State [[0.1   0.15  0.25  0.127 0.151 0.94  0.023 0.001 0.425 0.08 ]]
Logits tf.Tensor([[ 0.02210819 -0.16647784  0.36702293]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3086421  0.25559554 0.43576238]], shape=(1, 3), dtype=float32)
Selected action 2
[0.15, 0.15, 0.26, 0.208, 0.151, 0.94, 0.023, 0.001, 0.425, 0.08]
0.9377808333333333
1.4910715000000003
Reward 18.670902945382384
Current State [[0.15  0.15  0.26  0.208 0.151 0.94  0.023 0.001 0.425 0.08 ]]
Logits tf.Tensor([[ 0.01876361 -0.15721203  0.36585832]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3073529  0.25775793 0.4348892 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.09, 0.15, 0.26, 0.192, 0.151, 0.83, 0.029, 0.001, 0.48200000000000004, 0.13]
0.8280715
0.624405
Reward 23.808232000668355
Current State [[0.09  0.15  0.26  0.192 0.151 0.83  0.029 0.001 0.482 0.13 ]]
Logits tf.Tensor([[ 0.03541069 -0.145082    0.36976373]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30941603 0.25831866 0.43226534]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.38, 0.154, 0.151, 0.97, 0.048, 0.001, 0.44000000000000006, 0.14]
0.9685999999999999
0.70119
Reward 12.313237183224176
Current State [[0.04  0.04  0.38  0.154 0.151 0.97  0.048 0.001 0.44  0.14 ]]
Logits tf.Tensor([[ 0.03877378 -0.13305643  0.3588511 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.31062108 0.2615809  0.427798  ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.07, 0.08, 0.29, 0.146, 0.151, 0.84, 0.027, 0.002, 0.529, 0.1]
0.8433601666666666
2.2511898333333336
Reward 11.332760242003719
Current State [[0.07  0.08  0.29  0.146 0.151 0.84  0.027 0.002 0.529 0.1  ]]
Logits tf.Tensor([[ 0.04171796 -0.13420363  0.36939895]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30994013 0.2599417  0.4301182 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.09, 0.15, 0.26, 0.176, 0.151, 0.84, 0.027, 0.002, 0.529, 0.1]
0.8433601666666666
2.2511898333333336
Reward 17.33276024200372
Current State [[0.09  0.15  0.26  0.176 0.151 0.84  0.027 0.002 0.529 0.1  ]]
Logits tf.Tensor([[ 0.03798088 -0.14963348  0.38557693]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30820492 0.2554816  0.43631345]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.32, 0.156, 0.151, 0.9, 0.021, 0.003, 0.379, 0.07]
0.8985954999999998
2.624404166666667
Reward 5.181157361455383
Current State [[0.04  0.04  0.32  0.156 0.151 0.9   0.021 0.003 0.379 0.07 ]]
Logits tf.Tensor([[ 0.0425144  -0.11596842  0.32230267]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.314833   0.26869032 0.4164767 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.09, 0.15, 0.25, 0.158, 0.151, 0.86, 0.036, 0.002, 0.567, 0.13]
0.8639746666666668
1.6488098333333334
Reward 18.08728885788535
Current State [[0.09  0.15  0.25  0.158 0.151 0.86  0.036 0.002 0.567 0.13 ]]
Logits tf.Tensor([[ 0.03491757 -0.16373576  0.3980443 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30696955 0.2516641  0.4413664 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.22, 0.15, 0.27, 0.133, 0.151, 0.96, 0.034, 0.001, 0.44800000000000006, 0.13]
0.9616965
0.809524
Reward 22.607432262762075
Current State [[0.22  0.15  0.27  0.133 0.151 0.96  0.034 0.001 0.448 0.13 ]]
Logits tf.Tensor([[-0.0032402  -0.19658816  0.37753516]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30417195 0.25069705 0.44513097]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.04, 0.33, 0.135, 0.151, 0.96, 0.034, 0.001, 0.44800000000000006, 0.13]
0.9616965
0.809524
Reward 10.607432262762076
Current State [[0.05  0.04  0.33  0.135 0.151 0.96  0.034 0.001 0.448 0.13 ]]
Logits tf.Tensor([[ 0.03939103 -0.13872816  0.3536364 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.31190848 0.26101834 0.42707312]], shape=(1, 3), dtype=float32)
Selected action 2
[0.1, 0.15, 0.24, 0.142, 0.151, 0.83, 0.023, 0.002, 0.513, 0.1]
0.8341568333333333
2.4892853333333336
Reward 17.14734804267003
Current State [[0.1   0.15  0.24  0.142 0.151 0.83  0.023 0.002 0.513 0.1  ]]
Logits tf.Tensor([[ 0.03477354 -0.15591355  0.37810552]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30902082 0.25537208 0.4356071 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.07, 0.08, 0.28, 0.123, 0.151, 0.96, 0.038, 0.001, 0.43099999999999994, 0.1]
0.9623281666666668
0.7809523333333332
Reward 16.98212911574409
Current State [[0.07  0.08  0.28  0.123 0.151 0.96  0.038 0.001 0.431 0.1  ]]
Logits tf.Tensor([[ 0.02773084 -0.15364583  0.35586283]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.31031874 0.25884336 0.43083787]], shape=(1, 3), dtype=float32)
Selected action 2
[0.15, 0.15, 0.26, 0.164, 0.151, 0.96, 0.038, 0.001, 0.43099999999999994, 0.1]
0.9623281666666668
0.7809523333333332
Reward 22.98212911574409
Current State [[0.15  0.15  0.26  0.164 0.151 0.96  0.038 0.001 0.431 0.1  ]]
Logits tf.Tensor([[ 0.00939453 -0.17395402  0.37251323]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30578378 0.25455827 0.43965793]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.31, 0.138, 0.151, 0.96, 0.039, 0.002, 0.457, 0.09]
0.9586900000000002
2.0821435
Reward 5.755547434850569
Current State [[0.04  0.04  0.31  0.138 0.151 0.96  0.039 0.002 0.457 0.09 ]]
Logits tf.Tensor([[ 0.03992168 -0.13399579  0.3553864 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.31140396 0.26169342 0.42690256]], shape=(1, 3), dtype=float32)
Selected action 1
[0.05, 0.08, 0.28, 0.127, 0.151, 0.75, 0.038, 0.006, 0.544, 0.13]
0.7493996666666667
6.328570333333334
Reward 10.229388935965028
Current State [[0.05  0.08  0.28  0.127 0.151 0.75  0.038 0.006 0.544 0.13 ]]
Logits tf.Tensor([[ 0.03844395 -0.13455851  0.35700065]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3109185  0.2615246  0.42755693]], shape=(1, 3), dtype=float32)
Selected action 1
[0.09, 0.08, 0.3, 0.165, 0.151, 0.89, 0.035, 0.002, 0.606, 0.11]
0.8949588333333334
1.623810166666667
Reward 12.23392649426669
Current State [[0.09  0.08  0.3   0.165 0.151 0.89  0.035 0.002 0.606 0.11 ]]
Logits tf.Tensor([[ 0.03789738 -0.1471796   0.3978992 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3063376  0.2545789  0.43908352]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.15, 0.24, 0.177, 0.151, 0.89, 0.035, 0.002, 0.606, 0.11]
0.8949588333333334
1.623810166666667
Reward 18.23392649426669
Episode: 51 | Average Reward: 288 | Episode Reward: 338 | Loss: 828.891 | Steps: 19 | Worker: 0
Current State [[ 0.00247342 -0.00481589 -0.00906161  0.0070582  -0.00283616  0.0069395
   0.00971039  0.00612717  0.00838054  0.00061053]]
Logits tf.Tensor([[ 0.01970225 -0.0096472   0.00086185]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.338706   0.32890964 0.33238435]], shape=(1, 3), dtype=float32)
Selected action 2
[0.21, 0.15, 0.28, 0.192, 0.151, 0.83, 0.021, 0.001, 0.608, 0.09]
0.8293356666666666
0.8880951666666667
Reward 20.638200031431914
Current State [[0.21  0.15  0.28  0.192 0.151 0.83  0.021 0.001 0.608 0.09 ]]
Logits tf.Tensor([[ 0.02678233 -0.17310792  0.40332255]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30524522 0.24994107 0.44481373]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.38, 0.14, 0.151, 0.76, 0.04, 0.011, 0.615, 0.2]
0.7586734999999999
10.694643000000001
Reward 4.049168405543066
Current State [[0.04  0.04  0.38  0.14  0.151 0.76  0.04  0.011 0.615 0.2  ]]
Logits tf.Tensor([[ 0.04808998 -0.13450825  0.37072167]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3111524  0.25922188 0.42962572]], shape=(1, 3), dtype=float32)
Selected action 2
[0.14, 0.15, 0.26, 0.138, 0.151, 0.79, 0.034, 0.002, 0.842, 0.14]
0.790813
2.4238095
Reward 17.10671736871361
Current State [[0.14  0.15  0.26  0.138 0.151 0.79  0.034 0.002 0.842 0.14 ]]
Logits tf.Tensor([[ 0.03116611 -0.20032464  0.4670598 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2994286  0.23755167 0.46301973]], shape=(1, 3), dtype=float32)
Selected action 1
[0.07, 0.08, 0.29, 0.167, 0.151, 0.79, 0.034, 0.002, 0.842, 0.14]
0.790813
2.4238095
Reward 11.106717368713609
Current State [[0.07  0.08  0.29  0.167 0.151 0.79  0.034 0.002 0.842 0.14 ]]
Logits tf.Tensor([[ 0.03399377 -0.16872469  0.4574043 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29907265 0.24419522 0.45673212]], shape=(1, 3), dtype=float32)
Selected action 2
[0.11, 0.15, 0.26, 0.174, 0.151, 0.74, 0.031, 0.003, 0.834, 0.19]
0.7393175
2.6482141666666665
Reward 16.8947999751022
Current State [[0.11  0.15  0.26  0.174 0.151 0.74  0.031 0.003 0.834 0.19 ]]
Logits tf.Tensor([[ 0.03417859 -0.19805837  0.46312776]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3004445  0.23817989 0.46137553]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.15, 0.22, 0.119, 0.151, 0.97, 0.041, 0.001, 0.71, 0.18]
0.9673721666666667
0.9922621666666668
Reward 20.935704001144885
Current State [[0.06  0.15  0.22  0.119 0.151 0.97  0.041 0.001 0.71  0.18 ]]
Logits tf.Tensor([[ 0.03679118 -0.19558042  0.44887805]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30279016 0.2400071  0.45720276]], shape=(1, 3), dtype=float32)
Selected action 2
[0.1, 0.15, 0.26, 0.145, 0.151, 0.94, 0.046, 0.001, 0.434, 0.01]
0.9419629999999999
0.8488093333333333
Reward 21.968362748356043
Current State [[0.1   0.15  0.26  0.145 0.151 0.94  0.046 0.001 0.434 0.01 ]]
Logits tf.Tensor([[ 0.01755406 -0.155566    0.3739969 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30587807 0.25725466 0.43686727]], shape=(1, 3), dtype=float32)
Selected action 2
[0.21, 0.15, 0.3, 0.183, 0.151, 0.94, 0.046, 0.001, 0.434, 0.01]
0.9419629999999999
0.8488093333333333
Reward 21.968362748356043
Current State [[0.21  0.15  0.3   0.183 0.151 0.94  0.046 0.001 0.434 0.01 ]]
Logits tf.Tensor([[-0.00166386 -0.1650177   0.3762358 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3022511  0.25669906 0.4410498 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.43, 0.136, 0.151, 0.92, 0.059, 0.005, 0.426, 0.2]
0.9152273333333335
5.2125
Reward 4.45604290450419
Current State [[0.04  0.04  0.43  0.136 0.151 0.92  0.059 0.005 0.426 0.2  ]]
Logits tf.Tensor([[ 0.03794865 -0.13264617  0.35244846]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3112611  0.26244387 0.4262951 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.17, 0.15, 0.27, 0.182, 0.151, 0.8, 0.045, 0.002, 0.506, 0.16]
0.7955230000000001
1.9303568333333332
Reward 17.513980910112803
Current State [[0.17  0.15  0.27  0.182 0.151 0.8   0.045 0.002 0.506 0.16 ]]
Logits tf.Tensor([[ 0.01909061 -0.16690004  0.37061715]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30754876 0.255352   0.43709922]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.41, 0.117, 0.151, 0.93, 0.07, 0.002, 0.38, 0.18]
0.9293321666666667
2.1166665
Reward 5.647553648654
Current State [[0.04  0.04  0.41  0.117 0.151 0.93  0.07  0.002 0.38  0.18 ]]
Logits tf.Tensor([[ 0.02436755 -0.13745712  0.3400591 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.31038573 0.2640111  0.42560318]], shape=(1, 3), dtype=float32)
Selected action 2
[0.17, 0.15, 0.28, 0.161, 0.151, 0.93, 0.07, 0.002, 0.38, 0.18]
0.9293321666666667
2.1166665
Reward 17.647553648654
Current State [[0.17  0.15  0.28  0.161 0.151 0.93  0.07  0.002 0.38  0.18 ]]
Logits tf.Tensor([[-0.0081616  -0.18534933  0.3556462 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3052112  0.25565174 0.43913713]], shape=(1, 3), dtype=float32)
Selected action 2
[0.11, 0.15, 0.24, 0.168, 0.151, 0.95, 0.056, 0.001, 0.41500000000000004, 0.14]
0.9545426666666667
0.5190481666666666
Reward 29.026033689252426
Current State [[0.11  0.15  0.24  0.168 0.151 0.95  0.056 0.001 0.415 0.14 ]]
Logits tf.Tensor([[ 0.00971612 -0.17167261  0.36498797]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30668455 0.25580898 0.4375065 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.08, 0.08, 0.36, 0.138, 0.151, 0.98, 0.054, 0.0, 0.403, 0.08]
0.98098
0.33571400000000007
Reward 36.19893066171221
Current State [[0.08  0.08  0.36  0.138 0.151 0.98  0.054 0.    0.403 0.08 ]]
Logits tf.Tensor([[ 0.01976146 -0.14714928  0.35943955]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3076194  0.26033062 0.43205   ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.42, 0.157, 0.151, 0.93, 0.048, 0.001, 0.43499999999999994, 0.18]
0.9286656666666667
0.8023808333333332
Reward 10.354039335727617
Current State [[0.04  0.04  0.42  0.157 0.151 0.93  0.048 0.001 0.435 0.18 ]]
Logits tf.Tensor([[ 0.04260357 -0.126695    0.3547173 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.31147146 0.2629619  0.4255666 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.08, 0.08, 0.27, 0.182, 0.151, 0.93, 0.048, 0.001, 0.43499999999999994, 0.18]
0.9286656666666667
0.8023808333333332
Reward 16.354039335727617
Current State [[0.08  0.08  0.27  0.182 0.151 0.93  0.048 0.001 0.435 0.18 ]]
Logits tf.Tensor([[ 0.02831057 -0.14934146  0.3497571 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.31091094 0.2603051  0.4287839 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.1, 0.15, 0.25, 0.169, 0.151, 0.88, 0.075, 0.0, 0.371, 0.13]
0.8762483333333333
0.14940483333333335
Reward 60.329511500207964
Current State [[0.1   0.15  0.25  0.169 0.151 0.88  0.075 0.    0.371 0.13 ]]
Logits tf.Tensor([[ 0.00185535 -0.15907864  0.34641892]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30649257 0.2609319  0.43257558]], shape=(1, 3), dtype=float32)
Selected action 1
[0.08, 0.08, 0.34, 0.229, 0.151, 0.88, 0.075, 0.0, 0.371, 0.13]
0.8762483333333333
0.14940483333333335
Reward 54.329511500207964
Current State [[0.08  0.08  0.34  0.229 0.151 0.88  0.075 0.    0.371 0.13 ]]
Logits tf.Tensor([[ 0.02151093 -0.1254981   0.33515158]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3094362  0.26713198 0.42343184]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.39, 0.157, 0.151, 0.92, 0.036, 0.001, 0.41900000000000004, 0.1]
0.9217356666666668
0.5565481666666667
Reward 15.03638656147108
Current State [[0.04  0.04  0.39  0.157 0.151 0.92  0.036 0.001 0.419 0.1  ]]
Logits tf.Tensor([[ 0.0425168  -0.11742791  0.34564492]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.31188804 0.26578814 0.42232382]], shape=(1, 3), dtype=float32)
Selected action 0
[0.02, 0.04, 0.45, 0.204, 0.151, 0.92, 0.036, 0.001, 0.41900000000000004, 0.1]
0.9217356666666668
0.5565481666666667
Reward 15.03638656147108
Episode: 52 | Average Reward: 289 | Episode Reward: 416 | Loss: 1740.121 | Steps: 19 | Worker: 0
Current State [[-0.00824635  0.00825977 -0.00091073 -0.0066792   0.00868352  0.00867043
  -0.00223807 -0.00949139  0.00688697 -0.00569505]]
Logits tf.Tensor([[ 0.02107696 -0.00543598  0.0027773 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.33832908 0.32947683 0.33219406]], shape=(1, 3), dtype=float32)
Selected action 1
[0.06, 0.08, 0.31, 0.227, 0.151, 0.77, 0.038, 0.004, 0.5519999999999999, 0.19]
0.7735199999999999
3.6934514999999997
Reward 10.595348842108816
Current State [[0.06  0.08  0.31  0.227 0.151 0.77  0.038 0.004 0.552 0.19 ]]
Logits tf.Tensor([[ 0.0442578  -0.12661272  0.3606922 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3110268  0.26217407 0.42679918]], shape=(1, 3), dtype=float32)
Selected action 2
[0.14, 0.15, 0.27, 0.224, 0.151, 0.77, 0.038, 0.004, 0.5519999999999999, 0.19]
0.7735199999999999
3.6934514999999997
Reward 16.595348842108816
Current State [[0.14  0.15  0.27  0.224 0.151 0.77  0.038 0.004 0.552 0.19 ]]
Logits tf.Tensor([[ 0.03404453 -0.16213143  0.37531108]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3097322  0.25455883 0.43570897]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.04, 0.49, 0.212, 0.151, 0.9, 0.045, 0.001, 0.45999999999999996, 0.15]
0.9047993333333333
1.3374995
Reward 6.950636160514683
Current State [[0.05  0.04  0.49  0.212 0.151 0.9   0.045 0.001 0.46  0.15 ]]
Logits tf.Tensor([[ 0.05358571 -0.11179765  0.36727533]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.31094202 0.26354474 0.42551324]], shape=(1, 3), dtype=float32)
Selected action 1
[0.08, 0.08, 0.33, 0.237, 0.151, 0.9, 0.045, 0.001, 0.45999999999999996, 0.15]
0.9047993333333333
1.3374995
Reward 12.950636160514684
Current State [[0.08  0.08  0.33  0.237 0.151 0.9   0.045 0.001 0.46  0.15 ]]
Logits tf.Tensor([[ 0.03985719 -0.12760927  0.35995793]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.31026304 0.26242203 0.42731488]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.04, 0.32, 0.144, 0.151, 0.82, 0.031, 0.002, 0.564, 0.13]
0.8232169999999999
2.4827383333333333
Reward 5.131104911059166
Current State [[0.05  0.04  0.32  0.144 0.151 0.82  0.031 0.002 0.564 0.13 ]]
Logits tf.Tensor([[ 0.0435676  -0.12556241  0.36592123]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.31009945 0.2618477  0.42805284]], shape=(1, 3), dtype=float32)
Selected action 2
[0.12, 0.15, 0.27, 0.235, 0.151, 0.82, 0.031, 0.002, 0.564, 0.13]
0.8232169999999999
2.4827383333333333
Reward 17.131104911059168
Current State [[0.12  0.15  0.27  0.235 0.151 0.82  0.031 0.002 0.564 0.13 ]]
Logits tf.Tensor([[ 0.0379021  -0.15129668  0.38946652]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30779546 0.25473824 0.43746635]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.15, 0.25, 0.194, 0.151, 0.91, 0.045, 0.002, 0.47800000000000004, 0.13]
0.9053958333333332
1.9392853333333333
Reward 17.788411027565967
Current State [[0.08  0.15  0.25  0.194 0.151 0.91  0.045 0.002 0.478 0.13 ]]
Logits tf.Tensor([[ 0.0318306  -0.15474088  0.38000876]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30804452 0.25561512 0.43634033]], shape=(1, 3), dtype=float32)
Selected action 2
[0.17, 0.15, 0.29, 0.236, 0.151, 0.91, 0.045, 0.002, 0.47800000000000004, 0.13]
0.9053958333333332
1.9392853333333333
Reward 17.788411027565967
Current State [[0.17  0.15  0.29  0.236 0.151 0.91  0.045 0.002 0.478 0.13 ]]
Logits tf.Tensor([[ 0.0201346 -0.1589055  0.3821267]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30559918 0.25550303 0.43889776]], shape=(1, 3), dtype=float32)
Selected action 2
[0.15, 0.15, 0.27, 0.234, 0.151, 0.97, 0.028, 0.0, 0.378, 0.05]
0.9730893333333334
0.3398808333333333
Reward 41.488696732864426
Current State [[0.15  0.15  0.27  0.234 0.151 0.97  0.028 0.    0.378 0.05 ]]
Logits tf.Tensor([[ 0.0137853  -0.15112221  0.35637164]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30707267 0.26038906 0.43253824]], shape=(1, 3), dtype=float32)
Selected action 2
[0.14, 0.15, 0.26, 0.154, 0.151, 0.86, 0.04, 0.001, 0.513, 0.21]
0.8588523333333332
0.6172621666666666
Reward 24.406504817413076
Current State [[0.14  0.15  0.26  0.154 0.151 0.86  0.04  0.001 0.513 0.21 ]]
Logits tf.Tensor([[ 0.02340821 -0.17986465  0.3808787 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30809388 0.25142172 0.4404844 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.34, 0.192, 0.151, 0.86, 0.04, 0.001, 0.513, 0.21]
0.8588523333333332
0.6172621666666666
Reward 12.406504817413076
Current State [[0.04  0.04  0.34  0.192 0.151 0.86  0.04  0.001 0.513 0.21 ]]
Logits tf.Tensor([[ 0.04819215 -0.12487733  0.3580237 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.31208313 0.2624866  0.4254303 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.08, 0.08, 0.29, 0.153, 0.151, 0.84, 0.034, 0.002, 0.485, 0.11]
0.8392508333333333
1.6011903333333335
Reward 12.088052621800507
Current State [[0.08  0.08  0.29  0.153 0.151 0.84  0.034 0.002 0.485 0.11 ]]
Logits tf.Tensor([[ 0.03675802 -0.1343132   0.35689312]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.31055173 0.26172104 0.4277272 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.04, 0.33, 0.237, 0.151, 0.84, 0.034, 0.002, 0.485, 0.11]
0.8392508333333333
1.6011903333333335
Reward 6.088052621800508
Current State [[0.05  0.04  0.33  0.237 0.151 0.84  0.034 0.002 0.485 0.11 ]]
Logits tf.Tensor([[ 0.04753377 -0.10318626  0.34733737]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.31155732 0.26796684 0.42047578]], shape=(1, 3), dtype=float32)
Selected action 2
[0.15, 0.15, 0.27, 0.242, 0.151, 0.96, 0.028, 0.001, 0.561, 0.1]
0.9623521666666667
0.9023810000000001
Reward 21.627376262899595
Current State [[0.15  0.15  0.27  0.242 0.151 0.96  0.028 0.001 0.561 0.1  ]]
Logits tf.Tensor([[ 0.0330526  -0.16159046  0.41062188]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30470496 0.25081134 0.44448367]], shape=(1, 3), dtype=float32)
Selected action 2
[0.13, 0.15, 0.26, 0.245, 0.151, 0.96, 0.028, 0.001, 0.561, 0.1]
0.9623521666666667
0.9023810000000001
Reward 21.627376262899595
Current State [[0.13  0.15  0.26  0.245 0.151 0.96  0.028 0.001 0.561 0.1  ]]
Logits tf.Tensor([[ 0.03594449 -0.15873525  0.40950012]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30525127 0.25125176 0.44349694]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.24, 0.224, 0.152, 0.89, 0.032, 0.002, 0.44699999999999995, 0.11]
0.8949486666666665
1.5642858333333334
Reward 18.349233525850764
Current State [[0.05  0.15  0.24  0.224 0.152 0.89  0.032 0.002 0.447 0.11 ]]
Logits tf.Tensor([[ 0.04004316 -0.13727197  0.36589444]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.31029642 0.25987813 0.42982548]], shape=(1, 3), dtype=float32)
Selected action 2
[0.28, 0.15, 0.24, 0.241, 0.14, 0.89, 0.032, 0.002, 0.44699999999999995, 0.11]
0.8949486666666665
1.5642858333333334
Reward 18.349233525850764
Current State [[0.28  0.15  0.24  0.241 0.14  0.89  0.032 0.002 0.447 0.11 ]]
Logits tf.Tensor([[ 0.00204599 -0.17833605  0.35927492]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30634308 0.2557815  0.43787548]], shape=(1, 3), dtype=float32)
Selected action 1
[0.09, 0.08, 0.26, 0.212, 0.141, 0.65, 0.022, 0.027, 0.47300000000000003, 0.12]
0.6464665000000002
27.47023833333333
Reward 9.876225512654791
Current State [[0.09  0.08  0.26  0.212 0.141 0.65  0.022 0.027 0.473 0.12 ]]
Logits tf.Tensor([[ 0.04275145 -0.11455003  0.30870217]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.31654412 0.27047    0.41298583]], shape=(1, 3), dtype=float32)
Selected action 1
[0.12, 0.08, 0.25, 0.24, 0.137, 0.65, 0.022, 0.027, 0.47300000000000003, 0.12]
0.6464665000000002
27.47023833333333
Reward 9.876225512654791
Current State [[0.12  0.08  0.25  0.24  0.137 0.65  0.022 0.027 0.473 0.12 ]]
Logits tf.Tensor([[ 0.03997391 -0.11663514  0.3058127 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.31649947 0.27061915 0.41288134]], shape=(1, 3), dtype=float32)
Selected action 0
[0.03, 0.04, 0.3, 0.235, 0.139, 0.65, 0.022, 0.027, 0.47300000000000003, 0.12]
0.6464665000000002
27.47023833333333
Reward 3.8762255126547904
Episode: 53 | Average Reward: 289 | Episode Reward: 304 | Loss: 798.058 | Steps: 19 | Worker: 0
Current State [[ 3.75454284e-03  4.80699209e-03 -5.14110468e-03  1.03798390e-03
   5.94784750e-03 -8.45953828e-05  8.88594678e-03 -5.39899736e-03
   5.33727058e-03 -9.41241041e-03]]
Logits tf.Tensor([[ 0.01682292 -0.00654638 -0.0003743 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.33785477 0.3300509  0.3320943 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.09, 0.08, 0.26, 0.2, 0.139, 0.97, 0.036, 0.0, 0.45, 0.15]
0.9725126666666667
0.43750033333333327
Reward 27.558053346784128
Current State [[0.09  0.08  0.26  0.2   0.139 0.97  0.036 0.    0.45  0.15 ]]
Logits tf.Tensor([[ 0.03197739 -0.15146519  0.35737896]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.31084993 0.2587514  0.43039864]], shape=(1, 3), dtype=float32)
Selected action 2
[0.13, 0.15, 0.27, 0.219, 0.14, 0.92, 0.031, 0.001, 0.524, 0.11]
0.9179379999999998
1.3392851666666665
Reward 19.004118414289433
Current State [[0.13  0.15  0.27  0.219 0.14  0.92  0.031 0.001 0.524 0.11 ]]
Logits tf.Tensor([[ 0.0324425  -0.15902512  0.39496133]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3064955  0.25308755 0.44041696]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.31, 0.208, 0.14, 0.92, 0.031, 0.001, 0.524, 0.11]
0.9179379999999998
1.3392851666666665
Reward 7.004118414289433
Current State [[0.04  0.04  0.31  0.208 0.14  0.92  0.031 0.001 0.524 0.11 ]]
Logits tf.Tensor([[ 0.04813528 -0.1209435   0.36761817]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.31047627 0.2621793  0.42734444]], shape=(1, 3), dtype=float32)
Selected action 2
[0.1, 0.15, 0.26, 0.176, 0.141, 0.81, 0.015, 0.004, 0.511, 0.05]
0.8050655000000001
3.9523808333333337
Reward 16.571456637329682
Current State [[0.1   0.15  0.26  0.176 0.141 0.81  0.015 0.004 0.511 0.05 ]]
Logits tf.Tensor([[ 0.03966836 -0.14188847  0.37556967]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3092938  0.257942   0.43276417]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.34, 0.21, 0.141, 0.81, 0.015, 0.004, 0.511, 0.05]
0.8050655000000001
3.9523808333333337
Reward 4.571456637329681
Current State [[0.04  0.04  0.34  0.21  0.141 0.81  0.015 0.004 0.511 0.05 ]]
Logits tf.Tensor([[ 0.05244122 -0.09694336  0.35343048]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3112906  0.26809523 0.4206142 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.18, 0.15, 0.28, 0.236, 0.141, 0.7, 0.028, 0.003, 0.533, 0.09]
0.701437
2.9797614999999995
Reward 16.704877511072787
Current State [[0.18  0.15  0.28  0.236 0.141 0.7   0.028 0.003 0.533 0.09 ]]
Logits tf.Tensor([[ 0.02998171 -0.14739019  0.36250237]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30941102 0.2591219  0.4314671 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.11, 0.15, 0.26, 0.218, 0.141, 0.7, 0.028, 0.003, 0.533, 0.09]
0.701437
2.9797614999999995
Reward 16.704877511072787
Current State [[0.11  0.15  0.26  0.218 0.141 0.7   0.028 0.003 0.533 0.09 ]]
Logits tf.Tensor([[ 0.0367636  -0.1391001   0.36112514]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.31037784 0.2603239  0.42929825]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.32, 0.194, 0.141, 0.83, 0.021, 0.001, 0.493, 0.07]
0.8278841666666666
0.7005953333333335
Reward 10.55495241665193
Current State [[0.04  0.04  0.32  0.194 0.141 0.83  0.021 0.001 0.493 0.07 ]]
Logits tf.Tensor([[ 0.04895202 -0.10429303  0.34812763]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.31185037 0.2675425  0.4206071 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.14, 0.08, 0.29, 0.145, 0.141, 0.91, 0.033, 0.001, 0.5, 0.08]
0.9100533333333332
1.4994041666666662
Reward 12.544817034308714
Current State [[0.14  0.08  0.29  0.145 0.141 0.91  0.033 0.001 0.5   0.08 ]]
Logits tf.Tensor([[ 0.02399313 -0.15501253  0.36979002]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3077665  0.25732392 0.4349096 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.09, 0.08, 0.29, 0.214, 0.141, 0.91, 0.033, 0.001, 0.5, 0.08]
0.9100533333333332
1.4994041666666662
Reward 12.544817034308714
Current State [[0.09  0.08  0.29  0.214 0.141 0.91  0.033 0.001 0.5   0.08 ]]
Logits tf.Tensor([[ 0.03758052 -0.1332482   0.36946008]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3089709  0.26045194 0.4305772 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.06, 0.04, 0.3, 0.122, 0.142, 0.96, 0.046, 0.001, 0.472, 0.13]
0.963947
0.7797623333333333
Reward 11.01607476160562
Current State [[0.06  0.04  0.3   0.122 0.142 0.96  0.046 0.001 0.472 0.13 ]]
Logits tf.Tensor([[ 0.03120398 -0.14875758  0.35889262]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.31026423 0.25916442 0.43057132]], shape=(1, 3), dtype=float32)
Selected action 2
[0.18, 0.15, 0.27, 0.228, 0.142, 0.96, 0.046, 0.001, 0.472, 0.13]
0.963947
0.7797623333333333
Reward 23.01607476160562
Current State [[0.18  0.15  0.27  0.228 0.142 0.96  0.046 0.001 0.472 0.13 ]]
Logits tf.Tensor([[ 0.01313516 -0.17276314  0.38501406]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30480227 0.25309503 0.44210267]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.33, 0.214, 0.142, 0.9, 0.027, 0.002, 0.45199999999999996, 0.04]
0.9045288333333336
1.6815476666666667
Reward 6.162076165051174
Current State [[0.04  0.04  0.33  0.214 0.142 0.9   0.027 0.002 0.452 0.04 ]]
Logits tf.Tensor([[ 0.04656849 -0.10555675  0.34612185]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3117074  0.26771948 0.4205731 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.09, 0.15, 0.24, 0.206, 0.142, 0.9, 0.027, 0.002, 0.45199999999999996, 0.04]
0.9045288333333336
1.6815476666666667
Reward 18.162076165051175
Current State [[0.09  0.15  0.24  0.206 0.142 0.9   0.027 0.002 0.452 0.04 ]]
Logits tf.Tensor([[ 0.03220882 -0.14280757  0.3690617 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30864424 0.2590893  0.4322664 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.09, 0.15, 0.24, 0.22, 0.142, 0.86, 0.022, 0.003, 0.49000000000000005, 0.04]
0.8616705000000001
2.7476190000000003
Reward 17.04895032829119
Current State [[0.09  0.15  0.24  0.22  0.142 0.86  0.022 0.003 0.49  0.04 ]]
Logits tf.Tensor([[ 0.03876876 -0.13665897  0.37494922]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30876687 0.25908566 0.43214747]], shape=(1, 3), dtype=float32)
Selected action 2
[0.09, 0.15, 0.28, 0.204, 0.142, 0.91, 0.033, 0.003, 0.40199999999999997, 0.08]
0.9140866666666667
3.424404833333334
Reward 16.841005631019595
Current State [[0.09  0.15  0.28  0.204 0.142 0.91  0.033 0.003 0.402 0.08 ]]
Logits tf.Tensor([[ 0.02816943 -0.1446264   0.35826048]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30936727 0.26027358 0.4303592 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.09, 0.08, 0.32, 0.181, 0.142, 0.91, 0.033, 0.003, 0.40199999999999997, 0.08]
0.9140866666666667
3.424404833333334
Reward 10.841005631019595
Current State [[0.09  0.08  0.32  0.181 0.142 0.91  0.033 0.003 0.402 0.08 ]]
Logits tf.Tensor([[ 0.03070817 -0.1336552   0.34245628]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.31111512 0.26396054 0.42492434]], shape=(1, 3), dtype=float32)
Selected action 1
[0.07, 0.08, 0.3, 0.139, 0.142, 0.86, 0.028, 0.004, 0.492, 0.08]
0.8578235000000001
4.297618833333334
Reward 10.554510020736465
Current State [[0.07  0.08  0.3   0.139 0.142 0.86  0.028 0.004 0.492 0.08 ]]
Logits tf.Tensor([[ 0.03855821 -0.13557187  0.3620947 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.31034756 0.26075014 0.42890233]], shape=(1, 3), dtype=float32)
Selected action 0
[0.02, 0.04, 0.31, 0.192, 0.142, 0.86, 0.028, 0.004, 0.492, 0.08]
0.8578235000000001
4.297618833333334
Reward 4.554510020736465
Current State [[0.02  0.04  0.31  0.192 0.142 0.86  0.028 0.004 0.492 0.08 ]]
Logits tf.Tensor([[ 0.05050045 -0.10808475  0.3507194 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.31215814 0.26638025 0.42146167]], shape=(1, 3), dtype=float32)
Selected action 2
[0.19, 0.15, 0.27, 0.204, 0.142, 0.91, 0.036, 0.001, 0.622, 0.11]
0.9055385
1.3077383333333332
Reward 19.046701835015853
Episode: 54 | Average Reward: 289 | Episode Reward: 281 | Loss: 590.435 | Steps: 19 | Worker: 0
Current State [[ 0.00619947 -0.00158363  0.00911951  0.00989203 -0.00207247 -0.00053563
   0.00339875 -0.00318291 -0.00597364  0.00598401]]
Logits tf.Tensor([[ 0.01898436 -0.00904975 -0.00480264]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.33911538 0.3297406  0.33114406]], shape=(1, 3), dtype=float32)
Selected action 2
[0.11, 0.15, 0.25, 0.169, 0.142, 0.83, 0.029, 0.001, 0.562, 0.14]
0.8279499999999999
1.3136905
Reward 18.67851747144821
Current State [[0.11  0.15  0.25  0.169 0.142 0.83  0.029 0.001 0.562 0.14 ]]
Logits tf.Tensor([[ 0.03249084 -0.16752487  0.39263156]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30747956 0.251739   0.4407815 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.03, 0.04, 0.37, 0.194, 0.142, 0.83, 0.029, 0.001, 0.562, 0.14]
0.8279499999999999
1.3136905
Reward 6.6785174714482105
Current State [[0.03  0.04  0.37  0.194 0.142 0.83  0.029 0.001 0.562 0.14 ]]
Logits tf.Tensor([[ 0.05063    -0.11598822  0.37379447]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3097879  0.26224247 0.42796963]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.04, 0.45, 0.149, 0.142, 0.76, 0.035, 0.004, 0.75, 0.14]
0.7647301666666665
4.085119
Reward 4.503416082709432
Current State [[0.05  0.04  0.45  0.149 0.142 0.76  0.035 0.004 0.75  0.14 ]]
Logits tf.Tensor([[ 0.04312364 -0.14221168  0.42875662]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3029045  0.25166082 0.44543466]], shape=(1, 3), dtype=float32)
Selected action 1
[0.07, 0.08, 0.28, 0.206, 0.142, 0.76, 0.035, 0.004, 0.75, 0.14]
0.7647301666666665
4.085119
Reward 10.503416082709432
Current State [[0.07  0.08  0.28  0.206 0.142 0.76  0.035 0.004 0.75  0.14 ]]
Logits tf.Tensor([[ 0.03708331 -0.15600789  0.42129767]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30368674 0.25036138 0.44595188]], shape=(1, 3), dtype=float32)
Selected action 1
[0.1, 0.08, 0.27, 0.159, 0.142, 0.71, 0.028, 0.003, 0.8470000000000001, 0.18]
0.7085100000000001
3.219642666666667
Reward 10.639894240765617
Current State [[0.1   0.08  0.27  0.159 0.142 0.71  0.028 0.003 0.847 0.18 ]]
Logits tf.Tensor([[ 0.02920398 -0.1871249   0.45817265]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29929873 0.24107626 0.45962498]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.15, 0.23, 0.182, 0.142, 0.71, 0.028, 0.003, 0.8470000000000001, 0.18]
0.7085100000000001
3.219642666666667
Reward 16.639894240765617
Current State [[0.08  0.15  0.23  0.182 0.142 0.71  0.028 0.003 0.847 0.18 ]]
Logits tf.Tensor([[ 0.03044252 -0.20115602  0.4765214 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2980236  0.23641154 0.4655649 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.15, 0.27, 0.214, 0.142, 0.87, 0.031, 0.004, 0.626, 0.06]
0.8669111666666666
4.492857
Reward 16.527051389223498
Current State [[0.08  0.15  0.27  0.214 0.142 0.87  0.031 0.004 0.626 0.06 ]]
Logits tf.Tensor([[ 0.04053142 -0.15284142  0.41954914]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3044118  0.2508885  0.44469965]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.41, 0.141, 0.142, 0.98, 0.052, 0.001, 0.395, 0.14]
0.9815456666666668
0.5892850000000002
Reward 15.136359234093156
Current State [[0.04  0.04  0.41  0.141 0.142 0.98  0.052 0.001 0.395 0.14 ]]
Logits tf.Tensor([[ 0.03289938 -0.13811861  0.35251012]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.31061706 0.26179004 0.4275929 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.13, 0.15, 0.28, 0.216, 0.142, 0.98, 0.052, 0.001, 0.395, 0.14]
0.9815456666666668
0.5892850000000002
Reward 27.136359234093156
Current State [[0.13  0.15  0.28  0.216 0.142 0.98  0.052 0.001 0.395 0.14 ]]
Logits tf.Tensor([[ 0.01187922 -0.17091726  0.3685316 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30660954 0.25538665 0.43800378]], shape=(1, 3), dtype=float32)
Selected action 2
[0.15, 0.15, 0.31, 0.221, 0.142, 0.96, 0.06, 0.0, 0.42000000000000004, 0.17]
0.9585168333333333
0.31547616666666667
Reward 43.57104970945776
Current State [[0.15  0.15  0.31  0.221 0.142 0.96  0.06  0.    0.42  0.17 ]]
Logits tf.Tensor([[ 0.01227018 -0.17520598  0.3777351 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30578864 0.25351375 0.44069767]], shape=(1, 3), dtype=float32)
Selected action 2
[0.12, 0.15, 0.27, 0.222, 0.142, 0.96, 0.06, 0.0, 0.42000000000000004, 0.17]
0.9585168333333333
0.31547616666666667
Reward 43.57104970945776
Current State [[0.12  0.15  0.27  0.222 0.142 0.96  0.06  0.    0.42  0.17 ]]
Logits tf.Tensor([[ 0.01509178 -0.17098762  0.37366632]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3066078  0.2545482  0.43884403]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.04, 0.39, 0.214, 0.142, 0.88, 0.069, 0.005, 0.391, 0.22]
0.8830828333333332
4.946428333333333
Reward 4.468015804301732
Current State [[0.05  0.04  0.39  0.214 0.142 0.88  0.069 0.005 0.391 0.22 ]]
Logits tf.Tensor([[ 0.04052448 -0.12841235  0.3360629 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.31363574 0.26488492 0.42147928]], shape=(1, 3), dtype=float32)
Selected action 2
[0.18, 0.15, 0.29, 0.234, 0.142, 0.78, 0.038, 0.003, 0.5599999999999999, 0.18]
0.7779211666666668
3.2124993333333336
Reward 16.733743659432758
Current State [[0.18  0.15  0.29  0.234 0.142 0.78  0.038 0.003 0.56  0.18 ]]
Logits tf.Tensor([[ 0.02905251 -0.17197515  0.38292465]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30840757 0.25224337 0.43934909]], shape=(1, 3), dtype=float32)
Selected action 2
[0.17, 0.15, 0.29, 0.231, 0.142, 0.78, 0.038, 0.003, 0.5599999999999999, 0.18]
0.7779211666666668
3.2124993333333336
Reward 16.733743659432758
Current State [[0.17  0.15  0.29  0.231 0.142 0.78  0.038 0.003 0.56  0.18 ]]
Logits tf.Tensor([[ 0.03010537 -0.17053427  0.38317093]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3084866  0.252406   0.43910736]], shape=(1, 3), dtype=float32)
Selected action 2
[0.09, 0.15, 0.25, 0.216, 0.142, 0.89, 0.048, 0.0, 0.479, 0.13]
0.8884803333333332
0.4589284999999999
Reward 30.130990134484357
Current State [[0.09  0.15  0.25  0.216 0.142 0.89  0.048 0.    0.479 0.13 ]]
Logits tf.Tensor([[ 0.02854933 -0.15500925  0.38035142]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30732065 0.25578395 0.43689537]], shape=(1, 3), dtype=float32)
Selected action 1
[0.08, 0.08, 0.27, 0.198, 0.142, 0.89, 0.048, 0.0, 0.479, 0.13]
0.8884803333333332
0.4589284999999999
Reward 24.130990134484357
Current State [[0.08  0.08  0.27  0.198 0.142 0.89  0.048 0.    0.479 0.13 ]]
Logits tf.Tensor([[ 0.03165873 -0.14164616  0.36290765]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30925402 0.2600459  0.43070006]], shape=(1, 3), dtype=float32)
Selected action 2
[0.16, 0.15, 0.28, 0.233, 0.142, 0.91, 0.033, 0.001, 0.41200000000000003, 0.1]
0.9121511666666667
0.5934520000000002
Reward 25.814157508585915
Current State [[0.16  0.15  0.28  0.233 0.142 0.91  0.033 0.001 0.412 0.1  ]]
Logits tf.Tensor([[ 0.01783537 -0.15604077  0.36282274]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30746782 0.25839627 0.43413597]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.04, 0.33, 0.132, 0.142, 0.98, 0.051, 0.0, 0.375, 0.12]
0.9804171666666667
0.17618983333333332
Reward 47.77032792287055
Current State [[0.05  0.04  0.33  0.132 0.142 0.98  0.051 0.    0.375 0.12 ]]
Logits tf.Tensor([[ 0.02387012 -0.14584085  0.33841318]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.31118312 0.2626101  0.42620674]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.35, 0.212, 0.142, 0.98, 0.051, 0.0, 0.375, 0.12]
0.9804171666666667
0.17618983333333332
Reward 47.77032792287055
Current State [[0.04  0.04  0.35  0.212 0.142 0.98  0.051 0.    0.375 0.12 ]]
Logits tf.Tensor([[ 0.03425763 -0.12499613  0.33914337]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3115993 0.2657256 0.4226751]], shape=(1, 3), dtype=float32)
Selected action 2
[0.16, 0.15, 0.28, 0.208, 0.142, 0.87, 0.046, 0.001, 0.488, 0.17]
0.8729708333333334
0.9017856666666667
Reward 20.88540529772953
Episode: 55 | Average Reward: 291 | Episode Reward: 448 | Loss: 2133.394 | Steps: 19 | Worker: 0
Saving best model to ./Training/, episode score: 448.0232269103643
Current State [[-0.00467127  0.00206574  0.00616274  0.00058923  0.00362264 -0.00916636
  -0.00940091  0.00122407  0.00076138 -0.00155327]]
Logits tf.Tensor([[ 0.02368107 -0.00383253 -0.00928604]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3400861  0.33085665 0.32905725]], shape=(1, 3), dtype=float32)
Selected action 1
[0.1, 0.08, 0.33, 0.215, 0.142, 0.87, 0.046, 0.001, 0.488, 0.17]
0.8729708333333334
0.9017856666666667
Reward 14.88540529772953
Current State [[0.1   0.08  0.33  0.215 0.142 0.87  0.046 0.001 0.488 0.17 ]]
Logits tf.Tensor([[ 0.03563558 -0.14539458  0.37248832]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30912447 0.2579366  0.4329389 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.2, 0.15, 0.29, 0.216, 0.142, 0.93, 0.04, 0.001, 0.404, 0.13]
0.9299883333333333
1.4720241666666667
Reward 18.687362966949706
Current State [[0.2   0.15  0.29  0.216 0.142 0.93  0.04  0.001 0.404 0.13 ]]
Logits tf.Tensor([[ 0.00636635 -0.1798512   0.36972174]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30597508 0.25398776 0.44003713]], shape=(1, 3), dtype=float32)
Selected action 0
[0.06, 0.04, 0.47, 0.142, 0.142, 0.96, 0.056, 0.001, 0.43600000000000005, 0.16]
0.962115
0.8190476666666666
Reward 10.496687668790162
Current State [[0.06  0.04  0.47  0.142 0.142 0.96  0.056 0.001 0.436 0.16 ]]
Logits tf.Tensor([[ 0.03562929 -0.14186993  0.37523407]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.308475  0.2583051 0.4332199]], shape=(1, 3), dtype=float32)
Selected action 1
[0.08, 0.08, 0.35, 0.225, 0.142, 0.96, 0.056, 0.001, 0.43600000000000005, 0.16]
0.962115
0.8190476666666666
Reward 16.496687668790162
Current State [[0.08  0.08  0.35  0.225 0.142 0.96  0.056 0.001 0.436 0.16 ]]
Logits tf.Tensor([[ 0.0345189  -0.14822747  0.37271667]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30908108 0.25745815 0.4334608 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.2, 0.15, 0.27, 0.237, 0.142, 0.96, 0.056, 0.001, 0.43600000000000005, 0.16]
0.962115
0.8190476666666666
Reward 22.496687668790162
Current State [[0.2   0.15  0.27  0.237 0.142 0.96  0.056 0.001 0.436 0.16 ]]
Logits tf.Tensor([[ 0.00435411 -0.18759322  0.38282806]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30437645 0.25121722 0.4444063 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.04, 0.44, 0.169, 0.142, 0.92, 0.048, 0.001, 0.462, 0.17]
0.9207225000000001
1.1880953333333333
Reward 7.561135064553976
Current State [[0.05  0.04  0.44  0.169 0.142 0.92  0.048 0.001 0.462 0.17 ]]
Logits tf.Tensor([[ 0.04455622 -0.1322834   0.37292406]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30992246 0.25968838 0.4303892 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.04, 0.39, 0.135, 0.142, 0.88, 0.042, 0.002, 0.492, 0.13]
0.8796926666666668
2.3107143333333338
Reward 5.361761059106014
Current State [[0.05  0.04  0.39  0.135 0.142 0.88  0.042 0.002 0.492 0.13 ]]
Logits tf.Tensor([[ 0.04046563 -0.13440818  0.37151814]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30940634 0.2597661  0.43082756]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.39, 0.169, 0.142, 0.88, 0.042, 0.002, 0.492, 0.13]
0.8796926666666668
2.3107143333333338
Reward 5.361761059106014
Current State [[0.04  0.04  0.39  0.169 0.142 0.88  0.042 0.002 0.492 0.13 ]]
Logits tf.Tensor([[ 0.0445792  -0.1257236   0.37131482]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30961245 0.26113003 0.42925748]], shape=(1, 3), dtype=float32)
Selected action 0
[0.03, 0.04, 0.39, 0.254, 0.142, 0.78, 0.035, 0.003, 0.568, 0.15]
0.7790115
3.082142666666667
Reward 4.779346834981904
Current State [[0.03  0.04  0.39  0.254 0.142 0.78  0.035 0.003 0.568 0.15 ]]
Logits tf.Tensor([[ 0.05207371 -0.11012778  0.37344643]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30966565 0.26329935 0.42703494]], shape=(1, 3), dtype=float32)
Selected action 1
[0.06, 0.08, 0.31, 0.229, 0.142, 0.78, 0.035, 0.003, 0.568, 0.15]
0.7790115
3.082142666666667
Reward 10.779346834981904
Current State [[0.06  0.08  0.31  0.229 0.142 0.78  0.035 0.003 0.568 0.15 ]]
Logits tf.Tensor([[ 0.04203166 -0.13215673  0.3759754 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30896592 0.25957417 0.43145993]], shape=(1, 3), dtype=float32)
Selected action 2
[0.13, 0.15, 0.25, 0.235, 0.142, 0.75, 0.038, 0.005, 0.618, 0.17]
0.7467198333333334
5.098809666666667
Reward 16.339199989003745
Current State [[0.13  0.15  0.25  0.235 0.142 0.75  0.038 0.005 0.618 0.17 ]]
Logits tf.Tensor([[ 0.035615   -0.17445569  0.39576948]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.308254   0.24984819 0.4418978 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.1, 0.15, 0.26, 0.251, 0.142, 0.75, 0.038, 0.005, 0.618, 0.17]
0.7467198333333334
5.098809666666667
Reward 16.339199989003745
Current State [[0.1   0.15  0.26  0.251 0.142 0.75  0.038 0.005 0.618 0.17 ]]
Logits tf.Tensor([[ 0.04066839 -0.16478758  0.39687288]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3084349  0.25115108 0.440414  ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.12, 0.15, 0.27, 0.248, 0.142, 0.89, 0.036, 0.001, 0.471, 0.12]
0.8866868333333333
0.6839285
Reward 23.54231500023556
Current State [[0.12  0.15  0.27  0.248 0.142 0.89  0.036 0.001 0.471 0.12 ]]
Logits tf.Tensor([[ 0.03144319 -0.15491593  0.38350293]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.307506   0.25522244 0.4372715 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.37, 0.222, 0.142, 0.89, 0.036, 0.001, 0.471, 0.12]
0.8866868333333333
0.6839285
Reward 11.542315000235563
Current State [[0.04  0.04  0.37  0.222 0.142 0.89  0.036 0.001 0.471 0.12 ]]
Logits tf.Tensor([[ 0.04854001 -0.11629833  0.36330798]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.31075472 0.26352957 0.42571574]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.26, 0.193, 0.143, 0.91, 0.026, 0.003, 0.403, 0.09]
0.9059024999999999
2.6208338333333336
Reward 17.196291607125367
Current State [[0.03  0.15  0.26  0.193 0.143 0.91  0.026 0.003 0.403 0.09 ]]
Logits tf.Tensor([[ 0.04097772 -0.14583622  0.3657665 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.311203   0.25817344 0.4306235 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.06, 0.04, 0.24, 0.233, 0.145, 0.73, 0.019, 0.005, 0.792, 0.08]
0.7344431666666666
5.237499166666667
Reward 4.314607830289662
Current State [[0.06  0.04  0.24  0.233 0.145 0.73  0.019 0.005 0.792 0.08 ]]
Logits tf.Tensor([[ 0.03376617 -0.14342538  0.43959415]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29956588 0.25092217 0.44951192]], shape=(1, 3), dtype=float32)
Selected action 2
[0.17, 0.15, 0.28, 0.245, 0.138, 0.73, 0.019, 0.005, 0.792, 0.08]
0.7344431666666666
5.237499166666667
Reward 16.314607830289663
Current State [[0.17  0.15  0.28  0.245 0.138 0.73  0.019 0.005 0.792 0.08 ]]
Logits tf.Tensor([[ 0.03219188 -0.17710027  0.45763636]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2992732 0.2427579 0.4579689]], shape=(1, 3), dtype=float32)
Selected action 1
[0.04, 0.08, 0.29, 0.235, 0.14, 0.73, 0.019, 0.005, 0.792, 0.08]
0.7344431666666666
5.237499166666667
Reward 10.314607830289663
Current State [[0.04  0.08  0.29  0.235 0.14  0.73  0.019 0.005 0.792 0.08 ]]
Logits tf.Tensor([[ 0.04067613 -0.14496982  0.45021817]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29969773 0.24891922 0.45138308]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.15, 0.26, 0.227, 0.142, 0.71, 0.04, 0.0, 0.42800000000000005, 0.0]
0.7078650000000001
0.30178233333333326
Reward 35.074004523200415
Current State [[0.08  0.15  0.26  0.227 0.142 0.71  0.04  0.    0.428 0.   ]]
Logits tf.Tensor([[ 0.03057054 -0.11614896  0.34879738]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30881125 0.26666966 0.42451912]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.15, 0.25, 0.24, 0.139, 0.71, 0.04, 0.0, 0.42800000000000005, 0.0]
0.7078650000000001
0.30178233333333326
Reward 35.074004523200415
Episode: 56 | Average Reward: 291 | Episode Reward: 302 | Loss: 822.907 | Steps: 19 | Worker: 0
Current State [[ 0.00502574 -0.00792926  0.00033761  0.00487162 -0.00892036 -0.00490767
   0.0038345   0.00383593  0.00419812  0.0073379 ]]
Logits tf.Tensor([[ 0.02073449 -0.00985229 -0.00368826]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3394722  0.329246   0.33128178]], shape=(1, 3), dtype=float32)
Selected action 1
[0.07, 0.08, 0.21, 0.245, 0.139, 0.71, 0.04, 0.0, 0.42800000000000005, 0.0]
0.7078650000000001
0.30178233333333326
Reward 29.07400452320042
Current State [[0.07  0.08  0.21  0.245 0.139 0.71  0.04  0.    0.428 0.   ]]
Logits tf.Tensor([[ 0.03161273 -0.1082336   0.32562864]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.31140062 0.27076033 0.41783902]], shape=(1, 3), dtype=float32)
Selected action 2
[0.11, 0.15, 0.26, 0.242, 0.14, 0.64, 0.026, 0.0, 0.446, 0.01]
0.6398638333333334
0.4232129999999999
Reward 25.564565478562002
Current State [[0.11  0.15  0.26  0.242 0.14  0.64  0.026 0.    0.446 0.01 ]]
Logits tf.Tensor([[ 0.03568729 -0.12273193  0.3436219 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.31112874 0.26554585 0.42332545]], shape=(1, 3), dtype=float32)
Selected action 2
[0.11, 0.15, 0.26, 0.232, 0.141, 0.64, 0.026, 0.0, 0.446, 0.01]
0.6398638333333334
0.4232129999999999
Reward 25.564565478562002
Current State [[0.11  0.15  0.26  0.232 0.141 0.64  0.026 0.    0.446 0.01 ]]
Logits tf.Tensor([[ 0.03498984 -0.12444996  0.3439258 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.31108105 0.2652343  0.42368463]], shape=(1, 3), dtype=float32)
Selected action 0
[0.02, 0.04, 0.32, 0.216, 0.141, 0.94, 0.036, 0.0, 0.41500000000000004, 0.02]
0.9406413333333333
0.23273883333333334
Reward 41.184986693498786
Current State [[0.02  0.04  0.32  0.216 0.141 0.94  0.036 0.    0.415 0.02 ]]
Logits tf.Tensor([[ 0.04477536 -0.11815745  0.3543547 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.31128407 0.26448196 0.424234  ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.09, 0.08, 0.32, 0.223, 0.141, 0.94, 0.036, 0.0, 0.41500000000000004, 0.02]
0.9406413333333333
0.23273883333333334
Reward 47.184986693498786
Current State [[0.09  0.08  0.32  0.223 0.141 0.94  0.036 0.    0.415 0.02 ]]
Logits tf.Tensor([[ 0.0329223  -0.13699718  0.3655941 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30879235 0.26053822 0.43066946]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.15, 0.25, 0.23, 0.142, 0.85, 0.029, 0.002, 0.477, 0.11]
0.8464525
2.144642666666667
Reward 17.429052113289895
Current State [[0.07  0.15  0.25  0.23  0.142 0.85  0.029 0.002 0.477 0.11 ]]
Logits tf.Tensor([[ 0.04145588 -0.15335579  0.3826252 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3096377 0.2548286 0.4355337]], shape=(1, 3), dtype=float32)
Selected action 2
[0.13, 0.15, 0.25, 0.224, 0.148, 0.91, 0.043, 0.003, 0.49400000000000005, 0.15]
0.9065971666666666
2.6952385000000003
Reward 17.1532197782667
Current State [[0.13  0.15  0.25  0.224 0.148 0.91  0.043 0.003 0.494 0.15 ]]
Logits tf.Tensor([[ 0.02879099 -0.17909855  0.39788362]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3068691  0.24926877 0.44386208]], shape=(1, 3), dtype=float32)
Selected action 2
[0.13, 0.15, 0.25, 0.224, 0.148, 0.91, 0.043, 0.003, 0.49400000000000005, 0.15]
0.9065971666666666
2.6952385000000003
Reward 17.1532197782667
Current State [[0.13  0.15  0.25  0.224 0.148 0.91  0.043 0.003 0.494 0.15 ]]
Logits tf.Tensor([[ 0.02879099 -0.17909855  0.39788362]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3068691  0.24926877 0.44386208]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.04, 0.35, 0.254, 0.139, 0.91, 0.043, 0.003, 0.49400000000000005, 0.15]
0.9065971666666666
2.6952385000000003
Reward 5.153219778266698
Current State [[0.05  0.04  0.35  0.254 0.139 0.91  0.043 0.003 0.494 0.15 ]]
Logits tf.Tensor([[ 0.04822601 -0.13002798  0.37419257]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3103567  0.2596847  0.42995858]], shape=(1, 3), dtype=float32)
Selected action 2
[0.13, 0.15, 0.27, 0.206, 0.14, 0.66, 0.025, 0.002, 0.388, 0.0]
0.6587323333333333
1.6874980000000002
Reward 17.40817120153427
Current State [[0.13  0.15  0.27  0.206 0.14  0.66  0.025 0.002 0.388 0.   ]]
Logits tf.Tensor([[ 0.02763367 -0.12483934  0.3316912 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.31114563 0.26714405 0.42171028]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.32, 0.151, 0.138, 0.66, 0.025, 0.002, 0.388, 0.0]
0.6587323333333333
1.6874980000000002
Reward 5.4081712015342704
Current State [[0.04  0.04  0.32  0.151 0.138 0.66  0.025 0.002 0.388 0.   ]]
Logits tf.Tensor([[ 0.03750793 -0.09382677  0.31013766]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3134464  0.27486873 0.41168484]], shape=(1, 3), dtype=float32)
Selected action 1
[0.04, 0.08, 0.36, 0.124, 0.139, 0.71, 0.037, 0.001, 0.45499999999999996, 0.0]
0.713598
0.7833341666666666
Reward 14.47605725669435
Current State [[0.04  0.08  0.36  0.124 0.139 0.71  0.037 0.001 0.455 0.   ]]
Logits tf.Tensor([[ 0.03664432 -0.11819302  0.35346192]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.309664   0.26524407 0.4250919 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.34, 0.132, 0.142, 0.77, 0.023, 0.006, 0.524, 0.1]
0.7748151666666666
5.642857
Reward 16.303114901545158
Current State [[0.04  0.15  0.34  0.132 0.142 0.77  0.023 0.006 0.524 0.1  ]]
Logits tf.Tensor([[ 0.05158888 -0.1548839   0.39184844]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.31067857 0.25272098 0.43660042]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.34, 0.164, 0.142, 0.77, 0.023, 0.006, 0.524, 0.1]
0.7748151666666666
5.642857
Reward 16.303114901545158
Current State [[0.05  0.15  0.34  0.164 0.142 0.77  0.023 0.006 0.524 0.1  ]]
Logits tf.Tensor([[ 0.05154215 -0.151125    0.3912488 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.31045434 0.25350147 0.43604413]], shape=(1, 3), dtype=float32)
Selected action 0
[0.03, 0.04, 0.32, 0.149, 0.143, 0.8, 0.033, 0.002, 0.563, 0.1]
0.8033518333333333
1.8291666666666664
Reward 5.648232326543991
Current State [[0.03  0.04  0.32  0.149 0.143 0.8   0.033 0.002 0.563 0.1  ]]
Logits tf.Tensor([[ 0.04348273 -0.13124047  0.37747452]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30900237 0.25946602 0.43153158]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.38, 0.128, 0.143, 0.82, 0.017, 0.004, 0.533, 0.07]
0.8241555
3.7452381666666668
Reward 4.6398759204850215
Current State [[0.04  0.04  0.38  0.128 0.143 0.82  0.017 0.004 0.533 0.07 ]]
Logits tf.Tensor([[ 0.04989286 -0.12880537  0.38047573]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30977616 0.25908384 0.43113998]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.35, 0.171, 0.143, 0.82, 0.017, 0.004, 0.533, 0.07]
0.8241555
3.7452381666666668
Reward 4.6398759204850215
Current State [[0.04  0.04  0.35  0.171 0.143 0.82  0.017 0.004 0.533 0.07 ]]
Logits tf.Tensor([[ 0.05088572 -0.12160417  0.37604076]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30999947 0.26088524 0.42911527]], shape=(1, 3), dtype=float32)
Selected action 1
[0.03, 0.08, 0.33, 0.168, 0.143, 0.9, 0.044, 0.001, 0.45099999999999996, 0.12]
0.8993623333333335
1.1714281666666666
Reward 13.514991365938634
Current State [[0.03  0.08  0.33  0.168 0.143 0.9   0.044 0.001 0.451 0.12 ]]
Logits tf.Tensor([[ 0.04336588 -0.14338997  0.37411603]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.31039917 0.2575215  0.43207934]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.35, 0.158, 0.143, 0.84, 0.031, 0.002, 0.682, 0.11]
0.8425873333333335
1.9125001666666668
Reward 17.65514221464061
Current State [[0.04  0.15  0.35  0.158 0.143 0.84  0.031 0.002 0.682 0.11 ]]
Logits tf.Tensor([[ 0.04878866 -0.17286566  0.44756642]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30384105 0.24343508 0.4527239 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.01, 0.15, 0.37, 0.216, 0.143, 0.84, 0.031, 0.002, 0.682, 0.11]
0.8425873333333335
1.9125001666666668
Reward 17.65514221464061
Episode: 57 | Average Reward: 291 | Episode Reward: 359 | Loss: 747.444 | Steps: 19 | Worker: 0
Current State [[-0.00331459  0.00689168  0.00757626  0.00045836 -0.00876902 -0.00858385
  -0.00476979 -0.0054812   0.0041123   0.0026186 ]]
Logits tf.Tensor([[ 0.02400771 -0.00895757 -0.00373274]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3401114  0.32908234 0.33080623]], shape=(1, 3), dtype=float32)
Selected action 2
[0.02, 0.15, 0.36, 0.114, 0.143, 0.72, 0.026, 0.003, 0.619, 0.13]
0.7222883333333332
2.769047666666667
Reward 16.814446183322836
Current State [[0.02  0.15  0.36  0.114 0.143 0.72  0.026 0.003 0.619 0.13 ]]
Logits tf.Tensor([[ 0.05235324 -0.17112316  0.41355127]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3091399  0.24722962 0.4436305 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.15, 0.41, 0.172, 0.143, 0.72, 0.026, 0.003, 0.619, 0.13]
0.7222883333333332
2.769047666666667
Reward 16.814446183322836
Current State [[0.08  0.15  0.41  0.172 0.143 0.72  0.026 0.003 0.619 0.13 ]]
Logits tf.Tensor([[ 0.0480927  -0.1727177   0.41678363]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3079093  0.24690285 0.4451878 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.41, 0.206, 0.143, 0.8, 0.039, 0.004, 0.701, 0.16]
0.7962716666666668
3.5452386666666675
Reward 16.659059097289514
Current State [[0.03  0.15  0.41  0.206 0.143 0.8   0.039 0.004 0.701 0.16 ]]
Logits tf.Tensor([[ 0.05556942 -0.17829575  0.4529034 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30494115 0.24135132 0.45370752]], shape=(1, 3), dtype=float32)
Selected action 0
[0.03, 0.04, 0.39, 0.134, 0.143, 0.81, 0.035, 0.002, 0.687, 0.08]
0.811826833333333
2.2279759999999995
Reward 5.284125789874109
Current State [[0.03  0.04  0.39  0.134 0.143 0.81  0.035 0.002 0.687 0.08 ]]
Logits tf.Tensor([[ 0.04418672 -0.15187795  0.4309818 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30356255 0.24951598 0.44692144]], shape=(1, 3), dtype=float32)
Selected action 0
[0.03, 0.04, 0.35, 0.108, 0.143, 0.68, 0.019, 0.003, 0.826, 0.09]
0.6773031666666667
3.4267855000000003
Reward 4.546424906634223
Current State [[0.03  0.04  0.35  0.108 0.143 0.68  0.019 0.003 0.826 0.09 ]]
Logits tf.Tensor([[ 0.03303673 -0.16034673  0.4664012 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29703525 0.2448063  0.4581585 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.04, 0.39, 0.15, 0.144, 0.68, 0.019, 0.003, 0.826, 0.09]
0.6773031666666667
3.4267855000000003
Reward 4.546424906634223
Current State [[0.05  0.04  0.39  0.15  0.144 0.68  0.019 0.003 0.826 0.09 ]]
Logits tf.Tensor([[ 0.03417523 -0.15443316  0.47022605]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2963228 0.2453881 0.4582891]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.4, 0.147, 0.144, 0.77, 0.033, 0.002, 0.61, 0.19]
0.7685856666666667
2.3750003333333334
Reward 5.094562808847755
Current State [[0.04  0.04  0.4   0.147 0.144 0.77  0.033 0.002 0.61  0.19 ]]
Logits tf.Tensor([[ 0.04918749 -0.15450718  0.39568824]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30961457 0.25255615 0.43782926]], shape=(1, 3), dtype=float32)
Selected action 1
[0.05, 0.08, 0.41, 0.125, 0.144, 0.79, 0.041, 0.002, 0.546, 0.19]
0.7865505000000002
2.2136901666666664
Reward 11.24143230546137
Current State [[0.05  0.08  0.41  0.125 0.144 0.79  0.041 0.002 0.546 0.19 ]]
Logits tf.Tensor([[ 0.04772878 -0.16370404  0.3929454 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.31039327 0.25123966 0.43836713]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.39, 0.18, 0.144, 0.79, 0.041, 0.002, 0.546, 0.19]
0.7865505000000002
2.2136901666666664
Reward 17.24143230546137
Current State [[0.03  0.15  0.39  0.18  0.144 0.79  0.041 0.002 0.546 0.19 ]]
Logits tf.Tensor([[ 0.05469979 -0.17008948  0.40934706]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.31013882 0.24770309 0.44215804]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.15, 0.41, 0.152, 0.144, 0.81, 0.045, 0.001, 0.511, 0.15]
0.8133084999999999
1.4690475000000005
Reward 18.24748462859355
Current State [[0.06  0.15  0.41  0.152 0.144 0.81  0.045 0.001 0.511 0.15 ]]
Logits tf.Tensor([[ 0.04831201 -0.17152642  0.40842456]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30901018 0.24802656 0.44296327]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.4, 0.127, 0.144, 0.82, 0.043, 0.002, 0.497, 0.19]
0.8167193333333334
1.8023808333333333
Reward 17.718469913119016
Current State [[0.05  0.15  0.4   0.127 0.144 0.82  0.043 0.002 0.497 0.19 ]]
Logits tf.Tensor([[ 0.04928153 -0.17867845  0.40443936]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.31031212 0.24705689 0.442631  ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.02, 0.08, 0.38, 0.14, 0.144, 0.82, 0.043, 0.002, 0.497, 0.19]
0.8167193333333334
1.8023808333333333
Reward 11.718469913119014
Current State [[0.02  0.08  0.38  0.14  0.144 0.82  0.043 0.002 0.497 0.19 ]]
Logits tf.Tensor([[ 0.05140276 -0.15383019  0.38459828]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.31153837 0.25373477 0.43472686]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.15, 0.38, 0.171, 0.144, 0.81, 0.04, 0.003, 0.5349999999999999, 0.19]
0.8086273333333334
2.671429333333334
Reward 16.999636477959474
Current State [[0.06  0.15  0.38  0.171 0.144 0.81  0.04  0.003 0.535 0.19 ]]
Logits tf.Tensor([[ 0.05018128 -0.17735046  0.40954018]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30970222 0.24667695 0.44362083]], shape=(1, 3), dtype=float32)
Selected action 2
[0.02, 0.15, 0.37, 0.137, 0.144, 0.86, 0.044, 0.002, 0.49400000000000005, 0.2]
0.8608563333333332
1.7726189999999997
Reward 17.88517678249006
Current State [[0.02  0.15  0.37  0.137 0.144 0.86  0.044 0.002 0.494 0.2  ]]
Logits tf.Tensor([[ 0.05170294 -0.17685725  0.4088661 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.31008255 0.24672599 0.4431914 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.02, 0.15, 0.35, 0.15, 0.144, 0.86, 0.044, 0.002, 0.49400000000000005, 0.2]
0.8608563333333332
1.7726189999999997
Reward 17.88517678249006
Current State [[0.02  0.15  0.35  0.15  0.144 0.86  0.044 0.002 0.494 0.2  ]]
Logits tf.Tensor([[ 0.0506022  -0.17546953  0.4070079 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30999604 0.2472717  0.44273227]], shape=(1, 3), dtype=float32)
Selected action 1
[0.02, 0.08, 0.33, 0.142, 0.144, 0.78, 0.032, 0.002, 0.509, 0.15]
0.7814613333333335
2.2255948333333335
Reward 11.221818474909323
Current State [[0.02  0.08  0.33  0.142 0.144 0.78  0.032 0.002 0.509 0.15 ]]
Logits tf.Tensor([[ 0.04964466 -0.14649855  0.37654078]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.31166705 0.25615746 0.43217546]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.38, 0.133, 0.144, 0.9, 0.044, 0.001, 0.513, 0.04]
0.9003351666666666
1.0386905
Reward 20.169611664445583
Current State [[0.05  0.15  0.38  0.133 0.144 0.9   0.044 0.001 0.513 0.04 ]]
Logits tf.Tensor([[ 0.0426418  -0.16835277  0.42600706]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30515787 0.24711026 0.44773185]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.39, 0.166, 0.144, 0.9, 0.044, 0.001, 0.513, 0.04]
0.9003351666666666
1.0386905
Reward 20.169611664445583
Current State [[0.05  0.15  0.39  0.166 0.144 0.9   0.044 0.001 0.513 0.04 ]]
Logits tf.Tensor([[ 0.04562166 -0.16158484  0.42693138]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30515224 0.24804354 0.44680423]], shape=(1, 3), dtype=float32)
Selected action 0
[0.03, 0.04, 0.36, 0.183, 0.144, 0.84, 0.049, 0.002, 0.491, 0.17]
0.8448743333333332
1.615476
Reward 6.0818852926846505
Current State [[0.03  0.04  0.36  0.183 0.144 0.84  0.049 0.002 0.491 0.17 ]]
Logits tf.Tensor([[ 0.0457776  -0.13871583  0.37418386]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.31053215 0.2582154  0.4312525 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.37, 0.152, 0.144, 0.85, 0.034, 0.001, 0.5269999999999999, 0.12]
0.8498879999999999
1.4386908333333335
Reward 18.453184009084556
Episode: 58 | Average Reward: 291 | Episode Reward: 274 | Loss: 668.381 | Steps: 19 | Worker: 0
Current State [[-6.48909550e-03  8.13035126e-03  9.31596893e-03  8.96752643e-03
  -4.27849404e-03 -4.64623535e-05 -8.39929261e-03  2.98179504e-03
  -6.18485383e-03  7.10720600e-03]]
Logits tf.Tensor([[ 0.02552598 -0.01101647 -0.00458295]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.34077853 0.32855046 0.33067098]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.37, 0.192, 0.144, 0.85, 0.034, 0.001, 0.5269999999999999, 0.12]
0.8498879999999999
1.4386908333333335
Reward 18.453184009084556
Current State [[0.03  0.15  0.37  0.192 0.144 0.85  0.034 0.001 0.527 0.12 ]]
Logits tf.Tensor([[ 0.05620959 -0.16792224  0.42666492]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30791935 0.24609214 0.44598854]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.04, 0.4, 0.135, 0.144, 0.88, 0.042, 0.002, 0.528, 0.17]
0.8803038333333334
1.8589290000000003
Reward 5.822706776783891
Current State [[0.05  0.04  0.4   0.135 0.144 0.88  0.042 0.002 0.528 0.17 ]]
Logits tf.Tensor([[ 0.04728084 -0.1639482   0.40320852]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30891916 0.25009742 0.4409834 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.02, 0.08, 0.37, 0.164, 0.144, 0.88, 0.042, 0.002, 0.528, 0.17]
0.8803038333333334
1.8589290000000003
Reward 11.82270677678389
Current State [[0.02  0.08  0.37  0.164 0.144 0.88  0.042 0.002 0.528 0.17 ]]
Logits tf.Tensor([[ 0.05246322 -0.16433115  0.4121174 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30883935 0.24864517 0.44251546]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.39, 0.181, 0.144, 0.84, 0.073, 0.012, 0.437, 0.18]
0.8396143333333334
12.073809166666669
Reward 16.043963767546344
Current State [[0.04  0.15  0.39  0.181 0.144 0.84  0.073 0.012 0.437 0.18 ]]
Logits tf.Tensor([[ 0.04645284 -0.18040168  0.4022002 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.31014642 0.24719806 0.4426555 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.39, 0.142, 0.144, 0.81, 0.038, 0.001, 0.542, 0.2]
0.812435
1.2124994999999998
Reward 18.91221006058615
Current State [[0.04  0.15  0.39  0.142 0.144 0.81  0.038 0.001 0.542 0.2  ]]
Logits tf.Tensor([[ 0.05317231 -0.18877184  0.42117462]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30960277 0.24306913 0.44732812]], shape=(1, 3), dtype=float32)
Selected action 1
[0.06, 0.08, 0.4, 0.164, 0.144, 0.81, 0.038, 0.001, 0.542, 0.2]
0.812435
1.2124994999999998
Reward 12.912210060586151
Current State [[0.06  0.08  0.4   0.164 0.144 0.81  0.038 0.001 0.542 0.2  ]]
Logits tf.Tensor([[ 0.04940664 -0.17037678  0.40269294]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30993995 0.24878654 0.44127354]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.36, 0.167, 0.144, 0.87, 0.042, 0.003, 0.507, 0.18]
0.8703831666666667
3.1690476666666663
Reward 16.874857651797566
Current State [[0.03  0.15  0.36  0.167 0.144 0.87  0.042 0.003 0.507 0.18 ]]
Logits tf.Tensor([[ 0.05243722 -0.18233207  0.42230654]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30880412 0.24418788 0.44700798]], shape=(1, 3), dtype=float32)
Selected action 0
[0.06, 0.04, 0.44, 0.169, 0.144, 0.87, 0.042, 0.003, 0.507, 0.18]
0.8703831666666667
3.1690476666666663
Reward 4.874857651797567
Current State [[0.06  0.04  0.44  0.169 0.144 0.87  0.042 0.003 0.507 0.18 ]]
Logits tf.Tensor([[ 0.050892   -0.15622866  0.39906916]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3096546  0.2517249  0.43862054]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.04, 0.4, 0.184, 0.144, 0.82, 0.037, 0.002, 0.542, 0.15]
0.8187605
2.2863098333333336
Reward 5.254596115768138
Current State [[0.05  0.04  0.4   0.184 0.144 0.82  0.037 0.002 0.542 0.15 ]]
Logits tf.Tensor([[ 0.04899551 -0.1488498   0.39669666]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3089943 0.2535288 0.4374769]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.36, 0.125, 0.144, 0.78, 0.04, 0.003, 0.613, 0.17]
0.7779051666666666
2.9535713333333335
Reward 16.825483554072672
Current State [[0.04  0.15  0.36  0.125 0.144 0.78  0.04  0.003 0.613 0.17 ]]
Logits tf.Tensor([[ 0.04750933 -0.1938901   0.43330634]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3070957  0.24123223 0.4516721 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.04, 0.36, 0.156, 0.144, 0.78, 0.04, 0.003, 0.613, 0.17]
0.7779051666666666
2.9535713333333335
Reward 4.8254835540726715
Current State [[0.05  0.04  0.36  0.156 0.144 0.78  0.04  0.003 0.613 0.17 ]]
Logits tf.Tensor([[ 0.0424829  -0.16253428  0.4038192 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3077037  0.2506657  0.44163054]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.33, 0.14, 0.144, 0.76, 0.022, 0.005, 0.553, 0.1]
0.7643316666666669
4.500594500000001
Reward 16.43274249799404
Current State [[0.03  0.15  0.33  0.14  0.144 0.76  0.022 0.005 0.553 0.1  ]]
Logits tf.Tensor([[ 0.05369402 -0.16961426  0.41235915]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30947435 0.24753869 0.44298694]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.36, 0.152, 0.144, 0.9, 0.037, 0.001, 0.564, 0.08]
0.9001116666666668
1.4047625000000001
Reward 18.73956662858019
Current State [[0.04  0.15  0.36  0.152 0.144 0.9   0.037 0.001 0.564 0.08 ]]
Logits tf.Tensor([[ 0.05010502 -0.1803575   0.44665968]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30479816 0.2420604  0.4531415 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.03, 0.04, 0.39, 0.186, 0.144, 0.9, 0.037, 0.001, 0.564, 0.08]
0.9001116666666668
1.4047625000000001
Reward 6.739566628580189
Current State [[0.03  0.04  0.39  0.186 0.144 0.9   0.037 0.001 0.564 0.08 ]]
Logits tf.Tensor([[ 0.0503425  -0.14522535  0.41913328]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30596453 0.25161532 0.44242015]], shape=(1, 3), dtype=float32)
Selected action 1
[0.07, 0.08, 0.39, 0.178, 0.144, 0.89, 0.047, 0.002, 0.505, 0.22]
0.8912548333333333
1.6089283333333337
Reward 12.249197787761355
Current State [[0.07  0.08  0.39  0.178 0.144 0.89  0.047 0.002 0.505 0.22 ]]
Logits tf.Tensor([[ 0.04822124 -0.17790514  0.40780285]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30956426 0.24691379 0.44352195]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.38, 0.136, 0.144, 0.7, 0.023, 0.005, 0.6769999999999999, 0.15]
0.7020088333333333
5.093452166666667
Reward 4.305147495306868
Current State [[0.04  0.04  0.38  0.136 0.144 0.7   0.023 0.005 0.677 0.15 ]]
Logits tf.Tensor([[ 0.0476402  -0.1618115   0.41351607]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.307427   0.24933212 0.4432409 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.34, 0.177, 0.144, 0.7, 0.023, 0.005, 0.6769999999999999, 0.15]
0.7020088333333333
5.093452166666667
Reward 16.30514749530687
Current State [[0.03  0.15  0.34  0.177 0.144 0.7   0.023 0.005 0.677 0.15 ]]
Logits tf.Tensor([[ 0.05381741 -0.18273959  0.4326182 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30770433 0.24288362 0.44941202]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.35, 0.162, 0.144, 0.71, 0.015, 0.005, 0.915, 0.11]
0.7068869999999999
5.361904999999999
Reward 16.2816356991057
Current State [[0.05  0.15  0.35  0.162 0.144 0.71  0.015 0.005 0.915 0.11 ]]
Logits tf.Tensor([[ 0.03647321 -0.20967567  0.5312505 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29223198 0.22846866 0.47929928]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.33, 0.106, 0.144, 0.89, 0.032, 0.002, 0.696, 0.15]
0.8944764999999999
2.4005951666666667
Reward 17.32313276985214
Current State [[0.03  0.15  0.33  0.106 0.144 0.89  0.032 0.002 0.696 0.15 ]]
Logits tf.Tensor([[ 0.04945809 -0.20978679  0.47494367]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30284974 0.23368919 0.46346104]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.15, 0.34, 0.172, 0.144, 0.88, 0.03, 0.001, 0.5309999999999999, 0.09]
0.8803723333333332
1.2005953333333332
Reward 19.297534064205355
Episode: 59 | Average Reward: 291 | Episode Reward: 260 | Loss: 549.967 | Steps: 19 | Worker: 0
Current State [[-0.00473032 -0.00730377 -0.00775254 -0.0013488   0.00185508  0.00805938
   0.00933306  0.00875394  0.00420716 -0.00615419]]
Logits tf.Tensor([[ 0.01905643 -0.01326682  0.00262568]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3387652  0.32799032 0.3332445 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.03, 0.04, 0.31, 0.124, 0.144, 0.88, 0.03, 0.001, 0.5309999999999999, 0.09]
0.8803723333333332
1.2005953333333332
Reward 7.2975340642053546
Current State [[0.03  0.04  0.31  0.124 0.144 0.88  0.03  0.001 0.531 0.09 ]]
Logits tf.Tensor([[ 0.04686118 -0.16437124  0.4051238 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30860126 0.24983925 0.44155946]], shape=(1, 3), dtype=float32)
Selected action 1
[0.05, 0.08, 0.31, 0.155, 0.144, 0.91, 0.036, 0.001, 0.46799999999999997, 0.05]
0.9067343333333332
0.5333334999999999
Reward 21.502627283291247
Current State [[0.05  0.08  0.31  0.155 0.144 0.91  0.036 0.001 0.468 0.05 ]]
Logits tf.Tensor([[ 0.04232383 -0.16868997  0.4032886 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30821618 0.24958205 0.44220176]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.28, 0.114, 0.144, 0.82, 0.016, 0.002, 0.567, 0.05]
0.8240833333333334
1.550595
Reward 18.12730385056627
Current State [[0.04  0.15  0.28  0.114 0.144 0.82  0.016 0.002 0.567 0.05 ]]
Logits tf.Tensor([[ 0.04990046 -0.18545787  0.43347916]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30695423 0.24258214 0.45046365]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.33, 0.21, 0.144, 0.82, 0.016, 0.002, 0.567, 0.05]
0.8240833333333334
1.550595
Reward 18.12730385056627
Current State [[0.04  0.15  0.33  0.21  0.144 0.82  0.016 0.002 0.567 0.05 ]]
Logits tf.Tensor([[ 0.05721383 -0.16720872  0.43753523]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30658558 0.24495493 0.44845945]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.35, 0.171, 0.144, 0.85, 0.028, 0.002, 0.45999999999999996, 0.12]
0.8522304999999999
1.698215
Reward 17.96980697015095
Current State [[0.05  0.15  0.35  0.171 0.144 0.85  0.028 0.002 0.46  0.12 ]]
Logits tf.Tensor([[ 0.05267728 -0.17800818  0.4146828 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30957872 0.24580216 0.4446191 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.03, 0.04, 0.36, 0.124, 0.144, 0.87, 0.045, 0.001, 0.46900000000000003, 0.11]
0.8713398333333334
1.401786
Reward 6.62859561773142
Current State [[0.03  0.04  0.36  0.124 0.144 0.87  0.045 0.001 0.469 0.11 ]]
Logits tf.Tensor([[ 0.0425652  -0.15978508  0.3920389 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30910662 0.252481   0.4384124 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.04, 0.35, 0.138, 0.144, 0.87, 0.045, 0.001, 0.46900000000000003, 0.11]
0.8713398333333334
1.401786
Reward 6.62859561773142
Current State [[0.05  0.04  0.35  0.138 0.144 0.87  0.045 0.001 0.469 0.11 ]]
Logits tf.Tensor([[ 0.0399192  -0.16202985  0.39063415]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30890712 0.2524193  0.43867356]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.37, 0.155, 0.144, 0.76, 0.021, 0.003, 0.619, 0.1]
0.7631713333333335
3.327381166666667
Reward 16.679199539832982
Current State [[0.05  0.15  0.37  0.155 0.144 0.76  0.021 0.003 0.619 0.1  ]]
Logits tf.Tensor([[ 0.05355146 -0.18640232  0.44081166]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30678573 0.24133736 0.45187688]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.33, 0.135, 0.144, 0.85, 0.023, 0.005, 0.609, 0.1]
0.8476531666666668
4.732738166666667
Reward 16.470355015592993
Current State [[0.03  0.15  0.33  0.135 0.144 0.85  0.023 0.005 0.609 0.1  ]]
Logits tf.Tensor([[ 0.05465216 -0.19402625  0.45359802]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30580258 0.23847423 0.4557232 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.04, 0.08, 0.35, 0.19, 0.144, 0.85, 0.023, 0.005, 0.609, 0.1]
0.8476531666666668
4.732738166666667
Reward 10.470355015592993
Current State [[0.04  0.08  0.35  0.19  0.144 0.85  0.023 0.005 0.609 0.1  ]]
Logits tf.Tensor([[ 0.05404716 -0.16804609  0.43500903]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3063226  0.24531558 0.44836184]], shape=(1, 3), dtype=float32)
Selected action 1
[0.04, 0.08, 0.35, 0.169, 0.145, 0.75, 0.015, 0.003, 0.524, 0.07]
0.7547149999999999
2.9345235
Reward 10.798551005289237
Current State [[0.04  0.08  0.35  0.169 0.145 0.75  0.015 0.003 0.524 0.07 ]]
Logits tf.Tensor([[ 0.05356599 -0.14816137  0.39548007]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.31008166 0.25343522 0.43648314]], shape=(1, 3), dtype=float32)
Selected action 1
[0.03, 0.08, 0.36, 0.146, 0.145, 0.85, 0.03, 0.002, 0.45999999999999996, 0.07]
0.8522560000000001
2.016071833333333
Reward 11.56629307167627
Current State [[0.03  0.08  0.36  0.146 0.145 0.85  0.03  0.002 0.46  0.07 ]]
Logits tf.Tensor([[ 0.0500307  -0.15519965  0.3970968 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30965793 0.2522039  0.43813816]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.34, 0.158, 0.145, 0.85, 0.03, 0.002, 0.45999999999999996, 0.07]
0.8522560000000001
2.016071833333333
Reward 17.56629307167627
Current State [[0.04  0.15  0.34  0.158 0.145 0.85  0.03  0.002 0.46  0.07 ]]
Logits tf.Tensor([[ 0.05041854 -0.17249377  0.41557866]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30855343 0.24689984 0.4445467 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.05, 0.08, 0.35, 0.164, 0.145, 0.78, 0.02, 0.005, 0.533, 0.04]
0.7780831666666667
5.323809833333334
Reward 10.338018223426968
Current State [[0.05  0.08  0.35  0.164 0.145 0.78  0.02  0.005 0.533 0.04 ]]
Logits tf.Tensor([[ 0.05005929 -0.1519551   0.40482634]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30836296 0.2519582  0.43967885]], shape=(1, 3), dtype=float32)
Selected action 0
[0.06, 0.04, 0.32, 0.136, 0.145, 0.83, 0.034, 0.002, 0.572, 0.09]
0.8324546666666668
2.045834
Reward 5.488475280348144
Current State [[0.06  0.04  0.32  0.136 0.145 0.83  0.034 0.002 0.572 0.09 ]]
Logits tf.Tensor([[ 0.04031846 -0.16667129  0.4096888 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3067625  0.24940644 0.4438311 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.35, 0.151, 0.145, 0.83, 0.034, 0.002, 0.572, 0.09]
0.8324546666666668
2.045834
Reward 5.488475280348144
Current State [[0.04  0.04  0.35  0.151 0.145 0.83  0.034 0.002 0.572 0.09 ]]
Logits tf.Tensor([[ 0.04550821 -0.15905342  0.41360763]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3067494  0.25000212 0.44324845]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.34, 0.146, 0.145, 0.85, 0.037, 0.003, 0.5389999999999999, 0.08]
0.85277
3.236905
Reward 16.82580820783977
Current State [[0.03  0.15  0.34  0.146 0.145 0.85  0.037 0.003 0.539 0.08 ]]
Logits tf.Tensor([[ 0.05023149 -0.18307698  0.43815225]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30620158 0.24248388 0.4513145 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.15, 0.37, 0.134, 0.145, 0.75, 0.024, 0.005, 0.7230000000000001, 0.09]
0.7465738333333335
4.7482145000000004
Reward 16.38211864408786
Current State [[0.06  0.15  0.37  0.134 0.145 0.75  0.024 0.005 0.723 0.09 ]]
Logits tf.Tensor([[ 0.04702501 -0.19649772  0.470669  ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30198896 0.23671755 0.4612935 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.04, 0.36, 0.151, 0.145, 0.75, 0.024, 0.005, 0.7230000000000001, 0.09]
0.7465738333333335
4.7482145000000004
Reward 4.382118644087861
Current State [[0.05  0.04  0.36  0.151 0.145 0.75  0.024 0.005 0.723 0.09 ]]
Logits tf.Tensor([[ 0.04071056 -0.16976878  0.45131636]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30139303 0.24418737 0.45441958]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.37, 0.136, 0.145, 0.83, 0.034, 0.003, 0.688, 0.17]
0.8286031666666668
2.7505951666666664
Reward 16.99311751809347
Episode: 60 | Average Reward: 291 | Episode Reward: 255 | Loss: 486.245 | Steps: 19 | Worker: 0
Current State [[ 0.00701245  0.0053264   0.00598157  0.00497703 -0.009111   -0.00049559
   0.00442982 -0.00650918 -0.00596673 -0.00985566]]
Logits tf.Tensor([[ 0.01663795 -0.01395185  0.0014077 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3384371  0.32824114 0.3333217 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.08, 0.08, 0.41, 0.124, 0.145, 0.82, 0.043, 0.007, 0.639, 0.22]
0.8176073333333334
7.422618833333333
Reward 10.197501366877468
Current State [[0.08  0.08  0.41  0.124 0.145 0.82  0.043 0.007 0.639 0.22 ]]
Logits tf.Tensor([[ 0.04459    -0.21576028  0.44835642]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3059755  0.23584028 0.45818427]], shape=(1, 3), dtype=float32)
Selected action 2
[0.02, 0.15, 0.39, 0.16, 0.145, 0.82, 0.043, 0.007, 0.639, 0.22]
0.8176073333333334
7.422618833333333
Reward 16.197501366877468
Current State [[0.02  0.15  0.39  0.16  0.145 0.82  0.043 0.007 0.639 0.22 ]]
Logits tf.Tensor([[ 0.05640445 -0.21712182  0.4664423 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30603808 0.23280084 0.4611611 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.39, 0.148, 0.145, 0.74, 0.032, 0.006, 0.795, 0.18]
0.7411905000000001
5.969047333333333
Reward 16.251731343314226
Current State [[0.03  0.15  0.39  0.148 0.145 0.74  0.032 0.006 0.795 0.18 ]]
Logits tf.Tensor([[ 0.05259518 -0.22476834  0.50007915]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30100986 0.22809894 0.47089118]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.04, 0.4, 0.135, 0.145, 0.71, 0.033, 0.004, 0.744, 0.17]
0.7067563333333334
4.106547833333334
Reward 4.441944351455311
Current State [[0.05  0.04  0.4   0.135 0.145 0.71  0.033 0.004 0.744 0.17 ]]
Logits tf.Tensor([[ 0.04367298 -0.19300765  0.45840266]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30273628 0.23893258 0.45833108]], shape=(1, 3), dtype=float32)
Selected action 2
[0.02, 0.15, 0.33, 0.128, 0.145, 0.75, 0.027, 0.004, 0.817, 0.14]
0.7467228333333333
3.994643166666667
Reward 16.50231821423319
Current State [[0.02  0.15  0.33  0.128 0.145 0.75  0.027 0.004 0.817 0.14 ]]
Logits tf.Tensor([[ 0.0460635  -0.2242238   0.50824624]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29844546 0.22776173 0.47379276]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.15, 0.37, 0.162, 0.145, 0.75, 0.027, 0.004, 0.817, 0.14]
0.7467228333333333
3.994643166666667
Reward 16.50231821423319
Current State [[0.08  0.15  0.37  0.162 0.145 0.75  0.027 0.004 0.817 0.14 ]]
Logits tf.Tensor([[ 0.04468365 -0.22506689  0.5098807 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29798284 0.22753073 0.47448638]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.38, 0.14, 0.145, 0.79, 0.04, 0.002, 0.5429999999999999, 0.04]
0.7878884999999999
1.8065478333333331
Reward 17.63291563810484
Current State [[0.05  0.15  0.38  0.14  0.145 0.79  0.04  0.002 0.543 0.04 ]]
Logits tf.Tensor([[ 0.04626017 -0.18424192  0.44159052]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30497015 0.24218738 0.4528424 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.4, 0.13, 0.145, 0.86, 0.037, 0.002, 0.509, 0.15]
0.8600126666666665
2.155952666666666
Reward 17.449504738850724
Current State [[0.04  0.15  0.4   0.13  0.145 0.86  0.037 0.002 0.509 0.15 ]]
Logits tf.Tensor([[ 0.05502499 -0.20122899  0.44434574]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30769956 0.23814265 0.45415774]], shape=(1, 3), dtype=float32)
Selected action 0
[0.03, 0.04, 0.37, 0.138, 0.145, 0.86, 0.037, 0.002, 0.509, 0.15]
0.8600126666666665
2.155952666666666
Reward 5.449504738850724
Current State [[0.03  0.04  0.37  0.138 0.145 0.86  0.037 0.002 0.509 0.15 ]]
Logits tf.Tensor([[ 0.0498237  -0.17070149  0.41034934]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30900624 0.24785313 0.44314063]], shape=(1, 3), dtype=float32)
Selected action 2
[0.09, 0.15, 0.43, 0.181, 0.145, 0.83, 0.055, 0.002, 0.45899999999999996, 0.17]
0.8336729999999999
2.078571333333333
Reward 17.46009087658853
Current State [[0.09  0.15  0.43  0.181 0.145 0.83  0.055 0.002 0.459 0.17 ]]
Logits tf.Tensor([[ 0.04798564 -0.20318606  0.4277853 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30865335 0.240098   0.45124862]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.41, 0.138, 0.145, 0.77, 0.069, 0.005, 0.42699999999999994, 0.14]
0.7690526666666667
5.110119166666667
Reward 16.35526039608246
Current State [[0.04  0.15  0.41  0.138 0.145 0.77  0.069 0.005 0.427 0.14 ]]
Logits tf.Tensor([[ 0.04355852 -0.18730809  0.40844175]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3091963  0.24545406 0.4453496 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.02, 0.04, 0.34, 0.132, 0.145, 0.77, 0.069, 0.005, 0.42699999999999994, 0.14]
0.7690526666666667
5.110119166666667
Reward 4.35526039608246
Current State [[0.02  0.04  0.34  0.132 0.145 0.77  0.069 0.005 0.427 0.14 ]]
Logits tf.Tensor([[ 0.03525758 -0.15728658  0.3704609 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.310262   0.25592202 0.43381596]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.4, 0.157, 0.145, 0.83, 0.036, 0.002, 0.522, 0.13]
0.8328495000000001
2.3095236666666663
Reward 5.26636772333988
Current State [[0.04  0.04  0.4   0.157 0.145 0.83  0.036 0.002 0.522 0.13 ]]
Logits tf.Tensor([[ 0.05011744 -0.16463701  0.41221303]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30834925 0.24875753 0.4428932 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.02, 0.04, 0.39, 0.17, 0.145, 0.77, 0.038, 0.002, 0.599, 0.14]
0.7686646666666668
2.4238101666666667
Reward 5.064970798623556
Current State [[0.02  0.04  0.39  0.17  0.145 0.77  0.038 0.002 0.599 0.14 ]]
Logits tf.Tensor([[ 0.04928143 -0.16434143  0.42138168]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30689615 0.24786559 0.4452383 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.37, 0.174, 0.145, 0.77, 0.038, 0.002, 0.599, 0.14]
0.7686646666666668
2.4238101666666667
Reward 17.064970798623555
Current State [[0.03  0.15  0.37  0.174 0.145 0.77  0.038 0.002 0.599 0.14 ]]
Logits tf.Tensor([[ 0.05203929 -0.19450943  0.4472993 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30616024 0.23926216 0.45457757]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.34, 0.121, 0.145, 0.73, 0.027, 0.004, 0.5740000000000001, 0.17]
0.7348285000000001
3.6952379999999994
Reward 16.551422225946247
Current State [[0.05  0.15  0.34  0.121 0.145 0.73  0.027 0.004 0.574 0.17 ]]
Logits tf.Tensor([[ 0.04963004 -0.2051994   0.42736182]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30921265 0.23965487 0.45113248]], shape=(1, 3), dtype=float32)
Selected action 1
[0.06, 0.08, 0.39, 0.16, 0.145, 0.73, 0.027, 0.004, 0.5740000000000001, 0.17]
0.7348285000000001
3.6952379999999994
Reward 10.551422225946245
Current State [[0.06  0.08  0.39  0.16  0.145 0.73  0.027 0.004 0.574 0.17 ]]
Logits tf.Tensor([[ 0.04998288 -0.1817831   0.4114929 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3097292  0.24565601 0.4446148 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.06, 0.08, 0.39, 0.174, 0.145, 0.88, 0.034, 0.001, 0.449, 0.12]
0.8838331666666668
1.1761906666666666
Reward 13.411426766828113
Current State [[0.06  0.08  0.39  0.174 0.145 0.88  0.034 0.001 0.449 0.12 ]]
Logits tf.Tensor([[ 0.05057748 -0.17195427  0.41019827]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30928388 0.2475785  0.4431376 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.37, 0.124, 0.145, 0.9, 0.05, 0.001, 0.52, 0.11]
0.8951263333333332
0.769048
Reward 22.407943316130236
Current State [[0.03  0.15  0.37  0.124 0.145 0.9   0.05  0.001 0.52  0.11 ]]
Logits tf.Tensor([[ 0.04826843 -0.2024597   0.45514852]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30484477 0.23724054 0.45791465]], shape=(1, 3), dtype=float32)
Selected action 0
[0.06, 0.04, 0.37, 0.17, 0.145, 0.82, 0.039, 0.003, 0.534, 0.18]
0.8214189999999999
2.7886901666666666
Reward 4.963123719510688
Episode: 61 | Average Reward: 290 | Episode Reward: 254 | Loss: 505.584 | Steps: 19 | Worker: 0
Current State [[-0.00159436 -0.00593814 -0.0071483  -0.00023196 -0.00129926 -0.00877916
   0.00797514 -0.0067536   0.00360343 -0.0039705 ]]
Logits tf.Tensor([[ 0.01634973 -0.00985796  0.00218023]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.33783063 0.32909188 0.3330775 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.39, 0.152, 0.145, 0.82, 0.039, 0.003, 0.534, 0.18]
0.8214189999999999
2.7886901666666666
Reward 4.963123719510688
Current State [[0.04  0.04  0.39  0.152 0.145 0.82  0.039 0.003 0.534 0.18 ]]
Logits tf.Tensor([[ 0.05009873 -0.182891    0.4202424 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30863205 0.2444865  0.44688147]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.38, 0.136, 0.145, 0.82, 0.038, 0.005, 0.541, 0.2]
0.8246926666666667
4.7672615
Reward 16.445532089307054
Current State [[0.04  0.15  0.38  0.136 0.145 0.82  0.038 0.005 0.541 0.2  ]]
Logits tf.Tensor([[ 0.05477141 -0.21926188  0.45077196]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30805466 0.23421606 0.45772925]], shape=(1, 3), dtype=float32)
Selected action 1
[0.07, 0.08, 0.4, 0.143, 0.145, 0.84, 0.066, 0.009, 0.458, 0.23]
0.8447808333333332
8.746428166666664
Reward 10.1456358768677
Current State [[0.07  0.08  0.4   0.143 0.145 0.84  0.066 0.009 0.458 0.23 ]]
Logits tf.Tensor([[ 0.04259822 -0.20772895  0.41689697]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3093564  0.2408482  0.44979537]], shape=(1, 3), dtype=float32)
Selected action 1
[0.02, 0.08, 0.37, 0.157, 0.145, 0.84, 0.066, 0.009, 0.458, 0.23]
0.8447808333333332
8.746428166666664
Reward 10.1456358768677
Current State [[0.02  0.08  0.37  0.157 0.145 0.84  0.066 0.009 0.458 0.23 ]]
Logits tf.Tensor([[ 0.04888464 -0.19561514  0.4143232 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3101504 0.2428776 0.446972 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.02, 0.08, 0.37, 0.123, 0.145, 0.83, 0.04, 0.001, 0.55, 0.21]
0.8254193333333333
0.9761901666666667
Reward 14.025433293721486
Current State [[0.02  0.08  0.37  0.123 0.145 0.83  0.04  0.001 0.55  0.21 ]]
Logits tf.Tensor([[ 0.05202353 -0.20169729  0.4364982 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30819005 0.23912726 0.45268264]], shape=(1, 3), dtype=float32)
Selected action 0
[0.02, 0.04, 0.37, 0.147, 0.145, 0.83, 0.04, 0.001, 0.55, 0.21]
0.8254193333333333
0.9761901666666667
Reward 8.025433293721486
Current State [[0.02  0.04  0.37  0.147 0.145 0.83  0.04  0.001 0.55  0.21 ]]
Logits tf.Tensor([[ 0.05119531 -0.18731315  0.42490906]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30855408 0.24307953 0.44836643]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.36, 0.158, 0.145, 0.87, 0.042, 0.002, 0.493, 0.17]
0.8651301666666666
2.0851198333333336
Reward 17.527706867715057
Current State [[0.03  0.15  0.36  0.158 0.145 0.87  0.042 0.002 0.493 0.17 ]]
Logits tf.Tensor([[ 0.05283203 -0.20862824  0.44812703]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3072434  0.23655482 0.45620182]], shape=(1, 3), dtype=float32)
Selected action 1
[0.05, 0.08, 0.4, 0.142, 0.145, 0.84, 0.033, 0.002, 0.501, 0.02]
0.8446026666666666
1.5708331666666666
Reward 12.160799472195023
Current State [[0.05  0.08  0.4   0.142 0.145 0.84  0.033 0.002 0.501 0.02 ]]
Logits tf.Tensor([[ 0.04666576 -0.1731234   0.43281624]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30543733 0.24517089 0.4493918 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.03, 0.04, 0.39, 0.136, 0.145, 0.76, 0.037, 0.003, 0.619, 0.15]
0.75774
2.9535713333333335
Reward 4.795799564192446
Current State [[0.03  0.04  0.39  0.136 0.145 0.76  0.037 0.003 0.619 0.15 ]]
Logits tf.Tensor([[ 0.04652638 -0.18476045  0.4342843 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30607387 0.24287325 0.45105284]], shape=(1, 3), dtype=float32)
Selected action 1
[0.03, 0.08, 0.35, 0.153, 0.145, 0.76, 0.037, 0.003, 0.619, 0.15]
0.75774
2.9535713333333335
Reward 10.795799564192446
Current State [[0.03  0.08  0.35  0.153 0.145 0.76  0.037 0.003 0.619 0.15 ]]
Logits tf.Tensor([[ 0.0473935  -0.19192263  0.44005668]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3059896  0.24086457 0.4531459 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.36, 0.135, 0.145, 0.79, 0.033, 0.001, 0.515, 0.1]
0.7923431666666666
1.3333336666666669
Reward 18.472994263983512
Current State [[0.03  0.15  0.36  0.135 0.145 0.79  0.033 0.001 0.515 0.1  ]]
Logits tf.Tensor([[ 0.05271967 -0.19519687  0.43999282]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30737227 0.23988102 0.45274666]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.34, 0.167, 0.145, 0.82, 0.025, 0.003, 0.548, 0.11]
0.8227361666666667
2.6630951666666665
Reward 17.02780831129015
Current State [[0.03  0.15  0.34  0.167 0.145 0.82  0.025 0.003 0.548 0.11 ]]
Logits tf.Tensor([[ 0.05674612 -0.19795589  0.451676  ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30680236 0.23781706 0.45538062]], shape=(1, 3), dtype=float32)
Selected action 1
[0.04, 0.08, 0.36, 0.154, 0.145, 0.82, 0.025, 0.003, 0.548, 0.11]
0.8227361666666667
2.6630951666666665
Reward 11.027808311290151
Current State [[0.04  0.08  0.36  0.154 0.145 0.82  0.025 0.003 0.548 0.11 ]]
Logits tf.Tensor([[ 0.05291159 -0.18320087  0.43318564]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30746743 0.2428045  0.44972807]], shape=(1, 3), dtype=float32)
Selected action 2
[0.02, 0.15, 0.35, 0.15, 0.145, 0.9, 0.036, 0.002, 0.46900000000000003, 0.12]
0.8998858333333335
2.394048333333333
Reward 17.33874649112615
Current State [[0.02  0.15  0.35  0.15  0.145 0.9   0.036 0.002 0.469 0.12 ]]
Logits tf.Tensor([[ 0.05443293 -0.20019884  0.44704694]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30712074 0.23808056 0.4547987 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.03, 0.08, 0.37, 0.147, 0.145, 0.7, 0.017, 0.008, 1.0, 0.08]
0.6989016666666666
8.3125
Reward 10.098331212156072
Current State [[0.03  0.08  0.37  0.147 0.145 0.7   0.017 0.008 1.    0.08 ]]
Logits tf.Tensor([[ 0.02914907 -0.22436756  0.586551  ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2839137  0.22033603 0.49575025]], shape=(1, 3), dtype=float32)
Selected action 1
[0.0, 0.08, 0.32, 0.098, 0.145, 0.7, 0.017, 0.008, 1.0, 0.08]
0.6989016666666666
8.3125
Reward 10.098331212156072
Current State [[0.    0.08  0.32  0.098 0.145 0.7   0.017 0.008 1.    0.08 ]]
Logits tf.Tensor([[ 0.02936454 -0.2259836   0.5822436 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.28466532 0.22051509 0.49481964]], shape=(1, 3), dtype=float32)
Selected action 2
[0.01, 0.15, 0.31, 0.133, 0.145, 0.79, 0.019, 0.003, 0.689, 0.08]
0.7922123333333334
3.057737833333333
Reward 16.806797844079256
Current State [[0.01  0.15  0.31  0.133 0.145 0.79  0.019 0.003 0.689 0.08 ]]
Logits tf.Tensor([[ 0.05544433 -0.20780429  0.48191717]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30299398 0.23286626 0.4641398 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.05, 0.08, 0.37, 0.121, 0.145, 0.78, 0.024, 0.005, 0.619, 0.06]
0.7777665000000001
4.986309666666668
Reward 10.377115031107582
Current State [[0.05  0.08  0.37  0.121 0.145 0.78  0.024 0.005 0.619 0.06 ]]
Logits tf.Tensor([[ 0.04743606 -0.18937533  0.4495989 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30448863 0.2402842  0.4552272 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.34, 0.162, 0.145, 0.78, 0.024, 0.005, 0.619, 0.06]
0.7777665000000001
4.986309666666668
Reward 16.377115031107582
Current State [[0.03  0.15  0.34  0.162 0.145 0.78  0.024 0.005 0.619 0.06 ]]
Logits tf.Tensor([[ 0.05380226 -0.19590762  0.4640673 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3042988  0.2370569  0.45864436]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.37, 0.15, 0.145, 0.84, 0.035, 0.003, 0.509, 0.12]
0.8372793333333334
3.3785716666666668
Reward 16.758081589378975
Episode: 62 | Average Reward: 290 | Episode Reward: 253 | Loss: 566.453 | Steps: 19 | Worker: 0
Current State [[-0.00405188 -0.00435161  0.00471876 -0.00846468  0.00934878  0.00857835
  -0.00350512 -0.00870073  0.00219773  0.00014134]]
Logits tf.Tensor([[ 0.01662916 -0.01479316  0.01156964]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.33737972 0.32694328 0.33567703]], shape=(1, 3), dtype=float32)
Selected action 0
[0.03, 0.04, 0.3, 0.119, 0.145, 0.82, 0.026, 0.002, 0.613, 0.08]
0.8213155
1.9404770000000005
Reward 5.568882995041692
Current State [[0.03  0.04  0.3   0.119 0.145 0.82  0.026 0.002 0.613 0.08 ]]
Logits tf.Tensor([[ 0.04295533 -0.18629494  0.44278842]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30425605 0.24192297 0.45382094]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.31, 0.156, 0.145, 0.82, 0.026, 0.002, 0.613, 0.08]
0.8213155
1.9404770000000005
Reward 17.56888299504169
Current State [[0.04  0.15  0.31  0.156 0.145 0.82  0.026 0.002 0.613 0.08 ]]
Logits tf.Tensor([[ 0.04663289 -0.2103601   0.47593698]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3021548  0.23367856 0.46416664]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.33, 0.147, 0.145, 0.91, 0.03, 0.001, 0.522, 0.08]
0.9085846666666666
0.9803575
Reward 8.587956866474256
Current State [[0.04  0.04  0.33  0.147 0.145 0.91  0.03  0.001 0.522 0.08 ]]
Logits tf.Tensor([[ 0.04570427 -0.18458566  0.43633786]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3056029  0.24274138 0.45165566]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.04, 0.33, 0.121, 0.145, 0.88, 0.031, 0.001, 0.561, 0.12]
0.8794085
1.4142854999999996
Reward 6.62981159115391
Current State [[0.05  0.04  0.33  0.121 0.145 0.88  0.031 0.001 0.561 0.12 ]]
Logits tf.Tensor([[ 0.04154271 -0.19580756  0.44233546]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.304718   0.24033564 0.45494634]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.38, 0.172, 0.145, 0.88, 0.031, 0.001, 0.561, 0.12]
0.8794085
1.4142854999999996
Reward 6.62981159115391
Current State [[0.04  0.04  0.38  0.172 0.145 0.88  0.031 0.001 0.561 0.12 ]]
Logits tf.Tensor([[ 0.04849853 -0.18306194  0.4481495 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3044512  0.24151953 0.4540293 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.04, 0.34, 0.166, 0.145, 0.68, 0.027, 0.003, 0.5940000000000001, 0.12]
0.6834656666666666
3.3523813333333337
Reward 4.572218450375441
Current State [[0.05  0.04  0.34  0.166 0.145 0.68  0.027 0.003 0.594 0.12 ]]
Logits tf.Tensor([[ 0.03997209 -0.17399225  0.41485885]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30654123 0.2474944  0.44596434]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.32, 0.115, 0.145, 0.84, 0.035, 0.001, 0.567, 0.14]
0.8384308333333332
1.2755953333333336
Reward 18.836530872890403
Current State [[0.03  0.15  0.32  0.115 0.145 0.84  0.035 0.001 0.567 0.14 ]]
Logits tf.Tensor([[ 0.04601901 -0.22140221  0.46786612]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30393973 0.23262046 0.46343985]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.33, 0.159, 0.145, 0.84, 0.035, 0.001, 0.567, 0.14]
0.8384308333333332
1.2755953333333336
Reward 18.836530872890403
Current State [[0.04  0.15  0.33  0.159 0.145 0.84  0.035 0.001 0.567 0.14 ]]
Logits tf.Tensor([[ 0.04741224 -0.21590506  0.46878412]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30371606 0.2334052  0.46287873]], shape=(1, 3), dtype=float32)
Selected action 2
[0.02, 0.15, 0.32, 0.161, 0.145, 0.84, 0.026, 0.003, 0.5660000000000001, 0.13]
0.8437766666666667
3.346428499999999
Reward 16.776721407553048
Current State [[0.02  0.15  0.32  0.161 0.145 0.84  0.026 0.003 0.566 0.13 ]]
Logits tf.Tensor([[ 0.05340594 -0.20916444  0.46664453]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3048058  0.23441765 0.46077663]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.35, 0.16, 0.145, 0.92, 0.04, 0.001, 0.476, 0.09]
0.9208215
1.2577378333333336
Reward 19.290340560957436
Current State [[0.04  0.15  0.35  0.16  0.145 0.92  0.04  0.001 0.476 0.09 ]]
Logits tf.Tensor([[ 0.0476225  -0.2062298   0.46225366]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30398664 0.23583473 0.46017867]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.33, 0.133, 0.145, 0.9, 0.034, 0.001, 0.505, 0.12]
0.9036108333333333
1.2446423333333334
Reward 19.252282229823386
Current State [[0.04  0.15  0.33  0.133 0.145 0.9   0.034 0.001 0.505 0.12 ]]
Logits tf.Tensor([[ 0.04809967 -0.21588877  0.46359816]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3045894  0.23391931 0.46149126]], shape=(1, 3), dtype=float32)
Selected action 2
[0.01, 0.15, 0.32, 0.144, 0.145, 0.9, 0.034, 0.001, 0.505, 0.12]
0.9036108333333333
1.2446423333333334
Reward 19.252282229823386
Current State [[0.01  0.15  0.32  0.144 0.145 0.9   0.034 0.001 0.505 0.12 ]]
Logits tf.Tensor([[ 0.05157743 -0.20831119  0.4628236 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30489343 0.23511477 0.45999172]], shape=(1, 3), dtype=float32)
Selected action 0
[0.02, 0.04, 0.33, 0.146, 0.145, 0.88, 0.025, 0.002, 0.49400000000000005, 0.11]
0.877436
1.8809526666666667
Reward 5.786435759423105
Current State [[0.02  0.04  0.33  0.146 0.145 0.88  0.025 0.002 0.494 0.11 ]]
Logits tf.Tensor([[ 0.05059797 -0.17820351  0.42149982]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30821133 0.24517791 0.44661078]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.15, 0.35, 0.125, 0.145, 0.82, 0.029, 0.002, 0.528, 0.09]
0.8233490000000001
2.395832666666666
Reward 17.187007388036232
Current State [[0.07  0.15  0.35  0.125 0.145 0.82  0.029 0.002 0.528 0.09 ]]
Logits tf.Tensor([[ 0.04452355 -0.21231525  0.45559302]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30469942 0.23568283 0.45961776]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.35, 0.169, 0.145, 0.82, 0.029, 0.002, 0.528, 0.09]
0.8233490000000001
2.395832666666666
Reward 5.187007388036233
Current State [[0.04  0.04  0.35  0.169 0.145 0.82  0.029 0.002 0.528 0.09 ]]
Logits tf.Tensor([[ 0.04554982 -0.1706109   0.42453045]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3061474  0.24663414 0.4472185 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.02, 0.15, 0.36, 0.136, 0.145, 0.81, 0.029, 0.004, 0.618, 0.14]
0.8078083333333334
4.286309833333333
Reward 16.50859604246093
Current State [[0.02  0.15  0.36  0.136 0.145 0.81  0.029 0.004 0.618 0.14 ]]
Logits tf.Tensor([[ 0.05300271 -0.21746309  0.47823814]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3036768  0.2317127  0.46461052]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.37, 0.137, 0.145, 0.76, 0.031, 0.005, 0.546, 0.14]
0.7603091666666667
5.273810166666666
Reward 4.330162327845763
Current State [[0.04  0.04  0.37  0.137 0.145 0.76  0.031 0.005 0.546 0.14 ]]
Logits tf.Tensor([[ 0.04505274 -0.17968194  0.41851297]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30755216 0.24565056 0.44679728]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.04, 0.37, 0.165, 0.145, 0.76, 0.031, 0.005, 0.546, 0.14]
0.7603091666666667
5.273810166666666
Reward 4.330162327845763
Current State [[0.05  0.04  0.37  0.165 0.145 0.76  0.031 0.005 0.546 0.14 ]]
Logits tf.Tensor([[ 0.04490118 -0.17716835  0.41845575]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3073377  0.24613439 0.44652784]], shape=(1, 3), dtype=float32)
Selected action 0
[0.03, 0.04, 0.35, 0.173, 0.145, 0.88, 0.041, 0.002, 0.639, 0.18]
0.8819108333333332
2.085119166666667
Reward 5.567399598903046
Current State [[0.03  0.04  0.35  0.173 0.145 0.88  0.041 0.002 0.639 0.18 ]]
Logits tf.Tensor([[ 0.04434737 -0.20144396  0.46651497]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3023569  0.23646891 0.46117413]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.38, 0.126, 0.145, 0.73, 0.023, 0.005, 0.611, 0.08]
0.7323685
4.6523813333333335
Reward 16.382860119327244
Episode: 63 | Average Reward: 289 | Episode Reward: 237 | Loss: 473.323 | Steps: 19 | Worker: 0
Current State [[ 0.0057053  -0.00125156  0.00707441  0.00102353  0.00439087  0.00280547
  -0.00830733  0.00768943  0.00474198 -0.00468709]]
Logits tf.Tensor([[ 0.02037434 -0.01874813  0.00773097]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.33909005 0.32608014 0.33482978]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.39, 0.165, 0.145, 0.73, 0.023, 0.005, 0.611, 0.08]
0.7323685
4.6523813333333335
Reward 16.382860119327244
Current State [[0.04  0.15  0.39  0.165 0.145 0.73  0.023 0.005 0.611 0.08 ]]
Logits tf.Tensor([[ 0.05194093 -0.20462638  0.46900213]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3038407  0.23508243 0.46107686]], shape=(1, 3), dtype=float32)
Selected action 1
[0.04, 0.08, 0.4, 0.143, 0.145, 0.77, 0.035, 0.003, 0.9119999999999999, 0.17]
0.7737356666666667
3.0583334999999994
Reward 10.780395550946452
Current State [[0.04  0.08  0.4   0.143 0.145 0.77  0.035 0.003 0.912 0.17 ]]
Logits tf.Tensor([[ 0.03575521 -0.248957    0.57020634]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.28912243 0.2174868  0.49339077]], shape=(1, 3), dtype=float32)
Selected action 1
[0.03, 0.08, 0.4, 0.119, 0.145, 0.69, 0.024, 0.005, 0.8310000000000001, 0.13]
0.6910803333333333
5.2910715
Reward 10.276852055057635
Current State [[0.03  0.08  0.4   0.119 0.145 0.69  0.024 0.005 0.831 0.13 ]]
Logits tf.Tensor([[ 0.0399229  -0.21888109  0.52733165]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2941119  0.22704686 0.47884125]], shape=(1, 3), dtype=float32)
Selected action 1
[0.04, 0.08, 0.39, 0.149, 0.145, 0.69, 0.024, 0.005, 0.8310000000000001, 0.13]
0.6910803333333333
5.2910715
Reward 10.276852055057635
Current State [[0.04  0.08  0.39  0.149 0.145 0.69  0.024 0.005 0.831 0.13 ]]
Logits tf.Tensor([[ 0.0382193  -0.21867591  0.5284862 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2935822  0.22707093 0.4793469 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.02, 0.04, 0.32, 0.124, 0.145, 0.8, 0.032, 0.001, 0.722, 0.12]
0.8040681666666667
1.2642855
Reward 6.711794988309347
Current State [[0.02  0.04  0.32  0.124 0.145 0.8   0.032 0.001 0.722 0.12 ]]
Logits tf.Tensor([[ 0.03933145 -0.21022801  0.48517907]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29931542 0.2332098  0.46747485]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.36, 0.13, 0.145, 0.85, 0.048, 0.002, 0.503, 0.09]
0.8489943333333332
1.6541670000000002
Reward 18.03003401007514
Current State [[0.04  0.15  0.36  0.13  0.145 0.85  0.048 0.002 0.503 0.09 ]]
Logits tf.Tensor([[ 0.04306757 -0.21552908  0.46608976]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30314952 0.23407215 0.4627784 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.04, 0.39, 0.184, 0.145, 0.85, 0.048, 0.002, 0.503, 0.09]
0.8489943333333332
1.6541670000000002
Reward 6.0300340100751395
Current State [[0.05  0.04  0.39  0.184 0.145 0.85  0.048 0.002 0.503 0.09 ]]
Logits tf.Tensor([[ 0.0406639  -0.179538    0.43799022]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30393305 0.24386275 0.45220417]], shape=(1, 3), dtype=float32)
Selected action 2
[0.02, 0.15, 0.39, 0.145, 0.145, 0.91, 0.045, 0.002, 0.453, 0.14]
0.9085748333333332
1.7029763333333332
Reward 18.138382785008798
Current State [[0.02  0.15  0.39  0.145 0.145 0.91  0.045 0.002 0.453 0.14 ]]
Logits tf.Tensor([[ 0.05142894 -0.2152435   0.46546078]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30498692 0.23359676 0.46141633]], shape=(1, 3), dtype=float32)
Selected action 2
[0.02, 0.15, 0.38, 0.123, 0.145, 0.83, 0.047, 0.001, 0.48600000000000004, 0.15]
0.8272938333333333
1.4595239999999996
Reward 18.31997535051476
Current State [[0.02  0.15  0.38  0.123 0.145 0.83  0.047 0.001 0.486 0.15 ]]
Logits tf.Tensor([[ 0.04823798 -0.21597184  0.4582168 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.305381   0.2344753  0.46014374]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.39, 0.159, 0.145, 0.83, 0.047, 0.001, 0.48600000000000004, 0.15]
0.8272938333333333
1.4595239999999996
Reward 18.31997535051476
Current State [[0.04  0.15  0.39  0.159 0.145 0.83  0.047 0.001 0.486 0.15 ]]
Logits tf.Tensor([[ 0.04853625 -0.21500637  0.45911825]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30524847 0.23453002 0.4602216 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.04, 0.08, 0.4, 0.164, 0.145, 0.84, 0.06, 0.002, 0.44400000000000006, 0.14]
0.8363845000000001
2.333929
Reward 11.255746451576721
Current State [[0.04  0.08  0.4   0.164 0.145 0.84  0.06  0.002 0.444 0.14 ]]
Logits tf.Tensor([[ 0.04261932 -0.19142325  0.43161246]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30610785 0.24223177 0.45166042]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.34, 0.129, 0.145, 0.83, 0.039, 0.001, 0.488, 0.1]
0.8261470000000001
1.1440476666666666
Reward 7.2282948786045935
Current State [[0.04  0.04  0.34  0.129 0.145 0.83  0.039 0.001 0.488 0.1  ]]
Logits tf.Tensor([[ 0.03998728 -0.1839143   0.42224512]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30628023 0.24483854 0.44888124]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.15, 0.42, 0.153, 0.145, 0.9, 0.049, 0.001, 0.47400000000000003, 0.12]
0.9018068333333336
1.1392861666666667
Reward 19.668271039875275
Current State [[0.07  0.15  0.42  0.153 0.145 0.9   0.049 0.001 0.474 0.12 ]]
Logits tf.Tensor([[ 0.04609186 -0.22254783  0.47332883]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30326605 0.23182222 0.4649117 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.15, 0.39, 0.166, 0.145, 0.9, 0.049, 0.001, 0.47400000000000003, 0.12]
0.9018068333333336
1.1392861666666667
Reward 19.668271039875275
Current State [[0.06  0.15  0.39  0.166 0.145 0.9   0.049 0.001 0.474 0.12 ]]
Logits tf.Tensor([[ 0.04531605 -0.21901406  0.47042942]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30326152 0.23281997 0.4639185 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.02, 0.08, 0.37, 0.155, 0.145, 0.85, 0.044, 0.002, 0.504, 0.12]
0.8536586666666667
1.6005956666666667
Reward 12.137394241133183
Current State [[0.02  0.08  0.37  0.155 0.145 0.85  0.044 0.002 0.504 0.12 ]]
Logits tf.Tensor([[ 0.04702365 -0.19242093  0.44617823]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3050986  0.24013239 0.454769  ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.37, 0.133, 0.145, 0.79, 0.062, 0.003, 0.422, 0.1]
0.7929466666666667
2.6839291666666663
Reward 16.967098374162955
Current State [[0.04  0.15  0.37  0.133 0.145 0.79  0.062 0.003 0.422 0.1  ]]
Logits tf.Tensor([[ 0.03779953 -0.20284365  0.43248057]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30580735 0.2404019  0.4537908 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.07, 0.04, 0.41, 0.155, 0.145, 0.79, 0.062, 0.003, 0.422, 0.1]
0.7929466666666667
2.6839291666666663
Reward 4.967098374162955
Current State [[0.07  0.04  0.41  0.155 0.145 0.79  0.062 0.003 0.422 0.1  ]]
Logits tf.Tensor([[ 0.03224196 -0.17562295  0.40610442]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30621737 0.24874552 0.44503713]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.41, 0.157, 0.145, 0.85, 0.031, 0.001, 0.5, 0.15]
0.8512701666666668
1.2249994999999998
Reward 7.0616581029088215
Current State [[0.04  0.04  0.41  0.157 0.145 0.85  0.031 0.001 0.5   0.15 ]]
Logits tf.Tensor([[ 0.05150997 -0.18598102  0.43565136]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30703506 0.24212906 0.45083585]], shape=(1, 3), dtype=float32)
Selected action 1
[0.03, 0.08, 0.38, 0.142, 0.145, 0.84, 0.043, 0.002, 0.504, 0.19]
0.8439794999999999
1.9833333333333334
Reward 11.58018304704828
Current State [[0.03  0.08  0.38  0.142 0.145 0.84  0.043 0.002 0.504 0.19 ]]
Logits tf.Tensor([[ 0.04808434 -0.20488131  0.44373253]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30657533 0.23805407 0.4553706 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.02, 0.04, 0.37, 0.152, 0.145, 0.84, 0.043, 0.002, 0.504, 0.19]
0.8439794999999999
1.9833333333333334
Reward 5.580183047048279
Episode: 64 | Average Reward: 289 | Episode Reward: 249 | Loss: 497.739 | Steps: 19 | Worker: 0
Current State [[ 0.0033791  -0.00058423 -0.00846462  0.00613737  0.00375181  0.00028536
   0.00442273  0.00680735 -0.00074979 -0.00777191]]
Logits tf.Tensor([[ 0.0165664  -0.01693367  0.00611012]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.33822027 0.32707754 0.33470216]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.36, 0.168, 0.145, 0.86, 0.036, 0.004, 0.496, 0.13]
0.864053
3.5410713333333335
Reward 16.741696909271255
Current State [[0.03  0.15  0.36  0.168 0.145 0.86  0.036 0.004 0.496 0.13 ]]
Logits tf.Tensor([[ 0.0523672  -0.21752778  0.47017458]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3046841  0.23261403 0.46270186]], shape=(1, 3), dtype=float32)
Selected action 2
[0.02, 0.15, 0.36, 0.129, 0.145, 0.85, 0.033, 0.002, 0.545, 0.14]
0.8511041666666668
2.4994046666666674
Reward 17.172446281627185
Current State [[0.02  0.15  0.36  0.129 0.145 0.85  0.033 0.002 0.545 0.14 ]]
Logits tf.Tensor([[ 0.05259515 -0.22713472  0.48226246]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30369896 0.22959274 0.4667082 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.39, 0.162, 0.145, 0.85, 0.033, 0.002, 0.545, 0.14]
0.8511041666666668
2.4994046666666674
Reward 17.172446281627185
Current State [[0.05  0.15  0.39  0.162 0.145 0.85  0.033 0.002 0.545 0.14 ]]
Logits tf.Tensor([[ 0.05207337 -0.22746179  0.48471445]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30326387 0.22930852 0.46742758]], shape=(1, 3), dtype=float32)
Selected action 0
[0.03, 0.04, 0.37, 0.143, 0.145, 0.77, 0.032, 0.005, 0.5780000000000001, 0.17]
0.7662381666666666
4.828571666666666
Reward 4.38794262772051
Current State [[0.03  0.04  0.37  0.143 0.145 0.77  0.032 0.005 0.578 0.17 ]]
Logits tf.Tensor([[ 0.04680381 -0.19818874  0.44216466]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30603218 0.23953457 0.45443326]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.39, 0.131, 0.145, 0.81, 0.035, 0.001, 0.5429999999999999, 0.1]
0.8146458333333332
0.8428573333333332
Reward 20.874318303459063
Current State [[0.05  0.15  0.39  0.131 0.145 0.81  0.035 0.001 0.543 0.1  ]]
Logits tf.Tensor([[ 0.04760548 -0.22208813  0.47691014]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30304846 0.23141187 0.4655397 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.02, 0.04, 0.34, 0.145, 0.145, 0.86, 0.039, 0.002, 0.545, 0.22]
0.8632283333333334
1.989286
Reward 5.621975825925355
Current State [[0.02  0.04  0.34  0.145 0.145 0.86  0.039 0.002 0.545 0.22 ]]
Logits tf.Tensor([[ 0.04658827 -0.21000184  0.4491745 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30586904 0.23664635 0.4574846 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.39, 0.158, 0.145, 0.86, 0.039, 0.002, 0.545, 0.22]
0.8632283333333334
1.989286
Reward 17.621975825925354
Current State [[0.04  0.15  0.39  0.158 0.145 0.86  0.039 0.002 0.545 0.22 ]]
Logits tf.Tensor([[ 0.05343027 -0.2408277   0.48526993]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30439803 0.22680219 0.4687998 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.4, 0.149, 0.145, 0.85, 0.04, 0.002, 0.502, 0.15]
0.8508996666666667
1.6059519999999996
Reward 18.11859199895413
Current State [[0.05  0.15  0.4   0.149 0.145 0.85  0.04  0.002 0.502 0.15 ]]
Logits tf.Tensor([[ 0.05032893 -0.22645557  0.47390556]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3043554  0.23076771 0.46487695]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.38, 0.122, 0.145, 0.79, 0.034, 0.003, 0.5429999999999999, 0.15]
0.7936623333333334
3.1964279999999996
Reward 4.760131891516017
Current State [[0.04  0.04  0.38  0.122 0.145 0.79  0.034 0.003 0.543 0.15 ]]
Logits tf.Tensor([[ 0.04432506 -0.19823423  0.4389945 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30594972 0.24005342 0.4539968 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.15, 0.37, 0.161, 0.145, 0.79, 0.034, 0.003, 0.5429999999999999, 0.15]
0.7936623333333334
3.1964279999999996
Reward 16.760131891516018
Current State [[0.06  0.15  0.37  0.161 0.145 0.79  0.034 0.003 0.543 0.15 ]]
Logits tf.Tensor([[ 0.04749792 -0.2263677   0.468255  ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3045486  0.23158918 0.46386227]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.36, 0.143, 0.145, 0.85, 0.032, 0.001, 0.48600000000000004, 0.13]
0.8539941666666667
0.8297613333333334
Reward 21.34108722673405
Current State [[0.04  0.15  0.36  0.143 0.145 0.85  0.032 0.001 0.486 0.13 ]]
Logits tf.Tensor([[ 0.05048697 -0.2201297   0.46527475]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30516106 0.23281008 0.46202892]], shape=(1, 3), dtype=float32)
Selected action 0
[0.03, 0.04, 0.34, 0.114, 0.145, 0.79, 0.019, 0.006, 0.5389999999999999, 0.08]
0.7862308333333334
5.590476333333333
Reward 4.316223278186407
Current State [[0.03  0.04  0.34  0.114 0.145 0.79  0.019 0.006 0.539 0.08 ]]
Logits tf.Tensor([[ 0.04772605 -0.18620725  0.4334505 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30655155 0.24260937 0.45083904]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.38, 0.157, 0.145, 0.79, 0.019, 0.006, 0.5389999999999999, 0.08]
0.7862308333333334
5.590476333333333
Reward 16.316223278186406
Current State [[0.05  0.15  0.38  0.157 0.145 0.79  0.019 0.006 0.539 0.08 ]]
Logits tf.Tensor([[ 0.0545663  -0.21127547  0.4679927 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30501288 0.2338108  0.4611763 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.37, 0.167, 0.145, 0.93, 0.042, 0.003, 0.477, 0.14]
0.9283723333333334
2.619643166666667
Reward 17.2371028735218
Current State [[0.04  0.15  0.37  0.167 0.145 0.93  0.042 0.003 0.477 0.14 ]]
Logits tf.Tensor([[ 0.05003126 -0.22687931  0.48037204]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30340692 0.23001955 0.46657357]], shape=(1, 3), dtype=float32)
Selected action 1
[0.02, 0.08, 0.36, 0.136, 0.145, 0.7, 0.018, 0.008, 1.01, 0.08]
0.6964183333333335
8.035119333333332
Reward 10.108099268639808
Current State [[0.02  0.08  0.36  0.136 0.145 0.7   0.018 0.008 1.01  0.08 ]]
Logits tf.Tensor([[ 0.02536095 -0.2424097   0.6134653 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.28045335 0.21457018 0.50497645]], shape=(1, 3), dtype=float32)
Selected action 0
[0.03, 0.04, 0.36, 0.161, 0.145, 0.7, 0.018, 0.008, 1.01, 0.08]
0.6964183333333335
8.035119333333332
Reward 4.108099268639809
Current State [[0.03  0.04  0.36  0.161 0.145 0.7   0.018 0.008 1.01  0.08 ]]
Logits tf.Tensor([[ 0.02503773 -0.23488005  0.60822946]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.28067312 0.21643129 0.5028956 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.04, 0.38, 0.169, 0.145, 0.68, 0.016, 0.009, 0.78, 0.11]
0.6831138333333334
9.041071500000003
Reward 4.066383272148953
Current State [[0.05  0.04  0.38  0.169 0.145 0.68  0.016 0.009 0.78  0.11 ]]
Logits tf.Tensor([[ 0.04001791 -0.2030003   0.50560373]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2961029  0.23222086 0.4716763 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.36, 0.126, 0.145, 0.83, 0.032, 0.001, 0.5860000000000001, 0.01]
0.8301906666666666
1.182143
Reward 19.10641738667683
Current State [[0.04  0.15  0.36  0.126 0.145 0.83  0.032 0.001 0.586 0.01 ]]
Logits tf.Tensor([[ 0.04613188 -0.21383324  0.4913252 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30013174 0.2314251  0.46844313]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.04, 0.33, 0.158, 0.145, 0.83, 0.032, 0.001, 0.5860000000000001, 0.01]
0.8301906666666666
1.182143
Reward 7.106417386676833
Current State [[0.05  0.04  0.33  0.158 0.145 0.83  0.032 0.001 0.586 0.01 ]]
Logits tf.Tensor([[ 0.03932868 -0.18616404  0.4589607 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30124798 0.2404329  0.45831916]], shape=(1, 3), dtype=float32)
Selected action 0
[0.02, 0.04, 0.29, 0.138, 0.145, 0.86, 0.033, 0.001, 0.504, 0.01]
0.8583683333333334
0.8880953333333333
Reward 8.87430739705807
Episode: 65 | Average Reward: 289 | Episode Reward: 251 | Loss: 457.29 | Steps: 19 | Worker: 0
Current State [[ 0.00696877 -0.00611396 -0.00823165 -0.00201295  0.00317969  0.0015882
  -0.00556607 -0.00638973  0.00525879  0.00381171]]
Logits tf.Tensor([[ 0.01778955 -0.017963    0.01212781]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.33792537 0.3260571  0.33601752]], shape=(1, 3), dtype=float32)
Selected action 1
[0.04, 0.08, 0.31, 0.135, 0.145, 0.81, 0.024, 0.004, 0.589, 0.11]
0.8050713333333334
4.141071333333333
Reward 10.533058458360061
Current State [[0.04  0.08  0.31  0.135 0.145 0.81  0.024 0.004 0.589 0.11 ]]
Logits tf.Tensor([[ 0.04623799 -0.21639587  0.46674374]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30378932 0.23362109 0.46258953]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.15, 0.33, 0.182, 0.145, 0.81, 0.024, 0.004, 0.589, 0.11]
0.8050713333333334
4.141071333333333
Reward 16.53305845836006
Current State [[0.06  0.15  0.33  0.182 0.145 0.81  0.024 0.004 0.589 0.11 ]]
Logits tf.Tensor([[ 0.05010925 -0.23132707  0.48972678]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30240604 0.22822553 0.4693685 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.08, 0.08, 0.34, 0.154, 0.145, 0.87, 0.02, 0.001, 0.561, 0.06]
0.8692899999999998
1.2273806666666665
Reward 13.142903359773427
Current State [[0.08  0.08  0.34  0.154 0.145 0.87  0.02  0.001 0.561 0.06 ]]
Logits tf.Tensor([[ 0.04538525 -0.2152371   0.47502455]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30236372 0.232993   0.4646433 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.34, 0.129, 0.145, 0.86, 0.029, 0.002, 0.461, 0.12]
0.8616211666666668
1.6869046666666665
Reward 18.016920157730162
Current State [[0.05  0.15  0.34  0.129 0.145 0.86  0.029 0.002 0.461 0.12 ]]
Logits tf.Tensor([[ 0.04940793 -0.22895335  0.4640944 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30572447 0.23144051 0.462835  ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.02, 0.04, 0.35, 0.142, 0.145, 0.86, 0.029, 0.002, 0.461, 0.12]
0.8616211666666668
1.6869046666666665
Reward 6.01692015773016
Current State [[0.02  0.04  0.35  0.142 0.145 0.86  0.029 0.002 0.461 0.12 ]]
Logits tf.Tensor([[ 0.05176667 -0.19316871  0.4317625 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30816323 0.24121633 0.45062044]], shape=(1, 3), dtype=float32)
Selected action 2
[0.02, 0.15, 0.34, 0.147, 0.145, 0.91, 0.045, 0.001, 0.48200000000000004, 0.12]
0.9142454999999999
1.1613098333333336
Reward 19.64039256738792
Current State [[0.02  0.15  0.34  0.147 0.145 0.91  0.045 0.001 0.482 0.12 ]]
Logits tf.Tensor([[ 0.04890584 -0.23023258  0.482976  ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30303377 0.2292254  0.46774083]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.34, 0.145, 0.145, 0.73, 0.022, 0.003, 0.624, 0.07]
0.7261516666666666
2.735118833333333
Reward 4.834707990744037
Current State [[0.04  0.04  0.34  0.145 0.145 0.73  0.022 0.003 0.624 0.07 ]]
Logits tf.Tensor([[ 0.04367619 -0.19339396  0.45671502]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3029991  0.23904689 0.457954  ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.02, 0.15, 0.32, 0.16, 0.145, 0.73, 0.022, 0.003, 0.624, 0.07]
0.7261516666666666
2.735118833333333
Reward 16.834707990744036
Current State [[0.02  0.15  0.32  0.16  0.145 0.73  0.022 0.003 0.624 0.07 ]]
Logits tf.Tensor([[ 0.050873   -0.21490821  0.48114613]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3026374 0.2320039 0.4653587]], shape=(1, 3), dtype=float32)
Selected action 0
[0.03, 0.04, 0.32, 0.145, 0.145, 0.85, 0.023, 0.004, 0.599, 0.1]
0.8540166666666666
4.352381
Reward 4.5405121811261955
Current State [[0.03  0.04  0.32  0.145 0.145 0.85  0.023 0.004 0.599 0.1  ]]
Logits tf.Tensor([[ 0.04889876 -0.20600596  0.46693125]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30358592 0.23527618 0.46113792]], shape=(1, 3), dtype=float32)
Selected action 0
[0.03, 0.04, 0.31, 0.121, 0.145, 0.78, 0.02, 0.002, 0.583, 0.11]
0.7810883333333333
2.3988096666666667
Reward 5.103721022571956
Current State [[0.03  0.04  0.31  0.121 0.145 0.78  0.02  0.002 0.583 0.11 ]]
Logits tf.Tensor([[ 0.04642872 -0.20067495  0.44690973]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3054739  0.23859335 0.45593274]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.15, 0.36, 0.151, 0.145, 0.78, 0.02, 0.002, 0.583, 0.11]
0.7810883333333333
2.3988096666666667
Reward 17.103721022571957
Current State [[0.06  0.15  0.36  0.151 0.145 0.78  0.02  0.002 0.583 0.11 ]]
Logits tf.Tensor([[ 0.05115571 -0.23124419  0.48316208]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30355307 0.22887054 0.4675764 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.02, 0.04, 0.33, 0.144, 0.145, 0.87, 0.026, 0.003, 0.488, 0.04]
0.8666145000000001
2.5351193333333333
Reward 5.1785750514055895
Current State [[0.02  0.04  0.33  0.144 0.145 0.87  0.026 0.003 0.488 0.04 ]]
Logits tf.Tensor([[ 0.05112983 -0.18652268  0.43936652]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30648002 0.24165234 0.45186764]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.32, 0.128, 0.145, 0.76, 0.027, 0.005, 0.511, 0.09]
0.7588613333333334
4.6648805
Reward 16.403928439255374
Current State [[0.03  0.15  0.32  0.128 0.145 0.76  0.027 0.005 0.511 0.09 ]]
Logits tf.Tensor([[ 0.04983939 -0.21644902  0.45591125]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30607918 0.2345234  0.45939744]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.15, 0.36, 0.216, 0.145, 0.76, 0.027, 0.005, 0.511, 0.09]
0.7588613333333334
4.6648805
Reward 16.403928439255374
Current State [[0.06  0.15  0.36  0.216 0.145 0.76  0.027 0.005 0.511 0.09 ]]
Logits tf.Tensor([[ 0.05234382 -0.20853996  0.45900378]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30560815 0.2354315  0.45896032]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.15, 0.36, 0.192, 0.145, 0.91, 0.03, 0.003, 0.505, 0.02]
0.9101735000000002
2.6535715
Reward 17.183942778159725
Current State [[0.07  0.15  0.36  0.192 0.145 0.91  0.03  0.003 0.505 0.02 ]]
Logits tf.Tensor([[ 0.04984253 -0.21876891  0.49145925]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3012357  0.23027667 0.46848762]], shape=(1, 3), dtype=float32)
Selected action 1
[0.03, 0.08, 0.31, 0.136, 0.145, 0.8, 0.028, 0.004, 0.54, 0.04]
0.8018936666666666
3.991071333333333
Reward 10.559967090503022
Current State [[0.03  0.08  0.31  0.136 0.145 0.8   0.028 0.004 0.54  0.04 ]]
Logits tf.Tensor([[ 0.0463227  -0.19705786  0.45180842]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3045063  0.23872475 0.45676887]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.04, 0.36, 0.15, 0.145, 0.8, 0.028, 0.004, 0.54, 0.04]
0.8018936666666666
3.991071333333333
Reward 4.559967090503023
Current State [[0.05  0.04  0.36  0.15  0.145 0.8   0.028 0.004 0.54  0.04 ]]
Logits tf.Tensor([[ 0.04427402 -0.18870638  0.44823185]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3039597  0.24078749 0.45525283]], shape=(1, 3), dtype=float32)
Selected action 1
[0.06, 0.08, 0.37, 0.167, 0.145, 0.81, 0.035, 0.002, 0.525, 0.11]
0.811549
1.8339278333333333
Reward 11.664935363489452
Current State [[0.06  0.08  0.37  0.167 0.145 0.81  0.035 0.002 0.525 0.11 ]]
Logits tf.Tensor([[ 0.04543637 -0.20731167  0.45596442]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.304481   0.23647928 0.4590397 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.34, 0.124, 0.145, 0.77, 0.03, 0.007, 0.609, 0.14]
0.767598
6.951785999999999
Reward 16.19852655078271
Current State [[0.03  0.15  0.34  0.124 0.145 0.77  0.03  0.007 0.609 0.14 ]]
Logits tf.Tensor([[ 0.04999333 -0.238735    0.48643783]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30336013 0.22728217 0.46935767]], shape=(1, 3), dtype=float32)
Selected action 1
[0.05, 0.08, 0.38, 0.163, 0.145, 0.77, 0.03, 0.007, 0.609, 0.14]
0.767598
6.951785999999999
Reward 10.198526550782711
Episode: 66 | Average Reward: 288 | Episode Reward: 240 | Loss: 451.106 | Steps: 19 | Worker: 0
Current State [[-0.00894612  0.00890477 -0.00513953 -0.00178264 -0.00826352  0.00435149
  -0.00314662  0.00433182 -0.00561606 -0.00434756]]
Logits tf.Tensor([[ 0.02336297 -0.01818765  0.00671747]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.33981323 0.32598314 0.33420366]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.41, 0.156, 0.145, 0.88, 0.039, 0.004, 0.626, 0.13]
0.8785173333333333
4.246429
Reward 4.584734029660086
Current State [[0.04  0.04  0.41  0.156 0.145 0.88  0.039 0.004 0.626 0.13 ]]
Logits tf.Tensor([[ 0.04896367 -0.22545224  0.49979493]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30033347 0.22825825 0.47140837]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.42, 0.14, 0.145, 0.69, 0.032, 0.006, 0.786, 0.17]
0.6948289999999999
6.410119333333333
Reward 16.19075753386449
Current State [[0.03  0.15  0.42  0.14  0.145 0.69  0.032 0.006 0.786 0.17 ]]
Logits tf.Tensor([[ 0.05247919 -0.25562477  0.5411464 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29717848 0.21837832 0.48444316]], shape=(1, 3), dtype=float32)
Selected action 0
[0.01, 0.04, 0.36, 0.151, 0.145, 0.69, 0.032, 0.006, 0.786, 0.17]
0.6948289999999999
6.410119333333333
Reward 4.190757533864489
Current State [[0.01  0.04  0.36  0.151 0.145 0.69  0.032 0.006 0.786 0.17 ]]
Logits tf.Tensor([[ 0.04387795 -0.23374645  0.5173724 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29733795 0.22525768 0.4774044 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.01, 0.15, 0.35, 0.15, 0.145, 0.68, 0.031, 0.004, 0.762, 0.16]
0.677061
4.470833166666667
Reward 16.359013211846666
Current State [[0.01  0.15  0.35  0.15  0.145 0.68  0.031 0.004 0.762 0.16 ]]
Logits tf.Tensor([[ 0.05085618 -0.24987586  0.52501863]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29878002 0.2211797  0.48004028]], shape=(1, 3), dtype=float32)
Selected action 2
[0.02, 0.15, 0.31, 0.118, 0.145, 0.82, 0.032, 0.003, 0.771, 0.12]
0.8238143333333332
2.912500166666667
Reward 16.911068280338018
Current State [[0.02  0.15  0.31  0.118 0.145 0.82  0.032 0.003 0.771 0.12 ]]
Logits tf.Tensor([[ 0.04825358 -0.26512396  0.5482562 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29588428 0.21628371 0.487832  ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.15, 0.38, 0.186, 0.145, 0.82, 0.032, 0.003, 0.771, 0.12]
0.8238143333333332
2.912500166666667
Reward 16.911068280338018
Current State [[0.06  0.15  0.38  0.186 0.145 0.82  0.032 0.003 0.771 0.12 ]]
Logits tf.Tensor([[ 0.04827563 -0.26218307  0.556035  ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29457903 0.21595901 0.48946193]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.15, 0.39, 0.169, 0.145, 0.85, 0.036, 0.001, 0.591, 0.01]
0.8516875
0.7994046666666667
Reward 21.619165314345718
Current State [[0.06  0.15  0.39  0.169 0.145 0.85  0.036 0.001 0.591 0.01 ]]
Logits tf.Tensor([[ 0.04833762 -0.23023696  0.51513165]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.298353   0.22581197 0.47583503]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.38, 0.125, 0.145, 0.88, 0.046, 0.001, 0.5, 0.17]
0.8848306666666667
1.3017858333333334
Reward 18.96992545924372
Current State [[0.04  0.15  0.38  0.125 0.145 0.88  0.046 0.001 0.5   0.17 ]]
Logits tf.Tensor([[ 0.0502851  -0.2503016   0.49164045]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30347204 0.22468573 0.47184226]], shape=(1, 3), dtype=float32)
Selected action 0
[0.03, 0.04, 0.38, 0.155, 0.145, 0.88, 0.046, 0.001, 0.5, 0.17]
0.8848306666666667
1.3017858333333334
Reward 6.9699254592437185
Current State [[0.03  0.04  0.38  0.155 0.145 0.88  0.046 0.001 0.5   0.17 ]]
Logits tf.Tensor([[ 0.04849638 -0.21411516  0.45948628]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30512452 0.23465313 0.4602224 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.41, 0.158, 0.145, 0.86, 0.061, 0.002, 0.433, 0.14]
0.8554623333333334
2.256548
Reward 5.354109872572485
Current State [[0.04  0.04  0.41  0.158 0.145 0.86  0.061 0.002 0.433 0.14 ]]
Logits tf.Tensor([[ 0.04370563 -0.2011318   0.4410657 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30574277 0.23934516 0.4549121 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.41, 0.14, 0.145, 0.82, 0.042, 0.004, 0.533, 0.17]
0.823009
3.8345235
Reward 4.617099754277937
Current State [[0.04  0.04  0.41  0.14  0.145 0.82  0.042 0.004 0.533 0.17 ]]
Logits tf.Tensor([[ 0.04905191 -0.21425277  0.45851585]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30538845 0.2346934  0.45991814]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.39, 0.147, 0.145, 0.82, 0.042, 0.004, 0.533, 0.17]
0.823009
3.8345235
Reward 4.617099754277937
Current State [[0.04  0.04  0.39  0.147 0.145 0.82  0.042 0.004 0.533 0.17 ]]
Logits tf.Tensor([[ 0.04788491 -0.2144324   0.45627782]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30546802 0.23498642 0.4595455 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.41, 0.148, 0.145, 0.83, 0.037, 0.002, 0.538, 0.12]
0.8252503333333332
2.3898816666666667
Reward 17.194689220840317
Current State [[0.05  0.15  0.41  0.148 0.145 0.83  0.037 0.002 0.538 0.12 ]]
Logits tf.Tensor([[ 0.05343305 -0.23948282  0.49384248]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30308282 0.22612552 0.4707916 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.02, 0.15, 0.38, 0.136, 0.145, 0.77, 0.039, 0.002, 0.5940000000000001, 0.15]
0.7657879999999999
1.9351191666666667
Reward 17.434132840991687
Current State [[0.02  0.15  0.38  0.136 0.145 0.77  0.039 0.002 0.594 0.15 ]]
Logits tf.Tensor([[ 0.05189237 -0.24158016  0.49253365]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30308786 0.22600345 0.4709086 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.02, 0.08, 0.36, 0.123, 0.145, 0.74, 0.028, 0.003, 0.563, 0.17]
0.7421019999999999
3.407738166666667
Reward 10.630268429322097
Current State [[0.02  0.08  0.36  0.123 0.145 0.74  0.028 0.003 0.563 0.17 ]]
Logits tf.Tensor([[ 0.05165176 -0.21935633  0.45382324]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30696708 0.23409627 0.45893657]], shape=(1, 3), dtype=float32)
Selected action 0
[0.06, 0.04, 0.36, 0.164, 0.145, 0.74, 0.028, 0.003, 0.563, 0.17]
0.7421019999999999
3.407738166666667
Reward 4.630268429322096
Current State [[0.06  0.04  0.36  0.164 0.145 0.74  0.028 0.003 0.563 0.17 ]]
Logits tf.Tensor([[ 0.04591035 -0.2106685   0.4427366 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30667403 0.23727186 0.45605415]], shape=(1, 3), dtype=float32)
Selected action 1
[0.03, 0.08, 0.39, 0.13, 0.145, 0.83, 0.033, 0.001, 0.449, 0.03]
0.8276091666666666
1.145238
Reward 13.231549000539111
Current State [[0.03  0.08  0.39  0.13  0.145 0.83  0.033 0.001 0.449 0.03 ]]
Logits tf.Tensor([[ 0.04911979 -0.19513401  0.44726962]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3055902  0.23936541 0.45504436]], shape=(1, 3), dtype=float32)
Selected action 0
[0.03, 0.04, 0.38, 0.129, 0.145, 0.82, 0.043, 0.001, 0.545, 0.17]
0.8242793333333334
1.3374998333333334
Reward 6.5981296717372295
Current State [[0.03  0.04  0.38  0.129 0.145 0.82  0.043 0.001 0.545 0.17 ]]
Logits tf.Tensor([[ 0.04639731 -0.21681587  0.4593897 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30488628 0.23432888 0.46078482]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.39, 0.174, 0.145, 0.82, 0.043, 0.001, 0.545, 0.17]
0.8242793333333334
1.3374998333333334
Reward 18.59812967173723
Current State [[0.04  0.15  0.39  0.174 0.145 0.82  0.043 0.001 0.545 0.17 ]]
Logits tf.Tensor([[ 0.05271919 -0.24261725  0.49146944]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30348563 0.22587864 0.47063577]], shape=(1, 3), dtype=float32)
Selected action 1
[0.05, 0.08, 0.39, 0.142, 0.145, 0.86, 0.039, 0.002, 0.5269999999999999, 0.12]
0.8605324999999999
2.429762166666666
Reward 11.23604528807484
Episode: 67 | Average Reward: 288 | Episode Reward: 236 | Loss: 445.289 | Steps: 19 | Worker: 0
Current State [[ 0.00157381 -0.00793963 -0.00368384  0.00526922 -0.00942478 -0.00219478
  -0.00846831 -0.00718128 -0.00085928 -0.00149122]]
Logits tf.Tensor([[ 0.02085507 -0.01699627  0.00677402]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.33911252 0.32651654 0.3343709 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.37, 0.13, 0.145, 0.87, 0.045, 0.002, 0.488, 0.21]
0.8715356666666667
2.4791675000000004
Reward 17.22377811621957
Current State [[0.04  0.15  0.37  0.13  0.145 0.87  0.045 0.002 0.488 0.21 ]]
Logits tf.Tensor([[ 0.05312344 -0.26089007  0.49024966]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3049933  0.22280042 0.47220635]], shape=(1, 3), dtype=float32)
Selected action 0
[0.02, 0.04, 0.39, 0.154, 0.145, 0.87, 0.045, 0.002, 0.488, 0.21]
0.8715356666666667
2.4791675000000004
Reward 5.223778116219571
Current State [[0.02  0.04  0.39  0.154 0.145 0.87  0.045 0.002 0.488 0.21 ]]
Logits tf.Tensor([[ 0.05464512 -0.22125764  0.46055916]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30678988 0.23281874 0.46039143]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.4, 0.155, 0.145, 0.84, 0.074, 0.012, 0.433, 0.18]
0.8431391666666667
12.138094833333332
Reward 16.04367421800335
Current State [[0.04  0.15  0.4   0.155 0.145 0.84  0.074 0.012 0.433 0.18 ]]
Logits tf.Tensor([[ 0.04876764 -0.25036484  0.4735001 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30575034 0.22670202 0.46754768]], shape=(1, 3), dtype=float32)
Selected action 1
[0.05, 0.08, 0.4, 0.128, 0.145, 0.86, 0.039, 0.002, 0.532, 0.17]
0.8593159999999999
1.5660721666666666
Reward 12.220626217951054
Current State [[0.05  0.08  0.4   0.128 0.145 0.86  0.039 0.002 0.532 0.17 ]]
Logits tf.Tensor([[ 0.05253572 -0.24102208  0.4832616 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3045086  0.22704343 0.468448  ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.38, 0.167, 0.145, 0.86, 0.039, 0.002, 0.532, 0.17]
0.8593159999999999
1.5660721666666666
Reward 18.220626217951054
Current State [[0.05  0.15  0.38  0.167 0.145 0.86  0.039 0.002 0.532 0.17 ]]
Logits tf.Tensor([[ 0.05622712 -0.25526407  0.50184596]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30359977 0.22234254 0.47405773]], shape=(1, 3), dtype=float32)
Selected action 2
[0.02, 0.15, 0.37, 0.119, 0.145, 0.87, 0.042, 0.002, 0.493, 0.16]
0.8705498333333335
1.6196426666666668
Reward 18.159810229836978
Current State [[0.02  0.15  0.37  0.119 0.145 0.87  0.042 0.002 0.493 0.16 ]]
Logits tf.Tensor([[ 0.05549368 -0.251074    0.49173597]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30461317 0.22418575 0.47120106]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.04, 0.46, 0.132, 0.145, 0.8, 0.021, 0.002, 0.5860000000000001, 0.05]
0.8016688333333334
1.8452376666666666
Reward 5.624541672125198
Current State [[0.05  0.04  0.46  0.132 0.145 0.8   0.021 0.002 0.586 0.05 ]]
Logits tf.Tensor([[ 0.05357836 -0.20937087  0.48783624]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3018779  0.23207796 0.4660442 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.15, 0.41, 0.186, 0.145, 0.8, 0.021, 0.002, 0.5860000000000001, 0.05]
0.8016688333333334
1.8452376666666666
Reward 17.624541672125197
Current State [[0.06  0.15  0.41  0.186 0.145 0.8   0.021 0.002 0.586 0.05 ]]
Logits tf.Tensor([[ 0.05844742 -0.23343411  0.50691205]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30186284 0.22544837 0.47268882]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.37, 0.123, 0.145, 0.83, 0.044, 0.002, 0.563, 0.19]
0.8276803333333334
1.7333335000000005
Reward 5.843077093673702
Current State [[0.04  0.04  0.37  0.123 0.145 0.83  0.044 0.002 0.563 0.19 ]]
Logits tf.Tensor([[ 0.04662833 -0.23459898  0.47106996]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30454442 0.22988741 0.4655682 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.02, 0.04, 0.35, 0.133, 0.145, 0.86, 0.053, 0.002, 0.491, 0.23]
0.8645488333333333
2.309523833333333
Reward 5.331388827025814
Current State [[0.02  0.04  0.35  0.133 0.145 0.86  0.053 0.002 0.491 0.23 ]]
Logits tf.Tensor([[ 0.04760814 -0.22982956  0.45522776]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30665836 0.23236202 0.46097964]], shape=(1, 3), dtype=float32)
Selected action 0
[0.03, 0.04, 0.33, 0.149, 0.145, 0.86, 0.053, 0.002, 0.491, 0.23]
0.8645488333333333
2.309523833333333
Reward 5.331388827025814
Current State [[0.03  0.04  0.33  0.149 0.145 0.86  0.053 0.002 0.491 0.23 ]]
Logits tf.Tensor([[ 0.04578824 -0.23171449  0.45235148]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3068123  0.23246357 0.4607241 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.34, 0.149, 0.145, 0.8, 0.023, 0.003, 0.549, 0.11]
0.8042596666666666
2.739880166666666
Reward 16.958586097521497
Current State [[0.05  0.15  0.34  0.149 0.145 0.8   0.023 0.003 0.549 0.11 ]]
Logits tf.Tensor([[ 0.05547891 -0.2424031   0.4890066 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30440667 0.22598816 0.46960518]], shape=(1, 3), dtype=float32)
Selected action 1
[0.07, 0.08, 0.37, 0.131, 0.145, 0.85, 0.026, 0.005, 0.454, 0.08]
0.8451295
5.233333333333333
Reward 10.39916897578058
Current State [[0.07  0.08  0.37  0.131 0.145 0.85  0.026 0.005 0.454 0.08 ]]
Logits tf.Tensor([[ 0.0513094  -0.22011925  0.45336995]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30701298 0.2340328  0.45895424]], shape=(1, 3), dtype=float32)
Selected action 1
[0.03, 0.08, 0.36, 0.172, 0.145, 0.85, 0.026, 0.005, 0.454, 0.08]
0.8451295
5.233333333333333
Reward 10.39916897578058
Current State [[0.03  0.08  0.36  0.172 0.145 0.85  0.026 0.005 0.454 0.08 ]]
Logits tf.Tensor([[ 0.05885378 -0.20583797  0.45284656]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30766085 0.236112   0.45622712]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.04, 0.37, 0.154, 0.145, 0.68, 0.021, 0.008, 0.933, 0.13]
0.6845293333333334
7.730952
Reward 4.115163977965035
Current State [[0.05  0.04  0.37  0.154 0.145 0.68  0.021 0.008 0.933 0.13 ]]
Logits tf.Tensor([[ 0.03293696 -0.2574177   0.589366  ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.28633356 0.214177   0.4994895 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.03, 0.04, 0.35, 0.126, 0.145, 0.69, 0.017, 0.007, 1.038, 0.06]
0.6875300000000001
7.1916666666666655
Reward 4.141892985055101
Current State [[0.03  0.04  0.35  0.126 0.145 0.69  0.017 0.007 1.038 0.06 ]]
Logits tf.Tensor([[ 0.02834921 -0.25838193  0.6362214 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.27876642 0.2092737  0.5119599 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.04, 0.08, 0.33, 0.148, 0.145, 0.69, 0.017, 0.007, 1.038, 0.06]
0.6875300000000001
7.1916666666666655
Reward 10.141892985055101
Current State [[0.04  0.08  0.33  0.148 0.145 0.69  0.017 0.007 1.038 0.06 ]]
Logits tf.Tensor([[ 0.02747232 -0.27021766  0.64516175]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2779964  0.20642106 0.51558256]], shape=(1, 3), dtype=float32)
Selected action 1
[0.02, 0.08, 0.31, 0.128, 0.145, 0.81, 0.034, 0.002, 0.5820000000000001, 0.13]
0.8131811666666667
1.7035711666666664
Reward 11.842206535417573
Current State [[0.02  0.08  0.31  0.128 0.145 0.81  0.034 0.002 0.582 0.13 ]]
Logits tf.Tensor([[ 0.04851364 -0.23116544  0.47798118]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30372375 0.22962314 0.46665308]], shape=(1, 3), dtype=float32)
Selected action 1
[0.06, 0.08, 0.35, 0.131, 0.145, 0.85, 0.035, 0.001, 0.542, 0.16]
0.8453773333333333
1.3803575
Reward 12.576109886357072
Current State [[0.06  0.08  0.35  0.131 0.145 0.85  0.035 0.001 0.542 0.16 ]]
Logits tf.Tensor([[ 0.04797391 -0.24230556  0.47858822]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3042976  0.22763118 0.46807125]], shape=(1, 3), dtype=float32)
Selected action 1
[0.02, 0.08, 0.3, 0.104, 0.145, 0.88, 0.029, 0.003, 0.541, 0.06]
0.880771
3.168452333333333
Reward 10.889528430602756
Episode: 68 | Average Reward: 287 | Episode Reward: 218 | Loss: 338.377 | Steps: 19 | Worker: 0
Current State [[-0.00497045  0.00612464 -0.00547671 -0.00126913 -0.00573724  0.00799995
  -0.00740276  0.00902467  0.00652533 -0.00745353]]
Logits tf.Tensor([[ 0.02484775 -0.02381139  0.01250022]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.34010896 0.32395574 0.33593526]], shape=(1, 3), dtype=float32)
Selected action 1
[0.03, 0.08, 0.32, 0.129, 0.145, 0.88, 0.029, 0.003, 0.541, 0.06]
0.880771
3.168452333333333
Reward 10.889528430602756
Current State [[0.03  0.08  0.32  0.129 0.145 0.88  0.029 0.003 0.541 0.06 ]]
Logits tf.Tensor([[ 0.05456007 -0.23020889  0.4835506 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.304146   0.228775   0.46707898]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.32, 0.147, 0.145, 0.91, 0.031, 0.001, 0.533, 0.08]
0.9086676666666665
1.0869051666666667
Reward 7.9613808040623475
Current State [[0.04  0.04  0.32  0.147 0.145 0.91  0.031 0.001 0.533 0.08 ]]
Logits tf.Tensor([[ 0.05266316 -0.22676405  0.47456178]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30477855 0.23047864 0.46474278]], shape=(1, 3), dtype=float32)
Selected action 0
[0.06, 0.04, 0.37, 0.142, 0.145, 0.77, 0.023, 0.002, 0.512, 0.06]
0.7698828333333333
2.105357166666667
Reward 5.290269450459658
Current State [[0.06  0.04  0.37  0.142 0.145 0.77  0.023 0.002 0.512 0.06 ]]
Logits tf.Tensor([[ 0.05018061 -0.20570756  0.44819874]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3064571  0.23726784 0.45627508]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.35, 0.144, 0.145, 0.77, 0.023, 0.002, 0.512, 0.06]
0.7698828333333333
2.105357166666667
Reward 17.290269450459657
Current State [[0.05  0.15  0.35  0.144 0.145 0.77  0.023 0.002 0.512 0.06 ]]
Logits tf.Tensor([[ 0.05693315 -0.23174393  0.4758654 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3058486  0.22915831 0.46499303]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.36, 0.138, 0.145, 0.83, 0.024, 0.002, 0.483, 0.08]
0.8279745000000001
2.4369051666666666
Reward 17.168932235479325
Current State [[0.04  0.15  0.36  0.138 0.145 0.83  0.024 0.002 0.483 0.08 ]]
Logits tf.Tensor([[ 0.06066196 -0.23682426  0.48093656]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30627286 0.2274636  0.46626353]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.34, 0.167, 0.145, 0.69, 0.02, 0.003, 0.624, 0.09]
0.6867665
2.8589283333333335
Reward 4.7254518340146
Current State [[0.04  0.04  0.34  0.167 0.145 0.69  0.02  0.003 0.624 0.09 ]]
Logits tf.Tensor([[ 0.05040371 -0.20616172  0.46291137]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30447838 0.23557626 0.45994538]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.35, 0.172, 0.145, 0.69, 0.02, 0.003, 0.624, 0.09]
0.6867665
2.8589283333333335
Reward 16.7254518340146
Current State [[0.05  0.15  0.35  0.172 0.145 0.69  0.02  0.003 0.624 0.09 ]]
Logits tf.Tensor([[ 0.0555004  -0.23418185  0.48773956]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30402485 0.22756301 0.46841216]], shape=(1, 3), dtype=float32)
Selected action 0
[0.03, 0.04, 0.35, 0.141, 0.145, 0.89, 0.035, 0.002, 0.5, 0.12]
0.8904625
1.6785716666666666
Reward 6.122066820458031
Current State [[0.03  0.04  0.35  0.141 0.145 0.89  0.035 0.002 0.5   0.12 ]]
Logits tf.Tensor([[ 0.05419715 -0.22372214  0.46463442]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3062942  0.23197435 0.4617314 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.33, 0.137, 0.145, 0.85, 0.025, 0.003, 0.488, 0.07]
0.8546466666666668
2.978571666666667
Reward 16.929153769433828
Current State [[0.03  0.15  0.33  0.137 0.145 0.85  0.025 0.003 0.488 0.07 ]]
Logits tf.Tensor([[ 0.05964683 -0.23740086  0.483648  ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30571023 0.2271453  0.46714455]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.31, 0.151, 0.145, 0.85, 0.025, 0.003, 0.488, 0.07]
0.8546466666666668
2.978571666666667
Reward 16.929153769433828
Current State [[0.03  0.15  0.31  0.151 0.145 0.85  0.025 0.003 0.488 0.07 ]]
Logits tf.Tensor([[ 0.05857825 -0.23574972  0.48169953]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3056467  0.22771658 0.46663672]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.15, 0.37, 0.156, 0.145, 0.9, 0.034, 0.001, 0.519, 0.13]
0.8952196666666666
1.2833328333333336
Reward 19.07780053264343
Current State [[0.08  0.15  0.37  0.156 0.145 0.9   0.034 0.001 0.519 0.13 ]]
Logits tf.Tensor([[ 0.055537   -0.26455972  0.5083014 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30314675 0.22010842 0.4767448 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.02, 0.08, 0.32, 0.175, 0.145, 0.9, 0.034, 0.001, 0.519, 0.13]
0.8952196666666666
1.2833328333333336
Reward 13.077800532643431
Current State [[0.02  0.08  0.32  0.175 0.145 0.9   0.034 0.001 0.519 0.13 ]]
Logits tf.Tensor([[ 0.05742682 -0.23341025  0.48122132]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30530757 0.22825941 0.46643293]], shape=(1, 3), dtype=float32)
Selected action 1
[0.03, 0.08, 0.33, 0.179, 0.145, 0.87, 0.025, 0.002, 0.497, 0.11]
0.8716053333333332
1.8214283333333336
Reward 11.848345918256385
Current State [[0.03  0.08  0.33  0.179 0.145 0.87  0.025 0.002 0.497 0.11 ]]
Logits tf.Tensor([[ 0.05997345 -0.223252    0.46880737]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.306898   0.23120157 0.46190044]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.33, 0.126, 0.145, 0.81, 0.035, 0.002, 0.54, 0.08]
0.8149963333333333
1.5380956666666663
Reward 18.118765701447728
Current State [[0.03  0.15  0.33  0.126 0.145 0.81  0.035 0.002 0.54  0.08 ]]
Logits tf.Tensor([[ 0.05345569 -0.24416609  0.49154752]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30373633 0.22554918 0.4707145 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.03, 0.04, 0.35, 0.19, 0.145, 0.81, 0.035, 0.002, 0.54, 0.08]
0.8149963333333333
1.5380956666666663
Reward 6.118765701447729
Current State [[0.03  0.04  0.35  0.19  0.145 0.81  0.035 0.002 0.54  0.08 ]]
Logits tf.Tensor([[ 0.05299706 -0.20411777  0.46194386]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3050165  0.23586299 0.45912048]], shape=(1, 3), dtype=float32)
Selected action 1
[0.03, 0.08, 0.35, 0.172, 0.145, 0.8, 0.016, 0.002, 0.54, 0.08]
0.8009316666666667
2.1363095
Reward 11.334118386370008
Current State [[0.03  0.08  0.35  0.172 0.145 0.8   0.016 0.002 0.54  0.08 ]]
Logits tf.Tensor([[ 0.06111276 -0.21319117  0.4692543 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3063612  0.23286548 0.46077338]], shape=(1, 3), dtype=float32)
Selected action 1
[0.04, 0.08, 0.35, 0.129, 0.145, 0.78, 0.026, 0.002, 0.612, 0.08]
0.7788430000000001
2.4988094999999997
Reward 11.040239058173032
Current State [[0.04  0.08  0.35  0.129 0.145 0.78  0.026 0.002 0.612 0.08 ]]
Logits tf.Tensor([[ 0.0521617  -0.23118511  0.48764136]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3031256  0.22833192 0.46854252]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.35, 0.147, 0.145, 0.78, 0.026, 0.002, 0.612, 0.08]
0.7788430000000001
2.4988094999999997
Reward 17.040239058173032
Current State [[0.03  0.15  0.35  0.147 0.145 0.78  0.026 0.002 0.612 0.08 ]]
Logits tf.Tensor([[ 0.05774419 -0.24398267  0.5063358 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30251282 0.22372034 0.4737668 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.35, 0.182, 0.145, 0.76, 0.031, 0.005, 0.633, 0.16]
0.7588389999999998
4.774405499999999
Reward 16.388945771383753
Current State [[0.03  0.15  0.35  0.182 0.145 0.76  0.031 0.005 0.633 0.16 ]]
Logits tf.Tensor([[ 0.05866354 -0.25588244  0.50623006]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3035251  0.22160983 0.4748651 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.05, 0.08, 0.37, 0.138, 0.145, 0.71, 0.02, 0.005, 0.67, 0.08]
0.7114873333333335
5.114881499999999
Reward 10.310169286393787
Episode: 69 | Average Reward: 287 | Episode Reward: 254 | Loss: 561.113 | Steps: 19 | Worker: 0
Current State [[-0.00303016  0.00832382 -0.00341366  0.00677552 -0.00206589  0.00691125
  -0.00318909  0.0010427   0.00387865 -0.00298294]]
Logits tf.Tensor([[ 0.02130751 -0.02505042  0.01575247]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.33907953 0.32371932 0.33720118]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.38, 0.191, 0.145, 0.71, 0.02, 0.005, 0.67, 0.08]
0.7114873333333335
5.114881499999999
Reward 16.310169286393787
Current State [[0.03  0.15  0.38  0.191 0.145 0.71  0.02  0.005 0.67  0.08 ]]
Logits tf.Tensor([[ 0.06259471 -0.23438774  0.511729  ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30211368 0.2244877  0.4733986 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.07, 0.08, 0.39, 0.18, 0.145, 0.77, 0.037, 0.004, 0.757, 0.17]
0.7681396666666666
4.0470235
Reward 10.51410067977152
Current State [[0.07  0.08  0.39  0.18  0.145 0.77  0.037 0.004 0.757 0.17 ]]
Logits tf.Tensor([[ 0.05105065 -0.2685317   0.5384009 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29811156 0.21656385 0.48532462]], shape=(1, 3), dtype=float32)
Selected action 2
[0.02, 0.15, 0.37, 0.123, 0.145, 0.76, 0.03, 0.001, 0.754, 0.13]
0.7623063333333333
1.2946430000000004
Reward 18.442393939229746
Current State [[0.02  0.15  0.37  0.123 0.145 0.76  0.03  0.001 0.754 0.13 ]]
Logits tf.Tensor([[ 0.05875337 -0.26945004  0.5450779 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2988157  0.215212   0.48597226]], shape=(1, 3), dtype=float32)
Selected action 2
[0.02, 0.15, 0.37, 0.147, 0.145, 0.76, 0.03, 0.001, 0.754, 0.13]
0.7623063333333333
1.2946430000000004
Reward 18.442393939229746
Current State [[0.02  0.15  0.37  0.147 0.145 0.76  0.03  0.001 0.754 0.13 ]]
Logits tf.Tensor([[ 0.05989873 -0.2672582   0.54625374]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.298744   0.21538562 0.48587042]], shape=(1, 3), dtype=float32)
Selected action 1
[0.03, 0.08, 0.36, 0.166, 0.145, 0.72, 0.026, 0.004, 0.843, 0.15]
0.7224323333333333
4.4732145
Reward 10.399217594339198
Current State [[0.03  0.08  0.36  0.166 0.145 0.72  0.026 0.004 0.843 0.15 ]]
Logits tf.Tensor([[ 0.04962752 -0.26339322  0.5643147 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29374182 0.21479423 0.49146387]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.38, 0.142, 0.145, 0.78, 0.036, 0.002, 0.603, 0.05]
0.7752769999999999
2.0571431666666666
Reward 17.343450899596945
Current State [[0.04  0.15  0.38  0.142 0.145 0.78  0.036 0.002 0.603 0.05 ]]
Logits tf.Tensor([[ 0.05579408 -0.24412698  0.5087845 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30176055 0.22356737 0.47467208]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.4, 0.202, 0.145, 0.78, 0.036, 0.002, 0.603, 0.05]
0.7752769999999999
2.0571431666666666
Reward 17.343450899596945
Current State [[0.05  0.15  0.4   0.202 0.145 0.78  0.036 0.002 0.603 0.05 ]]
Logits tf.Tensor([[ 0.05773689 -0.23943241  0.51209706]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3013788  0.22389981 0.4747214 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.37, 0.113, 0.145, 0.84, 0.044, 0.001, 0.483, 0.15]
0.8439423333333332
1.2083333333333333
Reward 19.083033471712746
Current State [[0.03  0.15  0.37  0.113 0.145 0.84  0.044 0.001 0.483 0.15 ]]
Logits tf.Tensor([[ 0.05662552 -0.25674173  0.4874595 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30585515 0.22357443 0.47057045]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.37, 0.153, 0.145, 0.84, 0.044, 0.001, 0.483, 0.15]
0.8439423333333332
1.2083333333333333
Reward 19.083033471712746
Current State [[0.03  0.15  0.37  0.153 0.145 0.84  0.044 0.001 0.483 0.15 ]]
Logits tf.Tensor([[ 0.0583217 -0.250924   0.4877947]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3057685  0.22443421 0.46979728]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.4, 0.148, 0.145, 0.81, 0.058, 0.003, 0.43200000000000005, 0.16]
0.814014
2.5184523333333333
Reward 17.092755612962755
Current State [[0.05  0.15  0.4   0.148 0.145 0.81  0.058 0.003 0.432 0.16 ]]
Logits tf.Tensor([[ 0.05390752 -0.25086376  0.47063562]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30728745 0.22656058 0.46615198]], shape=(1, 3), dtype=float32)
Selected action 1
[0.03, 0.08, 0.38, 0.132, 0.145, 0.78, 0.039, 0.003, 0.557, 0.19]
0.7845141666666666
3.4916669999999996
Reward 10.6593916931904
Current State [[0.03  0.08  0.38  0.132 0.145 0.78  0.039 0.003 0.557 0.19 ]]
Logits tf.Tensor([[ 0.05608237 -0.243675    0.47429603]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3067256  0.22728305 0.46599138]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.4, 0.146, 0.145, 0.87, 0.043, 0.001, 0.487, 0.12]
0.8741426666666666
1.2178571666666669
Reward 7.201406353868103
Current State [[0.04  0.04  0.4   0.146 0.145 0.87  0.043 0.001 0.487 0.12 ]]
Logits tf.Tensor([[ 0.05493817 -0.2228738   0.46620435]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30616936 0.23190467 0.46192592]], shape=(1, 3), dtype=float32)
Selected action 2
[0.02, 0.15, 0.38, 0.152, 0.145, 0.87, 0.043, 0.001, 0.487, 0.12]
0.8741426666666666
1.2178571666666669
Reward 19.2014063538681
Current State [[0.02  0.15  0.38  0.152 0.145 0.87  0.043 0.001 0.487 0.12 ]]
Logits tf.Tensor([[ 0.06108908 -0.24816063  0.49679768]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3048729  0.22377591 0.4713512 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.02, 0.08, 0.36, 0.115, 0.145, 0.82, 0.038, 0.003, 0.509, 0.17]
0.8170179999999998
3.2214288333333334
Reward 10.78310777106904
Current State [[0.02  0.08  0.36  0.115 0.145 0.82  0.038 0.003 0.509 0.17 ]]
Logits tf.Tensor([[ 0.05734505 -0.23914966  0.46798247]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3075789  0.2286602  0.46376088]], shape=(1, 3), dtype=float32)
Selected action 1
[0.02, 0.08, 0.34, 0.144, 0.145, 0.79, 0.048, 0.002, 0.471, 0.08]
0.7908085
1.5351195000000002
Reward 12.040109947000982
Current State [[0.02  0.08  0.34  0.144 0.145 0.79  0.048 0.002 0.471 0.08 ]]
Logits tf.Tensor([[ 0.04991393 -0.2144601   0.45068341]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3066864  0.23543897 0.45787457]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.36, 0.153, 0.145, 0.79, 0.048, 0.002, 0.471, 0.08]
0.7908085
1.5351195000000002
Reward 18.040109947000982
Current State [[0.03  0.15  0.36  0.153 0.145 0.79  0.048 0.002 0.471 0.08 ]]
Logits tf.Tensor([[ 0.05428774 -0.23382592  0.47367156]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30574492 0.22920975 0.46504536]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.37, 0.118, 0.145, 0.87, 0.039, 0.001, 0.44000000000000006, 0.12]
0.8684461666666666
0.740476
Reward 10.481322798002617
Current State [[0.04  0.04  0.37  0.118 0.145 0.87  0.039 0.001 0.44  0.12 ]]
Logits tf.Tensor([[ 0.05311235 -0.22268786  0.4472145 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30844998 0.23410262 0.45744738]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.39, 0.154, 0.145, 0.89, 0.049, 0.001, 0.517, 0.14]
0.8908285
0.8910715
Reward 21.119242714376917
Current State [[0.04  0.15  0.39  0.154 0.145 0.89  0.049 0.001 0.517 0.14 ]]
Logits tf.Tensor([[ 0.05846249 -0.26237318  0.5115804 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30314493 0.21994452 0.47691053]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.37, 0.157, 0.145, 0.89, 0.049, 0.001, 0.517, 0.14]
0.8908285
0.8910715
Reward 21.119242714376917
Current State [[0.03  0.15  0.37  0.157 0.145 0.89  0.049 0.001 0.517 0.14 ]]
Logits tf.Tensor([[ 0.05832197 -0.2602316   0.5095903 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30325976 0.22053055 0.47620964]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.37, 0.15, 0.145, 0.85, 0.036, 0.002, 0.516, 0.13]
0.845715
1.7904755
Reward 17.816467704073
Episode: 70 | Average Reward: 287 | Episode Reward: 312 | Loss: 793.393 | Steps: 19 | Worker: 0
Current State [[-5.55712560e-03 -2.47800356e-05  8.21692794e-03  5.92683140e-03
   9.53249165e-03 -1.16499371e-03  1.02999418e-03  4.37565676e-03
   4.96152146e-03 -7.03896935e-03]]
Logits tf.Tensor([[ 0.01838807 -0.02376236  0.01430135]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3384499  0.32448056 0.33706957]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.39, 0.123, 0.145, 0.86, 0.04, 0.002, 0.499, 0.18]
0.8566381666666669
2.1630958333333337
Reward 17.435549439773688
Current State [[0.05  0.15  0.39  0.123 0.145 0.86  0.04  0.002 0.499 0.18 ]]
Logits tf.Tensor([[ 0.05655576 -0.26996958  0.50298613]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3044928  0.21966904 0.47583815]], shape=(1, 3), dtype=float32)
Selected action 0
[0.09, 0.04, 0.43, 0.168, 0.145, 0.86, 0.04, 0.002, 0.499, 0.18]
0.8566381666666669
2.1630958333333337
Reward 5.435549439773686
Current State [[0.09  0.04  0.43  0.168 0.145 0.86  0.04  0.002 0.499 0.18 ]]
Logits tf.Tensor([[ 0.05157999 -0.24015108  0.47541225]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3053645  0.22809795 0.46653754]], shape=(1, 3), dtype=float32)
Selected action 0
[0.03, 0.04, 0.38, 0.148, 0.145, 0.87, 0.042, 0.002, 0.605, 0.26]
0.8670961666666667
1.7791670000000004
Reward 5.894112798363103
Current State [[0.03  0.04  0.38  0.148 0.145 0.87  0.042 0.002 0.605 0.26 ]]
Logits tf.Tensor([[ 0.05522911 -0.2605628   0.50360274]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30349246 0.22131008 0.47519743]], shape=(1, 3), dtype=float32)
Selected action 0
[0.01, 0.04, 0.37, 0.138, 0.145, 0.74, 0.035, 0.002, 0.545, 0.15]
0.7357411666666667
2.331547666666667
Reward 5.057821591319881
Current State [[0.01  0.04  0.37  0.138 0.145 0.74  0.035 0.002 0.545 0.15 ]]
Logits tf.Tensor([[ 0.05346613 -0.21722253  0.45534918]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30698478 0.23418456 0.45883065]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.38, 0.145, 0.145, 0.74, 0.035, 0.002, 0.545, 0.15]
0.7357411666666667
2.331547666666667
Reward 17.05782159131988
Current State [[0.05  0.15  0.38  0.145 0.145 0.74  0.035 0.002 0.545 0.15 ]]
Logits tf.Tensor([[ 0.05381885 -0.25630352  0.48622406]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30540726 0.2239726  0.4706202 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.39, 0.142, 0.145, 0.89, 0.041, 0.002, 0.518, 0.21]
0.8855206666666668
2.3773803333333334
Reward 5.322520899864643
Current State [[0.04  0.04  0.39  0.142 0.145 0.89  0.041 0.002 0.518 0.21 ]]
Logits tf.Tensor([[ 0.05502499 -0.24552235  0.48311013]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30536872 0.22609894 0.4685323 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.02, 0.08, 0.39, 0.131, 0.145, 0.78, 0.036, 0.003, 0.562, 0.14]
0.7833693333333333
2.859524
Reward 10.871777159447943
Current State [[0.02  0.08  0.39  0.131 0.145 0.78  0.036 0.003 0.562 0.14 ]]
Logits tf.Tensor([[ 0.05569743 -0.23679724  0.48264125]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3049742  0.22763251 0.46739328]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.41, 0.159, 0.145, 0.78, 0.036, 0.003, 0.562, 0.14]
0.7833693333333333
2.859524
Reward 16.871777159447944
Current State [[0.04  0.15  0.41  0.159 0.145 0.78  0.036 0.003 0.562 0.14 ]]
Logits tf.Tensor([[ 0.05854679 -0.25692523  0.5034103 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30397707 0.2217344  0.4742885 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.03, 0.08, 0.38, 0.138, 0.145, 0.77, 0.034, 0.003, 0.542, 0.16]
0.7700775000000001
3.4851191666666663
Reward 10.643696723072068
Current State [[0.03  0.08  0.38  0.138 0.145 0.77  0.034 0.003 0.542 0.16 ]]
Logits tf.Tensor([[ 0.05520167 -0.23714077  0.47278124]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30629796 0.22865535 0.46504673]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.38, 0.126, 0.145, 0.83, 0.032, 0.001, 0.49400000000000005, 0.11]
0.8296571666666667
0.9851188333333333
Reward 20.002809440323645
Current State [[0.04  0.15  0.38  0.126 0.145 0.83  0.032 0.001 0.494 0.11 ]]
Logits tf.Tensor([[ 0.05876301 -0.2518117   0.49431962]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3049851  0.22356187 0.471453  ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.02, 0.15, 0.37, 0.136, 0.145, 0.83, 0.032, 0.001, 0.49400000000000005, 0.11]
0.8296571666666667
0.9851188333333333
Reward 20.002809440323645
Current State [[0.02  0.15  0.37  0.136 0.145 0.83  0.032 0.001 0.494 0.11 ]]
Logits tf.Tensor([[ 0.06083162 -0.24617882  0.49344438]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30516443 0.22449206 0.4703436 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.37, 0.144, 0.145, 0.75, 0.019, 0.008, 0.5309999999999999, 0.09]
0.7521961666666666
7.629166333333333
Reward 16.153280304536313
Current State [[0.04  0.15  0.37  0.144 0.145 0.75  0.019 0.008 0.531 0.09 ]]
Logits tf.Tensor([[ 0.06172507 -0.24104342  0.48186892]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30665904 0.22655053 0.4667904 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.03, 0.04, 0.42, 0.129, 0.145, 0.91, 0.04, 0.002, 0.489, 0.13]
0.9073886666666666
2.4988091666666663
Reward 5.278220700847257
Current State [[0.03  0.04  0.42  0.129 0.145 0.91  0.04  0.002 0.489 0.13 ]]
Logits tf.Tensor([[ 0.05737815 -0.2310529   0.4824108 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3049637  0.22855154 0.46648476]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.15, 0.39, 0.166, 0.145, 0.91, 0.04, 0.002, 0.489, 0.13]
0.9073886666666666
2.4988091666666663
Reward 17.278220700847257
Current State [[0.08  0.15  0.39  0.166 0.145 0.91  0.04  0.002 0.489 0.13 ]]
Logits tf.Tensor([[ 0.05516163 -0.2678535   0.5118059 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30277982 0.21920136 0.47801882]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.15, 0.37, 0.178, 0.145, 0.69, 0.017, 0.008, 0.992, 0.06]
0.6914678333333332
7.822024000000001
Reward 16.114620678112367
Current State [[0.06  0.15  0.37  0.178 0.145 0.69  0.017 0.008 0.992 0.06 ]]
Logits tf.Tensor([[ 0.03240403 -0.2855942   0.6508585 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2790442  0.20303372 0.51792204]], shape=(1, 3), dtype=float32)
Selected action 2
[0.02, 0.15, 0.35, 0.126, 0.145, 0.78, 0.018, 0.003, 0.705, 0.08]
0.7802608333333334
3.3821431666666673
Reward 16.684882418533874
Current State [[0.02  0.15  0.35  0.126 0.145 0.78  0.018 0.003 0.705 0.08 ]]
Logits tf.Tensor([[ 0.05984633 -0.25872815  0.5375314 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.299444   0.21775116 0.4828048 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.07, 0.04, 0.39, 0.16, 0.145, 0.78, 0.018, 0.003, 0.705, 0.08]
0.7802608333333334
3.3821431666666673
Reward 4.684882418533873
Current State [[0.07  0.04  0.39  0.16  0.145 0.78  0.018 0.003 0.705 0.08 ]]
Logits tf.Tensor([[ 0.04886543 -0.2357224   0.52337974]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29765823 0.22393553 0.47840628]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.34, 0.145, 0.145, 0.79, 0.025, 0.005, 0.624, 0.05]
0.7897866666666667
4.957737833333334
Reward 16.39040688831737
Current State [[0.04  0.15  0.34  0.145 0.145 0.79  0.025 0.005 0.624 0.05 ]]
Logits tf.Tensor([[ 0.05566545 -0.2505355   0.5179898 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30084246 0.22149186 0.4776657 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.07, 0.08, 0.33, 0.119, 0.145, 0.87, 0.034, 0.001, 0.51, 0.1]
0.8675426666666667
0.8166666666666667
Reward 15.595066318380356
Current State [[0.07  0.08  0.33  0.119 0.145 0.87  0.034 0.001 0.51  0.1  ]]
Logits tf.Tensor([[ 0.04608124 -0.24727482  0.48152673]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30382136 0.22657676 0.46960193]], shape=(1, 3), dtype=float32)
Selected action 1
[0.06, 0.08, 0.33, 0.184, 0.145, 0.87, 0.034, 0.001, 0.51, 0.1]
0.8675426666666667
0.8166666666666667
Reward 15.595066318380356
Episode: 71 | Average Reward: 286 | Episode Reward: 258 | Loss: 600.395 | Steps: 19 | Worker: 0
Current State [[ 6.38605845e-03 -9.48310745e-04  9.32304268e-03 -6.94400608e-03
   6.89659876e-03 -3.88749311e-03 -4.82395664e-05  6.84082726e-03
  -2.77888991e-03 -3.26932467e-03]]
Logits tf.Tensor([[ 0.01699126 -0.02473678  0.01312931]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.33837783 0.32454857 0.3370736 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.32, 0.157, 0.145, 0.87, 0.031, 0.001, 0.5690000000000001, 0.1]
0.8716238333333333
1.2773804999999996
Reward 18.985819952818076
Current State [[0.04  0.15  0.32  0.157 0.145 0.87  0.031 0.001 0.569 0.1  ]]
Logits tf.Tensor([[ 0.05297012 -0.26419303  0.52457136]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30023086 0.2186317  0.48113742]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.3, 0.146, 0.145, 0.82, 0.022, 0.002, 0.584, 0.09]
0.8207621666666667
2.0273808333333334
Reward 17.478400245636145
Current State [[0.04  0.15  0.3   0.146 0.145 0.82  0.022 0.002 0.584 0.09 ]]
Logits tf.Tensor([[ 0.05287617 -0.25929317  0.51473105]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30130714 0.22051391 0.47817895]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.35, 0.183, 0.145, 0.82, 0.022, 0.002, 0.584, 0.09]
0.8207621666666667
2.0273808333333334
Reward 5.478400245636144
Current State [[0.04  0.04  0.35  0.183 0.145 0.82  0.022 0.002 0.584 0.09 ]]
Logits tf.Tensor([[ 0.05337718 -0.22302231  0.4886644 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30267107 0.22957897 0.46774995]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.15, 0.34, 0.216, 0.145, 0.9, 0.031, 0.002, 0.453, 0.02]
0.8990263333333335
1.6351191666666665
Reward 18.226703663738935
Current State [[0.06  0.15  0.34  0.216 0.145 0.9   0.031 0.002 0.453 0.02 ]]
Logits tf.Tensor([[ 0.05535992 -0.23716316  0.49822754]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3027052  0.22593251 0.47136226]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.36, 0.165, 0.145, 0.91, 0.046, 0.001, 0.47800000000000004, 0.12]
0.913447
1.227975833333333
Reward 19.363746886098056
Current State [[0.05  0.15  0.36  0.165 0.145 0.91  0.046 0.001 0.478 0.12 ]]
Logits tf.Tensor([[ 0.05180215 -0.2627953   0.5115084 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30177826 0.22032309 0.4778987 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.35, 0.169, 0.145, 0.91, 0.046, 0.001, 0.47800000000000004, 0.12]
0.913447
1.227975833333333
Reward 19.363746886098056
Current State [[0.04  0.15  0.35  0.169 0.145 0.91  0.046 0.001 0.478 0.12 ]]
Logits tf.Tensor([[ 0.05237402 -0.2602375   0.51051027]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30187234 0.2208299  0.47729775]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.35, 0.126, 0.145, 0.83, 0.032, 0.002, 0.5700000000000001, 0.14]
0.8288910000000002
1.8380948333333333
Reward 17.70742630709899
Current State [[0.04  0.15  0.35  0.126 0.145 0.83  0.032 0.002 0.57  0.14 ]]
Logits tf.Tensor([[ 0.05402603 -0.2700626   0.5183836 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30173394 0.21820982 0.48005623]], shape=(1, 3), dtype=float32)
Selected action 1
[0.05, 0.08, 0.34, 0.144, 0.145, 0.86, 0.026, 0.003, 0.529, 0.1]
0.8561223333333333
2.5476191666666663
Reward 11.151732019952098
Current State [[0.05  0.08  0.34  0.144 0.145 0.86  0.026 0.003 0.529 0.1  ]]
Logits tf.Tensor([[ 0.05202216 -0.24182191  0.490307  ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30344972 0.22618921 0.4703611 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.33, 0.173, 0.145, 0.86, 0.026, 0.003, 0.529, 0.1]
0.8561223333333333
2.5476191666666663
Reward 17.1517320199521
Current State [[0.03  0.15  0.33  0.173 0.145 0.86  0.026 0.003 0.529 0.1  ]]
Logits tf.Tensor([[ 0.05893507 -0.25238714  0.51072377]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30270025 0.22172125 0.47557843]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.35, 0.13, 0.145, 0.75, 0.023, 0.005, 0.507, 0.05]
0.7511495000000001
5.025
Reward 16.351232329304167
Current State [[0.04  0.15  0.35  0.13  0.145 0.75  0.023 0.005 0.507 0.05 ]]
Logits tf.Tensor([[ 0.05536126 -0.23514824  0.48006412]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30515543 0.2282204  0.46662417]], shape=(1, 3), dtype=float32)
Selected action 1
[0.04, 0.08, 0.35, 0.126, 0.145, 0.88, 0.031, 0.002, 0.421, 0.06]
0.8796493333333333
2.264881666666667
Reward 11.3986579357212
Current State [[0.04  0.08  0.35  0.126 0.145 0.88  0.031 0.002 0.421 0.06 ]]
Logits tf.Tensor([[ 0.05064422 -0.22895353  0.4611823 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30639917 0.23166467 0.4619362 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.34, 0.165, 0.145, 0.88, 0.031, 0.002, 0.421, 0.06]
0.8796493333333333
2.264881666666667
Reward 17.3986579357212
Current State [[0.05  0.15  0.34  0.165 0.145 0.88  0.031 0.002 0.421 0.06 ]]
Logits tf.Tensor([[ 0.05333441 -0.24173315  0.48301575]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.304762   0.22688961 0.4683484 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.35, 0.158, 0.145, 0.79, 0.02, 0.005, 0.529, 0.04]
0.7923765
5.050595
Reward 16.38074035456077
Current State [[0.05  0.15  0.35  0.158 0.145 0.79  0.02  0.005 0.529 0.04 ]]
Logits tf.Tensor([[ 0.0564939  -0.24003276  0.49664614]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3033668  0.2255216  0.47111154]], shape=(1, 3), dtype=float32)
Selected action 2
[0.01, 0.15, 0.31, 0.15, 0.145, 0.84, 0.034, 0.002, 0.571, 0.09]
0.8437655000000001
1.9589283333333334
Reward 17.60597502876295
Current State [[0.01  0.15  0.31  0.15  0.145 0.84  0.034 0.002 0.571 0.09 ]]
Logits tf.Tensor([[ 0.05395468 -0.25469086  0.51777065]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30079067 0.220913   0.47829634]], shape=(1, 3), dtype=float32)
Selected action 1
[0.05, 0.08, 0.35, 0.169, 0.145, 0.84, 0.034, 0.002, 0.571, 0.09]
0.8437655000000001
1.9589283333333334
Reward 11.605975028762947
Current State [[0.05  0.08  0.35  0.169 0.145 0.84  0.034 0.002 0.571 0.09 ]]
Logits tf.Tensor([[ 0.04910448 -0.24049227  0.5011718 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30119368 0.22546314 0.47334325]], shape=(1, 3), dtype=float32)
Selected action 1
[0.04, 0.08, 0.34, 0.162, 0.145, 0.86, 0.037, 0.003, 0.5389999999999999, 0.08]
0.8553665000000001
3.0630953333333335
Reward 10.895123164390593
Current State [[0.04  0.08  0.34  0.162 0.145 0.86  0.037 0.003 0.539 0.08 ]]
Logits tf.Tensor([[ 0.04960807 -0.23707029  0.49482724]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30197018 0.22670504 0.47132477]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.35, 0.148, 0.145, 0.76, 0.02, 0.003, 0.8210000000000001, 0.07]
0.7625565000000001
3.0077383333333336
Reward 16.782726149833366
Current State [[0.04  0.15  0.35  0.148 0.145 0.76  0.02  0.003 0.821 0.07 ]]
Logits tf.Tensor([[ 0.04897168 -0.267631    0.58333373]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29112253 0.21211778 0.49675968]], shape=(1, 3), dtype=float32)
Selected action 1
[0.05, 0.08, 0.34, 0.144, 0.145, 0.76, 0.02, 0.003, 0.8210000000000001, 0.07]
0.7625565000000001
3.0077383333333336
Reward 10.782726149833364
Current State [[0.05  0.08  0.34  0.144 0.145 0.76  0.02  0.003 0.821 0.07 ]]
Logits tf.Tensor([[ 0.04170078 -0.2567856   0.57225823]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29054394 0.2155663  0.49388978]], shape=(1, 3), dtype=float32)
Selected action 1
[0.09, 0.08, 0.37, 0.146, 0.145, 0.75, 0.03, 0.003, 0.689, 0.14]
0.745486
3.146428333333333
Reward 10.711404739638017
Current State [[0.09  0.08  0.37  0.146 0.145 0.75  0.03  0.003 0.689 0.14 ]]
Logits tf.Tensor([[ 0.0404403  -0.26375368  0.51975715]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29826808 0.22003765 0.4816942 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.15, 0.37, 0.211, 0.145, 0.75, 0.03, 0.003, 0.689, 0.14]
0.745486
3.146428333333333
Reward 16.711404739638017
Episode: 72 | Average Reward: 287 | Episode Reward: 301 | Loss: 698.52 | Steps: 19 | Worker: 0
Current State [[ 0.00356226  0.00386254  0.00769176  0.00252892 -0.00506741  0.00342582
  -0.00647177 -0.00713461 -0.00925339 -0.00537015]]
Logits tf.Tensor([[ 0.01641023 -0.02429719  0.01489958]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.33799765 0.32451493 0.33748743]], shape=(1, 3), dtype=float32)
Selected action 1
[0.05, 0.08, 0.37, 0.175, 0.145, 0.82, 0.037, 0.002, 0.683, 0.18]
0.8200721666666667
2.058333
Reward 11.447146509539605
Current State [[0.05  0.08  0.37  0.175 0.145 0.82  0.037 0.002 0.683 0.18 ]]
Logits tf.Tensor([[ 0.04243763 -0.2680498   0.53845364]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29627386 0.21719529 0.48653084]], shape=(1, 3), dtype=float32)
Selected action 0
[0.02, 0.04, 0.41, 0.124, 0.145, 0.77, 0.035, 0.003, 0.704, 0.16]
0.7693966666666667
2.930952499999999
Reward 4.821689987341571
Current State [[0.02  0.04  0.41  0.124 0.145 0.77  0.035 0.003 0.704 0.16 ]]
Logits tf.Tensor([[ 0.04417778 -0.25179505  0.5288679 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.296958   0.22087961 0.48216233]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.39, 0.182, 0.145, 0.77, 0.035, 0.003, 0.704, 0.16]
0.7693966666666667
2.930952499999999
Reward 16.82168998734157
Current State [[0.04  0.15  0.39  0.182 0.145 0.77  0.035 0.003 0.704 0.16 ]]
Logits tf.Tensor([[ 0.04783086 -0.27719757  0.5525954 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29593658 0.21381621 0.4902472 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.02, 0.15, 0.37, 0.147, 0.145, 0.65, 0.028, 0.003, 0.818, 0.15]
0.6539588333333335
2.6166665
Reward 16.76713076519936
Current State [[0.02  0.15  0.37  0.147 0.145 0.65  0.028 0.003 0.818 0.15 ]]
Logits tf.Tensor([[ 0.04114331 -0.2694831   0.5729227 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29112542 0.21339135 0.49548328]], shape=(1, 3), dtype=float32)
Selected action 0
[0.02, 0.04, 0.39, 0.162, 0.145, 0.82, 0.032, 0.004, 0.678, 0.08]
0.8245846666666665
4.200595333333333
Reward 4.540857261250951
Current State [[0.02  0.04  0.39  0.162 0.145 0.82  0.032 0.004 0.678 0.08 ]]
Logits tf.Tensor([[ 0.04637335 -0.23597668  0.53221583]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29589704 0.22310926 0.48099363]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.4, 0.152, 0.145, 0.82, 0.032, 0.004, 0.678, 0.08]
0.8245846666666665
4.200595333333333
Reward 4.540857261250951
Current State [[0.04  0.04  0.4   0.152 0.145 0.82  0.032 0.004 0.678 0.08 ]]
Logits tf.Tensor([[ 0.0433025  -0.24125321  0.5344916 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29528084 0.22215407 0.4825651 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.06, 0.04, 0.43, 0.15, 0.145, 0.89, 0.04, 0.002, 0.481, 0.12]
0.8917028333333333
2.061904166666667
Reward 5.614629610006179
Current State [[0.06  0.04  0.43  0.15  0.145 0.89  0.04  0.002 0.481 0.12 ]]
Logits tf.Tensor([[ 0.0460162  -0.23319173  0.4904929 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30156302 0.22809702 0.47033995]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.37, 0.115, 0.145, 0.79, 0.044, 0.002, 0.49800000000000005, 0.16]
0.7938096666666666
2.1833333333333327
Reward 17.280338502602966
Current State [[0.03  0.15  0.37  0.115 0.145 0.79  0.044 0.002 0.498 0.16 ]]
Logits tf.Tensor([[ 0.04608224 -0.26068613  0.49729759]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30247664 0.22256869 0.4749547 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.03, 0.08, 0.38, 0.159, 0.145, 0.79, 0.044, 0.002, 0.49800000000000005, 0.16]
0.7938096666666666
2.1833333333333327
Reward 11.280338502602968
Current State [[0.03  0.08  0.38  0.159 0.145 0.79  0.044 0.002 0.498 0.16 ]]
Logits tf.Tensor([[ 0.04555232 -0.2343788   0.47868127]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30322224 0.22918624 0.4675915 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.04, 0.42, 0.165, 0.145, 0.83, 0.058, 0.003, 0.449, 0.13]
0.826411
2.8113095
Reward 4.960467793925877
Current State [[0.05  0.04  0.42  0.165 0.145 0.83  0.058 0.003 0.449 0.13 ]]
Logits tf.Tensor([[ 0.03991813 -0.22077891  0.4680495 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30258083 0.23314287 0.46427628]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.38, 0.112, 0.145, 0.84, 0.042, 0.002, 0.497, 0.13]
0.8406623333333332
2.210119
Reward 17.36017255287959
Current State [[0.03  0.15  0.38  0.112 0.145 0.84  0.042 0.002 0.497 0.13 ]]
Logits tf.Tensor([[ 0.04852254 -0.26161787  0.510364  ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3011742  0.22086431 0.47796157]], shape=(1, 3), dtype=float32)
Selected action 1
[0.06, 0.08, 0.39, 0.147, 0.145, 0.84, 0.042, 0.002, 0.497, 0.13]
0.8406623333333332
2.210119
Reward 11.36017255287959
Current State [[0.06  0.08  0.39  0.147 0.145 0.84  0.042 0.002 0.497 0.13 ]]
Logits tf.Tensor([[ 0.04319572 -0.24359155  0.49086735]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30162856 0.22642392 0.47194755]], shape=(1, 3), dtype=float32)
Selected action 1
[0.05, 0.08, 0.4, 0.155, 0.145, 0.89, 0.045, 0.001, 0.506, 0.13]
0.8861325
1.460118666666667
Reward 12.54451800236399
Current State [[0.05  0.08  0.4   0.155 0.145 0.89  0.045 0.001 0.506 0.13 ]]
Logits tf.Tensor([[ 0.04521099 -0.24760932  0.50654644]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3000888  0.22391313 0.4759981 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.05, 0.08, 0.38, 0.126, 0.145, 0.88, 0.043, 0.001, 0.497, 0.16]
0.8801928333333334
1.3845233333333333
Reward 12.71034741263867
Current State [[0.05  0.08  0.38  0.126 0.145 0.88  0.043 0.001 0.497 0.16 ]]
Logits tf.Tensor([[ 0.0439287  -0.25418153  0.4985321 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30140746 0.22371052 0.47488204]], shape=(1, 3), dtype=float32)
Selected action 0
[0.07, 0.04, 0.36, 0.184, 0.145, 0.88, 0.043, 0.001, 0.497, 0.16]
0.8801928333333334
1.3845233333333333
Reward 6.71034741263867
Current State [[0.07  0.04  0.36  0.184 0.145 0.88  0.043 0.001 0.497 0.16 ]]
Logits tf.Tensor([[ 0.0403702  -0.24062528  0.48435798]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3017553  0.22783487 0.47040984]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.42, 0.178, 0.145, 0.74, 0.066, 0.003, 0.421, 0.16]
0.7351851666666666
2.826191
Reward 4.811354808384495
Current State [[0.04  0.04  0.42  0.178 0.145 0.74  0.066 0.003 0.421 0.16 ]]
Logits tf.Tensor([[ 0.03989229 -0.21056777  0.44009572]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30575702 0.23801431 0.4562287 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.03, 0.08, 0.37, 0.118, 0.145, 0.82, 0.028, 0.003, 0.472, 0.14]
0.8176298333333333
2.7303573333333326
Reward 10.985095483004292
Current State [[0.03  0.08  0.37  0.118 0.145 0.82  0.028 0.003 0.472 0.14 ]]
Logits tf.Tensor([[ 0.05074714 -0.23537178  0.47456697]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30497476 0.2290889  0.4659363 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.15, 0.41, 0.158, 0.145, 0.82, 0.028, 0.003, 0.472, 0.14]
0.8176298333333333
2.7303573333333326
Reward 16.985095483004294
Current State [[0.07  0.15  0.41  0.158 0.145 0.82  0.028 0.003 0.472 0.14 ]]
Logits tf.Tensor([[ 0.05264912 -0.25785965  0.49832377]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3035254  0.22250657 0.47396806]], shape=(1, 3), dtype=float32)
Selected action 2
[0.02, 0.15, 0.37, 0.162, 0.145, 0.85, 0.044, 0.002, 0.515, 0.18]
0.8481351666666667
2.157738166666667
Reward 17.421238591110512
Current State [[0.02  0.15  0.37  0.162 0.145 0.85  0.044 0.002 0.515 0.18 ]]
Logits tf.Tensor([[ 0.0513537  -0.26405388  0.5169808 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3009778  0.21956071 0.47946146]], shape=(1, 3), dtype=float32)
Selected action 1
[0.06, 0.08, 0.4, 0.136, 0.145, 0.86, 0.03, 0.003, 0.517, 0.09]
0.8568010000000001
3.313690333333334
Reward 10.804537076529396
Episode: 73 | Average Reward: 286 | Episode Reward: 219 | Loss: 404.923 | Steps: 19 | Worker: 0
Current State [[-0.00323717  0.00230361  0.00826088 -0.00123835 -0.0043656  -0.00700992
   0.00310616  0.00543563 -0.00793307  0.00585923]]
Logits tf.Tensor([[ 0.01591839 -0.02436052  0.01268982]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3381465  0.324797   0.33705655]], shape=(1, 3), dtype=float32)
Selected action 0
[0.03, 0.04, 0.41, 0.153, 0.145, 0.86, 0.03, 0.003, 0.517, 0.09]
0.8568010000000001
3.313690333333334
Reward 4.804537076529396
Current State [[0.03  0.04  0.41  0.153 0.145 0.86  0.03  0.003 0.517 0.09 ]]
Logits tf.Tensor([[ 0.04571327 -0.22195408  0.4966775 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29985118 0.22943482 0.47071394]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.39, 0.124, 0.145, 0.91, 0.044, 0.002, 0.5349999999999999, 0.13]
0.9097588333333332
1.6136901666666665
Reward 18.303160562388072
Current State [[0.04  0.15  0.39  0.124 0.145 0.91  0.044 0.002 0.535 0.13 ]]
Logits tf.Tensor([[ 0.04348164 -0.27480373  0.5433675 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29621485 0.21546523 0.48831993]], shape=(1, 3), dtype=float32)
Selected action 1
[0.02, 0.08, 0.38, 0.116, 0.145, 0.73, 0.042, 0.003, 0.5509999999999999, 0.2]
0.7297191666666667
2.8351179999999996
Reward 10.799422862375758
Current State [[0.02  0.08  0.38  0.116 0.145 0.73  0.042 0.003 0.551 0.2  ]]
Logits tf.Tensor([[ 0.03886596 -0.24461642  0.4815933 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30210528 0.22753252 0.47036216]], shape=(1, 3), dtype=float32)
Selected action 0
[0.03, 0.04, 0.37, 0.165, 0.145, 0.73, 0.042, 0.003, 0.5509999999999999, 0.2]
0.7297191666666667
2.8351179999999996
Reward 4.799422862375758
Current State [[0.03  0.04  0.37  0.165 0.145 0.73  0.042 0.003 0.551 0.2  ]]
Logits tf.Tensor([[ 0.0378543  -0.22965367  0.47040698]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30243728 0.23145045 0.4661123 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.05, 0.08, 0.38, 0.165, 0.145, 0.82, 0.043, 0.002, 0.497, 0.16]
0.8153041666666666
2.469642833333334
Reward 11.124451365319011
Current State [[0.05  0.08  0.38  0.165 0.145 0.82  0.043 0.002 0.497 0.16 ]]
Logits tf.Tensor([[ 0.03981793 -0.24038856  0.48965722]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30087063 0.22734618 0.47178325]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.38, 0.198, 0.145, 0.82, 0.043, 0.002, 0.497, 0.16]
0.8153041666666666
2.469642833333334
Reward 17.12445136531901
Current State [[0.04  0.15  0.38  0.198 0.145 0.82  0.043 0.002 0.497 0.16 ]]
Logits tf.Tensor([[ 0.04665145 -0.25498202  0.5098939 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30040607 0.22218305 0.4774109 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.02, 0.15, 0.35, 0.152, 0.145, 0.81, 0.029, 0.003, 0.5589999999999999, 0.11]
0.8095303333333332
3.186309333333333
Reward 16.785034919997177
Current State [[0.02  0.15  0.35  0.152 0.145 0.81  0.029 0.003 0.559 0.11 ]]
Logits tf.Tensor([[ 0.04722486 -0.25288972  0.5221524 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29862952 0.22120483 0.4801657 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.39, 0.134, 0.145, 0.77, 0.034, 0.002, 0.584, 0.16]
0.7701496666666667
2.231547333333333
Reward 17.193800199114797
Current State [[0.05  0.15  0.39  0.134 0.145 0.77  0.034 0.002 0.584 0.16 ]]
Logits tf.Tensor([[ 0.04187705 -0.26965845  0.5208706 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29879552 0.21881442 0.48239008]], shape=(1, 3), dtype=float32)
Selected action 1
[0.03, 0.08, 0.37, 0.149, 0.145, 0.77, 0.034, 0.002, 0.584, 0.16]
0.7701496666666667
2.231547333333333
Reward 11.193800199114795
Current State [[0.03  0.08  0.37  0.149 0.145 0.77  0.034 0.002 0.584 0.16 ]]
Logits tf.Tensor([[ 0.04089656 -0.24392483  0.50066966]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29977247 0.22547346 0.47475407]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.36, 0.156, 0.145, 0.85, 0.054, 0.002, 0.49400000000000005, 0.22]
0.8524611666666667
2.1892853333333333
Reward 17.403438453751484
Current State [[0.03  0.15  0.36  0.156 0.145 0.85  0.054 0.002 0.494 0.22 ]]
Logits tf.Tensor([[ 0.04167369 -0.2718735   0.5148619 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2997644  0.21908279 0.4811529 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.02, 0.15, 0.33, 0.114, 0.145, 0.71, 0.027, 0.002, 0.587, 0.09]
0.7124434999999999
2.498214333333333
Reward 16.921380855577404
Current State [[0.02  0.15  0.33  0.114 0.145 0.71  0.027 0.002 0.587 0.09 ]]
Logits tf.Tensor([[ 0.04144045 -0.24396789  0.50092894]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29985267 0.2254014  0.4747459 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.39, 0.175, 0.145, 0.71, 0.027, 0.002, 0.587, 0.09]
0.7124434999999999
2.498214333333333
Reward 4.9213808555774055
Current State [[0.04  0.04  0.39  0.175 0.145 0.71  0.027 0.002 0.587 0.09 ]]
Logits tf.Tensor([[ 0.03765168 -0.2130492   0.48375395]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29935938 0.23297799 0.4676626 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.37, 0.233, 0.145, 0.76, 0.024, 0.005, 0.705, 0.17]
0.7583144999999999
5.2946426666666655
Reward 16.32643020511987
Current State [[0.04  0.15  0.37  0.233 0.145 0.76  0.024 0.005 0.705 0.17 ]]
Logits tf.Tensor([[ 0.04890449 -0.27214056  0.5543239 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2955894  0.21441779 0.48999286]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.37, 0.194, 0.145, 0.67, 0.02, 0.008, 0.968, 0.11]
0.6733336666666666
8.329167
Reward 16.08616525288185
Current State [[0.03  0.15  0.37  0.194 0.145 0.67  0.02  0.008 0.968 0.11 ]]
Logits tf.Tensor([[ 0.02650196 -0.28517872  0.6510773 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2778034  0.20341189 0.5187847 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.01, 0.04, 0.3, 0.106, 0.145, 0.67, 0.02, 0.008, 0.968, 0.11]
0.6733336666666666
8.329167
Reward 4.086165252881851
Current State [[0.01  0.04  0.3   0.106 0.145 0.67  0.02  0.008 0.968 0.11 ]]
Logits tf.Tensor([[ 0.02054944 -0.26938722  0.620306  ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2801131  0.20961173 0.5102752 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.01, 0.04, 0.31, 0.119, 0.145, 0.81, 0.02, 0.003, 0.7, 0.08]
0.8100091666666668
2.514881
Reward 5.0875734871698635
Current State [[0.01  0.04  0.31  0.119 0.145 0.81  0.02  0.003 0.7   0.08 ]]
Logits tf.Tensor([[ 0.03965455 -0.24090195  0.53068376]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29504094 0.22286308 0.482096  ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.02, 0.04, 0.36, 0.194, 0.145, 0.81, 0.02, 0.003, 0.7, 0.08]
0.8100091666666668
2.514881
Reward 5.0875734871698635
Current State [[0.02  0.04  0.36  0.194 0.145 0.81  0.02  0.003 0.7   0.08 ]]
Logits tf.Tensor([[ 0.04435751 -0.23046039  0.53781754]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29431808 0.22359653 0.48208535]], shape=(1, 3), dtype=float32)
Selected action 1
[0.05, 0.08, 0.34, 0.234, 0.145, 0.85, 0.032, 0.002, 0.5980000000000001, 0.01]
0.8475518333333335
1.6238096666666668
Reward 12.076357519247864
Current State [[0.05  0.08  0.34  0.234 0.145 0.85  0.032 0.002 0.598 0.01 ]]
Logits tf.Tensor([[ 0.04062857 -0.22383052  0.5244435 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29499632 0.2264454  0.47855824]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.15, 0.34, 0.235, 0.145, 0.85, 0.032, 0.002, 0.5980000000000001, 0.01]
0.8475518333333335
1.6238096666666668
Reward 18.076357519247864
Current State [[0.06  0.15  0.34  0.235 0.145 0.85  0.032 0.002 0.598 0.01 ]]
Logits tf.Tensor([[ 0.04182074 -0.24351795  0.54492176]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29363388 0.2207421  0.48562402]], shape=(1, 3), dtype=float32)
Selected action 0
[0.03, 0.04, 0.26, 0.192, 0.145, 0.89, 0.031, 0.001, 0.526, 0.1]
0.8879640000000001
0.991667
Reward 8.36716237161662
Episode: 74 | Average Reward: 285 | Episode Reward: 236 | Loss: 446.438 | Steps: 19 | Worker: 0
Current State [[ 0.00076254 -0.00529827  0.00645312 -0.00594323 -0.00646595  0.00253337
  -0.00295762  0.0079883  -0.00023378 -0.0011752 ]]
Logits tf.Tensor([[ 0.0163402  -0.02585115  0.01601165]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.33802536 0.3240603  0.33791435]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.33, 0.147, 0.145, 0.88, 0.037, 0.001, 0.45599999999999996, 0.11]
0.8769215
0.5345241666666667
Reward 14.87286746644326
Current State [[0.04  0.04  0.33  0.147 0.145 0.88  0.037 0.001 0.456 0.11 ]]
Logits tf.Tensor([[ 0.03481065 -0.2279156   0.4739117 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30118084 0.23159371 0.46722546]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.32, 0.15, 0.145, 0.88, 0.037, 0.001, 0.45599999999999996, 0.11]
0.8769215
0.5345241666666667
Reward 26.87286746644326
Current State [[0.05  0.15  0.32  0.15  0.145 0.88  0.037 0.001 0.456 0.11 ]]
Logits tf.Tensor([[ 0.03657666 -0.25601733  0.5083659 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29858014 0.22283785 0.47858202]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.33, 0.2, 0.145, 0.84, 0.029, 0.001, 0.506, 0.09]
0.8428716666666666
1.296428166666667
Reward 6.794520476130937
Current State [[0.04  0.04  0.33  0.2   0.145 0.84  0.029 0.001 0.506 0.09 ]]
Logits tf.Tensor([[ 0.0379333  -0.21544468  0.4814384 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29991    0.2327825  0.46730757]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.37, 0.218, 0.145, 0.84, 0.029, 0.001, 0.506, 0.09]
0.8428716666666666
1.296428166666667
Reward 6.794520476130937
Current State [[0.04  0.04  0.37  0.218 0.145 0.84  0.029 0.001 0.506 0.09 ]]
Logits tf.Tensor([[ 0.04048153 -0.21045296  0.48780233]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2992051  0.23280348 0.46799144]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.04, 0.35, 0.158, 0.145, 0.75, 0.019, 0.003, 0.504, 0.07]
0.7476131666666667
3.1202381666666668
Reward 4.722813108531307
Current State [[0.05  0.04  0.35  0.158 0.145 0.75  0.019 0.003 0.504 0.07 ]]
Logits tf.Tensor([[ 0.03702722 -0.20664667  0.46470195]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30143812 0.23625009 0.4623118 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.34, 0.24, 0.145, 0.75, 0.019, 0.003, 0.504, 0.07]
0.7476131666666667
3.1202381666666668
Reward 16.722813108531305
Current State [[0.04  0.15  0.34  0.24  0.145 0.75  0.019 0.003 0.504 0.07 ]]
Logits tf.Tensor([[ 0.04609102 -0.22211123  0.49386185]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3003388  0.22968501 0.46997616]], shape=(1, 3), dtype=float32)
Selected action 0
[0.02, 0.04, 0.34, 0.23, 0.145, 0.76, 0.019, 0.003, 0.616, 0.07]
0.7591216666666667
2.505357666666667
Reward 5.001007623418165
Current State [[0.02  0.04  0.34  0.23  0.145 0.76  0.019 0.003 0.616 0.07 ]]
Logits tf.Tensor([[ 0.04206375 -0.2053704   0.50100476]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29733595 0.2321604  0.47050363]], shape=(1, 3), dtype=float32)
Selected action 1
[0.03, 0.08, 0.32, 0.18, 0.145, 0.76, 0.019, 0.003, 0.616, 0.07]
0.7591216666666667
2.505357666666667
Reward 11.001007623418165
Current State [[0.03  0.08  0.32  0.18  0.145 0.76  0.019 0.003 0.616 0.07 ]]
Logits tf.Tensor([[ 0.03975653 -0.2250819   0.50835246]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29716983 0.2280273  0.47480285]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.32, 0.165, 0.145, 0.81, 0.027, 0.004, 0.542, 0.12]
0.8149143333333332
3.5886910000000003
Reward 16.669527643471547
Current State [[0.03  0.15  0.32  0.165 0.145 0.81  0.027 0.004 0.542 0.12 ]]
Logits tf.Tensor([[ 0.04203282 -0.2519886   0.5177496 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29811344 0.22217219 0.4797144 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.33, 0.141, 0.145, 0.86, 0.034, 0.002, 0.47300000000000003, 0.12]
0.8611173333333332
1.9636908333333336
Reward 17.644875087104342
Current State [[0.05  0.15  0.33  0.141 0.145 0.86  0.034 0.002 0.473 0.12 ]]
Logits tf.Tensor([[ 0.03838638 -0.25773156  0.5097745 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2988718  0.22227088 0.47885737]], shape=(1, 3), dtype=float32)
Selected action 1
[0.02, 0.08, 0.33, 0.174, 0.145, 0.86, 0.034, 0.002, 0.47300000000000003, 0.12]
0.8611173333333332
1.9636908333333336
Reward 11.644875087104342
Current State [[0.02  0.08  0.33  0.174 0.145 0.86  0.034 0.002 0.473 0.12 ]]
Logits tf.Tensor([[ 0.04088572 -0.22945453  0.48791945]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30059037 0.22938645 0.47002324]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.04, 0.39, 0.121, 0.145, 0.89, 0.028, 0.001, 0.5519999999999999, 0.11]
0.8852998333333333
1.4440483333333334
Reward 6.579733876459053
Current State [[0.05  0.04  0.39  0.121 0.145 0.89  0.028 0.001 0.552 0.11 ]]
Logits tf.Tensor([[ 0.03732318 -0.24124019  0.5144654 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2968828  0.22470175 0.4784155 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.02, 0.04, 0.34, 0.156, 0.145, 0.89, 0.028, 0.001, 0.5519999999999999, 0.11]
0.8852998333333333
1.4440483333333334
Reward 6.579733876459053
Current State [[0.02  0.04  0.34  0.156 0.145 0.89  0.028 0.001 0.552 0.11 ]]
Logits tf.Tensor([[ 0.04050683 -0.23183383  0.5073479 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29792562 0.2268986  0.4751758 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.15, 0.35, 0.181, 0.145, 0.79, 0.034, 0.002, 0.553, 0.08]
0.7894295
1.7648806666666668
Reward 17.688987639270263
Current State [[0.06  0.15  0.35  0.181 0.145 0.79  0.034 0.002 0.553 0.08 ]]
Logits tf.Tensor([[ 0.03549095 -0.24957179  0.5207956 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29615265 0.22269705 0.4811503 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.05, 0.08, 0.36, 0.124, 0.145, 0.81, 0.016, 0.003, 0.514, 0.07]
0.8136165
2.879761333333333
Reward 10.909626715296032
Current State [[0.05  0.08  0.36  0.124 0.145 0.81  0.016 0.003 0.514 0.07 ]]
Logits tf.Tensor([[ 0.04078482 -0.22947057  0.4916349 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30004528 0.22898991 0.47096482]], shape=(1, 3), dtype=float32)
Selected action 1
[0.04, 0.08, 0.35, 0.176, 0.145, 0.81, 0.016, 0.003, 0.514, 0.07]
0.8136165
2.879761333333333
Reward 10.909626715296032
Current State [[0.04  0.08  0.35  0.176 0.145 0.81  0.016 0.003 0.514 0.07 ]]
Logits tf.Tensor([[ 0.04379511 -0.21932772  0.49106205]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30005887 0.2306395  0.46930158]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.15, 0.36, 0.163, 0.145, 0.88, 0.041, 0.001, 0.488, 0.14]
0.8754083333333333
1.0607143333333335
Reward 19.88993259311311
Current State [[0.07  0.15  0.36  0.163 0.145 0.88  0.041 0.001 0.488 0.14 ]]
Logits tf.Tensor([[ 0.03634348 -0.26657537  0.5234267 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29706904 0.21943273 0.48349828]], shape=(1, 3), dtype=float32)
Selected action 0
[0.02, 0.04, 0.33, 0.132, 0.145, 0.75, 0.032, 0.004, 0.629, 0.15]
0.7498651666666666
4.1958335
Reward 4.468777641055633
Current State [[0.02  0.04  0.33  0.132 0.145 0.75  0.032 0.004 0.629 0.15 ]]
Logits tf.Tensor([[ 0.0334846 -0.2346261  0.497989 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29796946 0.22789392 0.47413656]], shape=(1, 3), dtype=float32)
Selected action 1
[0.04, 0.08, 0.38, 0.202, 0.145, 0.75, 0.032, 0.004, 0.629, 0.15]
0.7498651666666666
4.1958335
Reward 10.468777641055633
Current State [[0.04  0.08  0.38  0.202 0.145 0.75  0.032 0.004 0.629 0.15 ]]
Logits tf.Tensor([[ 0.03731627 -0.2408637   0.514057  ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29691425 0.22481175 0.47827408]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.39, 0.141, 0.145, 0.83, 0.036, 0.006, 0.654, 0.15]
0.8274386666666669
6.0553574999999995
Reward 16.30050699182369
Episode: 75 | Average Reward: 285 | Episode Reward: 242 | Loss: 453.15 | Steps: 19 | Worker: 0
Current State [[-0.0087449   0.00981388  0.00864008  0.00809609  0.00240996  0.00425254
  -0.00054631  0.00585941 -0.00277573 -0.00808665]]
Logits tf.Tensor([[ 0.01449416 -0.02668469  0.01893451]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.33736968 0.32375932 0.33887103]], shape=(1, 3), dtype=float32)
Selected action 2
[0.02, 0.15, 0.38, 0.174, 0.145, 0.83, 0.036, 0.006, 0.654, 0.15]
0.8274386666666669
6.0553574999999995
Reward 16.30050699182369
Current State [[0.02  0.15  0.38  0.174 0.145 0.83  0.036 0.006 0.654 0.15 ]]
Logits tf.Tensor([[ 0.03974907 -0.27110785  0.5622647 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29247612 0.21433197 0.493192  ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.39, 0.185, 0.145, 0.75, 0.033, 0.005, 0.783, 0.18]
0.7501438333333332
4.998214333333333
Reward 16.35361597788321
Current State [[0.03  0.15  0.39  0.185 0.145 0.75  0.033 0.005 0.783 0.18 ]]
Logits tf.Tensor([[ 0.03800998 -0.28209656  0.5836034 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.289712   0.21035166 0.49993628]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.38, 0.136, 0.145, 0.67, 0.027, 0.004, 0.8470000000000001, 0.18]
0.6705325
3.9303565
Reward 4.43587202789858
Current State [[0.04  0.04  0.38  0.136 0.145 0.67  0.027 0.004 0.847 0.18 ]]
Logits tf.Tensor([[ 0.02246203 -0.26320577  0.57522607]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.28656888 0.21536002 0.49807116]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.35, 0.162, 0.145, 0.79, 0.028, 0.002, 0.794, 0.15]
0.7880536666666665
1.6797613333333332
Reward 17.80006708243002
Current State [[0.03  0.15  0.35  0.162 0.145 0.79  0.028 0.002 0.794 0.15 ]]
Logits tf.Tensor([[ 0.03485714 -0.28523892  0.5903774 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2882736  0.20930949 0.5024169 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.04, 0.08, 0.34, 0.147, 0.145, 0.79, 0.028, 0.002, 0.794, 0.15]
0.7880536666666665
1.6797613333333332
Reward 11.800067082430019
Current State [[0.04  0.08  0.34  0.147 0.145 0.79  0.028 0.002 0.794 0.15 ]]
Logits tf.Tensor([[ 0.02987192 -0.27264076  0.57451606]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.28877082 0.21338983 0.49783936]], shape=(1, 3), dtype=float32)
Selected action 0
[0.03, 0.04, 0.38, 0.136, 0.145, 0.8, 0.056, 0.001, 0.472, 0.14]
0.8045518333333334
1.2845238333333335
Reward 6.655954152058505
Current State [[0.03  0.04  0.38  0.136 0.145 0.8   0.056 0.001 0.472 0.14 ]]
Logits tf.Tensor([[ 0.02715627 -0.22052757  0.472913  ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2991971  0.23355527 0.46724758]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.41, 0.144, 0.145, 0.86, 0.043, 0.002, 0.524, 0.17]
0.8560963333333335
1.7077381666666664
Reward 5.966996188836869
Current State [[0.04  0.04  0.41  0.144 0.145 0.86  0.043 0.002 0.524 0.17 ]]
Logits tf.Tensor([[ 0.03441217 -0.2373478   0.50412846]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2974794  0.22669037 0.4758303 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.37, 0.144, 0.145, 0.86, 0.043, 0.002, 0.524, 0.17]
0.8560963333333335
1.7077381666666664
Reward 5.966996188836869
Current State [[0.04  0.04  0.37  0.144 0.145 0.86  0.043 0.002 0.524 0.17 ]]
Logits tf.Tensor([[ 0.03150576 -0.23921627  0.4992919 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29768243 0.22708066 0.4752369 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.05, 0.08, 0.4, 0.148, 0.145, 0.84, 0.06, 0.002, 0.434, 0.16]
0.8351628333333333
2.1398813333333337
Reward 11.407806020030117
Current State [[0.05  0.08  0.4   0.148 0.145 0.84  0.06  0.002 0.434 0.16 ]]
Logits tf.Tensor([[ 0.02925621 -0.23640417  0.48546723]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29897308 0.2292225  0.4718044 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.4, 0.136, 0.145, 0.83, 0.041, 0.003, 0.5309999999999999, 0.15]
0.8303568333333333
3.120238333333333
Reward 16.837450713519964
Current State [[0.04  0.15  0.4   0.136 0.145 0.83  0.041 0.003 0.531 0.15 ]]
Logits tf.Tensor([[ 0.03757658 -0.26467675  0.52849567]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2964748  0.2191396  0.48438564]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.04, 0.34, 0.134, 0.145, 0.83, 0.041, 0.003, 0.5309999999999999, 0.15]
0.8303568333333333
3.120238333333333
Reward 4.837450713519963
Current State [[0.05  0.04  0.34  0.134 0.145 0.83  0.041 0.003 0.531 0.15 ]]
Logits tf.Tensor([[ 0.02716956 -0.23765244  0.49066737]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29788795 0.22858208 0.47352996]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.15, 0.4, 0.156, 0.145, 0.84, 0.038, 0.002, 0.53, 0.12]
0.8406948333333334
1.9726191666666668
Reward 17.583387053595782
Current State [[0.06  0.15  0.4   0.156 0.145 0.84  0.038 0.002 0.53  0.12 ]]
Logits tf.Tensor([[ 0.03633003 -0.26169276  0.53135824]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29561058 0.21942712 0.48496228]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.39, 0.139, 0.145, 0.81, 0.039, 0.002, 0.576, 0.16]
0.8106956666666666
1.5011903333333332
Reward 18.173543014522473
Current State [[0.05  0.15  0.39  0.139 0.145 0.81  0.039 0.002 0.576 0.16 ]]
Logits tf.Tensor([[ 0.03454979 -0.27198637  0.5355022 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29530895 0.217345   0.48734608]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.38, 0.158, 0.145, 0.81, 0.039, 0.002, 0.576, 0.16]
0.8106956666666666
1.5011903333333332
Reward 6.173543014522473
Current State [[0.04  0.04  0.38  0.158 0.145 0.81  0.039 0.002 0.576 0.16 ]]
Logits tf.Tensor([[ 0.03161529 -0.23582086  0.5042571 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29677415 0.22713289 0.476093  ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.02, 0.04, 0.35, 0.162, 0.145, 0.72, 0.025, 0.004, 0.5860000000000001, 0.16]
0.7206596666666666
4.166072
Reward 4.445500287235055
Current State [[0.02  0.04  0.35  0.162 0.145 0.72  0.025 0.004 0.586 0.16 ]]
Logits tf.Tensor([[ 0.03611262 -0.22188248  0.48068926]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30008143 0.23184262 0.46807593]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.41, 0.152, 0.145, 0.84, 0.033, 0.001, 0.45899999999999996, 0.12]
0.841457
1.4160708333333334
Reward 6.472782066228406
Current State [[0.04  0.04  0.41  0.152 0.145 0.84  0.033 0.001 0.459 0.12 ]]
Logits tf.Tensor([[ 0.03839967 -0.21628088  0.47990474]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30028135 0.23276731 0.46695128]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.15, 0.39, 0.162, 0.145, 0.84, 0.033, 0.001, 0.45899999999999996, 0.12]
0.841457
1.4160708333333334
Reward 18.472782066228405
Current State [[0.06  0.15  0.39  0.162 0.145 0.84  0.033 0.001 0.459 0.12 ]]
Logits tf.Tensor([[ 0.03951967 -0.25030047  0.50900716]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29872394 0.22356443 0.47771165]], shape=(1, 3), dtype=float32)
Selected action 1
[0.03, 0.08, 0.39, 0.136, 0.145, 0.88, 0.047, 0.001, 0.54, 0.09]
0.8754124999999999
1.0333335000000001
Reward 14.036363609426783
Current State [[0.03  0.08  0.39  0.136 0.145 0.88  0.047 0.001 0.54  0.09 ]]
Logits tf.Tensor([[ 0.03253085 -0.24118064  0.5240348 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29452267 0.22399965 0.4814777 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.04, 0.08, 0.39, 0.176, 0.145, 0.88, 0.047, 0.001, 0.54, 0.09]
0.8754124999999999
1.0333335000000001
Reward 14.036363609426783
Current State [[0.04  0.08  0.39  0.176 0.145 0.88  0.047 0.001 0.54  0.09 ]]
Logits tf.Tensor([[ 0.0324588 -0.2373278  0.5248234]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29414162 0.22458962 0.48126882]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.37, 0.159, 0.145, 0.84, 0.035, 0.002, 0.523, 0.13]
0.8360196666666667
1.7553571666666665
Reward 5.836679967478431
Episode: 76 | Average Reward: 284 | Episode Reward: 223 | Loss: 382.0 | Steps: 19 | Worker: 0
Current State [[ 0.00647905  0.00394022 -0.00130517 -0.00340582 -0.00855122 -0.00445239
   0.00335894  0.00164559  0.00393958  0.00612489]]
Logits tf.Tensor([[ 0.01209975 -0.02725773  0.02082706]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3366808  0.32368726 0.33963197]], shape=(1, 3), dtype=float32)
Selected action 1
[0.05, 0.08, 0.38, 0.132, 0.145, 0.84, 0.037, 0.002, 0.517, 0.2]
0.8430206666666666
1.9178564999999999
Reward 11.650106042652347
Current State [[0.05  0.08  0.38  0.132 0.145 0.84  0.037 0.002 0.517 0.2  ]]
Logits tf.Tensor([[ 0.0349213  -0.25316375  0.50329167]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29876727 0.22398517 0.4772475 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.39, 0.167, 0.145, 0.84, 0.037, 0.002, 0.517, 0.2]
0.8430206666666666
1.9178564999999999
Reward 5.6501060426523475
Current State [[0.04  0.04  0.39  0.167 0.145 0.84  0.037 0.002 0.517 0.2  ]]
Logits tf.Tensor([[ 0.03665496 -0.2344773   0.4932436 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2992941  0.22821644 0.47248945]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.37, 0.145, 0.145, 0.75, 0.031, 0.003, 0.563, 0.11]
0.7512386666666665
3.2386905
Reward 16.690224033773724
Current State [[0.03  0.15  0.37  0.145 0.145 0.75  0.031 0.003 0.563 0.11 ]]
Logits tf.Tensor([[ 0.03787969 -0.24652685  0.51260644]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2976159  0.22394426 0.47843984]], shape=(1, 3), dtype=float32)
Selected action 1
[0.05, 0.08, 0.39, 0.133, 0.145, 0.8, 0.035, 0.001, 0.532, 0.08]
0.8020168333333333
1.0904758333333333
Reward 13.311221002362455
Current State [[0.05  0.08  0.39  0.133 0.145 0.8   0.035 0.001 0.532 0.08 ]]
Logits tf.Tensor([[ 0.03174716 -0.23194744  0.502842  ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29673988 0.22795798 0.47530216]], shape=(1, 3), dtype=float32)
Selected action 2
[0.02, 0.15, 0.37, 0.165, 0.145, 0.8, 0.035, 0.001, 0.532, 0.08]
0.8020168333333333
1.0904758333333333
Reward 19.311221002362455
Current State [[0.02  0.15  0.37  0.165 0.145 0.8   0.035 0.001 0.532 0.08 ]]
Logits tf.Tensor([[ 0.03942777 -0.23941343  0.51965857]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29646254 0.22432135 0.4792161 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.39, 0.175, 0.145, 0.82, 0.036, 0.002, 0.55, 0.15]
0.8228401666666666
2.3339285000000003
Reward 17.228515005054614
Current State [[0.05  0.15  0.39  0.175 0.145 0.82  0.036 0.002 0.55  0.15 ]]
Logits tf.Tensor([[ 0.03800471 -0.26143226  0.5296719 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2961844  0.21954235 0.48427328]], shape=(1, 3), dtype=float32)
Selected action 0
[0.02, 0.04, 0.35, 0.106, 0.145, 0.77, 0.031, 0.004, 0.5780000000000001, 0.2]
0.7675161666666667
3.5482145
Reward 4.624141552667068
Current State [[0.02  0.04  0.35  0.106 0.145 0.77  0.031 0.004 0.578 0.2  ]]
Logits tf.Tensor([[ 0.0338164  -0.24021688  0.48839274]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29977706 0.22792253 0.47230047]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.39, 0.148, 0.145, 0.77, 0.031, 0.004, 0.5780000000000001, 0.2]
0.7675161666666667
3.5482145
Reward 16.62414155266707
Current State [[0.04  0.15  0.39  0.148 0.145 0.77  0.031 0.004 0.578 0.2  ]]
Logits tf.Tensor([[ 0.03935688 -0.26931548  0.52261305]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2979945  0.21885353 0.48315197]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.36, 0.176, 0.145, 0.77, 0.039, 0.003, 0.618, 0.17]
0.7704030000000001
3.245238333333333
Reward 4.713385305395358
Current State [[0.04  0.04  0.36  0.176 0.145 0.77  0.039 0.003 0.618 0.17 ]]
Logits tf.Tensor([[ 0.02910346 -0.23595011  0.50390023]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29630926 0.22731805 0.47637266]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.34, 0.119, 0.145, 0.77, 0.022, 0.003, 0.576, 0.08]
0.7690298333333333
3.203571666666667
Reward 16.724748989650777
Current State [[0.03  0.15  0.34  0.119 0.145 0.77  0.022 0.003 0.576 0.08 ]]
Logits tf.Tensor([[ 0.03831891 -0.24732427  0.5184322 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2969308 0.2231526 0.4799166]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.35, 0.163, 0.145, 0.77, 0.022, 0.003, 0.576, 0.08]
0.7690298333333333
3.203571666666667
Reward 16.724748989650777
Current State [[0.05  0.15  0.35  0.163 0.145 0.77  0.022 0.003 0.576 0.08 ]]
Logits tf.Tensor([[ 0.0374906  -0.24698707  0.5207302 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29640824 0.22301969 0.4805721 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.35, 0.158, 0.145, 0.85, 0.031, 0.001, 0.617, 0.09]
0.8534391666666667
1.4071428333333338
Reward 18.54232426562172
Current State [[0.05  0.15  0.35  0.158 0.145 0.85  0.031 0.001 0.617 0.09 ]]
Logits tf.Tensor([[ 0.03444214 -0.26493728  0.55520624]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29200563 0.21645738 0.491537  ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.04, 0.08, 0.35, 0.119, 0.145, 0.89, 0.045, 0.002, 0.465, 0.18]
0.891467
2.3130948333333334
Reward 11.384293332285148
Current State [[0.04  0.08  0.35  0.119 0.145 0.89  0.045 0.002 0.465 0.18 ]]
Logits tf.Tensor([[ 0.03248946 -0.25217247  0.4963393 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2991815  0.22506483 0.4757537 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.37, 0.182, 0.145, 0.89, 0.045, 0.002, 0.465, 0.18]
0.891467
2.3130948333333334
Reward 17.384293332285147
Current State [[0.04  0.15  0.37  0.182 0.145 0.89  0.045 0.002 0.465 0.18 ]]
Logits tf.Tensor([[ 0.03957107 -0.26134038  0.5215116 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29767603 0.22032294 0.4820011 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.37, 0.136, 0.145, 0.73, 0.016, 0.005, 0.77, 0.07]
0.7292566666666666
5.342857333333333
Reward 16.299902374119448
Current State [[0.04  0.15  0.37  0.136 0.145 0.73  0.016 0.005 0.77  0.07 ]]
Logits tf.Tensor([[ 0.03567859 -0.2533215   0.57283264]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.28900543 0.21646862 0.49452594]], shape=(1, 3), dtype=float32)
Selected action 1
[0.04, 0.08, 0.35, 0.142, 0.145, 0.72, 0.016, 0.005, 0.921, 0.13]
0.7219143333333334
4.830356666666668
Reward 10.351117688184988
Current State [[0.04  0.08  0.35  0.142 0.145 0.72  0.016 0.005 0.921 0.13 ]]
Logits tf.Tensor([[ 0.02259996 -0.27315322  0.61999136]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.28079295 0.20890182 0.5103052 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.34, 0.142, 0.145, 0.72, 0.016, 0.005, 0.921, 0.13]
0.7219143333333334
4.830356666666668
Reward 16.35111768818499
Current State [[0.03  0.15  0.34  0.142 0.145 0.72  0.016 0.005 0.921 0.13 ]]
Logits tf.Tensor([[ 0.02729826 -0.28800473  0.6318876 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.28089347 0.20493084 0.51417565]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.35, 0.152, 0.145, 0.85, 0.032, 0.003, 0.6719999999999999, 0.1]
0.8541503333333332
3.1619048333333333
Reward 16.855036517707582
Current State [[0.03  0.15  0.35  0.152 0.145 0.85  0.032 0.003 0.672 0.1  ]]
Logits tf.Tensor([[ 0.03647704 -0.26987034  0.5701658 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29058433 0.21390809 0.49550757]], shape=(1, 3), dtype=float32)
Selected action 2
[0.02, 0.15, 0.34, 0.122, 0.145, 0.85, 0.032, 0.001, 0.53, 0.04]
0.8479638333333333
0.7148804999999999
Reward 22.592262903978224
Current State [[0.02  0.15  0.34  0.122 0.145 0.85  0.032 0.001 0.53  0.04 ]]
Logits tf.Tensor([[ 0.03812958 -0.244954    0.527135  ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29549512 0.22264284 0.48186204]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.34, 0.15, 0.145, 0.81, 0.026, 0.004, 0.5519999999999999, 0.12]
0.8062741666666666
3.6660719999999998
Reward 16.63934723002804
Episode: 77 | Average Reward: 284 | Episode Reward: 289 | Loss: 737.624 | Steps: 19 | Worker: 0
Current State [[ 0.00972357 -0.00713023 -0.00242961  0.00818056  0.00184573 -0.00539176
   0.0062252  -0.00727537 -0.00069909  0.00758858]]
Logits tf.Tensor([[ 0.0080728  -0.02622947  0.0220536 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3355301  0.32421583 0.34025404]], shape=(1, 3), dtype=float32)
Selected action 2
[0.01, 0.15, 0.32, 0.123, 0.145, 0.81, 0.026, 0.004, 0.5519999999999999, 0.12]
0.8062741666666666
3.6660719999999998
Reward 16.63934723002804
Current State [[0.01  0.15  0.32  0.123 0.145 0.81  0.026 0.004 0.552 0.12 ]]
Logits tf.Tensor([[ 0.0384292 -0.2536218  0.5241751]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2965496  0.22144261 0.48200783]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.35, 0.161, 0.145, 0.82, 0.019, 0.002, 0.621, 0.06]
0.8249854999999999
1.926785666666667
Reward 17.593238534072672
Current State [[0.05  0.15  0.35  0.161 0.145 0.82  0.019 0.002 0.621 0.06 ]]
Logits tf.Tensor([[ 0.03637817 -0.2546134   0.550123  ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29247794 0.21863371 0.48888832]], shape=(1, 3), dtype=float32)
Selected action 1
[0.02, 0.08, 0.32, 0.136, 0.145, 0.86, 0.029, 0.001, 0.48200000000000004, 0.06]
0.8600941666666667
1.139881
Reward 13.431083391809073
Current State [[0.02  0.08  0.32  0.136 0.145 0.86  0.029 0.001 0.482 0.06 ]]
Logits tf.Tensor([[ 0.03540499 -0.22520174  0.49291825]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.298443   0.22997537 0.4715816 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.04, 0.37, 0.164, 0.145, 0.86, 0.029, 0.001, 0.48200000000000004, 0.06]
0.8600941666666667
1.139881
Reward 7.431083391809073
Current State [[0.05  0.04  0.37  0.164 0.145 0.86  0.029 0.001 0.482 0.06 ]]
Logits tf.Tensor([[ 0.03302733 -0.21556312  0.48884353]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2978531  0.23229545 0.46985146]], shape=(1, 3), dtype=float32)
Selected action 1
[0.03, 0.08, 0.34, 0.148, 0.145, 0.83, 0.037, 0.002, 0.491, 0.09]
0.8280403333333334
2.3500008333333335
Reward 11.22758623823671
Current State [[0.03  0.08  0.34  0.148 0.145 0.83  0.037 0.002 0.491 0.09 ]]
Logits tf.Tensor([[ 0.03164691 -0.22687119  0.49320278]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2977311  0.22990648 0.47236243]], shape=(1, 3), dtype=float32)
Selected action 1
[0.02, 0.08, 0.32, 0.119, 0.145, 0.79, 0.025, 0.002, 0.575, 0.09]
0.7940066666666666
1.8184530000000003
Reward 11.635461334652424
Current State [[0.02  0.08  0.32  0.119 0.145 0.79  0.025 0.002 0.575 0.09 ]]
Logits tf.Tensor([[ 0.03361335 -0.23272303  0.50586504]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29675508 0.2273682  0.47587672]], shape=(1, 3), dtype=float32)
Selected action 0
[0.02, 0.04, 0.31, 0.189, 0.145, 0.79, 0.025, 0.002, 0.575, 0.09]
0.7940066666666666
1.8184530000000003
Reward 5.635461334652424
Current State [[0.02  0.04  0.31  0.189 0.145 0.79  0.025 0.002 0.575 0.09 ]]
Logits tf.Tensor([[ 0.03431518 -0.21247467  0.49348533]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29725945 0.23225024 0.47049037]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.32, 0.148, 0.145, 0.87, 0.021, 0.005, 0.5740000000000001, 0.07]
0.8696581666666667
4.918452666666666
Reward 4.461046902182839
Current State [[0.04  0.04  0.32  0.148 0.145 0.87  0.021 0.005 0.574 0.07 ]]
Logits tf.Tensor([[ 0.03437379 -0.23033118  0.5098545 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29618925 0.2273052  0.47650552]], shape=(1, 3), dtype=float32)
Selected action 2
[0.02, 0.15, 0.31, 0.113, 0.145, 0.78, 0.02, 0.002, 0.5820000000000001, 0.11]
0.7816131666666667
2.2113094999999996
Reward 17.23275735984815
Current State [[0.02  0.15  0.31  0.113 0.145 0.78  0.02  0.002 0.582 0.11 ]]
Logits tf.Tensor([[ 0.03626177 -0.2542313   0.52374506]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29619905 0.22152571 0.48227525]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.36, 0.161, 0.145, 0.78, 0.02, 0.002, 0.5820000000000001, 0.11]
0.7816131666666667
2.2113094999999996
Reward 5.232757359848151
Current State [[0.04  0.04  0.36  0.161 0.145 0.78  0.02  0.002 0.582 0.11 ]]
Logits tf.Tensor([[ 0.03363252 -0.22267148  0.49969137]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29694673 0.22980905 0.47324422]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.34, 0.169, 0.145, 0.84, 0.025, 0.003, 0.502, 0.04]
0.8413568333333334
2.7375003333333328
Reward 17.020600375909112
Current State [[0.04  0.15  0.34  0.169 0.145 0.84  0.025 0.003 0.502 0.04 ]]
Logits tf.Tensor([[ 0.03787224 -0.23724729  0.519495  ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29601735 0.22481966 0.479163  ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.03, 0.04, 0.3, 0.146, 0.145, 0.77, 0.027, 0.004, 0.506, 0.09]
0.7681
4.433334
Reward 4.446604529235927
Current State [[0.03  0.04  0.3   0.146 0.145 0.77  0.027 0.004 0.506 0.09 ]]
Logits tf.Tensor([[ 0.03100854 -0.21099538  0.46547264]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3003735  0.23580915 0.46381736]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.33, 0.186, 0.145, 0.77, 0.027, 0.004, 0.506, 0.09]
0.7681
4.433334
Reward 4.446604529235927
Current State [[0.04  0.04  0.33  0.186 0.145 0.77  0.027 0.004 0.506 0.09 ]]
Logits tf.Tensor([[ 0.03254135 -0.20608774  0.47041768]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29965955 0.23604392 0.4642965 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.07, 0.08, 0.34, 0.157, 0.145, 0.92, 0.031, 0.001, 0.488, 0.02]
0.9184441666666667
1.4154763333333333
Reward 12.786947687204403
Current State [[0.07  0.08  0.34  0.157 0.145 0.92  0.031 0.001 0.488 0.02 ]]
Logits tf.Tensor([[ 0.03047565 -0.23584259  0.5106406 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29563618 0.22651501 0.47784886]], shape=(1, 3), dtype=float32)
Selected action 1
[0.04, 0.08, 0.35, 0.14, 0.145, 0.82, 0.029, 0.004, 0.508, 0.03]
0.8216623333333332
4.049999166666667
Reward 10.56808658550366
Current State [[0.04  0.08  0.35  0.14  0.145 0.82  0.029 0.004 0.508 0.03 ]]
Logits tf.Tensor([[ 0.03338182 -0.22089353  0.49682498]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2971754  0.23045309 0.47237155]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.04, 0.38, 0.147, 0.145, 0.82, 0.029, 0.004, 0.508, 0.03]
0.8216623333333332
4.049999166666667
Reward 4.568086585503661
Current State [[0.05  0.04  0.38  0.147 0.145 0.82  0.029 0.004 0.508 0.03 ]]
Logits tf.Tensor([[ 0.0314519  -0.21229714  0.49111974]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29697984 0.23273842 0.47028178]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.04, 0.36, 0.164, 0.145, 0.77, 0.029, 0.002, 0.595, 0.13]
0.7710436666666667
1.8589285000000002
Reward 5.527076887443232
Current State [[0.05  0.04  0.36  0.164 0.145 0.77  0.029 0.002 0.595 0.13 ]]
Logits tf.Tensor([[ 0.0281922  -0.22974011  0.5014712 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29604217 0.22873628 0.47522148]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.04, 0.35, 0.129, 0.145, 0.76, 0.032, 0.004, 0.624, 0.15]
0.7627135
3.7029763333333334
Reward 4.580942994216594
Current State [[0.05  0.04  0.35  0.129 0.145 0.76  0.032 0.004 0.624 0.15 ]]
Logits tf.Tensor([[ 0.02514243 -0.24155241  0.50547355]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2956379  0.22643107 0.47793108]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.38, 0.127, 0.145, 0.7, 0.019, 0.004, 0.6950000000000001, 0.07]
0.7047519999999998
3.969642666666666
Reward 16.463973054116995
Current State [[0.05  0.15  0.38  0.127 0.145 0.7   0.019 0.004 0.695 0.07 ]]
Logits tf.Tensor([[ 0.03114516 -0.24599922  0.54657745]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29134923 0.2208267  0.4878241 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.15, 0.41, 0.179, 0.145, 0.7, 0.019, 0.004, 0.6950000000000001, 0.07]
0.7047519999999998
3.969642666666666
Reward 16.463973054116995
Episode: 78 | Average Reward: 284 | Episode Reward: 207 | Loss: 301.104 | Steps: 19 | Worker: 0
Current State [[ 0.00483347 -0.00225898  0.00093346  0.00391849 -0.00244101  0.00371419
  -0.0041877  -0.00980534  0.00303261  0.00538408]]
Logits tf.Tensor([[ 0.01092789 -0.0271102   0.02565374]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.33585095 0.32331577 0.34083325]], shape=(1, 3), dtype=float32)
Selected action 1
[0.02, 0.08, 0.39, 0.163, 0.145, 0.77, 0.039, 0.004, 0.7030000000000001, 0.18]
0.7672491666666669
3.9630955
Reward 10.52970868624529
Current State [[0.02  0.08  0.39  0.163 0.145 0.77  0.039 0.004 0.703 0.18 ]]
Logits tf.Tensor([[ 0.03155302 -0.25932458  0.54708606]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29221496 0.218462   0.489323  ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.04, 0.08, 0.39, 0.129, 0.145, 0.8, 0.035, 0.002, 0.675, 0.12]
0.8019196666666667
2.0583331666666664
Reward 11.404488662296508
Current State [[0.04  0.08  0.39  0.129 0.145 0.8   0.035 0.002 0.675 0.12 ]]
Logits tf.Tensor([[ 0.02781799 -0.25560138  0.54684997]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29123917 0.21936245 0.48939836]], shape=(1, 3), dtype=float32)
Selected action 0
[0.03, 0.04, 0.36, 0.164, 0.145, 0.8, 0.035, 0.002, 0.675, 0.12]
0.8019196666666667
2.0583331666666664
Reward 5.404488662296507
Current State [[0.03  0.04  0.36  0.164 0.145 0.8   0.035 0.002 0.675 0.12 ]]
Logits tf.Tensor([[ 0.02813436 -0.23860377  0.53482306]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29191455 0.22356968 0.48451573]], shape=(1, 3), dtype=float32)
Selected action 2
[0.02, 0.15, 0.3, 0.133, 0.145, 0.68, 0.017, 0.004, 0.859, 0.08]
0.6837206666666665
4.3910721666666666
Reward 16.37602326772891
Current State [[0.02  0.15  0.3   0.133 0.145 0.68  0.017 0.004 0.859 0.08 ]]
Logits tf.Tensor([[ 0.02151584 -0.26433787  0.602126  ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.28260553 0.21234204 0.5050524 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.35, 0.123, 0.145, 0.83, 0.05, 0.002, 0.488, 0.08]
0.8288814999999999
1.7750005
Reward 17.78894586032036
Current State [[0.03  0.15  0.35  0.123 0.145 0.83  0.05  0.002 0.488 0.08 ]]
Logits tf.Tensor([[ 0.02834973 -0.2490441   0.51620245]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2952839  0.22375315 0.48096287]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.04, 0.39, 0.171, 0.145, 0.83, 0.05, 0.002, 0.488, 0.08]
0.8288814999999999
1.7750005
Reward 5.788945860320361
Current State [[0.05  0.04  0.39  0.171 0.145 0.83  0.05  0.002 0.488 0.08 ]]
Logits tf.Tensor([[ 0.025325   -0.2169931   0.48996758]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29618645 0.23244902 0.4713645 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.04, 0.4, 0.168, 0.145, 0.82, 0.046, 0.002, 0.515, 0.2]
0.8182949999999999
2.280952166666667
Reward 5.2575926799534125
Current State [[0.05  0.04  0.4   0.168 0.145 0.82  0.046 0.002 0.515 0.2  ]]
Logits tf.Tensor([[ 0.02918217 -0.23572132  0.49330324]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29780555 0.22850026 0.47369415]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.38, 0.118, 0.145, 0.83, 0.044, 0.001, 0.496, 0.17]
0.8258455
1.0333336666666666
Reward 19.718073524494734
Current State [[0.04  0.15  0.38  0.118 0.145 0.83  0.044 0.001 0.496 0.17 ]]
Logits tf.Tensor([[ 0.03270171 -0.26536188  0.5195629 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29678392 0.2202891  0.482927  ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.4, 0.138, 0.145, 0.83, 0.044, 0.001, 0.496, 0.17]
0.8258455
1.0333336666666666
Reward 19.718073524494734
Current State [[0.04  0.15  0.4   0.138 0.145 0.83  0.044 0.001 0.496 0.17 ]]
Logits tf.Tensor([[ 0.03457611 -0.2620155   0.5214461 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29668638 0.2205411  0.48277253]], shape=(1, 3), dtype=float32)
Selected action 0
[0.02, 0.04, 0.39, 0.147, 0.145, 0.81, 0.053, 0.002, 0.46900000000000003, 0.2]
0.8068723333333332
2.0470238333333333
Reward 5.426566094257549
Current State [[0.02  0.04  0.39  0.147 0.145 0.81  0.053 0.002 0.469 0.2  ]]
Logits tf.Tensor([[ 0.0301335  -0.22496656  0.47758   ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2994773  0.23204666 0.4684761 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.06, 0.04, 0.35, 0.134, 0.145, 0.8, 0.042, 0.002, 0.521, 0.19]
0.8044265
2.2767853333333323
Reward 5.232078610105989
Current State [[0.06  0.04  0.35  0.134 0.145 0.8   0.042 0.002 0.521 0.19 ]]
Logits tf.Tensor([[ 0.02434731 -0.2406097   0.48494804]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29830578 0.22887181 0.47282234]], shape=(1, 3), dtype=float32)
Selected action 1
[0.03, 0.08, 0.39, 0.181, 0.145, 0.8, 0.042, 0.002, 0.521, 0.19]
0.8044265
2.2767853333333323
Reward 11.23207861010599
Current State [[0.03  0.08  0.39  0.181 0.145 0.8   0.042 0.002 0.521 0.19 ]]
Logits tf.Tensor([[ 0.0341264  -0.23772806  0.50011015]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29801407 0.22707634 0.47490957]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.15, 0.4, 0.171, 0.145, 0.86, 0.045, 0.002, 0.465, 0.23]
0.8560665000000001
1.9291668333333332
Reward 17.671115422593804
Current State [[0.06  0.15  0.4   0.171 0.145 0.86  0.045 0.002 0.465 0.23 ]]
Logits tf.Tensor([[ 0.03667548 -0.27348724  0.51948726]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29815567 0.21864581 0.4831985 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.02, 0.15, 0.37, 0.124, 0.145, 0.77, 0.032, 0.002, 0.517, 0.15]
0.7729513333333334
2.275595833333333
Reward 17.168492460114862
Current State [[0.02  0.15  0.37  0.124 0.145 0.77  0.032 0.002 0.517 0.15 ]]
Logits tf.Tensor([[ 0.03757707 -0.2520617   0.5078311 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29860243 0.22351405 0.47788355]], shape=(1, 3), dtype=float32)
Selected action 1
[0.03, 0.08, 0.35, 0.167, 0.145, 0.77, 0.032, 0.002, 0.517, 0.15]
0.7729513333333334
2.275595833333333
Reward 11.168492460114862
Current State [[0.03  0.08  0.35  0.167 0.145 0.77  0.032 0.002 0.517 0.15 ]]
Logits tf.Tensor([[ 0.03380068 -0.22863746  0.48745257]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2991125  0.23006955 0.470818  ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.04, 0.41, 0.163, 0.145, 0.9, 0.043, 0.001, 0.519, 0.04]
0.8992485
1.0315476666666668
Reward 8.203490607100068
Current State [[0.05  0.04  0.41  0.163 0.145 0.9   0.043 0.001 0.519 0.04 ]]
Logits tf.Tensor([[ 0.02905663 -0.22431064  0.5179337 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29354206 0.22784227 0.47861567]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.04, 0.4, 0.136, 0.145, 0.77, 0.042, 0.004, 0.5349999999999999, 0.16]
0.7663504999999999
4.1208335
Reward 4.4983815470017845
Current State [[0.05  0.04  0.4   0.136 0.145 0.77  0.042 0.004 0.535 0.16 ]]
Logits tf.Tensor([[ 0.02675566 -0.23244174  0.48734522]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29791352 0.22989114 0.47219536]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.39, 0.151, 0.145, 0.77, 0.042, 0.004, 0.5349999999999999, 0.16]
0.7663504999999999
4.1208335
Reward 16.498381547001784
Current State [[0.04  0.15  0.39  0.151 0.145 0.77  0.042 0.004 0.535 0.16 ]]
Logits tf.Tensor([[ 0.03304949 -0.2585824   0.5160316 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29691702 0.22180991 0.48127308]], shape=(1, 3), dtype=float32)
Selected action 1
[0.05, 0.08, 0.39, 0.177, 0.145, 0.81, 0.035, 0.002, 0.522, 0.14]
0.811634
2.345833
Reward 11.197853385780821
Current State [[0.05  0.08  0.39  0.177 0.145 0.81  0.035 0.002 0.522 0.14 ]]
Logits tf.Tensor([[ 0.03343632 -0.23520987  0.5029684 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2972953  0.22725658 0.4754482 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.03, 0.04, 0.34, 0.13, 0.145, 0.87, 0.035, 0.003, 0.479, 0.07]
0.8726271666666668
3.2059526666666667
Reward 4.86403806733496
Episode: 79 | Average Reward: 283 | Episode Reward: 225 | Loss: 401.751 | Steps: 19 | Worker: 0
Current State [[ 0.00825963  0.00497219 -0.0070443   0.00591027  0.00459054  0.00277542
   0.00816685 -0.00755189 -0.00280636 -0.00967297]]
Logits tf.Tensor([[ 0.00554527 -0.02610215  0.02471203]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.33464965 0.32422468 0.34112567]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.41, 0.133, 0.145, 0.89, 0.056, 0.005, 0.477, 0.1]
0.8927146666666667
4.694643166666666
Reward 4.5155480904198235
Current State [[0.04  0.04  0.41  0.133 0.145 0.89  0.056 0.005 0.477 0.1  ]]
Logits tf.Tensor([[ 0.02817655 -0.23061754  0.4989142 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29645818 0.22886038 0.4746814 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.15, 0.4, 0.148, 0.145, 0.89, 0.056, 0.005, 0.477, 0.1]
0.8927146666666667
4.694643166666666
Reward 16.515548090419824
Current State [[0.06  0.15  0.4   0.148 0.145 0.89  0.056 0.005 0.477 0.1  ]]
Logits tf.Tensor([[ 0.03039659 -0.26153922  0.5310896 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29440504 0.21986656 0.48572838]], shape=(1, 3), dtype=float32)
Selected action 0
[0.02, 0.04, 0.38, 0.154, 0.145, 0.75, 0.038, 0.003, 0.581, 0.12]
0.7515411666666666
3.028571333333333
Reward 4.7595020484352215
Current State [[0.02  0.04  0.38  0.154 0.145 0.75  0.038 0.003 0.581 0.12 ]]
Logits tf.Tensor([[ 0.03043755 -0.22118713  0.49493206]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29684636 0.23080888 0.4723448 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.15, 0.4, 0.133, 0.145, 0.84, 0.043, 0.002, 0.47800000000000004, 0.15]
0.8377593333333333
2.2857145
Reward 17.29425225655916
Current State [[0.06  0.15  0.4   0.133 0.145 0.84  0.043 0.002 0.478 0.15 ]]
Logits tf.Tensor([[ 0.03406288 -0.26294842  0.5173584 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29722586 0.22084941 0.4819247 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.02, 0.15, 0.35, 0.136, 0.145, 0.84, 0.043, 0.002, 0.47800000000000004, 0.15]
0.8377593333333333
2.2857145
Reward 17.29425225655916
Current State [[0.02  0.15  0.35  0.136 0.145 0.84  0.043 0.002 0.478 0.15 ]]
Logits tf.Tensor([[ 0.03660398 -0.2546898   0.5132318 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29780254 0.22254667 0.47965086]], shape=(1, 3), dtype=float32)
Selected action 1
[0.06, 0.08, 0.39, 0.166, 0.145, 0.72, 0.025, 0.004, 0.621, 0.16]
0.720176
4.392856833333335
Reward 10.409019851297444
Current State [[0.06  0.08  0.39  0.166 0.145 0.72  0.025 0.004 0.621 0.16 ]]
Logits tf.Tensor([[ 0.0315446  -0.24505058  0.5080013 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29684868 0.22511858 0.4780327 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.03, 0.04, 0.4, 0.139, 0.145, 0.83, 0.04, 0.001, 0.5589999999999999, 0.22]
0.8261774999999999
1.4767861666666664
Reward 6.279333167492812
Current State [[0.03  0.04  0.4   0.139 0.145 0.83  0.04  0.001 0.559 0.22 ]]
Logits tf.Tensor([[ 0.03366311 -0.24511059  0.50623494]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29754594 0.22515634 0.47729775]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.37, 0.15, 0.145, 0.83, 0.04, 0.001, 0.5589999999999999, 0.22]
0.8261774999999999
1.4767861666666664
Reward 18.279333167492812
Current State [[0.03  0.15  0.37  0.15  0.145 0.83  0.04  0.001 0.559 0.22 ]]
Logits tf.Tensor([[ 0.03666142 -0.27548206  0.5344543 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29612407 0.21672626 0.48714966]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.37, 0.151, 0.145, 0.87, 0.043, 0.002, 0.562, 0.16]
0.86535
1.7916666666666667
Reward 17.871405381877054
Current State [[0.05  0.15  0.37  0.151 0.145 0.87  0.043 0.002 0.562 0.16 ]]
Logits tf.Tensor([[ 0.03298406 -0.27505928  0.5473366 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29347557 0.21567035 0.49085408]], shape=(1, 3), dtype=float32)
Selected action 2
[0.02, 0.15, 0.36, 0.123, 0.145, 0.86, 0.035, 0.003, 0.519, 0.09]
0.8622341666666669
3.284523833333333
Reward 16.82171971957918
Current State [[0.02  0.15  0.36  0.123 0.145 0.86  0.035 0.003 0.519 0.09 ]]
Logits tf.Tensor([[ 0.03803176 -0.25367376  0.53047997]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2955689  0.22078659 0.48364457]], shape=(1, 3), dtype=float32)
Selected action 1
[0.04, 0.08, 0.35, 0.146, 0.145, 0.86, 0.035, 0.003, 0.519, 0.09]
0.8622341666666669
3.284523833333333
Reward 10.821719719579178
Current State [[0.04  0.08  0.35  0.146 0.145 0.86  0.035 0.003 0.519 0.09 ]]
Logits tf.Tensor([[ 0.03294174 -0.23661014  0.5082711 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29653656 0.2264714  0.4769921 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.06, 0.08, 0.36, 0.184, 0.145, 0.91, 0.042, 0.002, 0.5309999999999999, 0.04]
0.9149243333333332
1.8339283333333334
Reward 11.954309484809901
Current State [[0.06  0.08  0.36  0.184 0.145 0.91  0.042 0.002 0.531 0.04 ]]
Logits tf.Tensor([[ 0.02985783 -0.23709635  0.52550656]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29349    0.22472768 0.4817823 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.07, 0.08, 0.37, 0.14, 0.145, 0.92, 0.043, 0.001, 0.5519999999999999, 0.17]
0.9192703333333333
1.2178576666666667
Reward 13.432845059688113
Current State [[0.07  0.08  0.37  0.14  0.145 0.92  0.043 0.001 0.552 0.17 ]]
Logits tf.Tensor([[ 0.02796864 -0.2680803   0.5353231 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2937166  0.21845204 0.48783138]], shape=(1, 3), dtype=float32)
Selected action 0
[0.02, 0.04, 0.35, 0.165, 0.145, 0.92, 0.043, 0.001, 0.5519999999999999, 0.17]
0.9192703333333333
1.2178576666666667
Reward 7.432845059688112
Current State [[0.02  0.04  0.35  0.165 0.145 0.92  0.043 0.001 0.552 0.17 ]]
Logits tf.Tensor([[ 0.03285227 -0.24566616  0.52001965]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2954556  0.22363164 0.4809128 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.34, 0.147, 0.145, 0.74, 0.023, 0.005, 0.8390000000000001, 0.15]
0.7381598333333332
5.167262
Reward 16.324968972469907
Current State [[0.03  0.15  0.34  0.147 0.145 0.74  0.023 0.005 0.839 0.15 ]]
Logits tf.Tensor([[ 0.03217093 -0.28337997  0.5976149 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2865645  0.2090164  0.50441915]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.34, 0.128, 0.145, 0.74, 0.02, 0.012, 0.396, 0.01]
0.7435775
12.3386895
Reward 16.009618769592148
Current State [[0.05  0.15  0.34  0.128 0.145 0.74  0.02  0.012 0.396 0.01 ]]
Logits tf.Tensor([[ 0.03928015 -0.2162563   0.45919538]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30336738 0.2349583  0.46167433]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.04, 0.35, 0.153, 0.145, 0.74, 0.02, 0.012, 0.396, 0.01]
0.7435775
12.3386895
Reward 4.009618769592149
Current State [[0.05  0.04  0.35  0.153 0.145 0.74  0.02  0.012 0.396 0.01 ]]
Logits tf.Tensor([[ 0.03634294 -0.18573888  0.4305812 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3044971  0.24385646 0.45164648]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.3, 0.112, 0.145, 0.89, 0.034, 0.001, 0.523, 0.1]
0.887312
0.9482148333333332
Reward 20.652032947712193
Current State [[0.03  0.15  0.3   0.112 0.145 0.89  0.034 0.001 0.523 0.1  ]]
Logits tf.Tensor([[ 0.03276269 -0.26483536  0.5312691 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29508445 0.21912964 0.48578587]], shape=(1, 3), dtype=float32)
Selected action 1
[0.02, 0.08, 0.32, 0.138, 0.145, 0.84, 0.019, 0.002, 0.5780000000000001, 0.07]
0.8438053333333333
1.5375006666666666
Reward 12.221216922903157
Current State [[0.02  0.08  0.32  0.138 0.145 0.84  0.019 0.002 0.578 0.07 ]]
Logits tf.Tensor([[ 0.03862647 -0.23315154  0.5166621 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29630277 0.22578964 0.4779076 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.15, 0.32, 0.146, 0.145, 0.84, 0.019, 0.002, 0.5780000000000001, 0.07]
0.8438053333333333
1.5375006666666666
Reward 18.221216922903157
Episode: 80 | Average Reward: 283 | Episode Reward: 261 | Loss: 585.563 | Steps: 19 | Worker: 0
Current State [[-6.30489648e-03 -2.01256129e-04  7.38816706e-03 -3.04286890e-04
   5.99030516e-03 -5.24797546e-03  8.51245380e-05  7.77931042e-03
   5.07536231e-03 -7.95629737e-03]]
Logits tf.Tensor([[ 0.01190306 -0.02320925  0.01787237]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.33653218 0.3249208  0.33854705]], shape=(1, 3), dtype=float32)
Selected action 1
[0.06, 0.08, 0.32, 0.165, 0.145, 0.9, 0.036, 0.0, 0.43099999999999994, 0.02]
0.8950111666666666
0.1327375
Reward 55.291750275303826
Current State [[0.06  0.08  0.32  0.165 0.145 0.9   0.036 0.    0.431 0.02 ]]
Logits tf.Tensor([[ 0.02981349 -0.22671744  0.48387843]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2986473  0.23107271 0.47028   ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.04, 0.35, 0.126, 0.145, 0.74, 0.02, 0.003, 0.489, 0.04]
0.7388873333333332
2.9684523333333335
Reward 4.76278857753251
Current State [[0.05  0.04  0.35  0.126 0.145 0.74  0.02  0.003 0.489 0.04 ]]
Logits tf.Tensor([[ 0.03166841 -0.20329474  0.46170917]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30048797 0.23756577 0.46194622]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.34, 0.142, 0.145, 0.74, 0.02, 0.003, 0.489, 0.04]
0.7388873333333332
2.9684523333333335
Reward 16.76278857753251
Current State [[0.04  0.15  0.34  0.142 0.145 0.74  0.02  0.003 0.489 0.04 ]]
Logits tf.Tensor([[ 0.03786348 -0.22522047  0.48832253]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29960665 0.23030086 0.4700925 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.05, 0.08, 0.36, 0.168, 0.145, 0.72, 0.028, 0.002, 0.48200000000000004, 0.08]
0.7215145
2.4988098333333335
Reward 10.937208741838976
Current State [[0.05  0.08  0.36  0.168 0.145 0.72  0.028 0.002 0.482 0.08 ]]
Logits tf.Tensor([[ 0.03209548 -0.21109363  0.46600336]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30053496 0.23565643 0.46380857]], shape=(1, 3), dtype=float32)
Selected action 1
[0.02, 0.08, 0.33, 0.13, 0.145, 0.85, 0.037, 0.001, 0.572, 0.13]
0.8546579999999999
1.170833666666667
Reward 13.276847851659483
Current State [[0.02  0.08  0.33  0.13  0.145 0.85  0.037 0.001 0.572 0.13 ]]
Logits tf.Tensor([[ 0.03187022 -0.24584769  0.51989007]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29528162 0.22367892 0.4810395 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.04, 0.34, 0.143, 0.145, 0.76, 0.016, 0.003, 0.554, 0.06]
0.7552856666666667
2.923214
Reward 4.803716743922923
Current State [[0.05  0.04  0.34  0.143 0.145 0.76  0.016 0.003 0.554 0.06 ]]
Logits tf.Tensor([[ 0.03292984 -0.21381181  0.48415643]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29836679 0.23312664 0.46850654]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.32, 0.134, 0.145, 0.76, 0.016, 0.003, 0.554, 0.06]
0.7552856666666667
2.923214
Reward 16.803716743922923
Current State [[0.03  0.15  0.32  0.134 0.145 0.76  0.016 0.003 0.554 0.06 ]]
Logits tf.Tensor([[ 0.03885538 -0.23747744  0.50985074]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29760593 0.2257521  0.47664198]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.35, 0.144, 0.145, 0.85, 0.028, 0.003, 0.493, 0.1]
0.849223
2.791667
Reward 17.006410860775503
Current State [[0.04  0.15  0.35  0.144 0.145 0.85  0.028 0.003 0.493 0.1  ]]
Logits tf.Tensor([[ 0.03891386 -0.25039315  0.5181481 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2972988  0.22261207 0.4800892 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.35, 0.134, 0.145, 0.81, 0.028, 0.003, 0.48600000000000004, 0.07]
0.8098293333333333
2.5708333333333337
Reward 17.055309974925812
Current State [[0.04  0.15  0.35  0.134 0.145 0.81  0.028 0.003 0.486 0.07 ]]
Logits tf.Tensor([[ 0.0371569  -0.24142703  0.5068871 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29793674 0.22549482 0.47656843]], shape=(1, 3), dtype=float32)
Selected action 1
[0.05, 0.08, 0.35, 0.153, 0.145, 0.81, 0.028, 0.003, 0.48600000000000004, 0.07]
0.8098293333333333
2.5708333333333337
Reward 11.055309974925814
Current State [[0.05  0.08  0.35  0.153 0.145 0.81  0.028 0.003 0.486 0.07 ]]
Logits tf.Tensor([[ 0.03379934 -0.22214136  0.48616892]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2988446  0.23136188 0.46979353]], shape=(1, 3), dtype=float32)
Selected action 1
[0.03, 0.08, 0.33, 0.156, 0.145, 0.89, 0.03, 0.002, 0.446, 0.09]
0.8918088333333334
2.088095
Reward 11.587902419337313
Current State [[0.03  0.08  0.33  0.156 0.145 0.89  0.03  0.002 0.446 0.09 ]]
Logits tf.Tensor([[ 0.03773076 -0.23025298  0.4873644 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3000608  0.22952257 0.47041664]], shape=(1, 3), dtype=float32)
Selected action 0
[0.03, 0.04, 0.29, 0.121, 0.145, 0.78, 0.02, 0.004, 0.5309999999999999, 0.04]
0.7849876666666665
4.391666666666666
Reward 4.4688924118661015
Current State [[0.03  0.04  0.29  0.121 0.145 0.78  0.02  0.004 0.531 0.04 ]]
Logits tf.Tensor([[ 0.03261184 -0.21143867  0.4724058 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29977497 0.23485811 0.46536687]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.36, 0.142, 0.145, 0.78, 0.02, 0.004, 0.5309999999999999, 0.04]
0.7849876666666665
4.391666666666666
Reward 16.4688924118661
Current State [[0.05  0.15  0.36  0.142 0.145 0.78  0.02  0.004 0.531 0.04 ]]
Logits tf.Tensor([[ 0.03788545 -0.23712222  0.51208097]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2970632  0.22563916 0.4772977 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.08, 0.08, 0.37, 0.159, 0.145, 0.82, 0.033, 0.002, 0.516, 0.08]
0.8203186666666666
1.5529763333333333
Reward 12.10991031005848
Current State [[0.08  0.08  0.37  0.159 0.145 0.82  0.033 0.002 0.516 0.08 ]]
Logits tf.Tensor([[ 0.0279512  -0.23502271  0.501537  ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29633984 0.2278148  0.47584528]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.15, 0.37, 0.146, 0.145, 0.82, 0.03, 0.005, 0.589, 0.11]
0.8209263333333333
4.695833166666666
Reward 16.4529468589179
Current State [[0.07  0.15  0.37  0.146 0.145 0.82  0.03  0.005 0.589 0.11 ]]
Logits tf.Tensor([[ 0.03254016 -0.26813617  0.5408329 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29387838 0.21756327 0.48855826]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.35, 0.149, 0.145, 0.78, 0.032, 0.003, 0.5599999999999999, 0.13]
0.7779178333333334
2.735714166666667
Reward 16.9177229119347
Current State [[0.04  0.15  0.35  0.149 0.145 0.78  0.032 0.003 0.56  0.13 ]]
Logits tf.Tensor([[ 0.03441008 -0.256409    0.5207728 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29638052 0.22158918 0.48203027]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.35, 0.157, 0.145, 0.78, 0.032, 0.003, 0.5599999999999999, 0.13]
0.7779178333333334
2.735714166666667
Reward 16.9177229119347
Current State [[0.05  0.15  0.35  0.157 0.145 0.78  0.032 0.003 0.56  0.13 ]]
Logits tf.Tensor([[ 0.0333278  -0.25745735  0.5208081 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29621863 0.22147565 0.4823057 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.36, 0.178, 0.145, 0.77, 0.031, 0.006, 0.613, 0.15]
0.7663056666666667
5.819642666666668
Reward 16.281011994459515
Current State [[0.05  0.15  0.36  0.178 0.145 0.77  0.031 0.006 0.613 0.15 ]]
Logits tf.Tensor([[ 0.03431654 -0.2642495   0.5336017 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29503533 0.21888119 0.48608342]], shape=(1, 3), dtype=float32)
Selected action 1
[0.07, 0.08, 0.37, 0.126, 0.145, 0.84, 0.032, 0.002, 0.678, 0.13]
0.8405533333333334
2.331547666666666
Reward 11.265886061658325
Current State [[0.07  0.08  0.37  0.126 0.145 0.84  0.032 0.002 0.678 0.13 ]]
Logits tf.Tensor([[ 0.02618894 -0.26908132  0.553944  ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29074392 0.21640955 0.4928466 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.15, 0.39, 0.171, 0.145, 0.84, 0.032, 0.002, 0.678, 0.13]
0.8405533333333334
2.331547666666666
Reward 17.265886061658325
Episode: 81 | Average Reward: 283 | Episode Reward: 307 | Loss: 640.738 | Steps: 19 | Worker: 0
Current State [[-0.00366823  0.00990407 -0.00181419  0.00497654 -0.00654454 -0.00093728
   0.00569994 -0.00346491 -0.00398174 -0.00105519]]
Logits tf.Tensor([[ 0.00976219 -0.02437101  0.02034036]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.33589995 0.32462806 0.339472  ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.02, 0.08, 0.38, 0.188, 0.145, 0.76, 0.037, 0.004, 0.758, 0.18]
0.7581125
4.496428500000001
Reward 10.427793115151616
Current State [[0.02  0.08  0.38  0.188 0.145 0.76  0.037 0.004 0.758 0.18 ]]
Logits tf.Tensor([[ 0.0303842  -0.26002884  0.5612871 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.28998774 0.21689765 0.4931146 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.37, 0.154, 0.145, 0.86, 0.036, 0.002, 0.693, 0.08]
0.8559048333333333
1.8005948333333335
Reward 5.8319286554929555
Current State [[0.04  0.04  0.37  0.154 0.145 0.86  0.036 0.002 0.693 0.08 ]]
Logits tf.Tensor([[ 0.02586506 -0.24344939  0.5557391 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.28879854 0.22061406 0.49058735]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.38, 0.153, 0.145, 0.86, 0.036, 0.002, 0.693, 0.08]
0.8559048333333333
1.8005948333333335
Reward 17.831928655492955
Current State [[0.03  0.15  0.38  0.153 0.145 0.86  0.036 0.002 0.693 0.08 ]]
Logits tf.Tensor([[ 0.03235516 -0.26611423  0.5831067 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.28764486 0.21341898 0.49893618]], shape=(1, 3), dtype=float32)
Selected action 1
[0.05, 0.08, 0.36, 0.166, 0.145, 0.71, 0.02, 0.003, 0.8039999999999999, 0.07]
0.7067308333333334
2.5636910000000004
Reward 10.879337985987608
Current State [[0.05  0.08  0.36  0.166 0.145 0.71  0.02  0.003 0.804 0.07 ]]
Logits tf.Tensor([[ 0.02055543 -0.23728794  0.5756712 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.28450644 0.21984275 0.4956508 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.03, 0.08, 0.36, 0.133, 0.145, 0.76, 0.033, 0.003, 0.615, 0.19]
0.7596083333333332
2.771428666666666
Reward 10.87236866968819
Current State [[0.03  0.08  0.36  0.133 0.145 0.76  0.033 0.003 0.615 0.19 ]]
Logits tf.Tensor([[ 0.02895838 -0.25026497  0.51197976]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2960914  0.22395495 0.47995365]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.41, 0.161, 0.145, 0.76, 0.033, 0.003, 0.615, 0.19]
0.7596083333333332
2.771428666666666
Reward 4.87236866968819
Current State [[0.04  0.04  0.41  0.161 0.145 0.76  0.033 0.003 0.615 0.19 ]]
Logits tf.Tensor([[ 0.02934437 -0.23863205  0.5074922 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2960323  0.22644272 0.47752494]], shape=(1, 3), dtype=float32)
Selected action 0
[0.03, 0.04, 0.38, 0.154, 0.145, 0.85, 0.048, 0.001, 0.52, 0.2]
0.8501511666666667
1.2232146666666663
Reward 7.062259526329393
Current State [[0.03  0.04  0.38  0.154 0.145 0.85  0.048 0.001 0.52  0.2  ]]
Logits tf.Tensor([[ 0.02860273 -0.23580848  0.4997217 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2967849  0.22782925 0.4753858 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.4, 0.135, 0.145, 0.81, 0.043, 0.001, 0.507, 0.16]
0.8105746666666666
1.1142859999999999
Reward 19.261204252928888
Current State [[0.05  0.15  0.4   0.135 0.145 0.81  0.043 0.001 0.507 0.16 ]]
Logits tf.Tensor([[ 0.03101698 -0.26009458  0.518048  ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29630426 0.22146738 0.4822284 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.4, 0.148, 0.145, 0.82, 0.059, 0.002, 0.466, 0.17]
0.8222901666666667
2.204165833333333
Reward 5.32530066703453
Current State [[0.04  0.04  0.4   0.148 0.145 0.82  0.059 0.002 0.466 0.17 ]]
Logits tf.Tensor([[ 0.0242141  -0.22411396  0.4800247 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29783574 0.23234284 0.46982142]], shape=(1, 3), dtype=float32)
Selected action 0
[0.02, 0.04, 0.37, 0.137, 0.145, 0.82, 0.059, 0.002, 0.466, 0.17]
0.8222901666666667
2.204165833333333
Reward 5.32530066703453
Current State [[0.02  0.04  0.37  0.137 0.145 0.82  0.059 0.002 0.466 0.17 ]]
Logits tf.Tensor([[ 0.0243405  -0.22313203  0.47606292]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29834828 0.23294187 0.46870986]], shape=(1, 3), dtype=float32)
Selected action 1
[0.04, 0.08, 0.36, 0.152, 0.145, 0.75, 0.04, 0.004, 0.528, 0.2]
0.7504816666666666
3.881547666666667
Reward 10.528668792534003
Current State [[0.04  0.08  0.36  0.152 0.145 0.75  0.04  0.004 0.528 0.2  ]]
Logits tf.Tensor([[ 0.02835475 -0.2397138   0.4843928 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29916245 0.22881599 0.47202158]], shape=(1, 3), dtype=float32)
Selected action 0
[0.02, 0.04, 0.38, 0.117, 0.145, 0.89, 0.049, 0.001, 0.466, 0.17]
0.8911453333333333
1.093451666666667
Reward 7.8216187951603695
Current State [[0.02  0.04  0.38  0.117 0.145 0.89  0.049 0.001 0.466 0.17 ]]
Logits tf.Tensor([[ 0.0293066  -0.23392716  0.4910333 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2980294  0.22905414 0.4729165 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.15, 0.41, 0.142, 0.145, 0.89, 0.049, 0.001, 0.466, 0.17]
0.8911453333333333
1.093451666666667
Reward 19.82161879516037
Current State [[0.06  0.15  0.41  0.142 0.145 0.89  0.049 0.001 0.466 0.17 ]]
Logits tf.Tensor([[ 0.03100185 -0.26636878  0.52797663]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29528928 0.21933164 0.4853791 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.02, 0.15, 0.36, 0.128, 0.145, 0.85, 0.038, 0.002, 0.491, 0.13]
0.8526826666666667
1.619642333333333
Reward 18.100477258697477
Current State [[0.02  0.15  0.36  0.128 0.145 0.85  0.038 0.002 0.491 0.13 ]]
Logits tf.Tensor([[ 0.03572353 -0.25186872  0.51981276]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29649276 0.22238953 0.48111773]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.38, 0.128, 0.145, 0.82, 0.071, 0.0, 0.421, 0.05]
0.8233125000000001
0.43988049999999995
Reward 29.394500267999813
Current State [[0.04  0.15  0.38  0.128 0.145 0.82  0.071 0.    0.421 0.05 ]]
Logits tf.Tensor([[ 0.01987809 -0.23601368  0.4982551 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29518735 0.22854163 0.47627106]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.37, 0.156, 0.145, 0.82, 0.071, 0.0, 0.421, 0.05]
0.8233125000000001
0.43988049999999995
Reward 29.394500267999813
Current State [[0.03  0.15  0.37  0.156 0.145 0.82  0.071 0.    0.421 0.05 ]]
Logits tf.Tensor([[ 0.02166953 -0.22981645  0.49775884]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2952107  0.22956894 0.47522038]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.38, 0.139, 0.145, 0.8, 0.023, 0.007, 0.507, 0.08]
0.7959246666666666
7.157738666666666
Reward 16.201528930785788
Current State [[0.04  0.15  0.38  0.139 0.145 0.8   0.023 0.007 0.507 0.08 ]]
Logits tf.Tensor([[ 0.03915925 -0.24081667  0.5114789 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29766226 0.22497374 0.47736394]], shape=(1, 3), dtype=float32)
Selected action 1
[0.04, 0.08, 0.39, 0.14, 0.145, 0.84, 0.044, 0.002, 0.503, 0.2]
0.8395100000000001
2.199405
Reward 11.366535727289154
Current State [[0.04  0.08  0.39  0.14  0.145 0.84  0.044 0.002 0.503 0.2  ]]
Logits tf.Tensor([[ 0.03083738 -0.24668634  0.503511  ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2974477  0.22536354 0.47718877]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.38, 0.148, 0.145, 0.81, 0.032, 0.003, 0.499, 0.12]
0.8066191666666669
3.1398803333333336
Reward 16.79729321347748
Current State [[0.04  0.15  0.38  0.148 0.145 0.81  0.032 0.003 0.499 0.12 ]]
Logits tf.Tensor([[ 0.03613465 -0.24759972  0.5132466 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29723155 0.22380543 0.47896302]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.39, 0.153, 0.145, 0.81, 0.032, 0.003, 0.499, 0.12]
0.8066191666666669
3.1398803333333336
Reward 16.79729321347748
Episode: 82 | Average Reward: 283 | Episode Reward: 273 | Loss: 725.529 | Steps: 19 | Worker: 0
Current State [[ 0.00591279  0.00348018  0.00155292  0.00893772  0.00963934  0.00173659
   0.00912954  0.00898778 -0.00810771 -0.00414268]]
Logits tf.Tensor([[ 0.00692478 -0.02840603  0.02133856]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3355925  0.32394278 0.3404647 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.11, 0.08, 0.41, 0.132, 0.145, 0.83, 0.034, 0.004, 0.5940000000000001, 0.19]
0.8255605000000001
3.5720241666666666
Reward 10.686658693048404
Current State [[0.11  0.08  0.41  0.132 0.145 0.83  0.034 0.004 0.594 0.19 ]]
Logits tf.Tensor([[ 0.02101536 -0.27136102  0.5278396 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29355657 0.2191363  0.4873071 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.06, 0.08, 0.4, 0.138, 0.145, 0.86, 0.044, 0.002, 0.495, 0.17]
0.8606931666666667
2.275594333333333
Reward 11.349931216977502
Current State [[0.06  0.08  0.4   0.138 0.145 0.86  0.044 0.002 0.495 0.17 ]]
Logits tf.Tensor([[ 0.02698786 -0.24617238  0.5077008 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29601583 0.22525942 0.47872478]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.36, 0.147, 0.145, 0.86, 0.044, 0.002, 0.495, 0.17]
0.8606931666666667
2.275594333333333
Reward 17.349931216977502
Current State [[0.03  0.15  0.36  0.147 0.145 0.86  0.044 0.002 0.495 0.17 ]]
Logits tf.Tensor([[ 0.03173888 -0.2584286   0.52412224]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29547778 0.22105823 0.48346406]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.38, 0.179, 0.145, 0.83, 0.04, 0.002, 0.514, 0.14]
0.8326045000000001
1.7255958333333334
Reward 17.868900727290264
Current State [[0.04  0.15  0.38  0.179 0.145 0.83  0.04  0.002 0.514 0.14 ]]
Logits tf.Tensor([[ 0.03230678 -0.24975191  0.52405983]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2950366  0.22252531 0.48243806]], shape=(1, 3), dtype=float32)
Selected action 1
[0.04, 0.08, 0.37, 0.126, 0.145, 0.81, 0.036, 0.002, 0.5559999999999999, 0.15]
0.8091245
2.474999833333333
Reward 11.109700245940632
Current State [[0.04  0.08  0.37  0.126 0.145 0.81  0.036 0.002 0.556 0.15 ]]
Logits tf.Tensor([[ 0.02706466 -0.2425255   0.5098165 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.295489   0.22566275 0.4788482 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.38, 0.145, 0.145, 0.81, 0.036, 0.002, 0.5559999999999999, 0.15]
0.8091245
2.474999833333333
Reward 17.10970024594063
Current State [[0.04  0.15  0.38  0.145 0.145 0.81  0.036 0.002 0.556 0.15 ]]
Logits tf.Tensor([[ 0.03090185 -0.25928244  0.5301799 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29449382 0.22031838 0.4851878 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.38, 0.146, 0.145, 0.79, 0.033, 0.003, 0.589, 0.2]
0.7858105000000001
2.957738
Reward 16.835527926223506
Current State [[0.03  0.15  0.38  0.146 0.145 0.79  0.033 0.003 0.589 0.2  ]]
Logits tf.Tensor([[ 0.03305694 -0.26747674  0.532902  ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29508197 0.21848547 0.48643255]], shape=(1, 3), dtype=float32)
Selected action 0
[0.03, 0.04, 0.37, 0.136, 0.145, 0.82, 0.035, 0.002, 0.55, 0.13]
0.8192363333333333
2.041666833333333
Reward 5.460960432694168
Current State [[0.03  0.04  0.37  0.136 0.145 0.82  0.035 0.002 0.55  0.13 ]]
Logits tf.Tensor([[ 0.02771725 -0.22537717  0.50004077]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2958483  0.22969502 0.4744567 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.37, 0.16, 0.145, 0.84, 0.031, 0.001, 0.495, 0.13]
0.8444901666666668
0.8494048333333333
Reward 21.078207290114882
Current State [[0.04  0.15  0.37  0.16  0.145 0.84  0.031 0.001 0.495 0.13 ]]
Logits tf.Tensor([[ 0.03501989 -0.24782492  0.5192556 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29615843 0.22319588 0.48064563]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.35, 0.135, 0.145, 0.84, 0.031, 0.001, 0.495, 0.13]
0.8444901666666668
0.8494048333333333
Reward 21.078207290114882
Current State [[0.03  0.15  0.35  0.135 0.145 0.84  0.031 0.001 0.495 0.13 ]]
Logits tf.Tensor([[ 0.03421832 -0.24934569  0.5173859 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29635805 0.22318575 0.48045617]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.36, 0.153, 0.145, 0.78, 0.019, 0.006, 0.567, 0.08]
0.7848473333333335
5.861904333333334
Reward 16.289685634065975
Current State [[0.04  0.15  0.36  0.153 0.145 0.78  0.019 0.006 0.567 0.08 ]]
Logits tf.Tensor([[ 0.03548083 -0.24118061  0.5218075 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2954522 0.2240447 0.4805031]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.15, 0.37, 0.135, 0.145, 0.94, 0.042, 0.002, 0.475, 0.13]
0.9368756666666667
2.3035716666666675
Reward 17.48751438183216
Current State [[0.07  0.15  0.37  0.135 0.145 0.94  0.042 0.002 0.475 0.13 ]]
Logits tf.Tensor([[ 0.0275414  -0.26988727  0.53704166]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29349744 0.21798804 0.4885145 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.04, 0.42, 0.162, 0.145, 0.94, 0.042, 0.002, 0.475, 0.13]
0.9368756666666667
2.3035716666666675
Reward 5.487514381832161
Current State [[0.05  0.04  0.42  0.162 0.145 0.94  0.042 0.002 0.475 0.13 ]]
Logits tf.Tensor([[ 0.03094803 -0.2327327   0.50910306]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.295743   0.2271953  0.47706163]], shape=(1, 3), dtype=float32)
Selected action 2
[0.02, 0.15, 0.37, 0.15, 0.145, 0.71, 0.018, 0.007, 0.9960000000000001, 0.08]
0.7064006666666667
6.851190833333334
Reward 16.170493564052027
Current State [[0.02  0.15  0.37  0.15  0.145 0.71  0.018 0.007 0.996 0.08 ]]
Logits tf.Tensor([[ 0.00944672 -0.2787801   0.67343116]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.27084795 0.20302534 0.5261267 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.38, 0.138, 0.145, 0.76, 0.018, 0.003, 0.7230000000000001, 0.08]
0.7640615
3.1160713333333327
Reward 16.746812625185044
Current State [[0.05  0.15  0.38  0.138 0.145 0.76  0.018 0.003 0.723 0.08 ]]
Logits tf.Tensor([[ 0.02902086 -0.25490114  0.5673727 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.28851646 0.21720254 0.49428093]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.37, 0.148, 0.145, 0.76, 0.018, 0.003, 0.7230000000000001, 0.08]
0.7640615
3.1160713333333327
Reward 16.746812625185044
Current State [[0.05  0.15  0.37  0.148 0.145 0.76  0.018 0.003 0.723 0.08 ]]
Logits tf.Tensor([[ 0.02895309 -0.25437805  0.566418  ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2886059  0.21739827 0.49399582]], shape=(1, 3), dtype=float32)
Selected action 2
[0.02, 0.15, 0.35, 0.126, 0.145, 0.77, 0.024, 0.006, 0.628, 0.06]
0.7660503333333334
5.624999833333333
Reward 16.29870323146015
Current State [[0.02  0.15  0.35  0.126 0.145 0.77  0.024 0.006 0.628 0.06 ]]
Logits tf.Tensor([[ 0.0340516  -0.24161537  0.534938  ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29331973 0.22264896 0.48403135]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.35, 0.138, 0.145, 0.75, 0.038, 0.013, 0.45899999999999996, 0.16]
0.7484858333333334
13.055357000000003
Reward 15.998817911987144
Current State [[0.05  0.15  0.35  0.138 0.145 0.75  0.038 0.013 0.459 0.16 ]]
Logits tf.Tensor([[ 0.03089519 -0.24705599  0.48159978]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30059355 0.22764966 0.47175682]], shape=(1, 3), dtype=float32)
Selected action 2
[0.02, 0.15, 0.3, 0.128, 0.145, 0.82, 0.025, 0.003, 0.61, 0.1]
0.8209068333333335
2.6738096666666675
Reward 17.019122566186144
Current State [[0.02  0.15  0.3   0.128 0.145 0.82  0.025 0.003 0.61  0.1  ]]
Logits tf.Tensor([[ 0.03121111 -0.25594997  0.54090434]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29281107 0.21972275 0.48746616]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.31, 0.142, 0.145, 0.82, 0.025, 0.003, 0.61, 0.1]
0.8209068333333335
2.6738096666666675
Reward 5.0191225661861445
Episode: 83 | Average Reward: 283 | Episode Reward: 293 | Loss: 702.083 | Steps: 19 | Worker: 0
Current State [[-0.00169641 -0.00199478 -0.00902474 -0.00953663 -0.00431718  0.00150148
  -0.00301412  0.0089527  -0.0028953   0.00701711]]
Logits tf.Tensor([[ 0.01187576 -0.02284494  0.01658891]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3366324  0.32514486 0.33822274]], shape=(1, 3), dtype=float32)
Selected action 1
[0.04, 0.08, 0.33, 0.141, 0.145, 0.87, 0.031, 0.001, 0.504, 0.03]
0.8664428333333335
0.8041671666666667
Reward 15.713037856880348
Current State [[0.04  0.08  0.33  0.141 0.145 0.87  0.031 0.001 0.504 0.03 ]]
Logits tf.Tensor([[ 0.02488491 -0.22432642  0.50733006]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29416558 0.22927715 0.4765573 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.02, 0.04, 0.34, 0.128, 0.145, 0.91, 0.033, 0.001, 0.512, 0.11]
0.907052
0.8869044999999999
Reward 9.291905204384692
Current State [[0.02  0.04  0.34  0.128 0.145 0.91  0.033 0.001 0.512 0.11 ]]
Logits tf.Tensor([[ 0.0271957  -0.23171563  0.5067362 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29522705 0.22788325 0.4768897 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.15, 0.36, 0.148, 0.145, 0.91, 0.033, 0.001, 0.512, 0.11]
0.907052
0.8869044999999999
Reward 21.29190520438469
Current State [[0.08  0.15  0.36  0.148 0.145 0.91  0.033 0.001 0.512 0.11 ]]
Logits tf.Tensor([[ 0.02379513 -0.26646626  0.54512423]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29134706 0.2179474  0.49070552]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.36, 0.172, 0.145, 0.84, 0.025, 0.002, 0.47400000000000003, 0.09]
0.8434415000000002
2.2910715
Reward 17.30194056377336
Current State [[0.04  0.15  0.36  0.172 0.145 0.84  0.025 0.002 0.474 0.09 ]]
Logits tf.Tensor([[ 0.03342403 -0.2363488   0.5170157 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29538238 0.2255401  0.47907752]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.35, 0.152, 0.145, 0.71, 0.019, 0.003, 0.645, 0.08]
0.7109905
2.741071666666666
Reward 16.80810002335892
Current State [[0.04  0.15  0.35  0.152 0.145 0.71  0.019 0.003 0.645 0.08 ]]
Logits tf.Tensor([[ 0.02622336 -0.23934853  0.531264  ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2920714  0.2239508  0.48397774]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.35, 0.145, 0.145, 0.71, 0.019, 0.003, 0.645, 0.08]
0.7109905
2.741071666666666
Reward 16.80810002335892
Current State [[0.05  0.15  0.35  0.145 0.145 0.71  0.019 0.003 0.645 0.08 ]]
Logits tf.Tensor([[ 0.02437907 -0.24219215  0.5318156 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2917979  0.22351763 0.48468444]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.35, 0.147, 0.145, 0.85, 0.028, 0.003, 0.52, 0.06]
0.8500630000000001
2.576190500000001
Reward 17.12370910642666
Current State [[0.05  0.15  0.35  0.147 0.145 0.85  0.028 0.003 0.52  0.06 ]]
Logits tf.Tensor([[ 0.02740975 -0.2456302   0.53188425]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29263917 0.22271666 0.48464411]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.15, 0.36, 0.134, 0.145, 0.67, 0.012, 0.004, 0.5980000000000001, 0.03]
0.6711729999999999
3.6374998333333335
Reward 16.49242938774007
Current State [[0.06  0.15  0.36  0.134 0.145 0.67  0.012 0.004 0.598 0.03 ]]
Logits tf.Tensor([[ 0.02518607 -0.22197786  0.51234984]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29336646 0.22912292 0.47751057]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.35, 0.147, 0.145, 0.83, 0.032, 0.003, 0.497, 0.13]
0.8345786666666668
2.8505955
Reward 16.95517082925991
Current State [[0.04  0.15  0.35  0.147 0.145 0.83  0.032 0.003 0.497 0.13 ]]
Logits tf.Tensor([[ 0.02918794 -0.24984378  0.5202344 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29493818 0.2231254  0.4819364 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.36, 0.158, 0.145, 0.83, 0.032, 0.003, 0.497, 0.13]
0.8345786666666668
2.8505955
Reward 16.95517082925991
Current State [[0.04  0.15  0.36  0.158 0.145 0.83  0.032 0.003 0.497 0.13 ]]
Logits tf.Tensor([[ 0.03017578 -0.24825925  0.5211202 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2949134  0.22323984 0.48184675]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.15, 0.36, 0.143, 0.145, 0.88, 0.031, 0.002, 0.526, 0.13]
0.8779943333333333
1.6898803333333334
Reward 18.06359741108189
Current State [[0.07  0.15  0.36  0.143 0.145 0.88  0.031 0.002 0.526 0.13 ]]
Logits tf.Tensor([[ 0.02569686 -0.26609376  0.5419018 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2921771  0.21823439 0.48958847]], shape=(1, 3), dtype=float32)
Selected action 2
[0.02, 0.15, 0.34, 0.14, 0.145, 0.73, 0.016, 0.002, 0.585, 0.07]
0.7299625000000002
2.1898809999999997
Reward 17.139205807958163
Current State [[0.02  0.15  0.34  0.14  0.145 0.73  0.016 0.002 0.585 0.07 ]]
Logits tf.Tensor([[ 0.03163295 -0.2309959   0.51615274]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29477462 0.22668971 0.47853568]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.34, 0.143, 0.145, 0.73, 0.016, 0.002, 0.585, 0.07]
0.7299625000000002
2.1898809999999997
Reward 17.139205807958163
Current State [[0.03  0.15  0.34  0.143 0.145 0.73  0.016 0.002 0.585 0.07 ]]
Logits tf.Tensor([[ 0.03016779 -0.23310214  0.51641226]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29457405 0.2263903  0.47903562]], shape=(1, 3), dtype=float32)
Selected action 0
[0.02, 0.04, 0.35, 0.154, 0.145, 0.75, 0.023, 0.004, 0.548, 0.1]
0.7494251666666667
3.5315485000000004
Reward 4.606956836038752
Current State [[0.02  0.04  0.35  0.154 0.145 0.75  0.023 0.004 0.548 0.1  ]]
Logits tf.Tensor([[ 0.02803576 -0.20730056  0.48562136]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29668674 0.23447298 0.46884036]], shape=(1, 3), dtype=float32)
Selected action 0
[0.06, 0.04, 0.35, 0.136, 0.145, 0.83, 0.041, 0.003, 0.483, 0.14]
0.8330455
2.8464289999999997
Reward 4.954679457004423
Current State [[0.06  0.04  0.35  0.136 0.145 0.83  0.041 0.003 0.483 0.14 ]]
Logits tf.Tensor([[ 0.01816458 -0.22889717  0.4833114 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2964421  0.23154867 0.4720093 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.34, 0.146, 0.145, 0.83, 0.041, 0.003, 0.483, 0.14]
0.8330455
2.8464289999999997
Reward 16.954679457004424
Current State [[0.04  0.15  0.34  0.146 0.145 0.83  0.041 0.003 0.483 0.14 ]]
Logits tf.Tensor([[ 0.02550279 -0.25145584  0.515885  ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.294896   0.22355649 0.48154753]], shape=(1, 3), dtype=float32)
Selected action 1
[0.05, 0.08, 0.36, 0.156, 0.145, 0.65, 0.017, 0.003, 0.818, 0.07]
0.6505538333333334
3.415476166666666
Reward 10.516847729734152
Current State [[0.05  0.08  0.36  0.156 0.145 0.65  0.017 0.003 0.818 0.07 ]]
Logits tf.Tensor([[ 0.01330825 -0.22950278  0.57573587]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.28253797 0.22162837 0.49583372]], shape=(1, 3), dtype=float32)
Selected action 1
[0.08, 0.08, 0.38, 0.136, 0.145, 0.73, 0.029, 0.003, 0.704, 0.13]
0.7263459999999999
2.8196430000000006
Reward 10.800361397233253
Current State [[0.08  0.08  0.38  0.136 0.145 0.73  0.029 0.003 0.704 0.13 ]]
Logits tf.Tensor([[ 0.01269009 -0.2521569   0.5445524 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2882324  0.22116746 0.49060014]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.04, 0.45, 0.132, 0.145, 0.83, 0.043, 0.002, 0.6599999999999999, 0.25]
0.8302693333333333
2.4309523333333334
Reward 5.1771690882545744
Current State [[0.05  0.04  0.45  0.132 0.145 0.83  0.043 0.002 0.66  0.25 ]]
Logits tf.Tensor([[ 0.02051703 -0.26685977  0.5470513 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29042047 0.21788186 0.49169767]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.42, 0.154, 0.145, 0.83, 0.043, 0.002, 0.6599999999999999, 0.25]
0.8302693333333333
2.4309523333333334
Reward 17.177169088254573
Episode: 84 | Average Reward: 283 | Episode Reward: 287 | Loss: 603.082 | Steps: 19 | Worker: 0
Current State [[-0.00987713  0.00309582  0.00032259  0.00268897 -0.00750029 -0.00317676
   0.00199116 -0.00656822  0.00415265 -0.00486927]]
Logits tf.Tensor([[ 0.00735931 -0.02039141  0.02065452]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3348945  0.32572874 0.33937675]], shape=(1, 3), dtype=float32)
Selected action 1
[0.07, 0.08, 0.43, 0.167, 0.145, 0.76, 0.034, 0.004, 0.8210000000000001, 0.14]
0.7611871666666666
4.095238333333333
Reward 10.49797831168638
Current State [[0.07  0.08  0.43  0.167 0.145 0.76  0.034 0.004 0.821 0.14 ]]
Logits tf.Tensor([[ 0.00896583 -0.26464763  0.6071901 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2793677  0.21249431 0.508138  ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.41, 0.145, 0.145, 0.71, 0.03, 0.003, 0.787, 0.16]
0.7107271666666667
3.191666166666667
Reward 16.650949596011642
Current State [[0.04  0.15  0.41  0.145 0.145 0.71  0.03  0.003 0.787 0.16 ]]
Logits tf.Tensor([[ 0.01786183 -0.27117202  0.59281677]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.28360447 0.21241602 0.50397944]], shape=(1, 3), dtype=float32)
Selected action 1
[0.02, 0.08, 0.38, 0.134, 0.145, 0.71, 0.03, 0.003, 0.787, 0.16]
0.7107271666666667
3.191666166666667
Reward 10.650949596011642
Current State [[0.02  0.08  0.38  0.134 0.145 0.71  0.03  0.003 0.787 0.16 ]]
Logits tf.Tensor([[ 0.01767214 -0.25436246  0.5733717 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.28530768 0.21735537 0.49733692]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.15, 0.4, 0.151, 0.145, 0.82, 0.034, 0.003, 0.774, 0.15]
0.8249036666666668
2.5035716666666668
Reward 17.121510147856526
Current State [[0.07  0.15  0.4   0.151 0.145 0.82  0.034 0.003 0.774 0.15 ]]
Logits tf.Tensor([[ 0.01302055 -0.29274723  0.6112386 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.28125975 0.207164   0.51157624]], shape=(1, 3), dtype=float32)
Selected action 0
[0.02, 0.04, 0.39, 0.127, 0.145, 0.78, 0.034, 0.002, 0.633, 0.05]
0.7845430000000001
1.961904833333333
Reward 5.454298774749109
Current State [[0.02  0.04  0.39  0.127 0.145 0.78  0.034 0.002 0.633 0.05 ]]
Logits tf.Tensor([[ 0.01821381 -0.2195443   0.5344927 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.28866914 0.22758484 0.48374602]], shape=(1, 3), dtype=float32)
Selected action 1
[0.05, 0.08, 0.4, 0.128, 0.145, 0.85, 0.036, 0.002, 0.51, 0.14]
0.8491733333333333
2.185714
Reward 11.399256483394009
Current State [[0.05  0.08  0.4   0.128 0.145 0.85  0.036 0.002 0.51  0.14 ]]
Logits tf.Tensor([[ 0.02133621 -0.24370453  0.5218406 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2926777  0.2245349  0.48278737]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.4, 0.14, 0.145, 0.85, 0.036, 0.002, 0.51, 0.14]
0.8491733333333333
2.185714
Reward 17.39925648339401
Current State [[0.05  0.15  0.4   0.14  0.145 0.85  0.036 0.002 0.51  0.14 ]]
Logits tf.Tensor([[ 0.02408855 -0.26143852  0.54161334]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29158878 0.21916337 0.4892479 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.43, 0.15, 0.145, 0.85, 0.048, 0.002, 0.48600000000000004, 0.15]
0.8512830000000001
1.5071431666666666
Reward 6.308984299853454
Current State [[0.04  0.04  0.43  0.15  0.145 0.85  0.048 0.002 0.486 0.15 ]]
Logits tf.Tensor([[ 0.01931253 -0.22706896  0.5094514 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29289725 0.2289355  0.47816727]], shape=(1, 3), dtype=float32)
Selected action 1
[0.04, 0.08, 0.39, 0.114, 0.145, 0.76, 0.039, 0.003, 0.534, 0.18]
0.7605026666666669
2.8541666666666665
Reward 10.83890945669409
Current State [[0.04  0.08  0.39  0.114 0.145 0.76  0.039 0.003 0.534 0.18 ]]
Logits tf.Tensor([[ 0.01826323 -0.2441319   0.5040127 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29458553 0.22659726 0.4788172 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.02, 0.08, 0.38, 0.14, 0.145, 0.76, 0.039, 0.003, 0.534, 0.18]
0.7605026666666669
2.8541666666666665
Reward 10.83890945669409
Current State [[0.02  0.08  0.38  0.14  0.145 0.76  0.039 0.003 0.534 0.18 ]]
Logits tf.Tensor([[ 0.02147255 -0.23632741  0.503477  ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2948055  0.22781092 0.47738358]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.15, 0.39, 0.162, 0.145, 0.84, 0.044, 0.002, 0.507, 0.2]
0.8392183333333334
1.6946425000000003
Reward 17.935090479075594
Current State [[0.07  0.15  0.39  0.162 0.145 0.84  0.044 0.002 0.507 0.2  ]]
Logits tf.Tensor([[ 0.01915872 -0.272094    0.53746176]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29184276 0.21810192 0.49005532]], shape=(1, 3), dtype=float32)
Selected action 1
[0.04, 0.08, 0.38, 0.125, 0.145, 0.84, 0.044, 0.002, 0.485, 0.23]
0.8397161666666668
2.0672618333333337
Reward 11.485031317738148
Current State [[0.04  0.08  0.38  0.125 0.145 0.84  0.044 0.002 0.485 0.23 ]]
Logits tf.Tensor([[ 0.02023151 -0.25235125  0.50976527]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2947274  0.2244085  0.48086405]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.38, 0.135, 0.145, 0.84, 0.044, 0.002, 0.485, 0.23]
0.8397161666666668
2.0672618333333337
Reward 17.485031317738148
Current State [[0.03  0.15  0.38  0.135 0.145 0.84  0.044 0.002 0.485 0.23 ]]
Logits tf.Tensor([[ 0.02403311 -0.26840764  0.52950484]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2937542  0.21926974 0.48697615]], shape=(1, 3), dtype=float32)
Selected action 2
[0.02, 0.15, 0.33, 0.12, 0.145, 0.86, 0.041, 0.001, 0.45899999999999996, 0.17]
0.8640711666666666
1.4565474999999999
Reward 18.467221548891082
Current State [[0.02  0.15  0.33  0.12  0.145 0.86  0.041 0.001 0.459 0.17 ]]
Logits tf.Tensor([[ 0.02266715 -0.2585214   0.52187073]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29391927 0.22187553 0.4842052 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.15, 0.38, 0.143, 0.145, 0.85, 0.075, 0.001, 0.41500000000000004, 0.04]
0.8475290000000001
1.023213
Reward 19.909893696549844
Current State [[0.06  0.15  0.38  0.143 0.145 0.85  0.075 0.001 0.415 0.04 ]]
Logits tf.Tensor([[ 0.00641152 -0.2413492   0.51626194]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29022616 0.22653508 0.4832388 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.03, 0.04, 0.31, 0.124, 0.145, 0.81, 0.026, 0.007, 0.502, 0.09]
0.8081151666666667
6.727976833333334
Reward 4.235965044180098
Current State [[0.03  0.04  0.31  0.124 0.145 0.81  0.026 0.007 0.502 0.09 ]]
Logits tf.Tensor([[ 0.02177149 -0.2189173   0.4836297 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29646263 0.23304518 0.47049215]], shape=(1, 3), dtype=float32)
Selected action 1
[0.06, 0.08, 0.38, 0.135, 0.145, 0.81, 0.026, 0.007, 0.502, 0.09]
0.8081151666666667
6.727976833333334
Reward 10.235965044180098
Current State [[0.06  0.08  0.38  0.135 0.145 0.81  0.026 0.007 0.502 0.09 ]]
Logits tf.Tensor([[ 0.02186473 -0.23140107  0.50714236]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2940409  0.22825263 0.4777065 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.36, 0.15, 0.145, 0.83, 0.043, 0.002, 0.507, 0.2]
0.825988
2.2172623333333332
Reward 5.322751883246092
Current State [[0.04  0.04  0.36  0.15  0.145 0.83  0.043 0.002 0.507 0.2  ]]
Logits tf.Tensor([[ 0.01766073 -0.23635636  0.50080526]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29439104 0.22835281 0.47725618]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.35, 0.129, 0.145, 0.83, 0.031, 0.003, 0.495, 0.1]
0.833591
3.2232141666666663
Reward 16.80478483523045
Current State [[0.03  0.15  0.35  0.129 0.145 0.83  0.031 0.003 0.495 0.1  ]]
Logits tf.Tensor([[ 0.02494489 -0.24738662  0.527305  ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29289278 0.22306766 0.48403963]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.36, 0.149, 0.145, 0.83, 0.031, 0.003, 0.495, 0.1]
0.833591
3.2232141666666663
Reward 16.80478483523045
Episode: 85 | Average Reward: 283 | Episode Reward: 255 | Loss: 533.983 | Steps: 19 | Worker: 0
Current State [[-0.00743097 -0.00466834  0.00820155  0.00889914  0.00768882 -0.00229281
   0.00644814 -0.0094502  -0.00964862 -0.00762709]]
Logits tf.Tensor([[ 0.00016974 -0.01902666  0.02095882]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.33311197 0.32677844 0.34010956]], shape=(1, 3), dtype=float32)
Selected action 0
[0.06, 0.04, 0.4, 0.153, 0.145, 0.91, 0.041, 0.002, 0.525, 0.15]
0.9082459999999999
1.9738095000000002
Reward 5.754094045990323
Current State [[0.06  0.04  0.4   0.153 0.145 0.91  0.041 0.002 0.525 0.15 ]]
Logits tf.Tensor([[ 0.01170829 -0.24485071  0.53645843]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.28870478 0.22337359 0.48792163]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.37, 0.121, 0.145, 0.82, 0.043, 0.003, 0.503, 0.17]
0.8193041666666667
3.075595
Reward 4.838626883221671
Current State [[0.04  0.04  0.37  0.121 0.145 0.82  0.043 0.003 0.503 0.17 ]]
Logits tf.Tensor([[ 0.01116435 -0.23458035  0.50435674]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29242697 0.22871353 0.47885954]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.37, 0.161, 0.145, 0.82, 0.043, 0.003, 0.503, 0.17]
0.8193041666666667
3.075595
Reward 4.838626883221671
Current State [[0.04  0.04  0.37  0.161 0.145 0.82  0.043 0.003 0.503 0.17 ]]
Logits tf.Tensor([[ 0.01266989 -0.22877122  0.5051817 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29223388 0.22954828 0.4782178 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.03, 0.08, 0.36, 0.142, 0.145, 0.85, 0.042, 0.002, 0.505, 0.17]
0.8547091666666666
1.7815478333333332
Reward 11.854690779544
Current State [[0.03  0.08  0.36  0.142 0.145 0.85  0.042 0.002 0.505 0.17 ]]
Logits tf.Tensor([[ 0.01466704 -0.24378324  0.5235359 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29106525 0.22477439 0.48416042]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.15, 0.37, 0.129, 0.145, 0.82, 0.037, 0.003, 0.562, 0.17]
0.8161574999999999
2.7690478333333326
Reward 16.963970110474385
Current State [[0.06  0.15  0.37  0.129 0.145 0.82  0.037 0.003 0.562 0.17 ]]
Logits tf.Tensor([[ 0.01249015 -0.27495015  0.55306   ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.28841996 0.21636729 0.49521276]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.15, 0.4, 0.145, 0.145, 0.78, 0.032, 0.004, 0.579, 0.2]
0.779241
3.7535713333333334
Reward 16.587716981216072
Current State [[0.08  0.15  0.4   0.145 0.145 0.78  0.032 0.004 0.579 0.2  ]]
Logits tf.Tensor([[ 0.01310696 -0.2797626   0.54862493]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2894815  0.21598779 0.49453074]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.04, 0.4, 0.155, 0.145, 0.78, 0.032, 0.004, 0.579, 0.2]
0.779241
3.7535713333333334
Reward 4.587716981216071
Current State [[0.05  0.04  0.4   0.155 0.145 0.78  0.032 0.004 0.579 0.2  ]]
Logits tf.Tensor([[ 0.01345162 -0.24204442  0.5194016 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29128256 0.22560774 0.4831097 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.15, 0.38, 0.124, 0.145, 0.76, 0.034, 0.003, 0.592, 0.16]
0.7633880000000001
3.196428666666667
Reward 16.71949531322216
Current State [[0.06  0.15  0.38  0.124 0.145 0.76  0.034 0.003 0.592 0.16 ]]
Logits tf.Tensor([[ 0.011949   -0.26877394  0.5448722 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.28908888 0.21833079 0.4925803 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.04, 0.08, 0.36, 0.124, 0.145, 0.85, 0.024, 0.001, 0.58, 0.14]
0.8465619999999999
1.3630953333333335
Reward 12.625525357452592
Current State [[0.04  0.08  0.36  0.124 0.145 0.85  0.024 0.001 0.58  0.14 ]]
Logits tf.Tensor([[ 0.01670957 -0.25001654  0.5448062 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.28888506 0.22125211 0.4898629 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.35, 0.138, 0.145, 0.85, 0.024, 0.001, 0.58, 0.14]
0.8465619999999999
1.3630953333333335
Reward 18.62552535745259
Current State [[0.03  0.15  0.35  0.138 0.145 0.85  0.024 0.001 0.58  0.14 ]]
Logits tf.Tensor([[ 0.02004547 -0.26509416  0.56421137]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.28776318 0.2163718  0.49586502]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.15, 0.38, 0.153, 0.145, 0.82, 0.024, 0.004, 0.6519999999999999, 0.09]
0.8155978333333334
4.310118833333333
Reward 16.51174000402048
Current State [[0.06  0.15  0.38  0.153 0.145 0.82  0.024 0.004 0.652 0.09 ]]
Logits tf.Tensor([[ 0.01507944 -0.26530683  0.5795008 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.28458232 0.21499962 0.50041807]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.38, 0.13, 0.145, 0.92, 0.041, 0.002, 0.47400000000000003, 0.12]
0.9154135
2.1583333333333328
Reward 5.57321635465198
Current State [[0.04  0.04  0.38  0.13  0.145 0.92  0.041 0.002 0.474 0.12 ]]
Logits tf.Tensor([[ 0.01437995 -0.23661976  0.51804876]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29130706 0.2266435  0.4820495 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.03, 0.04, 0.41, 0.164, 0.145, 0.92, 0.041, 0.002, 0.47400000000000003, 0.12]
0.9154135
2.1583333333333328
Reward 5.57321635465198
Current State [[0.03  0.04  0.41  0.164 0.145 0.92  0.041 0.002 0.474 0.12 ]]
Logits tf.Tensor([[ 0.01841863 -0.22809729  0.52307934]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29087165 0.22732173 0.48180664]], shape=(1, 3), dtype=float32)
Selected action 0
[0.03, 0.04, 0.36, 0.161, 0.145, 0.67, 0.017, 0.008, 1.024, 0.11]
0.6721726666666666
8.186904833333335
Reward 4.090906584437992
Current State [[0.03  0.04  0.36  0.161 0.145 0.67  0.017 0.008 1.024 0.11 ]]
Logits tf.Tensor([[-0.00383288 -0.27011225  0.6772534 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26721907 0.20474993 0.528031  ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.34, 0.118, 0.145, 0.74, 0.015, 0.005, 0.786, 0.07]
0.7380398333333332
4.820238166666666
Reward 16.36567535784294
Current State [[0.04  0.15  0.34  0.118 0.145 0.74  0.015 0.005 0.786 0.07 ]]
Logits tf.Tensor([[ 0.01035945 -0.25853226  0.59965795]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2803516  0.21425201 0.50539637]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.34, 0.165, 0.145, 0.74, 0.015, 0.005, 0.786, 0.07]
0.7380398333333332
4.820238166666666
Reward 16.36567535784294
Current State [[0.05  0.15  0.34  0.165 0.145 0.74  0.015 0.005 0.786 0.07 ]]
Logits tf.Tensor([[ 0.01101418 -0.25622153  0.60199046]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.28001454 0.21434908 0.5056364 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.02, 0.08, 0.33, 0.14, 0.145, 0.84, 0.027, 0.003, 0.645, 0.07]
0.8393281666666667
3.0392858333333335
Reward 10.881497710609494
Current State [[0.02  0.08  0.33  0.14  0.145 0.84  0.027 0.003 0.645 0.07 ]]
Logits tf.Tensor([[ 0.01620784 -0.24145447  0.55972683]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.28613022 0.22113752 0.49273232]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.33, 0.127, 0.145, 0.88, 0.034, 0.001, 0.51, 0.12]
0.8769895000000001
0.8339285000000001
Reward 21.512676260501948
Current State [[0.05  0.15  0.33  0.127 0.145 0.88  0.034 0.001 0.51  0.12 ]]
Logits tf.Tensor([[ 0.01386334 -0.2645994   0.5487259 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.28867024 0.21850796 0.4928218 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.3, 0.146, 0.145, 0.86, 0.03, 0.001, 0.577, 0.08]
0.8603191666666667
1.318452
Reward 6.808465064896913
Current State [[0.04  0.04  0.3   0.146 0.145 0.86  0.03  0.001 0.577 0.08 ]]
Logits tf.Tensor([[ 0.01128107 -0.232561    0.5260096 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.28928527 0.22668722 0.48402756]], shape=(1, 3), dtype=float32)
Selected action 1
[0.06, 0.08, 0.33, 0.164, 0.145, 0.86, 0.03, 0.001, 0.577, 0.08]
0.8603191666666667
1.318452
Reward 12.808465064896913
Episode: 86 | Average Reward: 282 | Episode Reward: 229 | Loss: 470.56 | Steps: 19 | Worker: 0
Current State [[ 0.00976482 -0.00793449  0.00482345 -0.00018764  0.00889027 -0.00386683
   0.00394746  0.00454116 -0.00661539  0.00502082]]
Logits tf.Tensor([[ 0.00273518 -0.02503644  0.02194892]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.33422348 0.32506925 0.34070727]], shape=(1, 3), dtype=float32)
Selected action 1
[0.02, 0.08, 0.27, 0.123, 0.145, 0.91, 0.029, 0.001, 0.5269999999999999, 0.07]
0.9091898333333333
0.9916663333333334
Reward 14.517352827611385
Current State [[0.02  0.08  0.27  0.123 0.145 0.91  0.029 0.001 0.527 0.07 ]]
Logits tf.Tensor([[ 0.01221915 -0.24510978  0.5324855 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2893862  0.2237285  0.48688528]], shape=(1, 3), dtype=float32)
Selected action 1
[0.03, 0.08, 0.33, 0.115, 0.145, 0.93, 0.033, 0.001, 0.523, 0.11]
0.9251828333333332
0.8910716666666666
Reward 15.410227919152172
Current State [[0.03  0.08  0.33  0.115 0.145 0.93  0.033 0.001 0.523 0.11 ]]
Logits tf.Tensor([[ 0.01180972 -0.25362006  0.5456153 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.28799468 0.22085631 0.49114907]], shape=(1, 3), dtype=float32)
Selected action 1
[0.06, 0.08, 0.35, 0.16, 0.145, 0.93, 0.033, 0.001, 0.523, 0.11]
0.9251828333333332
0.8910716666666666
Reward 15.410227919152172
Current State [[0.06  0.08  0.35  0.16  0.145 0.93  0.033 0.001 0.523 0.11 ]]
Logits tf.Tensor([[ 0.00981465 -0.25265455  0.54950476]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.28697494 0.22072677 0.49229833]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.33, 0.137, 0.145, 0.72, 0.031, 0.001, 0.577, 0.16]
0.7211861666666667
1.2922611666666663
Reward 18.2718582757104
Current State [[0.03  0.15  0.33  0.137 0.145 0.72  0.031 0.001 0.577 0.16 ]]
Logits tf.Tensor([[ 0.01036294 -0.2544214   0.5310635 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.28980651 0.22238925 0.4878042 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.04, 0.35, 0.125, 0.145, 0.89, 0.037, 0.001, 0.542, 0.15]
0.8856308333333334
0.9261901666666666
Reward 8.79923830268875
Current State [[0.05  0.04  0.35  0.125 0.145 0.89  0.037 0.001 0.542 0.15 ]]
Logits tf.Tensor([[ 0.00643239 -0.24815813  0.5343797 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.28812778 0.22336641 0.4885058 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.37, 0.156, 0.145, 0.89, 0.037, 0.001, 0.542, 0.15]
0.8856308333333334
0.9261901666666666
Reward 20.79923830268875
Current State [[0.05  0.15  0.37  0.156 0.145 0.89  0.037 0.001 0.542 0.15 ]]
Logits tf.Tensor([[ 0.0123558 -0.2705785  0.5720244]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2854157  0.21508051 0.49950388]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.35, 0.145, 0.145, 0.84, 0.028, 0.003, 0.5700000000000001, 0.15]
0.8424233333333333
3.1333328333333337
Reward 16.849431250842613
Current State [[0.04  0.15  0.35  0.145 0.145 0.84  0.028 0.003 0.57  0.15 ]]
Logits tf.Tensor([[ 0.01417765 -0.2673484   0.56368697]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.28677666 0.21641065 0.4968127 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.35, 0.126, 0.145, 0.86, 0.033, 0.002, 0.487, 0.07]
0.8612323333333333
2.38631
Reward 17.26773521176331
Current State [[0.04  0.15  0.35  0.126 0.145 0.86  0.033 0.002 0.487 0.07 ]]
Logits tf.Tensor([[ 0.01325896 -0.24952233  0.54366696]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.28830612 0.22168146 0.49001244]], shape=(1, 3), dtype=float32)
Selected action 0
[0.03, 0.04, 0.36, 0.147, 0.145, 0.86, 0.033, 0.002, 0.487, 0.07]
0.8612323333333333
2.38631
Reward 5.267735211763309
Current State [[0.03  0.04  0.36  0.147 0.145 0.86  0.033 0.002 0.487 0.07 ]]
Logits tf.Tensor([[ 0.01311949 -0.21806125  0.51137227]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29074508 0.23073412 0.47852078]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.37, 0.149, 0.145, 0.88, 0.034, 0.001, 0.529, 0.14]
0.8773168333333332
1.4095241666666665
Reward 6.633357626332789
Current State [[0.04  0.04  0.37  0.149 0.145 0.88  0.034 0.001 0.529 0.14 ]]
Logits tf.Tensor([[ 0.01109748 -0.23665725  0.5308109 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.28884226 0.22545621 0.48570144]], shape=(1, 3), dtype=float32)
Selected action 1
[0.03, 0.08, 0.31, 0.123, 0.145, 0.85, 0.027, 0.002, 0.585, 0.14]
0.8484996666666665
1.6184521666666667
Reward 12.08871729159951
Current State [[0.03  0.08  0.31  0.123 0.145 0.85  0.027 0.002 0.585 0.14 ]]
Logits tf.Tensor([[ 0.01075895 -0.25204268  0.5447348 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2878033  0.22129036 0.49090624]], shape=(1, 3), dtype=float32)
Selected action 1
[0.06, 0.08, 0.35, 0.167, 0.145, 0.81, 0.026, 0.005, 0.495, 0.13]
0.811841
5.185715000000001
Reward 10.379403913945325
Current State [[0.06  0.08  0.35  0.167 0.145 0.81  0.026 0.005 0.495 0.13 ]]
Logits tf.Tensor([[ 0.01319535 -0.23282084  0.512717  ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29155862 0.22797245 0.480469  ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.34, 0.174, 0.145, 0.81, 0.026, 0.005, 0.495, 0.13]
0.811841
5.185715000000001
Reward 16.379403913945325
Current State [[0.05  0.15  0.34  0.174 0.145 0.81  0.026 0.005 0.495 0.13 ]]
Logits tf.Tensor([[ 0.01649961 -0.24881673  0.532072  ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2905659  0.22285339 0.48658073]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.34, 0.144, 0.145, 0.91, 0.039, 0.003, 0.512, 0.1]
0.9051101666666667
2.724405166666666
Reward 5.134083970160148
Current State [[0.04  0.04  0.34  0.144 0.145 0.91  0.039 0.003 0.512 0.1  ]]
Logits tf.Tensor([[ 0.00925228 -0.2374781   0.526658  ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.28909913 0.22588801 0.48501286]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.34, 0.137, 0.145, 0.78, 0.038, 0.006, 0.508, 0.12]
0.7774446666666667
5.624999999999999
Reward 16.3066689644862
Current State [[0.03  0.15  0.34  0.137 0.145 0.78  0.038 0.006 0.508 0.12 ]]
Logits tf.Tensor([[ 0.01227791 -0.24832669  0.5291051 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29008338 0.22353406 0.48638263]], shape=(1, 3), dtype=float32)
Selected action 1
[0.02, 0.08, 0.35, 0.152, 0.145, 0.78, 0.038, 0.006, 0.508, 0.12]
0.7774446666666667
5.624999999999999
Reward 10.306668964486201
Current State [[0.02  0.08  0.35  0.152 0.145 0.78  0.038 0.006 0.508 0.12 ]]
Logits tf.Tensor([[ 0.01285881 -0.22470403  0.51042604]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29126817 0.22967872 0.47905317]], shape=(1, 3), dtype=float32)
Selected action 0
[0.06, 0.04, 0.36, 0.154, 0.145, 0.81, 0.033, 0.003, 0.665, 0.14]
0.8115706666666667
2.522619166666667
Reward 5.08588741743679
Current State [[0.06  0.04  0.36  0.154 0.145 0.81  0.033 0.003 0.665 0.14 ]]
Logits tf.Tensor([[ 0.00294014 -0.24994761  0.5580233 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.28420064 0.22069745 0.49510193]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.39, 0.131, 0.145, 0.69, 0.019, 0.002, 0.731, 0.09]
0.6878203333333335
2.3613095
Reward 16.948542115884884
Current State [[0.05  0.15  0.39  0.131 0.145 0.69  0.019 0.002 0.731 0.09 ]]
Logits tf.Tensor([[ 0.00674539 -0.2492005   0.58069164]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.28173438 0.2181142  0.50015146]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.39, 0.16, 0.145, 0.69, 0.019, 0.002, 0.731, 0.09]
0.6878203333333335
2.3613095
Reward 16.948542115884884
Current State [[0.04  0.15  0.39  0.16  0.145 0.69  0.019 0.002 0.731 0.09 ]]
Logits tf.Tensor([[ 0.00883608 -0.24397211  0.58104455]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2817859  0.21883969 0.4993744 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.03, 0.04, 0.42, 0.158, 0.145, 0.77, 0.032, 0.003, 0.755, 0.13]
0.7661636666666668
3.3672613333333334
Reward 4.671453121704176
Episode: 87 | Average Reward: 282 | Episode Reward: 253 | Loss: 456.808 | Steps: 19 | Worker: 0
Current State [[ 0.00813672 -0.0015862  -0.00049742 -0.00258065 -0.00046696 -0.00870867
  -0.00675361  0.00258467 -0.00779608 -0.0070797 ]]
Logits tf.Tensor([[ 0.00388745 -0.0177209   0.01357712]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.33463168 0.32747844 0.33788994]], shape=(1, 3), dtype=float32)
Selected action 1
[0.03, 0.08, 0.41, 0.123, 0.145, 0.75, 0.035, 0.004, 0.763, 0.14]
0.7457883333333334
4.186309499999999
Reward 10.46646977317194
Current State [[0.03  0.08  0.41  0.123 0.145 0.75  0.035 0.004 0.763 0.14 ]]
Logits tf.Tensor([[ 0.00111223 -0.25655457  0.5919424 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2794592  0.21598083 0.50455993]], shape=(1, 3), dtype=float32)
Selected action 2
[0.02, 0.15, 0.38, 0.15, 0.145, 0.69, 0.029, 0.003, 0.807, 0.13]
0.6927379999999999
2.7571430000000006
Reward 16.772876209250693
Current State [[0.02  0.15  0.38  0.15  0.145 0.69  0.029 0.003 0.807 0.13 ]]
Logits tf.Tensor([[ 0.00258383 -0.26070789  0.61013174]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.27743548 0.21321407 0.5093505 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.02, 0.08, 0.35, 0.114, 0.145, 0.69, 0.029, 0.003, 0.807, 0.13]
0.6927379999999999
2.7571430000000006
Reward 10.772876209250693
Current State [[0.02  0.08  0.35  0.114 0.145 0.69  0.029 0.003 0.807 0.13 ]]
Logits tf.Tensor([[-5.2834325e-04 -2.5095001e-01  5.9046674e-01]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.27899787 0.21719216 0.50381   ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.15, 0.4, 0.177, 0.145, 0.74, 0.021, 0.006, 0.714, 0.07]
0.7449776666666666
5.890475333333333
Reward 16.260684367028464
Current State [[0.08  0.15  0.4   0.177 0.145 0.74  0.021 0.006 0.714 0.07 ]]
Logits tf.Tensor([[ 0.00229089 -0.25408763  0.5951166 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2791002  0.21598144 0.50491834]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.39, 0.131, 0.145, 0.8, 0.074, 0.003, 0.41, 0.18]
0.8043136666666668
2.842857333333334
Reward 16.911376950815892
Current State [[0.05  0.15  0.39  0.131 0.145 0.8   0.074 0.003 0.41  0.18 ]]
Logits tf.Tensor([[-0.0016466  -0.25874656  0.51813614]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.28943956 0.22382097 0.48673952]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.41, 0.149, 0.145, 0.8, 0.074, 0.003, 0.41, 0.18]
0.8043136666666668
2.842857333333334
Reward 16.911376950815892
Current State [[0.04  0.15  0.41  0.149 0.145 0.8   0.074 0.003 0.41  0.18 ]]
Logits tf.Tensor([[ 0.00311381 -0.25412196  0.52061784]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.28976938 0.22404557 0.48618507]], shape=(1, 3), dtype=float32)
Selected action 0
[0.03, 0.04, 0.35, 0.136, 0.145, 0.93, 0.042, 0.001, 0.454, 0.09]
0.9256378333333332
1.2404758333333332
Reward 7.378400849983474
Current State [[0.03  0.04  0.35  0.136 0.145 0.93  0.042 0.001 0.454 0.09 ]]
Logits tf.Tensor([[ 0.00844449 -0.23195162  0.5170554 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.28991425 0.22796431 0.48212147]], shape=(1, 3), dtype=float32)
Selected action 0
[0.06, 0.04, 0.44, 0.135, 0.145, 0.82, 0.056, 0.003, 0.441, 0.16]
0.8226621666666667
2.506546833333333
Reward 5.115604524866148
Current State [[0.06  0.04  0.44  0.135 0.145 0.82  0.056 0.003 0.441 0.16 ]]
Logits tf.Tensor([[ 0.0018645 -0.2278951  0.5052277]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2899391  0.23042175 0.47963917]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.04, 0.43, 0.158, 0.145, 0.82, 0.056, 0.003, 0.441, 0.16]
0.8226621666666667
2.506546833333333
Reward 5.115604524866148
Current State [[0.05  0.04  0.43  0.158 0.145 0.82  0.056 0.003 0.441 0.16 ]]
Logits tf.Tensor([[ 0.00389586 -0.22236125  0.5039165 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.29016897 0.2314135  0.47841758]], shape=(1, 3), dtype=float32)
Selected action 1
[0.02, 0.08, 0.37, 0.138, 0.145, 0.79, 0.035, 0.003, 0.558, 0.15]
0.7928528333333333
2.626190333333333
Reward 10.99607220264303
Current State [[0.02  0.08  0.37  0.138 0.145 0.79  0.035 0.003 0.558 0.15 ]]
Logits tf.Tensor([[ 0.00916486 -0.23873012  0.5328319 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.28829667 0.2249988  0.4867045 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.15, 0.39, 0.133, 0.145, 0.86, 0.041, 0.001, 0.502, 0.12]
0.8605068333333333
1.3083338333333334
Reward 18.839045844540873
Current State [[0.07  0.15  0.39  0.133 0.145 0.86  0.041 0.001 0.502 0.12 ]]
Logits tf.Tensor([[ 0.00546507 -0.26531753  0.55776644]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.28571194 0.21793601 0.49635208]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.39, 0.164, 0.145, 0.86, 0.041, 0.001, 0.502, 0.12]
0.8605068333333333
1.3083338333333334
Reward 18.839045844540873
Current State [[0.04  0.15  0.39  0.164 0.145 0.86  0.041 0.001 0.502 0.12 ]]
Logits tf.Tensor([[ 0.01072548 -0.2542263   0.5582802 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2860197  0.21944658 0.49453375]], shape=(1, 3), dtype=float32)
Selected action 1
[0.03, 0.08, 0.38, 0.171, 0.145, 0.83, 0.038, 0.002, 0.524, 0.19]
0.8282736666666666
2.4095231666666668
Reward 11.187431494063365
Current State [[0.03  0.08  0.38  0.171 0.145 0.83  0.038 0.002 0.524 0.19 ]]
Logits tf.Tensor([[ 0.0107756  -0.24316199  0.5343884 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.28869563 0.2239528  0.48735157]], shape=(1, 3), dtype=float32)
Selected action 1
[0.04, 0.08, 0.37, 0.132, 0.145, 0.8, 0.041, 0.002, 0.48600000000000004, 0.08]
0.7967013333333334
1.9226189999999999
Reward 11.525134424698859
Current State [[0.04  0.08  0.37  0.132 0.145 0.8   0.041 0.002 0.486 0.08 ]]
Logits tf.Tensor([[ 0.00575013 -0.2254791   0.51556957]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.28913867 0.22944817 0.48141316]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.15, 0.39, 0.165, 0.145, 0.8, 0.041, 0.002, 0.48600000000000004, 0.08]
0.7967013333333334
1.9226189999999999
Reward 17.52513442469886
Current State [[0.06  0.15  0.39  0.165 0.145 0.8   0.041 0.002 0.486 0.08 ]]
Logits tf.Tensor([[ 0.0071019  -0.24297549  0.5375545 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.28748503 0.22387627 0.48863876]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.38, 0.158, 0.145, 0.87, 0.039, 0.001, 0.434, 0.11]
0.8701900000000001
0.7678573333333333
Reward 22.157437266960105
Current State [[0.05  0.15  0.38  0.158 0.145 0.87  0.039 0.001 0.434 0.11 ]]
Logits tf.Tensor([[ 0.01194133 -0.24776274  0.53838575]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.28866845 0.22264414 0.4886875 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.04, 0.08, 0.38, 0.121, 0.145, 0.91, 0.051, 0.001, 0.518, 0.09]
0.9087481666666666
0.6815476666666668
Reward 17.87313979037983
Current State [[0.04  0.08  0.38  0.121 0.145 0.91  0.051 0.001 0.518 0.09 ]]
Logits tf.Tensor([[ 0.00263629 -0.2485774   0.55228174]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.28486013 0.2215802  0.49355966]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.37, 0.124, 0.145, 0.82, 0.043, 0.002, 0.517, 0.16]
0.8237381666666669
2.394047499999999
Reward 17.188954727246113
Current State [[0.04  0.15  0.37  0.124 0.145 0.82  0.043 0.002 0.517 0.16 ]]
Logits tf.Tensor([[ 0.00696695 -0.26510265  0.5491588 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.28722644 0.21880946 0.49396405]], shape=(1, 3), dtype=float32)
Selected action 1
[0.03, 0.08, 0.36, 0.147, 0.145, 0.82, 0.043, 0.002, 0.517, 0.16]
0.8237381666666669
2.394047499999999
Reward 11.188954727246115
Current State [[0.03  0.08  0.36  0.147 0.145 0.82  0.043 0.002 0.517 0.16 ]]
Logits tf.Tensor([[ 0.00654003 -0.2401184   0.52879655]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.28841424 0.22536907 0.48621663]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.04, 0.39, 0.174, 0.145, 0.86, 0.043, 0.003, 0.51, 0.23]
0.8600425000000002
2.897619166666666
Reward 4.973219819827567
Episode: 88 | Average Reward: 282 | Episode Reward: 267 | Loss: 590.001 | Steps: 19 | Worker: 0
Current State [[-0.00355619  0.00391997 -0.00396138  0.00270802 -0.00380647 -0.00587746
   0.00893652  0.00953967  0.00621433 -0.00540555]]
Logits tf.Tensor([[ 0.00098527 -0.02093717  0.01988701]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.33362272 0.3263885  0.33998877]], shape=(1, 3), dtype=float32)
Selected action 0
[0.06, 0.04, 0.41, 0.142, 0.145, 0.84, 0.071, 0.014, 0.438, 0.17]
0.8361943333333334
14.313095333333333
Reward 4.002829595138238
Current State [[0.06  0.04  0.41  0.142 0.145 0.84  0.071 0.014 0.438 0.17 ]]
Logits tf.Tensor([[-0.00619119 -0.2330268   0.50591534]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.28852913 0.22997265 0.4814982 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.38, 0.151, 0.145, 0.84, 0.071, 0.014, 0.438, 0.17]
0.8361943333333334
14.313095333333333
Reward 16.002829595138238
Current State [[0.04  0.15  0.38  0.151 0.145 0.84  0.071 0.014 0.438 0.17 ]]
Logits tf.Tensor([[-9.9572819e-05 -2.5835723e-01  5.3623402e-01]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.28718114 0.22181763 0.4910013 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.38, 0.147, 0.145, 0.86, 0.038, 0.002, 0.5389999999999999, 0.16]
0.8592704999999999
1.566667333333333
Reward 18.21933277941979
Current State [[0.05  0.15  0.38  0.147 0.145 0.86  0.038 0.002 0.539 0.16 ]]
Logits tf.Tensor([[ 0.00410264 -0.26846725  0.56978005]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.28392473 0.21618603 0.49988922]], shape=(1, 3), dtype=float32)
Selected action 1
[0.02, 0.08, 0.37, 0.134, 0.145, 0.87, 0.042, 0.002, 0.492, 0.16]
0.8715548333333332
1.5583326666666664
Reward 12.278476045842382
Current State [[0.02  0.08  0.37  0.134 0.145 0.87  0.042 0.002 0.492 0.16 ]]
Logits tf.Tensor([[ 0.00535172 -0.24152283  0.5357046 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2872927  0.22444415 0.4882631 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.15, 0.39, 0.156, 0.145, 0.87, 0.042, 0.002, 0.492, 0.16]
0.8715548333333332
1.5583326666666664
Reward 18.278476045842382
Current State [[0.06  0.15  0.39  0.156 0.145 0.87  0.042 0.002 0.492 0.16 ]]
Logits tf.Tensor([[ 0.00414145 -0.2648541   0.5595651 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2851582  0.21790266 0.4969392 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.38, 0.162, 0.145, 0.78, 0.023, 0.002, 0.593, 0.07]
0.7836991666666667
2.338095833333334
Reward 17.147754430399296
Current State [[0.03  0.15  0.38  0.162 0.145 0.78  0.023 0.002 0.593 0.07 ]]
Logits tf.Tensor([[ 0.00915726 -0.23923425  0.5622585 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.28419662 0.22168882 0.49411458]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.04, 0.39, 0.133, 0.145, 0.86, 0.047, 0.001, 0.5469999999999999, 0.19]
0.8606626666666667
1.0535716666666668
Reward 7.834270525860015
Current State [[0.05  0.04  0.39  0.133 0.145 0.86  0.047 0.001 0.547 0.19 ]]
Logits tf.Tensor([[-0.00266639 -0.24753015  0.54239744]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.28510097 0.22318022 0.4917189 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.03, 0.08, 0.35, 0.163, 0.145, 0.86, 0.047, 0.001, 0.5469999999999999, 0.19]
0.8606626666666667
1.0535716666666668
Reward 13.834270525860015
Current State [[0.03  0.08  0.35  0.163 0.145 0.86  0.047 0.001 0.547 0.19 ]]
Logits tf.Tensor([[-1.2180535e-04 -2.5057977e-01  5.5016196e-01]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.28472272 0.22164075 0.49363655]], shape=(1, 3), dtype=float32)
Selected action 2
[0.02, 0.15, 0.34, 0.154, 0.145, 0.89, 0.054, 0.002, 0.485, 0.21]
0.8865803333333334
1.6226193333333332
Reward 18.208004022593446
Current State [[0.02  0.15  0.34  0.154 0.145 0.89  0.054 0.002 0.485 0.21 ]]
Logits tf.Tensor([[ 0.00333395 -0.26869333  0.55842346]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2853938  0.21742254 0.49718365]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.15, 0.36, 0.136, 0.145, 0.77, 0.028, 0.002, 0.557, 0.08]
0.7708090000000001
1.6720236666666668
Reward 17.758448438752133
Current State [[0.06  0.15  0.36  0.136 0.145 0.77  0.028 0.002 0.557 0.08 ]]
Logits tf.Tensor([[ 0.00229673 -0.24705662  0.5470721 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.28542677 0.22243439 0.49213883]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.36, 0.174, 0.145, 0.81, 0.024, 0.002, 0.5740000000000001, 0.08]
0.8149196666666665
1.8499999999999999
Reward 17.65478419198482
Current State [[0.05  0.15  0.36  0.174 0.145 0.81  0.024 0.002 0.574 0.08 ]]
Logits tf.Tensor([[ 0.0063485  -0.24698174  0.56446266]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2838018  0.22029023 0.49590793]], shape=(1, 3), dtype=float32)
Selected action 2
[0.01, 0.15, 0.34, 0.156, 0.145, 0.81, 0.024, 0.002, 0.5740000000000001, 0.08]
0.8149196666666665
1.8499999999999999
Reward 17.65478419198482
Current State [[0.01  0.15  0.34  0.156 0.145 0.81  0.024 0.002 0.574 0.08 ]]
Logits tf.Tensor([[ 0.01087815 -0.23976685  0.56212157]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.28459966 0.2215035  0.49389693]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.36, 0.143, 0.145, 0.72, 0.022, 0.006, 0.9369999999999999, 0.13]
0.7212735
5.6958335
Reward 16.26130881967643
Current State [[0.04  0.15  0.36  0.143 0.145 0.72  0.022 0.006 0.937 0.13 ]]
Logits tf.Tensor([[-0.01249928 -0.2862873   0.6744071 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26680538 0.20290367 0.5302909 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.0, 0.08, 0.31, 0.096, 0.145, 0.72, 0.022, 0.006, 0.9369999999999999, 0.13]
0.7212735
5.6958335
Reward 10.26130881967643
Current State [[0.    0.08  0.31  0.096 0.145 0.72  0.022 0.006 0.937 0.13 ]]
Logits tf.Tensor([[-0.01519299 -0.27214047  0.6537267 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26841775 0.20759666 0.5239856 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.01, 0.15, 0.32, 0.111, 0.145, 0.64, 0.016, 0.007, 0.8039999999999999, 0.11]
0.636519
6.829761833333333
Reward 16.132773286928558
Current State [[0.01  0.15  0.32  0.111 0.145 0.64  0.016 0.007 0.804 0.11 ]]
Logits tf.Tensor([[-0.00463296 -0.251447    0.59662926]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.27733818 0.21668044 0.5059814 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.36, 0.134, 0.145, 0.85, 0.041, 0.001, 0.537, 0.15]
0.8451506666666667
1.3553568333333328
Reward 18.639934415822957
Current State [[0.05  0.15  0.36  0.134 0.145 0.85  0.041 0.001 0.537 0.15 ]]
Logits tf.Tensor([[ 0.00095522 -0.26753464  0.5653766 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.28385198 0.21701424 0.49913377]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.33, 0.176, 0.145, 0.85, 0.041, 0.001, 0.537, 0.15]
0.8451506666666667
1.3553568333333328
Reward 6.639934415822957
Current State [[0.04  0.04  0.33  0.176 0.145 0.85  0.041 0.001 0.537 0.15 ]]
Logits tf.Tensor([[-0.00082282 -0.23270017  0.52801055]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.28653336 0.22723338 0.4862332 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.37, 0.18, 0.145, 0.84, 0.035, 0.002, 0.5589999999999999, 0.14]
0.8424011666666666
1.9297616666666664
Reward 5.634924591042659
Current State [[0.04  0.04  0.37  0.18  0.145 0.84  0.035 0.002 0.559 0.14 ]]
Logits tf.Tensor([[ 0.00275748 -0.22919248  0.53868634]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.28554943 0.22643661 0.48801392]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.31, 0.12, 0.145, 0.82, 0.025, 0.002, 0.615, 0.1]
0.8180788333333333
2.366666333333333
Reward 17.196351465018942
Current State [[0.04  0.15  0.31  0.12  0.145 0.82  0.025 0.002 0.615 0.1  ]]
Logits tf.Tensor([[ 0.00242283 -0.26222548  0.57379353]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2826321  0.21691333 0.50045455]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.31, 0.188, 0.145, 0.82, 0.025, 0.002, 0.615, 0.1]
0.8180788333333333
2.366666333333333
Reward 17.196351465018942
Episode: 89 | Average Reward: 282 | Episode Reward: 286 | Loss: 675.54 | Steps: 19 | Worker: 0
Current State [[-0.00797431 -0.00259261 -0.0060666  -0.00529773 -0.00496109  0.00675437
   0.00469057 -0.00881373  0.0064749  -0.00046951]]
Logits tf.Tensor([[-0.00117174 -0.0201019   0.02778323]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3321568  0.32592815 0.34191498]], shape=(1, 3), dtype=float32)
Selected action 1
[0.04, 0.08, 0.32, 0.158, 0.145, 0.85, 0.024, 0.002, 0.5650000000000001, 0.09]
0.8529796666666666
1.6982140000000001
Reward 11.97212805325611
Current State [[0.04  0.08  0.32  0.158 0.145 0.85  0.024 0.002 0.565 0.09 ]]
Logits tf.Tensor([[-0.00060029 -0.23599498  0.55110073]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2835703  0.22409391 0.49233577]], shape=(1, 3), dtype=float32)
Selected action 0
[0.03, 0.04, 0.34, 0.169, 0.145, 0.9, 0.03, 0.002, 0.46900000000000003, 0.08]
0.9010453333333334
1.6827383333333332
Reward 6.14884781648517
Current State [[0.03  0.04  0.34  0.169 0.145 0.9   0.03  0.002 0.469 0.08 ]]
Logits tf.Tensor([[ 0.00354789 -0.21975726  0.5203498 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.28764334 0.23007749 0.48227918]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.37, 0.19, 0.145, 0.9, 0.03, 0.002, 0.46900000000000003, 0.08]
0.9010453333333334
1.6827383333333332
Reward 18.14884781648517
Current State [[0.05  0.15  0.37  0.19  0.145 0.9   0.03  0.002 0.469 0.08 ]]
Logits tf.Tensor([[ 0.00400952 -0.24408987  0.5623491 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.28344268 0.22116533 0.49539202]], shape=(1, 3), dtype=float32)
Selected action 1
[0.03, 0.08, 0.35, 0.131, 0.145, 0.91, 0.044, 0.001, 0.491, 0.12]
0.9076434999999999
1.1863093333333334
Reward 13.498084912833106
Current State [[0.03  0.08  0.35  0.131 0.145 0.91  0.044 0.001 0.491 0.12 ]]
Logits tf.Tensor([[-0.00378821 -0.24475779  0.5469931 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.28405273 0.22322725 0.49272004]], shape=(1, 3), dtype=float32)
Selected action 0
[0.02, 0.04, 0.33, 0.162, 0.145, 0.91, 0.044, 0.001, 0.491, 0.12]
0.9076434999999999
1.1863093333333334
Reward 7.4980849128331055
Current State [[0.02  0.04  0.33  0.162 0.145 0.91  0.044 0.001 0.491 0.12 ]]
Logits tf.Tensor([[-0.00233336 -0.231005    0.53071856]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.28573754 0.22732987 0.4869326 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.34, 0.154, 0.145, 0.82, 0.032, 0.002, 0.588, 0.15]
0.8206406666666667
1.9089286666666667
Reward 17.601834245278248
Current State [[0.03  0.15  0.34  0.154 0.145 0.82  0.032 0.002 0.588 0.15 ]]
Logits tf.Tensor([[-0.00166754 -0.26191205  0.5760138 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2814709  0.21697554 0.5015536 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.34, 0.133, 0.145, 0.86, 0.026, 0.003, 0.5269999999999999, 0.1]
0.8583729999999999
2.5488098333333338
Reward 17.155087977358605
Current State [[0.03  0.15  0.34  0.133 0.145 0.86  0.026 0.003 0.527 0.1  ]]
Logits tf.Tensor([[ 0.00299637 -0.25271294  0.5659991 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.28326172 0.21934855 0.4973898 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.34, 0.156, 0.145, 0.86, 0.026, 0.003, 0.5269999999999999, 0.1]
0.8583729999999999
2.5488098333333338
Reward 17.155087977358605
Current State [[0.04  0.15  0.34  0.156 0.145 0.86  0.026 0.003 0.527 0.1  ]]
Logits tf.Tensor([[ 0.00213787 -0.2515391   0.5666133 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.28292805 0.21953587 0.4975361 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.04, 0.35, 0.156, 0.145, 0.77, 0.025, 0.004, 0.501, 0.05]
0.7697319999999999
3.7982145000000003
Reward 4.567159578618318
Current State [[0.05  0.04  0.35  0.156 0.145 0.77  0.025 0.004 0.501 0.05 ]]
Logits tf.Tensor([[-0.00151322 -0.20523885  0.5063045 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.28757554 0.2345714  0.4778531 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.01, 0.04, 0.31, 0.117, 0.145, 0.88, 0.032, 0.002, 0.40700000000000003, 0.05]
0.8820526666666666
1.6958333333333335
Reward 6.066631296213065
Current State [[0.01  0.04  0.31  0.117 0.145 0.88  0.032 0.002 0.407 0.05 ]]
Logits tf.Tensor([[ 0.00495481 -0.21083754  0.4892777 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2916321  0.23502705 0.4733409 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.03, 0.08, 0.32, 0.124, 0.145, 0.79, 0.02, 0.006, 0.504, 0.07]
0.7902038333333332
6.113690166666667
Reward 10.271532098350887
Current State [[0.03  0.08  0.32  0.124 0.145 0.79  0.02  0.006 0.504 0.07 ]]
Logits tf.Tensor([[ 0.00384937 -0.22014676  0.5150275 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2884694  0.23057884 0.48095185]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.34, 0.168, 0.145, 0.79, 0.02, 0.006, 0.504, 0.07]
0.7902038333333332
6.113690166666667
Reward 16.27153209835089
Current State [[0.04  0.15  0.34  0.168 0.145 0.79  0.02  0.006 0.504 0.07 ]]
Logits tf.Tensor([[ 0.00558065 -0.23286062  0.5407102 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2860801  0.22538963 0.48853028]], shape=(1, 3), dtype=float32)
Selected action 2
[0.02, 0.15, 0.33, 0.14, 0.145, 0.83, 0.031, 0.002, 0.514, 0.04]
0.8316078333333333
1.8041665
Reward 17.758110976933878
Current State [[0.02  0.15  0.33  0.14  0.145 0.83  0.031 0.002 0.514 0.04 ]]
Logits tf.Tensor([[ 0.00157317 -0.2348332   0.5534271 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2836132  0.22390123 0.4924856 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.03, 0.08, 0.32, 0.123, 0.145, 0.82, 0.028, 0.005, 0.581, 0.11]
0.8204440000000001
5.217856833333334
Reward 10.382139415769585
Current State [[0.03  0.08  0.32  0.123 0.145 0.82  0.028 0.005 0.581 0.11 ]]
Logits tf.Tensor([[-0.00174815 -0.24071285  0.5485096 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.28399876 0.22363272 0.49236855]], shape=(1, 3), dtype=float32)
Selected action 0
[0.03, 0.04, 0.33, 0.16, 0.145, 0.82, 0.028, 0.005, 0.581, 0.11]
0.8204440000000001
5.217856833333334
Reward 4.3821394157695845
Current State [[0.03  0.04  0.33  0.16  0.145 0.82  0.028 0.005 0.581 0.11 ]]
Logits tf.Tensor([[-0.00138472 -0.22575337  0.53891146]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.28445166 0.22728272 0.4882656 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.36, 0.149, 0.145, 0.8, 0.034, 0.002, 0.524, 0.09]
0.7979933333333334
1.9613088333333335
Reward 17.488306269308023
Current State [[0.04  0.15  0.36  0.149 0.145 0.8   0.034 0.002 0.524 0.09 ]]
Logits tf.Tensor([[-0.00096246 -0.24322651  0.55280674]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.28371638 0.22267446 0.4936092 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.35, 0.126, 0.145, 0.79, 0.03, 0.007, 0.592, 0.13]
0.7886419999999998
6.7273813333333345
Reward 16.224796953505916
Current State [[0.03  0.15  0.35  0.126 0.145 0.79  0.03  0.007 0.592 0.13 ]]
Logits tf.Tensor([[-4.6722265e-04 -2.5779605e-01  5.6654578e-01]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.28279686 0.21863423 0.49856895]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.4, 0.141, 0.145, 0.79, 0.03, 0.007, 0.592, 0.13]
0.7886419999999998
6.7273813333333345
Reward 4.224796953505917
Current State [[0.04  0.04  0.4   0.141 0.145 0.79  0.03  0.007 0.592 0.13 ]]
Logits tf.Tensor([[-0.00317003 -0.2323726   0.54544055]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.28360638 0.22551455 0.4908791 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.39, 0.163, 0.145, 0.79, 0.025, 0.004, 0.679, 0.09]
0.7880535000000001
4.350594833333334
Reward 16.478636706671303
Current State [[0.03  0.15  0.39  0.163 0.145 0.79  0.025 0.004 0.679 0.09 ]]
Logits tf.Tensor([[-0.00090464 -0.253588    0.5981522 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2780006  0.21592686 0.5060726 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.02, 0.15, 0.38, 0.117, 0.145, 0.77, 0.037, 0.004, 0.7110000000000001, 0.16]
0.7738651666666666
3.847619333333333
Reward 16.560822506106366
Episode: 90 | Average Reward: 282 | Episode Reward: 249 | Loss: 502.653 | Steps: 19 | Worker: 0
Current State [[-0.00067007 -0.00900352  0.00389981  0.00400713 -0.00760013 -0.00065022
  -0.00369615  0.00515079 -0.00778517  0.00243825]]
Logits tf.Tensor([[ 0.00227204 -0.01911688  0.01512216]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.33425015 0.32717684 0.33857304]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.04, 0.4, 0.135, 0.145, 0.79, 0.034, 0.002, 0.675, 0.13]
0.7891373333333332
2.2904760000000004
Reward 5.1910581362700965
Current State [[0.05  0.04  0.4   0.135 0.145 0.79  0.034 0.002 0.675 0.13 ]]
Logits tf.Tensor([[-0.01560858 -0.24573545  0.57932925]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.27721173 0.22022608 0.50256217]], shape=(1, 3), dtype=float32)
Selected action 1
[0.03, 0.08, 0.37, 0.153, 0.145, 0.79, 0.034, 0.002, 0.675, 0.13]
0.7891373333333332
2.2904760000000004
Reward 11.191058136270097
Current State [[0.03  0.08  0.37  0.153 0.145 0.79  0.034 0.002 0.675 0.13 ]]
Logits tf.Tensor([[-0.01138754 -0.24782535  0.5849652 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.27739865 0.21898821 0.5036132 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.02, 0.08, 0.33, 0.129, 0.145, 0.69, 0.017, 0.004, 0.8550000000000001, 0.07]
0.6910005
4.343452166666666
Reward 10.389551204300087
Current State [[0.02  0.08  0.33  0.129 0.145 0.69  0.017 0.004 0.855 0.07 ]]
Logits tf.Tensor([[-0.02371759 -0.23880467  0.63047945]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2680916  0.21620815 0.5157003 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.37, 0.135, 0.145, 0.82, 0.049, 0.003, 0.499, 0.02]
0.8226671666666666
2.5160720000000003
Reward 17.109910647027576
Current State [[0.04  0.15  0.37  0.135 0.145 0.82  0.049 0.003 0.499 0.02 ]]
Logits tf.Tensor([[-0.00924539 -0.23412387  0.5572592 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.28084284 0.2242848  0.4948723 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.37, 0.147, 0.145, 0.82, 0.049, 0.003, 0.499, 0.02]
0.8226671666666666
2.5160720000000003
Reward 17.109910647027576
Current State [[0.04  0.15  0.37  0.147 0.145 0.82  0.049 0.003 0.499 0.02 ]]
Logits tf.Tensor([[-0.00894851 -0.23270828  0.5578228 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2807353  0.22444992 0.49481484]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.38, 0.136, 0.145, 0.83, 0.043, 0.003, 0.524, 0.17]
0.8321464999999999
2.607143
Reward 5.074304065353918
Current State [[0.04  0.04  0.38  0.136 0.145 0.83  0.043 0.003 0.524 0.17 ]]
Logits tf.Tensor([[-0.01033263 -0.2355184   0.5375033 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.28345683 0.22630282 0.4902403 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.04, 0.08, 0.38, 0.142, 0.145, 0.78, 0.041, 0.001, 0.526, 0.18]
0.7826188333333335
1.4708335000000001
Reward 12.130688635515414
Current State [[0.04  0.08  0.38  0.142 0.145 0.78  0.041 0.001 0.526 0.18 ]]
Logits tf.Tensor([[-0.00921003 -0.24113046  0.5358252 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2842784  0.22543539 0.49028617]], shape=(1, 3), dtype=float32)
Selected action 1
[0.06, 0.08, 0.39, 0.153, 0.145, 0.78, 0.041, 0.001, 0.526, 0.18]
0.7826188333333335
1.4708335000000001
Reward 12.130688635515414
Current State [[0.06  0.08  0.39  0.153 0.145 0.78  0.041 0.001 0.526 0.18 ]]
Logits tf.Tensor([[-0.01133786 -0.24413772  0.5371717 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2838503  0.22489804 0.49125168]], shape=(1, 3), dtype=float32)
Selected action 2
[0.02, 0.15, 0.38, 0.16, 0.145, 0.84, 0.059, 0.002, 0.434, 0.15]
0.8373265
2.332142833333333
Reward 17.258937943532757
Current State [[0.02  0.15  0.38  0.16  0.145 0.84  0.059 0.002 0.434 0.15 ]]
Logits tf.Tensor([[-0.00588751 -0.24507     0.54720885]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2836156 0.2232824 0.493102 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.02, 0.08, 0.37, 0.133, 0.145, 0.83, 0.038, 0.001, 0.5, 0.11]
0.8295423333333335
1.4994045000000003
Reward 12.245396824604741
Current State [[0.02  0.08  0.37  0.133 0.145 0.83  0.038 0.001 0.5   0.11 ]]
Logits tf.Tensor([[-0.00436899 -0.22851768  0.53944963]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.28394827 0.2269304  0.4891214 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.04, 0.44, 0.144, 0.145, 0.89, 0.047, 0.001, 0.493, 0.1]
0.8855824999999998
1.2196436666666668
Reward 7.252895904885359
Current State [[0.05  0.04  0.44  0.144 0.145 0.89  0.047 0.001 0.493 0.1  ]]
Logits tf.Tensor([[-0.0104017  -0.23042694  0.55327517]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.28092888 0.225445   0.49362612]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.39, 0.153, 0.145, 0.89, 0.047, 0.001, 0.493, 0.1]
0.8855824999999998
1.2196436666666668
Reward 7.252895904885359
Current State [[0.04  0.04  0.39  0.153 0.145 0.89  0.047 0.001 0.493 0.1  ]]
Logits tf.Tensor([[-0.01015504 -0.22801271  0.5440169 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.28210822 0.22688267 0.49100912]], shape=(1, 3), dtype=float32)
Selected action 1
[0.02, 0.08, 0.36, 0.138, 0.145, 0.84, 0.043, 0.002, 0.514, 0.11]
0.8425693333333334
1.7238089999999997
Reward 11.901513927535543
Current State [[0.02  0.08  0.36  0.138 0.145 0.84  0.043 0.002 0.514 0.11 ]]
Logits tf.Tensor([[-0.00685892 -0.23237929  0.5453447 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.28287122 0.22575974 0.49136898]], shape=(1, 3), dtype=float32)
Selected action 1
[0.02, 0.08, 0.35, 0.124, 0.145, 0.8, 0.062, 0.002, 0.429, 0.1]
0.8048273333333333
2.262499833333334
Reward 11.243369921171452
Current State [[0.02  0.08  0.35  0.124 0.145 0.8   0.062 0.002 0.429 0.1  ]]
Logits tf.Tensor([[-0.01263226 -0.221098    0.5083495 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.28608143 0.23224913 0.48166946]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.15, 0.39, 0.154, 0.145, 0.8, 0.062, 0.002, 0.429, 0.1]
0.8048273333333333
2.262499833333334
Reward 17.24336992117145
Current State [[0.06  0.15  0.39  0.154 0.145 0.8   0.062 0.002 0.429 0.1  ]]
Logits tf.Tensor([[-0.01359682 -0.2419492   0.5363163 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.28337073 0.22551882 0.49111047]], shape=(1, 3), dtype=float32)
Selected action 1
[0.05, 0.08, 0.37, 0.149, 0.145, 0.86, 0.032, 0.001, 0.484, 0.16]
0.8615195
1.1589283333333331
Reward 13.360683169689796
Current State [[0.05  0.08  0.37  0.149 0.145 0.86  0.032 0.001 0.484 0.16 ]]
Logits tf.Tensor([[-0.00476703 -0.24154659  0.5418864 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.28436336 0.22440968 0.49122694]], shape=(1, 3), dtype=float32)
Selected action 1
[0.03, 0.08, 0.38, 0.141, 0.145, 0.83, 0.042, 0.002, 0.517, 0.19]
0.8338466666666666
2.2369049999999997
Reward 11.323902825538177
Current State [[0.03  0.08  0.38  0.141 0.145 0.83  0.042 0.002 0.517 0.19 ]]
Logits tf.Tensor([[-0.00671912 -0.24519137  0.54653674]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.28354833 0.22338802 0.4930637 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.39, 0.143, 0.145, 0.83, 0.042, 0.002, 0.517, 0.19]
0.8338466666666666
2.2369049999999997
Reward 17.323902825538177
Current State [[0.05  0.15  0.39  0.143 0.145 0.83  0.042 0.002 0.517 0.19 ]]
Logits tf.Tensor([[-0.00729966 -0.26852718  0.56769776]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.28191    0.21710049 0.50098956]], shape=(1, 3), dtype=float32)
Selected action 1
[0.02, 0.08, 0.33, 0.132, 0.145, 0.86, 0.036, 0.004, 0.493, 0.15]
0.8606076666666665
3.869643000000001
Reward 10.649758403033488
Current State [[0.02  0.08  0.33  0.132 0.145 0.86  0.036 0.004 0.493 0.15 ]]
Logits tf.Tensor([[-0.00464059 -0.24083404  0.5377072 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.28492722 0.22498648 0.49008635]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.38, 0.118, 0.145, 0.85, 0.033, 0.002, 0.5519999999999999, 0.16]
0.8453496666666667
2.2220238333333335
Reward 17.36051520392242
Episode: 91 | Average Reward: 281 | Episode Reward: 244 | Loss: 511.237 | Steps: 19 | Worker: 0
Current State [[ 0.00946002  0.00265407 -0.00962513 -0.00292996 -0.00099412  0.00260141
  -0.00864033  0.00422751 -0.00304032 -0.00599976]]
Logits tf.Tensor([[-0.00047577 -0.01900349  0.02004327]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.33306977 0.3269556  0.33997464]], shape=(1, 3), dtype=float32)
Selected action 0
[0.03, 0.04, 0.39, 0.148, 0.145, 0.75, 0.031, 0.003, 0.562, 0.1]
0.753644
3.4267855000000003
Reward 4.639342051540147
Current State [[0.03  0.04  0.39  0.148 0.145 0.75  0.031 0.003 0.562 0.1  ]]
Logits tf.Tensor([[-0.01358256 -0.21117467  0.5337041 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2817488  0.23123252 0.4870187 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.02, 0.08, 0.37, 0.134, 0.145, 0.75, 0.031, 0.003, 0.562, 0.1]
0.753644
3.4267855000000003
Reward 10.639342051540147
Current State [[0.02  0.08  0.37  0.134 0.145 0.75  0.031 0.003 0.562 0.1  ]]
Logits tf.Tensor([[-0.01140913 -0.2191105   0.53967935]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.28188148 0.2290145  0.489104  ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.42, 0.153, 0.145, 0.81, 0.039, 0.001, 0.563, 0.16]
0.8088915
1.235713833333333
Reward 6.8206624494262735
Current State [[0.04  0.04  0.42  0.153 0.145 0.81  0.039 0.001 0.563 0.16 ]]
Logits tf.Tensor([[-0.01694352 -0.22995995  0.5529435 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2796256  0.22597745 0.4943969 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.02, 0.15, 0.36, 0.116, 0.145, 0.89, 0.041, 0.002, 0.523, 0.21]
0.8857516666666668
2.2672613333333334
Reward 17.409666271447648
Current State [[0.02  0.15  0.36  0.116 0.145 0.89  0.041 0.002 0.523 0.21 ]]
Logits tf.Tensor([[-0.01101656 -0.27140203  0.58418006]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2790068  0.21504574 0.5059475 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.39, 0.154, 0.145, 0.89, 0.041, 0.002, 0.523, 0.21]
0.8857516666666668
2.2672613333333334
Reward 17.409666271447648
Current State [[0.05  0.15  0.39  0.154 0.145 0.89  0.041 0.002 0.523 0.21 ]]
Logits tf.Tensor([[-0.01275486 -0.27253523  0.5875782 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.27824563 0.21458888 0.5071655 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.03, 0.04, 0.4, 0.151, 0.145, 0.85, 0.036, 0.002, 0.53, 0.09]
0.8451326666666666
1.6041668333333334
Reward 6.102471823333399
Current State [[0.03  0.04  0.4   0.151 0.145 0.85  0.036 0.002 0.53  0.09 ]]
Logits tf.Tensor([[-0.01229107 -0.21752153  0.55000037]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.28017887 0.22819439 0.4916267 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.39, 0.12, 0.145, 0.73, 0.037, 0.003, 0.619, 0.16]
0.727794
2.5446433333333327
Reward 16.925060891736983
Current State [[0.04  0.15  0.39  0.12  0.145 0.73  0.037 0.003 0.619 0.16 ]]
Logits tf.Tensor([[-0.01676766 -0.25659177  0.56896234]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.27909043 0.21957892 0.5013306 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.15, 0.39, 0.141, 0.145, 0.73, 0.037, 0.003, 0.619, 0.16]
0.727794
2.5446433333333327
Reward 16.925060891736983
Current State [[0.06  0.15  0.39  0.141 0.145 0.73  0.037 0.003 0.619 0.16 ]]
Logits tf.Tensor([[-0.01937256 -0.259257    0.57050496]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2785138  0.21911204 0.5023741 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.34, 0.139, 0.145, 0.8, 0.033, 0.002, 0.518, 0.1]
0.7953231666666668
1.7232143333333334
Reward 17.76115473736936
Current State [[0.03  0.15  0.34  0.139 0.145 0.8   0.033 0.002 0.518 0.1  ]]
Logits tf.Tensor([[-0.01111283 -0.23938672  0.55641997]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2809134  0.22358073 0.49550593]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.36, 0.135, 0.145, 0.82, 0.025, 0.002, 0.549, 0.11]
0.8231001666666666
2.3565478333333334
Reward 17.213208234433885
Current State [[0.04  0.15  0.36  0.135 0.145 0.82  0.025 0.002 0.549 0.11 ]]
Logits tf.Tensor([[-0.01006082 -0.24848202  0.57180136]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.27954525 0.22024554 0.5002092 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.38, 0.16, 0.145, 0.82, 0.025, 0.002, 0.549, 0.11]
0.8231001666666666
2.3565478333333334
Reward 5.213208234433885
Current State [[0.04  0.04  0.38  0.16  0.145 0.82  0.025 0.002 0.549 0.11 ]]
Logits tf.Tensor([[-0.0109584  -0.21814087  0.54537314]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.28112528 0.22851865 0.4903561 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.37, 0.152, 0.145, 0.88, 0.032, 0.003, 0.47300000000000003, 0.11]
0.8816733333333334
3.3726188333333336
Reward 16.816958934752947
Current State [[0.04  0.15  0.37  0.152 0.145 0.88  0.032 0.003 0.473 0.11 ]]
Logits tf.Tensor([[-0.00759512 -0.24583162  0.56591755]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.28070128 0.22119722 0.49810144]], shape=(1, 3), dtype=float32)
Selected action 1
[0.04, 0.08, 0.39, 0.124, 0.145, 0.7, 0.017, 0.007, 1.002, 0.1]
0.7040445000000001
6.8422616666666665
Reward 10.169691641677609
Current State [[0.04  0.08  0.39  0.124 0.145 0.7   0.017 0.007 1.002 0.1  ]]
Logits tf.Tensor([[-0.04065417 -0.26391575  0.7057438 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2558007  0.20461638 0.53958297]], shape=(1, 3), dtype=float32)
Selected action 0
[0.03, 0.04, 0.33, 0.138, 0.145, 0.72, 0.018, 0.006, 1.126, 0.09]
0.7246375
5.674404833333332
Reward 4.265485756433691
Current State [[0.03  0.04  0.33  0.138 0.145 0.72  0.018 0.006 1.126 0.09 ]]
Logits tf.Tensor([[-0.04725723 -0.2814886   0.7577734 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24826564 0.19642247 0.55531186]], shape=(1, 3), dtype=float32)
Selected action 2
[0.02, 0.15, 0.33, 0.144, 0.145, 0.72, 0.018, 0.006, 1.126, 0.09]
0.7246375
5.674404833333332
Reward 16.26548575643369
Current State [[0.02  0.15  0.33  0.144 0.145 0.72  0.018 0.006 1.126 0.09 ]]
Logits tf.Tensor([[-0.05216764 -0.3010417   0.7816256 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2449952 0.1910174 0.5639874]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.15, 0.36, 0.14, 0.145, 0.81, 0.025, 0.004, 0.5900000000000001, 0.15]
0.8104001666666666
3.7136903333333326
Reward 16.632159334862465
Current State [[0.06  0.15  0.36  0.14  0.145 0.81  0.025 0.004 0.59  0.15 ]]
Logits tf.Tensor([[-0.01406392 -0.26406723  0.5813172 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.27835613 0.21678326 0.50486064]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.33, 0.121, 0.145, 0.86, 0.035, 0.001, 0.534, 0.13]
0.8610706666666667
1.2214288333333332
Reward 19.122856774300338
Current State [[0.03  0.15  0.33  0.121 0.145 0.86  0.035 0.001 0.534 0.13 ]]
Logits tf.Tensor([[-0.01348962 -0.25743154  0.5758055 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.27884278 0.21848255 0.50267464]], shape=(1, 3), dtype=float32)
Selected action 2
[0.02, 0.15, 0.28, 0.121, 0.145, 0.86, 0.035, 0.001, 0.534, 0.13]
0.8610706666666667
1.2214288333333332
Reward 19.122856774300338
Current State [[0.02  0.15  0.28  0.121 0.145 0.86  0.035 0.001 0.534 0.13 ]]
Logits tf.Tensor([[-0.01529284 -0.25766063  0.56905013]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.27944046 0.21929581 0.5012637 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.04, 0.34, 0.152, 0.145, 0.9, 0.032, 0.002, 0.51, 0.08]
0.8995896666666664
2.158333333333333
Reward 5.537014013047972
Current State [[0.05  0.04  0.34  0.152 0.145 0.9   0.032 0.002 0.51  0.08 ]]
Logits tf.Tensor([[-0.01382351 -0.22677268  0.5422736 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.28152755 0.2275298  0.4909427 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.15, 0.32, 0.121, 0.145, 0.91, 0.032, 0.001, 0.477, 0.01]
0.9121496666666666
0.6505953333333333
Reward 24.505957435016825
Episode: 92 | Average Reward: 281 | Episode Reward: 269 | Loss: 645.003 | Steps: 19 | Worker: 0
Current State [[-0.00232226 -0.00051592  0.00088551 -0.00366299 -0.00994635 -0.00591743
   0.00203882 -0.00794422  0.00542437 -0.00664175]]
Logits tf.Tensor([[-0.00485825 -0.01573162  0.02027472]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.33171487 0.3281276  0.3401575 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.03, 0.04, 0.41, 0.181, 0.145, 0.91, 0.032, 0.001, 0.477, 0.01]
0.9121496666666666
0.6505953333333333
Reward 12.505957435016823
Current State [[0.03  0.04  0.41  0.181 0.145 0.91  0.032 0.001 0.477 0.01 ]]
Logits tf.Tensor([[-0.01299327 -0.2017614   0.5519249 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.27876255 0.2308094  0.49042806]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.34, 0.146, 0.145, 0.83, 0.027, 0.002, 0.509, 0.08]
0.8258876666666667
1.523809666666667
Reward 18.184121751383007
Current State [[0.04  0.15  0.34  0.146 0.145 0.83  0.027 0.002 0.509 0.08 ]]
Logits tf.Tensor([[-0.01575648 -0.23771098  0.56523854]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.27864715 0.22318292 0.49816996]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.36, 0.131, 0.145, 0.72, 0.018, 0.003, 0.519, 0.07]
0.7206730000000001
3.4071425
Reward 16.604070257626898
Current State [[0.05  0.15  0.36  0.131 0.145 0.72  0.018 0.003 0.519 0.07 ]]
Logits tf.Tensor([[-0.01485167 -0.22493754  0.53737044]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.28187883 0.22846693 0.4896542 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.34, 0.123, 0.145, 0.7, 0.019, 0.003, 0.679, 0.09]
0.7004196666666668
2.7827378333333335
Reward 4.774817283490786
Current State [[0.04  0.04  0.34  0.123 0.145 0.7   0.019 0.003 0.679 0.09 ]]
Logits tf.Tensor([[-0.02348349 -0.21570209  0.5557153 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.27702868 0.22858372 0.49438763]], shape=(1, 3), dtype=float32)
Selected action 1
[0.04, 0.08, 0.34, 0.147, 0.145, 0.7, 0.019, 0.003, 0.679, 0.09]
0.7004196666666668
2.7827378333333335
Reward 10.774817283490787
Current State [[0.04  0.08  0.34  0.147 0.145 0.7   0.019 0.003 0.679 0.09 ]]
Logits tf.Tensor([[-0.02274189 -0.22228493  0.565716  ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.27621913 0.22625247 0.4975283 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.33, 0.144, 0.145, 0.76, 0.021, 0.005, 0.514, 0.08]
0.7568918333333333
4.923809
Reward 16.36809878920084
Current State [[0.04  0.15  0.33  0.144 0.145 0.76  0.021 0.005 0.514 0.08 ]]
Logits tf.Tensor([[-0.01403441 -0.22864123  0.5451628 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.28120488 0.22689258 0.49190256]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.32, 0.126, 0.145, 0.64, 0.012, 0.004, 0.587, 0.04]
0.635877
4.323214166666667
Reward 16.341714861787977
Current State [[0.03  0.15  0.32  0.126 0.145 0.64  0.012 0.004 0.587 0.04 ]]
Logits tf.Tensor([[-0.01733867 -0.21016125  0.5346947 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.28078777 0.23154551 0.4876668 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.32, 0.129, 0.145, 0.64, 0.012, 0.004, 0.587, 0.04]
0.635877
4.323214166666667
Reward 4.341714861787977
Current State [[0.04  0.04  0.32  0.129 0.145 0.64  0.012 0.004 0.587 0.04 ]]
Logits tf.Tensor([[-0.01736313 -0.18668011  0.50904506]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2827189  0.23868296 0.47859815]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.33, 0.156, 0.145, 0.89, 0.028, 0.003, 0.48, 0.08]
0.8873385
3.041666666666667
Reward 16.950504592649516
Current State [[0.04  0.15  0.33  0.156 0.145 0.89  0.028 0.003 0.48  0.08 ]]
Logits tf.Tensor([[-0.01450607 -0.24276984  0.56786114]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.27884784 0.22193898 0.49921328]], shape=(1, 3), dtype=float32)
Selected action 1
[0.03, 0.08, 0.33, 0.126, 0.145, 0.87, 0.031, 0.002, 0.537, 0.14]
0.8668128333333335
1.9077388333333332
Reward 11.72471737113431
Current State [[0.03  0.08  0.33  0.126 0.145 0.87  0.031 0.002 0.537 0.14 ]]
Logits tf.Tensor([[-0.01850863 -0.24054156  0.56000936]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.27899587 0.22344473 0.49755943]], shape=(1, 3), dtype=float32)
Selected action 0
[0.03, 0.04, 0.29, 0.129, 0.145, 0.87, 0.031, 0.002, 0.537, 0.14]
0.8668128333333335
1.9077388333333332
Reward 5.724717371134309
Current State [[0.03  0.04  0.29  0.129 0.145 0.87  0.031 0.002 0.537 0.14 ]]
Logits tf.Tensor([[-0.02009512 -0.23382688  0.54015946]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.28100282 0.22692804 0.49206915]], shape=(1, 3), dtype=float32)
Selected action 1
[0.05, 0.08, 0.36, 0.162, 0.145, 0.8, 0.022, 0.004, 0.545, 0.07]
0.7982731666666668
3.683332833333333
Reward 10.625884413461058
Current State [[0.05  0.08  0.36  0.162 0.145 0.8   0.022 0.004 0.545 0.07 ]]
Logits tf.Tensor([[-0.01609861 -0.21903     0.5516804 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2792767  0.22798315 0.49274018]], shape=(1, 3), dtype=float32)
Selected action 1
[0.09, 0.08, 0.36, 0.139, 0.145, 0.8, 0.027, 0.003, 0.5429999999999999, 0.12]
0.8005008333333333
2.5291668333333335
Reward 11.06213567750229
Current State [[0.09  0.08  0.36  0.139 0.145 0.8   0.027 0.003 0.543 0.12 ]]
Logits tf.Tensor([[-0.0252395  -0.23909286  0.55084705]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.27882108 0.22513877 0.49604014]], shape=(1, 3), dtype=float32)
Selected action 1
[0.07, 0.08, 0.36, 0.134, 0.145, 0.85, 0.038, 0.003, 0.511, 0.13]
0.8472625
3.361905166666667
Reward 10.776186201991614
Current State [[0.07  0.08  0.36  0.134 0.145 0.85  0.038 0.003 0.511 0.13 ]]
Logits tf.Tensor([[-0.02445563 -0.24057497  0.5519851 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2789142  0.2247042  0.49638155]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.35, 0.138, 0.145, 0.85, 0.038, 0.003, 0.511, 0.13]
0.8472625
3.361905166666667
Reward 16.776186201991614
Current State [[0.05  0.15  0.35  0.138 0.145 0.85  0.038 0.003 0.511 0.13 ]]
Logits tf.Tensor([[-0.02043051 -0.25318187  0.57322645]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.27755046 0.21991728 0.50253224]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.35, 0.145, 0.145, 0.75, 0.02, 0.003, 0.8230000000000001, 0.07]
0.7489591666666667
3.156547833333334
Reward 4.7128590108596
Current State [[0.04  0.04  0.35  0.145 0.145 0.75  0.02  0.003 0.823 0.07 ]]
Logits tf.Tensor([[-0.03643586 -0.2304704   0.6296714 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2652327  0.21845347 0.51631385]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.35, 0.11, 0.145, 0.71, 0.029, 0.003, 0.737, 0.14]
0.7128071666666667
3.2535716666666668
Reward 16.635795699823227
Current State [[0.04  0.15  0.35  0.11  0.145 0.71  0.029 0.003 0.737 0.14 ]]
Logits tf.Tensor([[-0.02988386 -0.26064017  0.60258114]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2720217  0.21596695 0.51201135]], shape=(1, 3), dtype=float32)
Selected action 2
[0.02, 0.15, 0.36, 0.158, 0.145, 0.71, 0.029, 0.003, 0.737, 0.14]
0.7128071666666667
3.2535716666666668
Reward 16.635795699823227
Current State [[0.02  0.15  0.36  0.158 0.145 0.71  0.029 0.003 0.737 0.14 ]]
Logits tf.Tensor([[-0.02557684 -0.2508506   0.6046501 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2720101  0.21714501 0.51084495]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.38, 0.145, 0.145, 0.83, 0.044, 0.003, 0.658, 0.25]
0.8280314999999998
2.6613101666666665
Reward 17.03775219289021
Current State [[0.05  0.15  0.38  0.145 0.145 0.83  0.044 0.003 0.658 0.25 ]]
Logits tf.Tensor([[-0.02813523 -0.29046372  0.6167615 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.27210525 0.20931922 0.51857555]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.42, 0.136, 0.145, 0.8, 0.035, 0.003, 0.8310000000000001, 0.14]
0.8007463333333333
2.6345234999999994
Reward 5.005258872726595
Episode: 93 | Average Reward: 281 | Episode Reward: 243 | Loss: 451.116 | Steps: 19 | Worker: 0
Current State [[ 0.00117579 -0.00505139  0.00316383 -0.00513759  0.00052986 -0.00462345
   0.00471605 -0.00342142  0.00549495  0.0045669 ]]
Logits tf.Tensor([[-0.00499673 -0.01863768  0.02342175]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3316444  0.32715118 0.34120443]], shape=(1, 3), dtype=float32)
Selected action 2
[0.01, 0.15, 0.38, 0.151, 0.145, 0.8, 0.035, 0.003, 0.8310000000000001, 0.14]
0.8007463333333333
2.6345234999999994
Reward 17.005258872726596
Current State [[0.01  0.15  0.38  0.151 0.145 0.8   0.035 0.003 0.831 0.14 ]]
Logits tf.Tensor([[-0.03686187 -0.26943728  0.66606   ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2623202  0.20788611 0.5297937 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.02, 0.15, 0.38, 0.13, 0.145, 0.68, 0.028, 0.004, 0.8310000000000001, 0.17]
0.683548
4.142262166666667
Reward 16.413345638667924
Current State [[0.02  0.15  0.38  0.13  0.145 0.68  0.028 0.004 0.831 0.17 ]]
Logits tf.Tensor([[-0.03691404 -0.2633956   0.6427126 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2652186  0.2114678  0.52331364]], shape=(1, 3), dtype=float32)
Selected action 1
[0.02, 0.08, 0.33, 0.122, 0.145, 0.85, 0.036, 0.002, 0.77, 0.19]
0.8480893333333335
1.7970235
Reward 11.81441280862198
Current State [[0.02  0.08  0.33  0.122 0.145 0.85  0.036 0.002 0.77  0.19 ]]
Logits tf.Tensor([[-0.03423386 -0.26918352  0.6350515 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26713312 0.2111983  0.52166855]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.39, 0.134, 0.145, 0.79, 0.035, 0.002, 0.619, 0.05]
0.7931556666666667
1.6732144999999998
Reward 17.82516001788154
Current State [[0.05  0.15  0.39  0.134 0.145 0.79  0.035 0.002 0.619 0.05 ]]
Logits tf.Tensor([[-0.03102166 -0.2402378   0.5989994 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.27108574 0.21991013 0.5090041 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.15, 0.4, 0.15, 0.145, 0.79, 0.035, 0.002, 0.619, 0.05]
0.7931556666666667
1.6732144999999998
Reward 17.82516001788154
Current State [[0.06  0.15  0.4   0.15  0.145 0.79  0.035 0.002 0.619 0.05 ]]
Logits tf.Tensor([[-0.03185795 -0.24086228  0.6008217 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2707063  0.21964885 0.50964487]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.37, 0.142, 0.145, 0.87, 0.039, 0.002, 0.485, 0.14]
0.8734106666666668
1.7428571666666668
Reward 17.966118942136294
Current State [[0.03  0.15  0.37  0.142 0.145 0.87  0.039 0.002 0.485 0.14 ]]
Logits tf.Tensor([[-0.02081784 -0.24633124  0.5757081 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.27670893 0.22084314 0.50244796]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.45, 0.129, 0.145, 0.84, 0.057, 0.002, 0.446, 0.15]
0.8360676666666668
2.1767855000000003
Reward 5.3779715798276735
Current State [[0.04  0.04  0.45  0.129 0.145 0.84  0.057 0.002 0.446 0.15 ]]
Logits tf.Tensor([[-0.02823649 -0.21555054  0.53648996]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.27869514 0.23108937 0.49021545]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.4, 0.16, 0.145, 0.84, 0.057, 0.002, 0.446, 0.15]
0.8360676666666668
2.1767855000000003
Reward 17.377971579827673
Current State [[0.04  0.15  0.4   0.16  0.145 0.84  0.057 0.002 0.446 0.15 ]]
Logits tf.Tensor([[-0.0253831  -0.24143638  0.5611782 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.27750888 0.22358681 0.49890432]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.4, 0.15, 0.145, 0.78, 0.055, 0.005, 0.47400000000000003, 0.16]
0.7843785
5.459523333333334
Reward 4.3282035467081625
Current State [[0.04  0.04  0.4   0.15  0.145 0.78  0.055 0.005 0.474 0.16 ]]
Logits tf.Tensor([[-0.0295262  -0.21275531  0.5221426 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2802121  0.23329826 0.48648965]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.37, 0.126, 0.145, 0.77, 0.038, 0.003, 0.5549999999999999, 0.18]
0.7682503333333333
3.4958326666666664
Reward 16.63864496472334
Current State [[0.05  0.15  0.37  0.126 0.145 0.77  0.038 0.003 0.555 0.18 ]]
Logits tf.Tensor([[-0.02748987 -0.25703382  0.5684018 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.27704328 0.22022061 0.50273615]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.39, 0.149, 0.145, 0.77, 0.038, 0.003, 0.5549999999999999, 0.18]
0.7682503333333333
3.4958326666666664
Reward 16.63864496472334
Current State [[0.05  0.15  0.39  0.149 0.145 0.77  0.038 0.003 0.555 0.18 ]]
Logits tf.Tensor([[-0.02598671 -0.2537625   0.57074946]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.27681783 0.22043079 0.5027514 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.02, 0.15, 0.37, 0.156, 0.145, 0.88, 0.048, 0.001, 0.481, 0.2]
0.8835166666666666
1.1410716666666667
Reward 19.556836155680074
Current State [[0.02  0.15  0.37  0.156 0.145 0.88  0.048 0.001 0.481 0.2  ]]
Logits tf.Tensor([[-0.02199347 -0.253867    0.5784473 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.27655107 0.21931785 0.5041311 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.02, 0.15, 0.36, 0.126, 0.145, 0.78, 0.032, 0.002, 0.502, 0.14]
0.7841609999999998
2.0136903333333334
Reward 17.403612677259336
Current State [[0.02  0.15  0.36  0.126 0.145 0.78  0.032 0.002 0.502 0.14 ]]
Logits tf.Tensor([[-0.01870767 -0.23692696  0.55324465]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2796677  0.22483861 0.49549362]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.04, 0.36, 0.155, 0.145, 0.78, 0.032, 0.002, 0.502, 0.14]
0.7841609999999998
2.0136903333333334
Reward 5.403612677259336
Current State [[0.05  0.04  0.36  0.155 0.145 0.78  0.032 0.002 0.502 0.14 ]]
Logits tf.Tensor([[-0.02516789 -0.212115    0.52412915]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.28077877 0.23290253 0.48631868]], shape=(1, 3), dtype=float32)
Selected action 2
[0.02, 0.15, 0.38, 0.136, 0.145, 0.9, 0.044, 0.001, 0.509, 0.04]
0.900678
1.022619
Reward 20.265459125643464
Current State [[0.02  0.15  0.38  0.136 0.145 0.9   0.044 0.001 0.509 0.04 ]]
Logits tf.Tensor([[-0.02352576 -0.23635615  0.5913204 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.27339843 0.22098611 0.5056155 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.38, 0.138, 0.145, 0.78, 0.041, 0.003, 0.5269999999999999, 0.2]
0.7754020000000001
3.112499666666667
Reward 16.763701516623257
Current State [[0.04  0.15  0.38  0.138 0.145 0.78  0.041 0.003 0.527 0.2  ]]
Logits tf.Tensor([[-0.02493917 -0.25556427  0.56457424]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.27799803 0.22074074 0.50126123]], shape=(1, 3), dtype=float32)
Selected action 0
[0.03, 0.04, 0.37, 0.152, 0.145, 0.84, 0.037, 0.003, 0.502, 0.15]
0.8428228333333331
2.6702378333333323
Reward 5.058170436353455
Current State [[0.03  0.04  0.37  0.152 0.145 0.84  0.037 0.003 0.502 0.15 ]]
Logits tf.Tensor([[-0.02294286 -0.21764627  0.5389873 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.27955347 0.2300945  0.4903521 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.37, 0.155, 0.145, 0.84, 0.037, 0.003, 0.502, 0.15]
0.8428228333333331
2.6702378333333323
Reward 17.058170436353457
Current State [[0.03  0.15  0.37  0.155 0.145 0.84  0.037 0.003 0.502 0.15 ]]
Logits tf.Tensor([[-0.02041717 -0.2447617   0.57274574]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2771048  0.22141775 0.5014775 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.04, 0.36, 0.131, 0.145, 0.85, 0.033, 0.004, 0.492, 0.09]
0.8500886666666667
3.6261908333333337
Reward 4.700744090172025
Current State [[0.05  0.04  0.36  0.131 0.145 0.85  0.033 0.004 0.492 0.09 ]]
Logits tf.Tensor([[-0.02490018 -0.2172257   0.5360547 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.27953395 0.23062618 0.48983988]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.04, 0.41, 0.152, 0.145, 0.85, 0.033, 0.004, 0.492, 0.09]
0.8500886666666667
3.6261908333333337
Reward 4.700744090172025
Episode: 94 | Average Reward: 281 | Episode Reward: 270 | Loss: 527.237 | Steps: 19 | Worker: 0
Current State [[ 0.00187558  0.00072533 -0.00364935  0.00258346  0.00109023  0.00972439
  -0.00317744  0.00196199 -0.00498769 -0.00177784]]
Logits tf.Tensor([[-0.0038757  -0.01991014  0.02476902]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.33187833 0.3265993  0.3415224 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.41, 0.158, 0.145, 0.86, 0.07, 0.008, 0.404, 0.14]
0.8644948333333334
7.822023166666667
Reward 16.198923616016025
Current State [[0.04  0.15  0.41  0.158 0.145 0.86  0.07  0.008 0.404 0.14 ]]
Logits tf.Tensor([[-0.03005928 -0.24190535  0.560525  ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.27669162 0.2238682  0.49944016]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.37, 0.146, 0.145, 0.85, 0.039, 0.002, 0.491, 0.15]
0.8537676666666667
2.093452
Reward 17.49299805932347
Current State [[0.03  0.15  0.37  0.146 0.145 0.85  0.039 0.002 0.491 0.15 ]]
Logits tf.Tensor([[-0.02502192 -0.2465368   0.57761264]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.27561653 0.22085261 0.50353086]], shape=(1, 3), dtype=float32)
Selected action 1
[0.04, 0.08, 0.38, 0.133, 0.145, 0.87, 0.047, 0.002, 0.48600000000000004, 0.17]
0.8745830000000001
2.2428571666666666
Reward 11.406151077886953
Current State [[0.04  0.08  0.38  0.133 0.145 0.87  0.047 0.002 0.486 0.17 ]]
Logits tf.Tensor([[-0.03106108 -0.23913318  0.56119895]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2762264  0.22433686 0.4994367 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.35, 0.132, 0.145, 0.87, 0.047, 0.002, 0.48600000000000004, 0.17]
0.8745830000000001
2.2428571666666666
Reward 17.406151077886953
Current State [[0.03  0.15  0.35  0.132 0.145 0.87  0.047 0.002 0.486 0.17 ]]
Logits tf.Tensor([[-0.02929904 -0.25555378  0.5794943 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.27504817 0.21935502 0.5055968 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.04, 0.08, 0.39, 0.178, 0.145, 0.8, 0.031, 0.003, 0.5589999999999999, 0.13]
0.8035478333333334
2.9684521666666663
Reward 10.857483122816799
Current State [[0.04  0.08  0.39  0.178 0.145 0.8   0.031 0.003 0.559 0.13 ]]
Logits tf.Tensor([[-0.02791878 -0.2254055   0.5688166 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.27495408 0.22567983 0.49936607]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.4, 0.138, 0.145, 0.84, 0.037, 0.002, 0.537, 0.22]
0.8433959999999998
1.7464286666666669
Reward 17.871094794671208
Current State [[0.05  0.15  0.4   0.138 0.145 0.84  0.037 0.002 0.537 0.22 ]]
Logits tf.Tensor([[-0.02836669 -0.26832652  0.59134823]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2743441  0.21581535 0.50984055]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.04, 0.37, 0.145, 0.145, 0.84, 0.037, 0.002, 0.537, 0.22]
0.8433959999999998
1.7464286666666669
Reward 5.87109479467121
Current State [[0.05  0.04  0.37  0.145 0.145 0.84  0.037 0.002 0.537 0.22 ]]
Logits tf.Tensor([[-0.0317489  -0.23812579  0.55606705]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.27673396 0.22513038 0.4981357 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.15, 0.36, 0.153, 0.145, 0.85, 0.047, 0.002, 0.515, 0.2]
0.8505486666666667
1.5708331666666666
Reward 18.181275412760264
Current State [[0.06  0.15  0.36  0.153 0.145 0.85  0.047 0.002 0.515 0.2  ]]
Logits tf.Tensor([[-0.03391484 -0.26501462  0.5853057 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.27388707 0.21737327 0.50873965]], shape=(1, 3), dtype=float32)
Selected action 1
[0.02, 0.08, 0.35, 0.113, 0.145, 0.86, 0.034, 0.002, 0.52, 0.11]
0.8629566666666668
2.2297618333333338
Reward 11.39206859444453
Current State [[0.02  0.08  0.35  0.113 0.145 0.86  0.034 0.002 0.52  0.11 ]]
Logits tf.Tensor([[-0.02579878 -0.23047464  0.56245285]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2765679  0.22537835 0.49805376]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.04, 0.36, 0.144, 0.145, 0.86, 0.034, 0.002, 0.52, 0.11]
0.8629566666666668
2.2297618333333338
Reward 5.392068594444529
Current State [[0.05  0.04  0.36  0.144 0.145 0.86  0.034 0.002 0.52  0.11 ]]
Logits tf.Tensor([[-0.03070384 -0.22342478  0.5540899 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.276294   0.22786301 0.49584296]], shape=(1, 3), dtype=float32)
Selected action 1
[0.04, 0.08, 0.37, 0.158, 0.145, 0.91, 0.045, 0.001, 0.5269999999999999, 0.04]
0.9103661666666666
1.2196421666666666
Reward 13.379815644373242
Current State [[0.04  0.08  0.37  0.158 0.145 0.91  0.045 0.001 0.527 0.04 ]]
Logits tf.Tensor([[-0.03213813 -0.22750568  0.58322185]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.27226776 0.22394903 0.50378317]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.37, 0.161, 0.145, 0.88, 0.034, 0.003, 0.53, 0.13]
0.8789536666666666
2.7315476666666667
Reward 17.086166819516443
Current State [[0.03  0.15  0.37  0.161 0.145 0.88  0.034 0.003 0.53  0.13 ]]
Logits tf.Tensor([[-0.02472703 -0.24883404  0.59793746]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2729915  0.2181829  0.50882554]], shape=(1, 3), dtype=float32)
Selected action 2
[0.02, 0.15, 0.35, 0.161, 0.145, 0.88, 0.034, 0.003, 0.53, 0.13]
0.8789536666666666
2.7315476666666667
Reward 17.086166819516443
Current State [[0.02  0.15  0.35  0.161 0.145 0.88  0.034 0.003 0.53  0.13 ]]
Logits tf.Tensor([[-0.02487726 -0.24763824  0.5953295 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.27325252 0.21868566 0.5080618 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.03, 0.08, 0.37, 0.155, 0.145, 0.74, 0.023, 0.005, 0.8320000000000001, 0.15]
0.7372983333333334
5.204167
Reward 10.320314857449926
Current State [[0.03  0.08  0.37  0.155 0.145 0.74  0.023 0.005 0.832 0.15 ]]
Logits tf.Tensor([[-0.03915128 -0.2513321   0.6440922 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26391432 0.21345876 0.52262694]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.36, 0.127, 0.145, 0.71, 0.019, 0.012, 0.425, 0.02]
0.714741
11.947619666666665
Reward 16.007992564134057
Current State [[0.05  0.15  0.36  0.127 0.145 0.71  0.019 0.012 0.425 0.02 ]]
Logits tf.Tensor([[-0.01722346 -0.2044853   0.51205546]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.28353238 0.23511258 0.4813551 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.02, 0.15, 0.32, 0.12, 0.145, 0.85, 0.032, 0.001, 0.545, 0.1]
0.8545086666666669
1.4220238333333335
Reward 18.5105764477086
Current State [[0.02  0.15  0.32  0.12  0.145 0.85  0.032 0.001 0.545 0.1  ]]
Logits tf.Tensor([[-0.02896757 -0.2472234   0.58855397]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.27335504 0.2197555  0.50688946]], shape=(1, 3), dtype=float32)
Selected action 0
[0.07, 0.04, 0.34, 0.15, 0.145, 0.85, 0.032, 0.001, 0.545, 0.1]
0.8545086666666669
1.4220238333333335
Reward 6.510576447708603
Current State [[0.07  0.04  0.34  0.15  0.145 0.85  0.032 0.001 0.545 0.1  ]]
Logits tf.Tensor([[-0.03501018 -0.22746874  0.5577519 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.27518594 0.22700872 0.49780533]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.26, 0.098, 0.145, 0.85, 0.027, 0.002, 0.5940000000000001, 0.06]
0.8523398333333334
2.1107141666666664
Reward 5.473412755440976
Current State [[0.04  0.04  0.26  0.098 0.145 0.85  0.027 0.002 0.594 0.06 ]]
Logits tf.Tensor([[-0.03442506 -0.23055516  0.5579966 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.27546176 0.22640349 0.49813467]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.04, 0.32, 0.12, 0.145, 0.92, 0.036, 0.001, 0.44299999999999995, 0.01]
0.9151846666666666
0.5619041666666666
Reward 14.74940360113865
Current State [[0.05  0.04  0.32  0.12  0.145 0.92  0.036 0.001 0.443 0.01 ]]
Logits tf.Tensor([[-0.0284762 -0.2159973  0.5321941]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2792627  0.23151202 0.48922533]], shape=(1, 3), dtype=float32)
Selected action 1
[0.04, 0.08, 0.33, 0.155, 0.145, 0.92, 0.036, 0.001, 0.44299999999999995, 0.01]
0.9151846666666666
0.5619041666666666
Reward 20.74940360113865
Episode: 95 | Average Reward: 281 | Episode Reward: 271 | Loss: 565.506 | Steps: 19 | Worker: 0
Current State [[-0.00199848 -0.00900957 -0.00396275  0.00400615 -0.00762018 -0.00941356
   0.00943159 -0.00101294 -0.00371581 -0.00614971]]
Logits tf.Tensor([[-0.00639448 -0.01303715  0.01382546]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.33180645 0.32960966 0.33858386]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.39, 0.151, 0.145, 0.82, 0.019, 0.004, 0.536, 0.07]
0.8225673333333333
4.408333
Reward 4.500936480377005
Current State [[0.04  0.04  0.39  0.151 0.145 0.82  0.019 0.004 0.536 0.07 ]]
Logits tf.Tensor([[-0.02704879 -0.20800526  0.558331  ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.27547115 0.22987285 0.494656  ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.34, 0.131, 0.145, 0.72, 0.025, 0.004, 0.575, 0.1]
0.7158575
3.8113095
Reward 16.50598015349736
Current State [[0.04  0.15  0.34  0.131 0.145 0.72  0.025 0.004 0.575 0.1  ]]
Logits tf.Tensor([[-0.03363566 -0.23334818  0.5658949 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.27470794 0.22497651 0.50031555]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.34, 0.176, 0.145, 0.72, 0.025, 0.004, 0.575, 0.1]
0.7158575
3.8113095
Reward 16.50598015349736
Current State [[0.03  0.15  0.34  0.176 0.145 0.72  0.025 0.004 0.575 0.1  ]]
Logits tf.Tensor([[-0.03149371 -0.22561358  0.5675567 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.27442756 0.22600734 0.49956504]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.35, 0.147, 0.145, 0.78, 0.03, 0.002, 0.588, 0.1]
0.7830533333333334
1.5964286666666667
Reward 17.910470844921207
Current State [[0.04  0.15  0.35  0.147 0.145 0.78  0.03  0.002 0.588 0.1  ]]
Logits tf.Tensor([[-0.03559724 -0.24045835  0.59006804]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.27142566 0.22114693 0.5074274 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.35, 0.123, 0.145, 0.84, 0.034, 0.001, 0.5309999999999999, 0.17]
0.8375155000000001
1.3613098333333329
Reward 18.592083842646264
Current State [[0.04  0.15  0.35  0.123 0.145 0.84  0.034 0.001 0.531 0.17 ]]
Logits tf.Tensor([[-0.03257824 -0.25775173  0.58797634]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.27334824 0.21823515 0.5084166 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.15, 0.36, 0.145, 0.145, 0.84, 0.034, 0.001, 0.5309999999999999, 0.17]
0.8375155000000001
1.3613098333333329
Reward 18.592083842646264
Current State [[0.06  0.15  0.36  0.145 0.145 0.84  0.034 0.001 0.531 0.17 ]]
Logits tf.Tensor([[-0.03451575 -0.25893593  0.5894569 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.27282843 0.21798429 0.5091873 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.02, 0.08, 0.35, 0.161, 0.145, 0.84, 0.021, 0.004, 0.5519999999999999, 0.1]
0.8378423333333334
3.595238
Reward 10.694836361114803
Current State [[0.02  0.08  0.35  0.161 0.145 0.84  0.021 0.004 0.552 0.1  ]]
Logits tf.Tensor([[-0.02484714 -0.22068085  0.5719689 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.27484035 0.22595973 0.49919984]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.31, 0.145, 0.145, 0.72, 0.018, 0.006, 0.536, 0.05]
0.7204626666666666
6.4541665
Reward 16.203183099343878
Current State [[0.03  0.15  0.31  0.145 0.145 0.72  0.018 0.006 0.536 0.05 ]]
Logits tf.Tensor([[-0.02820623 -0.2152666   0.55116767]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.27667764 0.2294747  0.4938476 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.06, 0.08, 0.35, 0.152, 0.145, 0.83, 0.029, 0.002, 0.472, 0.07]
0.8250773333333333
2.0982138333333333
Reward 11.422020030295592
Current State [[0.06  0.08  0.35  0.152 0.145 0.83  0.029 0.002 0.472 0.07 ]]
Logits tf.Tensor([[-0.03122411 -0.21697699  0.54414225]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.27714184 0.23016043 0.49269772]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.33, 0.133, 0.145, 0.83, 0.029, 0.002, 0.472, 0.07]
0.8250773333333333
2.0982138333333333
Reward 17.42202003029559
Current State [[0.03  0.15  0.33  0.133 0.145 0.83  0.029 0.002 0.472 0.07 ]]
Logits tf.Tensor([[-0.0284357  -0.23021987  0.56289977]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.27596325 0.22553687 0.49849984]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.34, 0.132, 0.145, 0.76, 0.019, 0.006, 0.521, 0.08]
0.7625166666666667
5.6875005
Reward 16.290389117657096
Current State [[0.03  0.15  0.34  0.132 0.145 0.76  0.019 0.006 0.521 0.08 ]]
Logits tf.Tensor([[-0.02580751 -0.2252843   0.5589643 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.27672157 0.22667904 0.4965994 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.02, 0.08, 0.32, 0.152, 0.145, 0.79, 0.032, 0.002, 0.548, 0.07]
0.7903573333333331
2.3779765
Reward 11.134740278145038
Current State [[0.02  0.08  0.32  0.152 0.145 0.79  0.032 0.002 0.548 0.07 ]]
Logits tf.Tensor([[-0.03112042 -0.21336906  0.55594206]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.27532348 0.22945298 0.49522352]], shape=(1, 3), dtype=float32)
Selected action 1
[0.03, 0.08, 0.33, 0.151, 0.145, 0.79, 0.032, 0.002, 0.548, 0.07]
0.7903573333333331
2.3779765
Reward 11.134740278145038
Current State [[0.03  0.08  0.33  0.151 0.145 0.79  0.032 0.002 0.548 0.07 ]]
Logits tf.Tensor([[-0.03209577 -0.21550502  0.55781126]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.27500874 0.22892483 0.49606648]], shape=(1, 3), dtype=float32)
Selected action 0
[0.03, 0.04, 0.34, 0.14, 0.145, 0.82, 0.029, 0.005, 0.5900000000000001, 0.11]
0.8210489999999999
4.632143999999999
Reward 4.462814311997656
Current State [[0.03  0.04  0.34  0.14  0.145 0.82  0.029 0.005 0.59  0.11 ]]
Logits tf.Tensor([[-0.03318254 -0.22233891  0.56763756]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.27387723 0.22667643 0.4994463 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.09, 0.04, 0.34, 0.11, 0.145, 0.77, 0.032, 0.003, 0.554, 0.1]
0.770749
2.819047166666666
Reward 4.869388619976787
Current State [[0.09  0.04  0.34  0.11  0.145 0.77  0.032 0.003 0.554 0.1  ]]
Logits tf.Tensor([[-0.04359554 -0.22819568  0.5457842 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.27515566 0.22877452 0.49606982]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.34, 0.138, 0.145, 0.77, 0.032, 0.003, 0.554, 0.1]
0.770749
2.819047166666666
Reward 16.86938861997679
Current State [[0.04  0.15  0.34  0.138 0.145 0.77  0.032 0.003 0.554 0.1  ]]
Logits tf.Tensor([[-0.03428537 -0.2371416   0.5748491 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.27358025 0.22334972 0.50307006]], shape=(1, 3), dtype=float32)
Selected action 0
[0.02, 0.04, 0.43, 0.143, 0.145, 0.77, 0.031, 0.006, 0.616, 0.15]
0.7727365000000002
5.763690333333334
Reward 4.290392622135866
Current State [[0.02  0.04  0.43  0.143 0.145 0.77  0.031 0.006 0.616 0.15 ]]
Logits tf.Tensor([[-0.03290102 -0.22276308  0.575243  ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.27291894 0.22572392 0.5013572 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.03, 0.04, 0.4, 0.131, 0.145, 0.86, 0.034, 0.002, 0.679, 0.13]
0.8555431666666667
2.003572333333333
Reward 5.587489457016741
Current State [[0.03  0.04  0.4   0.131 0.145 0.86  0.034 0.002 0.679 0.13 ]]
Logits tf.Tensor([[-0.03900041 -0.24122863  0.61930275]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26677904 0.21793404 0.5152869 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.02, 0.08, 0.4, 0.157, 0.145, 0.86, 0.034, 0.002, 0.679, 0.13]
0.8555431666666667
2.003572333333333
Reward 11.58748945701674
Current State [[0.02  0.08  0.4   0.157 0.145 0.86  0.034 0.002 0.679 0.13 ]]
Logits tf.Tensor([[-0.03597442 -0.2443761   0.62919444]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2661911  0.21611544 0.51769346]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.15, 0.42, 0.176, 0.145, 0.7, 0.036, 0.007, 0.7769999999999999, 0.19]
0.7046738333333333
6.627976
Reward 16.18278769826413
Episode: 96 | Average Reward: 280 | Episode Reward: 250 | Loss: 452.979 | Steps: 19 | Worker: 0
Current State [[-0.00053208  0.00427356 -0.00548752  0.00073481  0.00363305 -0.00841002
  -0.00353604  0.00734693 -0.0080968  -0.00650913]]
Logits tf.Tensor([[-0.00379835 -0.01273256  0.01387525]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.33234334 0.32938737 0.3382693 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.02, 0.15, 0.39, 0.127, 0.145, 0.73, 0.029, 0.002, 0.771, 0.13]
0.7271248333333334
1.6726188333333332
Reward 17.6258870513981
Current State [[0.02  0.15  0.39  0.127 0.145 0.73  0.029 0.002 0.771 0.13 ]]
Logits tf.Tensor([[-0.04976461 -0.2530004   0.64459515]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2618821  0.21371825 0.52439964]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.39, 0.131, 0.145, 0.73, 0.029, 0.002, 0.771, 0.13]
0.7271248333333334
1.6726188333333332
Reward 17.6258870513981
Current State [[0.03  0.15  0.39  0.131 0.145 0.73  0.029 0.002 0.771 0.13 ]]
Logits tf.Tensor([[-0.05127819 -0.25464898  0.6454901 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2615589  0.21342567 0.5250154 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.15, 0.4, 0.149, 0.145, 0.63, 0.02, 0.01, 0.735, 0.11]
0.6308653333333333
9.876785666666667
Reward 16.02295163351121
Current State [[0.06  0.15  0.4   0.149 0.145 0.63  0.02  0.01  0.735 0.11 ]]
Logits tf.Tensor([[-0.0488868  -0.23276007  0.61220866]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26532558 0.22076184 0.51391256]], shape=(1, 3), dtype=float32)
Selected action 1
[0.04, 0.08, 0.39, 0.124, 0.145, 0.8, 0.037, 0.003, 0.587, 0.06]
0.804976
2.6363098333333337
Reward 11.011561260676816
Current State [[0.04  0.08  0.39  0.124 0.145 0.8   0.037 0.003 0.587 0.06 ]]
Logits tf.Tensor([[-0.04059067 -0.22226998  0.58623916]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26986647 0.22503321 0.50510037]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.38, 0.133, 0.145, 0.82, 0.04, 0.002, 0.518, 0.17]
0.8214113333333334
2.2238098333333336
Reward 17.307765674456036
Current State [[0.03  0.15  0.38  0.133 0.145 0.82  0.04  0.002 0.518 0.17 ]]
Logits tf.Tensor([[-0.03565466 -0.24984273  0.5852173 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.272647   0.22007973 0.50727326]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.15, 0.39, 0.143, 0.145, 0.82, 0.04, 0.002, 0.518, 0.17]
0.8214113333333334
2.2238098333333336
Reward 17.307765674456036
Current State [[0.06  0.15  0.39  0.143 0.145 0.82  0.04  0.002 0.518 0.17 ]]
Logits tf.Tensor([[-0.0394035  -0.25496936  0.586502  ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2720331  0.21928182 0.5086851 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.06, 0.08, 0.39, 0.152, 0.145, 0.85, 0.048, 0.001, 0.489, 0.17]
0.8460993333333333
0.9154761666666666
Reward 14.569682477737032
Current State [[0.06  0.08  0.39  0.152 0.145 0.85  0.048 0.001 0.489 0.17 ]]
Logits tf.Tensor([[-0.04228292 -0.2355163   0.56641847]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.27305    0.2250723  0.50187767]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.4, 0.112, 0.145, 0.8, 0.055, 0.002, 0.46699999999999997, 0.19]
0.803604
2.4035713333333333
Reward 17.143833220042165
Current State [[0.05  0.15  0.4   0.112 0.145 0.8   0.055 0.002 0.467 0.19 ]]
Logits tf.Tensor([[-0.04150413 -0.25293368  0.5670334 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.27418533 0.22193283 0.5038819 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.02, 0.15, 0.38, 0.138, 0.145, 0.8, 0.055, 0.002, 0.46699999999999997, 0.19]
0.803604
2.4035713333333333
Reward 17.143833220042165
Current State [[0.02  0.15  0.38  0.138 0.145 0.8   0.055 0.002 0.467 0.19 ]]
Logits tf.Tensor([[-0.03703574 -0.24307637  0.5654031 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.27469748 0.22354883 0.5017537 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.4, 0.165, 0.145, 0.84, 0.045, 0.002, 0.496, 0.22]
0.8373796666666669
1.8029768333333334
Reward 5.775995190848555
Current State [[0.04  0.04  0.4   0.165 0.145 0.84  0.045 0.002 0.496 0.22 ]]
Logits tf.Tensor([[-0.03837588 -0.22567855  0.55465966]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.27482605 0.22788374 0.49729022]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.39, 0.127, 0.145, 0.84, 0.045, 0.002, 0.483, 0.23]
0.8387983333333333
2.0386911666666667
Reward 17.510683726106997
Current State [[0.03  0.15  0.39  0.127 0.145 0.84  0.045 0.002 0.483 0.23 ]]
Logits tf.Tensor([[-0.0351227  -0.25780427  0.58093786]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2738234  0.21915993 0.50701666]], shape=(1, 3), dtype=float32)
Selected action 0
[0.03, 0.04, 0.35, 0.14, 0.145, 0.84, 0.045, 0.002, 0.483, 0.23]
0.8387983333333333
2.0386911666666667
Reward 5.510683726106999
Current State [[0.03  0.04  0.35  0.14  0.145 0.84  0.045 0.002 0.483 0.23 ]]
Logits tf.Tensor([[-0.03857756 -0.23002951  0.5424282 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2767327  0.22851463 0.49475262]], shape=(1, 3), dtype=float32)
Selected action 2
[0.02, 0.15, 0.31, 0.119, 0.145, 0.87, 0.04, 0.001, 0.46799999999999997, 0.15]
0.8748881666666667
0.8601188333333333
Reward 21.250026829510198
Current State [[0.02  0.15  0.31  0.119 0.145 0.87  0.04  0.001 0.468 0.15 ]]
Logits tf.Tensor([[-0.03590188 -0.24874237  0.5723824 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.27430615 0.22171758 0.5039763 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.34, 0.132, 0.145, 0.88, 0.071, 0.001, 0.422, 0.07]
0.8755180000000002
1.3226183333333332
Reward 18.86415227450999
Current State [[0.03  0.15  0.34  0.132 0.145 0.88  0.071 0.001 0.422 0.07 ]]
Logits tf.Tensor([[-0.04514985 -0.23693666  0.56598926]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.27262726 0.22504912 0.5023236 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.37, 0.169, 0.145, 0.88, 0.071, 0.001, 0.422, 0.07]
0.8755180000000002
1.3226183333333332
Reward 18.86415227450999
Current State [[0.04  0.15  0.37  0.169 0.145 0.88  0.071 0.001 0.422 0.07 ]]
Logits tf.Tensor([[-0.04467622 -0.2321858   0.57168275]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.27165106 0.2252045  0.50314444]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.38, 0.151, 0.145, 0.84, 0.028, 0.005, 0.48600000000000004, 0.1]
0.8387354999999999
4.574405
Reward 16.487684918545547
Current State [[0.04  0.15  0.38  0.151 0.145 0.84  0.028 0.005 0.486 0.1  ]]
Logits tf.Tensor([[-0.02997401 -0.23403591  0.57951134]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.27360559 0.22310123 0.5032932 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.36, 0.131, 0.145, 0.83, 0.043, 0.002, 0.502, 0.2]
0.8285388333333332
2.0994046666666666
Reward 17.428916041281138
Current State [[0.03  0.15  0.36  0.131 0.145 0.83  0.043 0.002 0.502 0.2  ]]
Logits tf.Tensor([[-0.03654719 -0.25469917  0.5810522 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.27333802 0.21976466 0.5068974 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.05, 0.08, 0.38, 0.126, 0.145, 0.85, 0.032, 0.003, 0.489, 0.1]
0.8481065
2.9488099999999995
Reward 10.932167254346812
Current State [[0.05  0.08  0.38  0.126 0.145 0.85  0.032 0.003 0.489 0.1  ]]
Logits tf.Tensor([[-0.03573295 -0.2258812   0.56250393]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.27429235 0.22679494 0.49891278]], shape=(1, 3), dtype=float32)
Selected action 0
[0.03, 0.04, 0.39, 0.168, 0.145, 0.85, 0.032, 0.003, 0.489, 0.1]
0.8481065
2.9488099999999995
Reward 4.932167254346813
Current State [[0.03  0.04  0.39  0.168 0.145 0.85  0.032 0.003 0.489 0.1  ]]
Logits tf.Tensor([[-0.03241257 -0.20612317  0.5532493 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.27497306 0.2311259  0.49390098]], shape=(1, 3), dtype=float32)
Selected action 1
[0.02, 0.08, 0.39, 0.16, 0.145, 0.9, 0.04, 0.002, 0.546, 0.13]
0.8994956666666667
2.1809518333333333
Reward 11.515554556905176
Episode: 97 | Average Reward: 280 | Episode Reward: 294 | Loss: 652.553 | Steps: 19 | Worker: 0
Current State [[-0.00388514 -0.00474743  0.00535154 -0.00380817  0.00471526 -0.00353263
   0.00578279  0.00194308 -0.00755558  0.00852395]]
Logits tf.Tensor([[-0.00713804 -0.01762982  0.02179921]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.33124393 0.3277868  0.34096926]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.39, 0.142, 0.145, 0.84, 0.044, 0.003, 0.485, 0.19]
0.8444434999999999
2.588690833333333
Reward 17.106424936043524
Current State [[0.04  0.15  0.39  0.142 0.145 0.84  0.044 0.003 0.485 0.19 ]]
Logits tf.Tensor([[-0.04186502 -0.25138056  0.5871802 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.27123824 0.21996798 0.5087938 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.03, 0.04, 0.34, 0.124, 0.145, 0.84, 0.044, 0.003, 0.485, 0.19]
0.8444434999999999
2.588690833333333
Reward 5.106424936043523
Current State [[0.03  0.04  0.34  0.124 0.145 0.84  0.044 0.003 0.485 0.19 ]]
Logits tf.Tensor([[-0.04518365 -0.22599052  0.5455063 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2747381  0.22929548 0.49596646]], shape=(1, 3), dtype=float32)
Selected action 1
[0.04, 0.08, 0.38, 0.16, 0.145, 0.86, 0.045, 0.001, 0.512, 0.16]
0.8581465000000001
1.486905
Reward 12.377127027492225
Current State [[0.04  0.08  0.38  0.16  0.145 0.86  0.045 0.001 0.512 0.16 ]]
Logits tf.Tensor([[-0.04628517 -0.23153718  0.58053035]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.27008516 0.2244124  0.5055024 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.04, 0.39, 0.123, 0.145, 0.86, 0.035, 0.002, 0.571, 0.19]
0.8579191666666668
2.4869043333333334
Reward 5.19312820346053
Current State [[0.05  0.04  0.39  0.123 0.145 0.86  0.035 0.002 0.571 0.19 ]]
Logits tf.Tensor([[-0.04878437 -0.24003907  0.58934355]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2688999 0.2220904 0.5090097]], shape=(1, 3), dtype=float32)
Selected action 2
[0.02, 0.15, 0.4, 0.15, 0.145, 0.86, 0.035, 0.002, 0.571, 0.19]
0.8579191666666668
2.4869043333333334
Reward 17.19312820346053
Current State [[0.02  0.15  0.4   0.15  0.145 0.86  0.035 0.002 0.571 0.19 ]]
Logits tf.Tensor([[-0.0405334  -0.25750983  0.6209717 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26718998 0.21507429 0.5177358 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.4, 0.157, 0.145, 0.79, 0.032, 0.003, 0.557, 0.16]
0.7862035000000002
2.964881666666666
Reward 16.833311313866467
Current State [[0.04  0.15  0.4   0.157 0.145 0.79  0.032 0.003 0.557 0.16 ]]
Logits tf.Tensor([[-0.04114388 -0.24543825  0.5957829 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26984116 0.21998055 0.51017827]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.04, 0.35, 0.133, 0.145, 0.77, 0.039, 0.003, 0.616, 0.17]
0.7749308333333332
2.8874996666666664
Reward 4.847311273464909
Current State [[0.05  0.04  0.35  0.133 0.145 0.77  0.039 0.003 0.616 0.17 ]]
Logits tf.Tensor([[-0.05350107 -0.23261836  0.5769562 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2692169  0.22506742 0.50571567]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.35, 0.166, 0.145, 0.77, 0.039, 0.003, 0.616, 0.17]
0.7749308333333332
2.8874996666666664
Reward 16.84731127346491
Current State [[0.04  0.15  0.35  0.166 0.145 0.77  0.039 0.003 0.616 0.17 ]]
Logits tf.Tensor([[-0.0509524  -0.25242588  0.6066394 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2668329  0.21814263 0.5150244 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.34, 0.136, 0.145, 0.84, 0.022, 0.002, 0.5559999999999999, 0.11]
0.8436600000000002
1.9172624999999999
Reward 17.65246016260417
Current State [[0.03  0.15  0.34  0.136 0.145 0.84  0.022 0.002 0.556 0.11 ]]
Logits tf.Tensor([[-0.04159109 -0.24242826  0.6050362 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26830247 0.21948367 0.5122139 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.34, 0.121, 0.145, 0.85, 0.025, 0.003, 0.6599999999999999, 0.09]
0.8532756666666667
3.0273808333333334
Reward 16.90663285395174
Current State [[0.03  0.15  0.34  0.121 0.145 0.85  0.025 0.003 0.66  0.09 ]]
Logits tf.Tensor([[-0.05011503 -0.25299302  0.6421304 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2621524  0.21401541 0.5238322 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.36, 0.14, 0.145, 0.91, 0.041, 0.002, 0.461, 0.14]
0.9079855000000001
1.9880958333333334
Reward 17.736613116854222
Current State [[0.05  0.15  0.36  0.14  0.145 0.91  0.041 0.002 0.461 0.14 ]]
Logits tf.Tensor([[-0.04340949 -0.2519714   0.5932221 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2701349 0.2192822 0.5105829]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.15, 0.38, 0.164, 0.145, 0.91, 0.041, 0.002, 0.461, 0.14]
0.9079855000000001
1.9880958333333334
Reward 17.736613116854222
Current State [[0.07  0.15  0.38  0.164 0.145 0.91  0.041 0.002 0.461 0.14 ]]
Logits tf.Tensor([[-0.04450578 -0.25165626  0.5971292 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26936162 0.21896334 0.51167506]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.36, 0.163, 0.145, 0.68, 0.017, 0.009, 0.9490000000000001, 0.07]
0.6826909999999999
8.83988
Reward 16.072632956358593
Current State [[0.05  0.15  0.36  0.163 0.145 0.68  0.017 0.009 0.949 0.07 ]]
Logits tf.Tensor([[-0.07426852 -0.2568836   0.72566605]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24639742 0.20527092 0.5483317 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.02, 0.08, 0.36, 0.124, 0.145, 0.69, 0.018, 0.013, 0.6809999999999999, 0.09]
0.6948236666666668
12.511904333333336
Reward 9.99220549767229
Current State [[0.02  0.08  0.36  0.124 0.145 0.69  0.018 0.013 0.681 0.09 ]]
Logits tf.Tensor([[-0.04337551 -0.21515009  0.5855783 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2689751  0.22652249 0.5045024 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.35, 0.155, 0.145, 0.69, 0.018, 0.013, 0.6809999999999999, 0.09]
0.6948236666666668
12.511904333333336
Reward 15.99220549767229
Current State [[0.03  0.15  0.35  0.155 0.145 0.69  0.018 0.013 0.681 0.09 ]]
Logits tf.Tensor([[-0.04675258 -0.23048787  0.60392815]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2667377 0.2219674 0.5112949]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.31, 0.151, 0.145, 0.82, 0.029, 0.003, 0.6980000000000001, 0.01]
0.8214461666666667
2.9130958333333328
Reward 4.9072132269731235
Current State [[0.04  0.04  0.31  0.151 0.145 0.82  0.029 0.003 0.698 0.01 ]]
Logits tf.Tensor([[-0.05760496 -0.22063272  0.6150644 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26253414 0.2230405  0.5144254 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.03, 0.08, 0.32, 0.129, 0.145, 0.84, 0.032, 0.001, 0.532, 0.15]
0.8433286666666666
1.1398811666666664
Reward 13.338509524011457
Current State [[0.03  0.08  0.32  0.129 0.145 0.84  0.032 0.001 0.532 0.15 ]]
Logits tf.Tensor([[-0.04302337 -0.23246737  0.5703455 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.27217838 0.22520557 0.502616  ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.33, 0.15, 0.145, 0.87, 0.029, 0.001, 0.5700000000000001, 0.07]
0.869139
1.2029761666666667
Reward 19.230547404707018
Current State [[0.05  0.15  0.33  0.15  0.145 0.87  0.029 0.001 0.57  0.07 ]]
Logits tf.Tensor([[-0.04939768 -0.24602531  0.6171787 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2653185  0.21795823 0.5167232 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.31, 0.159, 0.145, 0.87, 0.029, 0.001, 0.5700000000000001, 0.07]
0.869139
1.2029761666666667
Reward 19.230547404707018
Current State [[0.03  0.15  0.31  0.159 0.145 0.87  0.029 0.001 0.57  0.07 ]]
Logits tf.Tensor([[-0.04776134 -0.24144673  0.61475056]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26570478 0.21891871 0.5153765 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.32, 0.13, 0.145, 0.9, 0.031, 0.001, 0.489, 0.07]
0.8998751666666667
1.0815471666666667
Reward 19.934722999068743
Episode: 98 | Average Reward: 280 | Episode Reward: 284 | Loss: 700.41 | Steps: 19 | Worker: 0
Current State [[ 0.00032556 -0.00069479 -0.00636751 -0.00383059  0.0043757  -0.00530871
   0.00579035 -0.00920174  0.00452459 -0.00632449]]
Logits tf.Tensor([[-0.01271588 -0.01586223  0.02829513]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.32908568 0.3280519  0.3428624 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.35, 0.133, 0.145, 0.91, 0.032, 0.001, 0.533, 0.1]
0.9117118333333333
1.2119044999999997
Reward 7.416856064880485
Current State [[0.04  0.04  0.35  0.133 0.145 0.91  0.032 0.001 0.533 0.1  ]]
Logits tf.Tensor([[-0.05120787 -0.22763428  0.58817136]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26784056 0.22452015 0.5076393 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.35, 0.149, 0.145, 0.91, 0.032, 0.001, 0.533, 0.1]
0.9117118333333333
1.2119044999999997
Reward 19.416856064880484
Current State [[0.05  0.15  0.35  0.149 0.145 0.91  0.032 0.001 0.533 0.1  ]]
Logits tf.Tensor([[-0.05424822 -0.25198525  0.62539387]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26359093 0.21629894 0.52011013]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.36, 0.15, 0.145, 0.66, 0.028, 0.011, 0.445, 0.1]
0.6560661666666666
11.152976166666667
Reward 16.0043126851019
Current State [[0.04  0.15  0.36  0.15  0.145 0.66  0.028 0.011 0.445 0.1  ]]
Logits tf.Tensor([[-0.03911408 -0.20864874  0.5235928 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.27781826 0.2344946  0.48768714]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.35, 0.125, 0.145, 0.77, 0.035, 0.002, 0.583, 0.17]
0.7734396666666666
1.7363093333333335
Reward 5.679673745981137
Current State [[0.04  0.04  0.35  0.125 0.145 0.77  0.035 0.002 0.583 0.17 ]]
Logits tf.Tensor([[-0.05534694 -0.22691947  0.5728299 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2690682  0.22664669 0.5042851 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.36, 0.176, 0.145, 0.77, 0.035, 0.002, 0.583, 0.17]
0.7734396666666666
1.7363093333333335
Reward 17.679673745981138
Current State [[0.05  0.15  0.36  0.176 0.145 0.77  0.035 0.002 0.583 0.17 ]]
Logits tf.Tensor([[-0.0551508  -0.24951658  0.6052991 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2660268  0.21903495 0.5149383 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.33, 0.148, 0.145, 0.89, 0.035, 0.002, 0.501, 0.11]
0.8882893333333334
1.7464286666666669
Reward 18.005609972370603
Current State [[0.03  0.15  0.33  0.148 0.145 0.89  0.035 0.002 0.501 0.11 ]]
Logits tf.Tensor([[-0.05077909 -0.24468604  0.6062071 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26647446 0.21950424 0.5140213 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.34, 0.129, 0.145, 0.76, 0.018, 0.004, 0.52, 0.04]
0.7580221666666667
4.323809499999999
Reward 16.454948401780964
Current State [[0.03  0.15  0.34  0.129 0.145 0.76  0.018 0.004 0.52  0.04 ]]
Logits tf.Tensor([[-0.04520036 -0.21607803  0.5784246 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26964328 0.22728898 0.50306773]], shape=(1, 3), dtype=float32)
Selected action 1
[0.06, 0.08, 0.36, 0.13, 0.145, 0.85, 0.034, 0.002, 0.485, 0.13]
0.8542041666666668
2.3934519999999995
Reward 11.248851226978804
Current State [[0.06  0.08  0.36  0.13  0.145 0.85  0.034 0.002 0.485 0.13 ]]
Logits tf.Tensor([[-0.05112279 -0.23141886  0.5714946 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2703563  0.2257537  0.50389004]], shape=(1, 3), dtype=float32)
Selected action 1
[0.05, 0.08, 0.36, 0.152, 0.145, 0.85, 0.034, 0.002, 0.485, 0.13]
0.8542041666666668
2.3934519999999995
Reward 11.248851226978804
Current State [[0.05  0.08  0.36  0.152 0.145 0.85  0.034 0.002 0.485 0.13 ]]
Logits tf.Tensor([[-0.04902992 -0.22590795  0.571792  ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.27039167 0.22655632 0.503052  ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.35, 0.147, 0.145, 0.87, 0.031, 0.001, 0.524, 0.13]
0.8724941666666666
1.4267865000000002
Reward 18.57083654411157
Current State [[0.05  0.15  0.35  0.147 0.145 0.87  0.031 0.001 0.524 0.13 ]]
Logits tf.Tensor([[-0.05215586 -0.25002664  0.61221796]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26569253 0.21799429 0.51631314]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.15, 0.37, 0.131, 0.145, 0.72, 0.022, 0.008, 0.479, 0.08]
0.7218863333333333
7.798809000000001
Reward 16.130369676550224
Current State [[0.08  0.15  0.37  0.131 0.145 0.72  0.022 0.008 0.479 0.08 ]]
Logits tf.Tensor([[-0.0475302  -0.22718397  0.55502033]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2730501  0.22814961 0.4988003 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.01, 0.15, 0.32, 0.115, 0.145, 0.72, 0.022, 0.008, 0.479, 0.08]
0.7218863333333333
7.798809000000001
Reward 16.130369676550224
Current State [[0.01  0.15  0.32  0.115 0.145 0.72  0.022 0.008 0.479 0.08 ]]
Logits tf.Tensor([[-0.03938717 -0.21190175  0.54760873]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.27471596 0.23118612 0.4940979 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.36, 0.162, 0.145, 0.82, 0.026, 0.006, 0.446, 0.08]
0.816407
5.869643166666665
Reward 16.310123147074787
Current State [[0.05  0.15  0.36  0.162 0.145 0.82  0.026 0.006 0.446 0.08 ]]
Logits tf.Tensor([[-0.0426276  -0.22413556  0.5719725 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.27152306 0.22645336 0.5020236 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.05, 0.08, 0.34, 0.13, 0.145, 0.78, 0.042, 0.002, 0.5309999999999999, 0.18]
0.7803606666666667
1.5214290000000001
Reward 12.02826907992238
Current State [[0.05  0.08  0.34  0.13  0.145 0.78  0.042 0.002 0.531 0.18 ]]
Logits tf.Tensor([[-0.05574304 -0.23471734  0.5675267 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.27018675 0.22591053 0.5039027 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.04, 0.36, 0.147, 0.145, 0.78, 0.042, 0.002, 0.5309999999999999, 0.18]
0.7803606666666667
1.5214290000000001
Reward 6.02826907992238
Current State [[0.05  0.04  0.36  0.147 0.145 0.78  0.042 0.002 0.531 0.18 ]]
Logits tf.Tensor([[-0.05608612 -0.2229636   0.55999947]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.27041873 0.22885625 0.50072503]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.35, 0.148, 0.145, 0.71, 0.018, 0.007, 0.701, 0.06]
0.7050326666666666
6.817261833333332
Reward 16.17168823524714
Current State [[0.04  0.15  0.35  0.148 0.145 0.71  0.018 0.007 0.701 0.06 ]]
Logits tf.Tensor([[-0.06001033 -0.2314282   0.62929434]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26076987 0.21969064 0.51953954]], shape=(1, 3), dtype=float32)
Selected action 0
[0.03, 0.04, 0.43, 0.139, 0.145, 0.76, 0.028, 0.002, 0.759, 0.1]
0.760401
1.5023803333333334
Reward 5.992406187874912
Current State [[0.03  0.04  0.43  0.139 0.145 0.76  0.028 0.002 0.759 0.1  ]]
Logits tf.Tensor([[-0.06190578 -0.22370747  0.644328  ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2579344  0.21940154 0.52266407]], shape=(1, 3), dtype=float32)
Selected action 0
[0.03, 0.04, 0.4, 0.121, 0.145, 0.69, 0.032, 0.004, 0.74, 0.17]
0.6853075
4.373809666666667
Reward 4.379927414861955
Current State [[0.03  0.04  0.4   0.121 0.145 0.69  0.032 0.004 0.74  0.17 ]]
Logits tf.Tensor([[-0.05892027 -0.23256922  0.61128765]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26348826 0.2214861  0.5150257 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.43, 0.156, 0.145, 0.69, 0.032, 0.004, 0.74, 0.17]
0.6853075
4.373809666666667
Reward 4.379927414861955
Current State [[0.04  0.04  0.43  0.156 0.145 0.69  0.032 0.004 0.74  0.17 ]]
Logits tf.Tensor([[-0.05964803 -0.23035863  0.6186229 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26222402 0.22107203 0.51670396]], shape=(1, 3), dtype=float32)
Selected action 0
[0.03, 0.04, 0.42, 0.156, 0.145, 0.75, 0.032, 0.002, 0.783, 0.11]
0.7526808333333332
2.2333338333333335
Reward 5.156230796734486
Episode: 99 | Average Reward: 280 | Episode Reward: 244 | Loss: 428.175 | Steps: 19 | Worker: 0
Current State [[-0.00323129  0.00225005 -0.00158365 -0.00549999  0.00961373 -0.00200106
   0.00266775  0.00420927 -0.00170576  0.0085955 ]]
Logits tf.Tensor([[-0.00948534 -0.01950199  0.02923243]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.33008632 0.32679647 0.34311718]], shape=(1, 3), dtype=float32)
Selected action 0
[0.02, 0.04, 0.36, 0.126, 0.145, 0.62, 0.027, 0.006, 0.843, 0.18]
0.6213466666666666
6.289880833333334
Reward 4.154005156498764
Current State [[0.02  0.04  0.36  0.126 0.145 0.62  0.027 0.006 0.843 0.18 ]]
Logits tf.Tensor([[-0.0701946  -0.24464568  0.646895  ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2571765  0.21600714 0.52681637]], shape=(1, 3), dtype=float32)
Selected action 2
[0.02, 0.15, 0.35, 0.142, 0.145, 0.62, 0.027, 0.006, 0.843, 0.18]
0.6213466666666666
6.289880833333334
Reward 16.154005156498762
Current State [[0.02  0.15  0.35  0.142 0.145 0.62  0.027 0.006 0.843 0.18 ]]
Logits tf.Tensor([[-0.07219512 -0.26314557  0.6724014 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25433868 0.21012789 0.5355334 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.02, 0.15, 0.33, 0.147, 0.145, 0.84, 0.035, 0.002, 0.768, 0.22]
0.8410068333333334
2.131548
Reward 17.428422248179736
Current State [[0.02  0.15  0.33  0.147 0.145 0.84  0.035 0.002 0.768 0.22 ]]
Logits tf.Tensor([[-0.07398504 -0.2861245   0.6924376 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25246754 0.20420882 0.5433237 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.15, 0.38, 0.124, 0.145, 0.86, 0.036, 0.001, 0.589, 0.02]
0.8637140000000001
0.6505955
Reward 23.820842241254308
Current State [[0.07  0.15  0.38  0.124 0.145 0.86  0.036 0.001 0.589 0.02 ]]
Logits tf.Tensor([[-0.06919309 -0.24659517  0.64671695]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2575003  0.21564181 0.5268579 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.39, 0.151, 0.145, 0.88, 0.046, 0.001, 0.45499999999999996, 0.15]
0.8769186666666666
0.889286
Reward 21.01802460552128
Current State [[0.05  0.15  0.39  0.151 0.145 0.88  0.046 0.001 0.455 0.15 ]]
Logits tf.Tensor([[-0.05459166 -0.24797696  0.60509694]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26607388 0.21928862 0.5146375 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.37, 0.144, 0.145, 0.88, 0.046, 0.001, 0.45499999999999996, 0.15]
0.8769186666666666
0.889286
Reward 21.01802460552128
Current State [[0.05  0.15  0.37  0.144 0.145 0.88  0.046 0.001 0.455 0.15 ]]
Logits tf.Tensor([[-0.05580647 -0.24987064  0.60202026]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26636854 0.21938246 0.51424897]], shape=(1, 3), dtype=float32)
Selected action 0
[0.03, 0.04, 0.39, 0.142, 0.145, 0.82, 0.059, 0.003, 0.434, 0.18]
0.8219589999999999
2.7827376666666663
Reward 4.966809175586304
Current State [[0.03  0.04  0.39  0.142 0.145 0.82  0.059 0.003 0.434 0.18 ]]
Logits tf.Tensor([[-0.05762066 -0.21449336  0.54951787]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.27100378 0.2316575  0.4973387 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.04, 0.42, 0.132, 0.145, 0.75, 0.07, 0.004, 0.42800000000000005, 0.15]
0.7501643333333334
4.058332500000001
Reward 4.493781065039744
Current State [[0.05  0.04  0.42  0.132 0.145 0.75  0.07  0.004 0.428 0.15 ]]
Logits tf.Tensor([[-0.06456892 -0.20827255  0.5371181 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.27090436 0.23464228 0.49445337]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.33, 0.146, 0.145, 0.75, 0.07, 0.004, 0.42800000000000005, 0.15]
0.7501643333333334
4.058332500000001
Reward 4.493781065039744
Current State [[0.04  0.04  0.33  0.146 0.145 0.75  0.07  0.004 0.428 0.15 ]]
Logits tf.Tensor([[-0.06374312 -0.20690411  0.5205834 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2731944  0.23675425 0.49005136]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.38, 0.153, 0.145, 0.81, 0.038, 0.003, 0.536, 0.16]
0.8119995000000001
2.9422618333333337
Reward 16.88069748237154
Current State [[0.04  0.15  0.38  0.153 0.145 0.81  0.038 0.003 0.536 0.16 ]]
Logits tf.Tensor([[-0.05643611 -0.24908547  0.6105067 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26503804 0.21859574 0.51636624]], shape=(1, 3), dtype=float32)
Selected action 1
[0.04, 0.08, 0.39, 0.12, 0.145, 0.89, 0.045, 0.001, 0.492, 0.15]
0.8869265
1.251190666666667
Reward 13.146687288609183
Current State [[0.04  0.08  0.39  0.12  0.145 0.89  0.045 0.001 0.492 0.15 ]]
Logits tf.Tensor([[-0.05782695 -0.23935364  0.5971686 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.266019   0.22185878 0.5121222 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.15, 0.39, 0.142, 0.145, 0.89, 0.045, 0.001, 0.492, 0.15]
0.8869265
1.251190666666667
Reward 19.146687288609183
Current State [[0.06  0.15  0.39  0.142 0.145 0.89  0.045 0.001 0.492 0.15 ]]
Logits tf.Tensor([[-0.05869853 -0.25684738  0.6203944 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26368973 0.2162909  0.52001935]], shape=(1, 3), dtype=float32)
Selected action 1
[0.05, 0.08, 0.38, 0.174, 0.145, 0.81, 0.034, 0.002, 0.521, 0.13]
0.8111891666666667
1.706547833333333
Reward 11.831895935195945
Current State [[0.05  0.08  0.38  0.174 0.145 0.81  0.034 0.002 0.521 0.13 ]]
Logits tf.Tensor([[-0.05568781 -0.22349823  0.5866476 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26692083 0.22568533 0.50739384]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.38, 0.129, 0.145, 0.89, 0.042, 0.001, 0.505, 0.04]
0.8939611666666667
1.0994045
Reward 19.80940975918965
Current State [[0.05  0.15  0.38  0.129 0.145 0.89  0.042 0.001 0.505 0.04 ]]
Logits tf.Tensor([[-0.06175807 -0.24169123  0.6240239 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2617356  0.21863455 0.51962984]], shape=(1, 3), dtype=float32)
Selected action 1
[0.05, 0.08, 0.39, 0.145, 0.145, 0.89, 0.042, 0.001, 0.505, 0.04]
0.8939611666666667
1.0994045
Reward 13.809409759189647
Current State [[0.05  0.08  0.39  0.145 0.145 0.89  0.042 0.001 0.505 0.04 ]]
Logits tf.Tensor([[-0.05947393 -0.22445537  0.6039409 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2638996  0.22376296 0.51233745]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.38, 0.169, 0.145, 0.87, 0.052, 0.001, 0.489, 0.17]
0.8717711666666667
1.3547616666666664
Reward 6.755498881071735
Current State [[0.04  0.04  0.38  0.169 0.145 0.87  0.052 0.001 0.489 0.17 ]]
Logits tf.Tensor([[-0.06051595 -0.22435957  0.5797039 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26696762 0.22662207 0.5064103 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.02, 0.04, 0.35, 0.131, 0.145, 0.83, 0.033, 0.002, 0.5309999999999999, 0.13]
0.8313310000000002
1.7470241666666668
Reward 5.834555843652396
Current State [[0.02  0.04  0.35  0.131 0.145 0.83  0.033 0.002 0.531 0.13 ]]
Logits tf.Tensor([[-0.05295333 -0.21798083  0.57610905]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26854858 0.22769436 0.50375706]], shape=(1, 3), dtype=float32)
Selected action 0
[0.02, 0.04, 0.4, 0.172, 0.145, 0.87, 0.033, 0.004, 0.503, 0.12]
0.8683531666666667
3.7839288333333334
Reward 4.6797237118188315
Current State [[0.02  0.04  0.4   0.172 0.145 0.87  0.033 0.004 0.503 0.12 ]]
Logits tf.Tensor([[-0.04937052 -0.21137175  0.5857019 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26755142 0.2275365  0.5049121 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.38, 0.159, 0.145, 0.87, 0.033, 0.004, 0.503, 0.12]
0.8683531666666667
3.7839288333333334
Reward 16.67972371181883
Current State [[0.04  0.15  0.38  0.159 0.145 0.87  0.033 0.004 0.503 0.12 ]]
Logits tf.Tensor([[-0.05315625 -0.2431331   0.61660874]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26449734 0.21873356 0.5167691 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.03, 0.08, 0.38, 0.153, 0.145, 0.86, 0.07, 0.008, 0.40599999999999997, 0.1]
0.8649901666666667
8.298214833333335
Reward 10.174822220746819
Episode: 100 | Average Reward: 280 | Episode Reward: 256 | Loss: 481.215 | Steps: 19 | Worker: 0
Current State [[-0.00125579 -0.00876846 -0.00291314  0.00637789  0.00412321  0.00566087
  -0.00176328  0.00886244 -0.0046426   0.00657159]]
Logits tf.Tensor([[-0.00785161 -0.02064423  0.02849799]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3306542  0.32645124 0.3428945 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.02, 0.15, 0.38, 0.126, 0.145, 0.85, 0.043, 0.003, 0.554, 0.15]
0.851106
2.526191
Reward 17.15572940211335
Current State [[0.02  0.15  0.38  0.126 0.145 0.85  0.043 0.003 0.554 0.15 ]]
Logits tf.Tensor([[-0.06308693 -0.25436085  0.63481164]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26072684 0.21533595 0.52393717]], shape=(1, 3), dtype=float32)
Selected action 1
[0.04, 0.08, 0.39, 0.144, 0.145, 0.85, 0.043, 0.003, 0.554, 0.15]
0.851106
2.526191
Reward 11.155729402113352
Current State [[0.04  0.08  0.39  0.144 0.145 0.85  0.043 0.003 0.554 0.15 ]]
Logits tf.Tensor([[-0.06369209 -0.2400028   0.61635405]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26230702 0.21990706 0.5177859 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.4, 0.135, 0.145, 0.88, 0.042, 0.002, 0.502, 0.14]
0.8788041666666667
2.0261903333333335
Reward 5.620896310475621
Current State [[0.04  0.04  0.4   0.135 0.145 0.88  0.042 0.002 0.502 0.14 ]]
Logits tf.Tensor([[-0.06126795 -0.22781496  0.59484553]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26497996 0.22432753 0.51069254]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.42, 0.148, 0.145, 0.81, 0.027, 0.003, 0.5860000000000001, 0.1]
0.8071368333333333
3.213691
Reward 4.772460019527078
Current State [[0.04  0.04  0.42  0.148 0.145 0.81  0.027 0.003 0.586 0.1  ]]
Logits tf.Tensor([[-0.05968288 -0.2198145   0.60988206]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26278314 0.22389957 0.5133172 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.01, 0.08, 0.36, 0.141, 0.145, 0.81, 0.027, 0.003, 0.5860000000000001, 0.1]
0.8071368333333333
3.213691
Reward 10.772460019527077
Current State [[0.01  0.08  0.36  0.141 0.145 0.81  0.027 0.003 0.586 0.1  ]]
Logits tf.Tensor([[-0.05763056 -0.222971    0.6122442 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2630473  0.22296025 0.5139925 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.39, 0.152, 0.145, 0.78, 0.039, 0.002, 0.583, 0.22]
0.7756908333333334
2.3696436666666663
Reward 17.11165447127661
Current State [[0.03  0.15  0.39  0.152 0.145 0.78  0.039 0.002 0.583 0.22 ]]
Logits tf.Tensor([[-0.06175546 -0.2607143   0.6238451 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26284337 0.21542212 0.5217345 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.38, 0.126, 0.145, 0.83, 0.042, 0.002, 0.576, 0.22]
0.8277841666666668
1.9875000000000003
Reward 17.535521659116245
Current State [[0.03  0.15  0.38  0.126 0.145 0.83  0.042 0.002 0.576 0.22 ]]
Logits tf.Tensor([[-0.06391028 -0.2701937   0.63563955]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26133892 0.212626   0.5260351 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.03, 0.08, 0.38, 0.15, 0.145, 0.83, 0.042, 0.002, 0.576, 0.22]
0.8277841666666668
1.9875000000000003
Reward 11.535521659116245
Current State [[0.03  0.08  0.38  0.15  0.145 0.83  0.042 0.002 0.576 0.22 ]]
Logits tf.Tensor([[-0.06332511 -0.2478636   0.6150936 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2630024  0.21868332 0.5183143 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.03, 0.08, 0.37, 0.129, 0.145, 0.81, 0.03, 0.005, 0.529, 0.11]
0.8102418333333333
5.015477000000001
Reward 10.39940407797604
Current State [[0.03  0.08  0.37  0.129 0.145 0.81  0.03  0.005 0.529 0.11 ]]
Logits tf.Tensor([[-0.05582615 -0.22472806  0.5925357 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26617002 0.224805   0.509025  ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.38, 0.147, 0.145, 0.9, 0.038, 0.002, 0.597, 0.06]
0.8966061666666666
1.6934525
Reward 18.116515721397818
Current State [[0.05  0.15  0.38  0.147 0.145 0.9   0.038 0.002 0.597 0.06 ]]
Logits tf.Tensor([[-0.07148295 -0.2542782   0.6669746 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2547353  0.21217887 0.5330858 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.01, 0.04, 0.37, 0.129, 0.145, 0.86, 0.046, 0.002, 0.502, 0.24]
0.8598798333333334
2.0178566666666664
Reward 5.583154998962253
Current State [[0.01  0.04  0.37  0.129 0.145 0.86  0.046 0.002 0.502 0.24 ]]
Logits tf.Tensor([[-0.05827999 -0.23430993  0.58406454]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26741362 0.22425115 0.50833523]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.38, 0.165, 0.145, 0.86, 0.046, 0.002, 0.502, 0.24]
0.8598798333333334
2.0178566666666664
Reward 17.583154998962254
Current State [[0.04  0.15  0.38  0.165 0.145 0.86  0.046 0.002 0.502 0.24 ]]
Logits tf.Tensor([[-0.05915591 -0.2650312   0.6205831 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26404053 0.21491173 0.5210477 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.0, 0.04, 0.31, 0.147, 0.145, 0.72, 0.016, 0.005, 0.818, 0.07]
0.7207791666666667
4.743452166666668
Reward 4.361054426955515
Current State [[0.    0.04  0.31  0.147 0.145 0.72  0.016 0.005 0.818 0.07 ]]
Logits tf.Tensor([[-0.0793933  -0.22007862  0.66423637]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2517421  0.21870412 0.52955383]], shape=(1, 3), dtype=float32)
Selected action 0
[0.03, 0.04, 0.29, 0.125, 0.145, 0.7, 0.014, 0.005, 0.93, 0.1]
0.7032450000000001
5.306547499999999
Reward 4.284333783158157
Current State [[0.03  0.04  0.29  0.125 0.145 0.7   0.014 0.005 0.93  0.1  ]]
Logits tf.Tensor([[-0.08916846 -0.25055867  0.7083145 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24564554 0.20903453 0.5453199 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.38, 0.149, 0.145, 0.7, 0.014, 0.005, 0.93, 0.1]
0.7032450000000001
5.306547499999999
Reward 4.284333783158157
Current State [[0.04  0.04  0.38  0.149 0.145 0.7   0.014 0.005 0.93  0.1  ]]
Logits tf.Tensor([[-0.08891535 -0.2421685   0.7182393 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24393615 0.20927589 0.546788  ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.02, 0.15, 0.32, 0.165, 0.145, 0.84, 0.033, 0.001, 0.5650000000000001, 0.01]
0.8374266666666668
1.2684528333333336
Reward 18.853719916214814
Current State [[0.02  0.15  0.32  0.165 0.145 0.84  0.033 0.001 0.565 0.01 ]]
Logits tf.Tensor([[-0.06570635 -0.22672378  0.63061357]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25922632 0.22067347 0.5201002 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.33, 0.117, 0.145, 0.88, 0.033, 0.001, 0.512, 0.05]
0.8845228333333333
0.8624996666666668
Reward 21.31323852152311
Current State [[0.04  0.15  0.33  0.117 0.145 0.88  0.033 0.001 0.512 0.05 ]]
Logits tf.Tensor([[-0.06428374 -0.24406947  0.62111837]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26177883 0.2187029  0.5195183 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.02, 0.15, 0.29, 0.11, 0.145, 0.88, 0.029, 0.002, 0.575, 0.11]
0.8759541666666667
2.066072
Reward 17.57242892387245
Current State [[0.02  0.15  0.29  0.11  0.145 0.88  0.029 0.002 0.575 0.11 ]]
Logits tf.Tensor([[-0.06605978 -0.25849804  0.6378098 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25997624 0.21446615 0.52555764]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.33, 0.16, 0.145, 0.88, 0.029, 0.002, 0.575, 0.11]
0.8759541666666667
2.066072
Reward 17.57242892387245
Current State [[0.05  0.15  0.33  0.16  0.145 0.88  0.029 0.002 0.575 0.11 ]]
Logits tf.Tensor([[-0.06711692 -0.25566396  0.645338  ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25858822 0.21415283 0.527259  ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.15, 0.33, 0.151, 0.145, 0.82, 0.021, 0.002, 0.585, 0.1]
0.8183315
2.0583331666666664
Reward 17.44304307552786
Episode: 101 | Average Reward: 280 | Episode Reward: 253 | Loss: 539.412 | Steps: 19 | Worker: 0
Current State [[-0.00523857 -0.00330713 -0.0026317  -0.00819025  0.00644786 -0.00283574
   0.00876154  0.00896514  0.00279476 -0.0029892 ]]
Logits tf.Tensor([[-0.01101627 -0.01939832  0.02983579]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.32966843 0.32691666 0.34341493]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.32, 0.135, 0.145, 0.92, 0.031, 0.001, 0.503, 0.08]
0.9163751666666666
1.3750000000000002
Reward 18.890823226815733
Current State [[0.04  0.15  0.32  0.135 0.145 0.92  0.031 0.001 0.503 0.08 ]]
Logits tf.Tensor([[-0.06684529 -0.2521128   0.63243467]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26020083 0.2161962  0.523603  ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.37, 0.16, 0.145, 0.92, 0.031, 0.001, 0.503, 0.08]
0.9163751666666666
1.3750000000000002
Reward 6.890823226815732
Current State [[0.04  0.04  0.37  0.16  0.145 0.92  0.031 0.001 0.503 0.08 ]]
Logits tf.Tensor([[-0.05993846 -0.2226718   0.60307163]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26382142 0.22420014 0.51197845]], shape=(1, 3), dtype=float32)
Selected action 0
[0.02, 0.04, 0.34, 0.155, 0.145, 0.75, 0.025, 0.003, 0.5589999999999999, 0.1]
0.7531248333333334
2.6553578333333334
Reward 4.914479080589844
Current State [[0.02  0.04  0.34  0.155 0.145 0.75  0.025 0.003 0.559 0.1  ]]
Logits tf.Tensor([[-0.05823799 -0.20557857  0.57690597]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2666458 0.2301153 0.5032389]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.42, 0.144, 0.145, 0.85, 0.035, 0.001, 0.538, 0.15]
0.8472821666666667
1.3053575
Reward 6.78824897111945
Current State [[0.04  0.04  0.42  0.144 0.145 0.85  0.035 0.001 0.538 0.15 ]]
Logits tf.Tensor([[-0.06322654 -0.22864893  0.6085285 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2627979  0.22273056 0.51447153]], shape=(1, 3), dtype=float32)
Selected action 1
[0.04, 0.08, 0.34, 0.151, 0.145, 0.85, 0.035, 0.001, 0.538, 0.15]
0.8472821666666667
1.3053575
Reward 12.788248971119451
Current State [[0.04  0.08  0.34  0.151 0.145 0.85  0.035 0.001 0.538 0.15 ]]
Logits tf.Tensor([[-0.06419786 -0.23764172  0.6065843 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26339838 0.22145595 0.51514566]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.34, 0.152, 0.145, 0.81, 0.027, 0.004, 0.595, 0.15]
0.8118716666666665
3.792857333333333
Reward 16.614675647965814
Current State [[0.04  0.15  0.34  0.152 0.145 0.81  0.027 0.004 0.595 0.15 ]]
Logits tf.Tensor([[-0.06810456 -0.2559119   0.6381231 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25939617 0.21498089 0.52562296]], shape=(1, 3), dtype=float32)
Selected action 1
[0.06, 0.08, 0.34, 0.146, 0.145, 0.91, 0.038, 0.002, 0.47300000000000003, 0.07]
0.9117555
1.5577379999999998
Reward 12.422728727543586
Current State [[0.06  0.08  0.34  0.146 0.145 0.91  0.038 0.002 0.473 0.07 ]]
Logits tf.Tensor([[-0.06514524 -0.2336334   0.59741646]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26422197 0.22325207 0.512526  ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.03, 0.04, 0.33, 0.136, 0.145, 0.89, 0.035, 0.001, 0.51, 0.14]
0.8898745
1.2517865
Reward 7.159054511054881
Current State [[0.03  0.04  0.33  0.136 0.145 0.89  0.035 0.001 0.51  0.14 ]]
Logits tf.Tensor([[-0.06080467 -0.2306673   0.589473  ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2659678  0.22441849 0.5096137 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.33, 0.136, 0.145, 0.89, 0.035, 0.001, 0.51, 0.14]
0.8898745
1.2517865
Reward 19.159054511054883
Current State [[0.03  0.15  0.33  0.136 0.145 0.89  0.035 0.001 0.51  0.14 ]]
Logits tf.Tensor([[-0.06537856 -0.25565794  0.62969655]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26105657 0.2158228  0.52312064]], shape=(1, 3), dtype=float32)
Selected action 1
[0.06, 0.08, 0.36, 0.196, 0.145, 0.86, 0.027, 0.001, 0.5700000000000001, 0.14]
0.8589414999999998
1.4869053333333333
Reward 12.380101668048693
Current State [[0.06  0.08  0.36  0.196 0.145 0.86  0.027 0.001 0.57  0.14 ]]
Logits tf.Tensor([[-0.06603909 -0.23768798  0.6260912 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26040024 0.21932858 0.5202711 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.35, 0.127, 0.145, 0.79, 0.024, 0.005, 0.523, 0.13]
0.7914566666666667
4.815476333333333
Reward 16.41068597668792
Current State [[0.04  0.15  0.35  0.127 0.145 0.79  0.024 0.005 0.523 0.13 ]]
Logits tf.Tensor([[-0.06038181 -0.24390873  0.60635114]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2645368  0.22018176 0.51528144]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.35, 0.149, 0.145, 0.79, 0.024, 0.005, 0.523, 0.13]
0.7914566666666667
4.815476333333333
Reward 4.41068597668792
Current State [[0.04  0.04  0.35  0.149 0.145 0.79  0.024 0.005 0.523 0.13 ]]
Logits tf.Tensor([[-0.05702853 -0.21537495  0.5741009 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26786053 0.22863342 0.50350606]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.36, 0.161, 0.145, 0.91, 0.039, 0.002, 0.524, 0.11]
0.9136791666666666
2.139286166666667
Reward 17.587918640664853
Current State [[0.04  0.15  0.36  0.161 0.145 0.91  0.039 0.002 0.524 0.11 ]]
Logits tf.Tensor([[-0.0678871  -0.25343513  0.64513147]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25834525 0.2145942  0.5270605 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.04, 0.34, 0.123, 0.145, 0.81, 0.036, 0.006, 0.492, 0.1]
0.8054120000000001
5.8696418333333344
Reward 4.302751248593693
Current State [[0.05  0.04  0.34  0.123 0.145 0.81  0.036 0.006 0.492 0.1  ]]
Logits tf.Tensor([[-0.06199136 -0.21869075  0.5660341 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2681779  0.22928168 0.5025404 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.09, 0.15, 0.36, 0.153, 0.145, 0.81, 0.036, 0.006, 0.492, 0.1]
0.8054120000000001
5.8696418333333344
Reward 16.302751248593694
Current State [[0.09  0.15  0.36  0.153 0.145 0.81  0.036 0.006 0.492 0.1  ]]
Logits tf.Tensor([[-0.06885556 -0.24751797  0.6065144 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26307842 0.22003569 0.5168859 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.02, 0.15, 0.34, 0.155, 0.145, 0.81, 0.035, 0.003, 0.644, 0.14]
0.8092719999999999
3.480357166666666
Reward 16.69263884364004
Current State [[0.02  0.15  0.34  0.155 0.145 0.81  0.035 0.003 0.644 0.14 ]]
Logits tf.Tensor([[-0.07213474 -0.25479597  0.65575874]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.256163   0.21339667 0.53044033]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.37, 0.124, 0.145, 0.66, 0.015, 0.004, 0.687, 0.05]
0.6631454999999999
4.075595
Reward 16.404072726763694
Current State [[0.05  0.15  0.37  0.124 0.145 0.66  0.015 0.004 0.687 0.05 ]]
Logits tf.Tensor([[-0.07436508 -0.22646576  0.63505006]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25695688 0.22070071 0.52234244]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.37, 0.157, 0.145, 0.78, 0.031, 0.003, 0.8210000000000001, 0.16]
0.7844041666666666
3.2791665
Reward 16.721132986178937
Current State [[0.05  0.15  0.37  0.157 0.145 0.78  0.031 0.003 0.821 0.16 ]]
Logits tf.Tensor([[-0.08806826 -0.28239524  0.7122173 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24694009 0.20332766 0.5497322 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.38, 0.158, 0.145, 0.78, 0.031, 0.003, 0.8210000000000001, 0.16]
0.7844041666666666
3.2791665
Reward 16.721132986178937
Current State [[0.04  0.15  0.38  0.158 0.145 0.78  0.031 0.003 0.821 0.16 ]]
Logits tf.Tensor([[-0.08710992 -0.27932858  0.7127803 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2468878  0.20371364 0.54939854]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.15, 0.4, 0.135, 0.145, 0.79, 0.037, 0.003, 0.752, 0.15]
0.7912051666666665
2.9994050000000003
Reward 16.827269429078143
Episode: 102 | Average Reward: 279 | Episode Reward: 260 | Loss: 587.87 | Steps: 19 | Worker: 0
Current State [[ 0.00520626  0.00693372  0.00498517 -0.00579884  0.00738425  0.00729428
  -0.00068086  0.00641996 -0.00542963  0.00750908]]
Logits tf.Tensor([[-0.01144869 -0.02694647  0.03870075]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.32937536 0.3243101  0.34631455]], shape=(1, 3), dtype=float32)
Selected action 2
[0.02, 0.15, 0.36, 0.119, 0.145, 0.78, 0.032, 0.003, 0.794, 0.14]
0.7848834999999997
2.5392858333333335
Reward 17.028515317809244
Current State [[0.02  0.15  0.36  0.119 0.145 0.78  0.032 0.003 0.794 0.14 ]]
Logits tf.Tensor([[-0.08592547 -0.27474546  0.70505774]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24792366 0.2052648  0.5468115 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.02, 0.15, 0.35, 0.164, 0.145, 0.78, 0.032, 0.003, 0.794, 0.14]
0.7848834999999997
2.5392858333333335
Reward 17.028515317809244
Current State [[0.02  0.15  0.35  0.164 0.145 0.78  0.032 0.003 0.794 0.14 ]]
Logits tf.Tensor([[-0.08502465 -0.27012497  0.7063621 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24767955 0.2058269  0.5464936 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.03, 0.08, 0.37, 0.145, 0.145, 0.76, 0.022, 0.006, 0.737, 0.06]
0.7636706666666667
5.547023666666665
Reward 10.304543219444604
Current State [[0.03  0.08  0.37  0.145 0.145 0.76  0.022 0.006 0.737 0.06 ]]
Logits tf.Tensor([[-0.07672942 -0.23196015  0.6654496 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25273424 0.21639551 0.5308702 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.38, 0.131, 0.145, 0.8, 0.074, 0.004, 0.40599999999999997, 0.17]
0.8008683333333334
3.5386905
Reward 16.666308164119016
Current State [[0.03  0.15  0.38  0.131 0.145 0.8   0.074 0.004 0.406 0.17 ]]
Logits tf.Tensor([[-0.06636596 -0.24569769  0.5835197 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26658487 0.22281928 0.51059586]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.38, 0.147, 0.145, 0.8, 0.074, 0.004, 0.40599999999999997, 0.17]
0.8008683333333334
3.5386905
Reward 16.666308164119016
Current State [[0.03  0.15  0.38  0.147 0.145 0.8   0.074 0.004 0.406 0.17 ]]
Logits tf.Tensor([[-0.06493423 -0.24378893  0.5841343 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26666775 0.2229949  0.51033735]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.38, 0.132, 0.145, 0.93, 0.043, 0.001, 0.453, 0.07]
0.9330515
0.9684519999999999
Reward 20.85184122855999
Current State [[0.03  0.15  0.38  0.132 0.145 0.93  0.043 0.001 0.453 0.07 ]]
Logits tf.Tensor([[-0.06517398 -0.24705577  0.63056093]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2604925  0.21717258 0.52233493]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.41, 0.13, 0.145, 0.83, 0.056, 0.003, 0.441, 0.15]
0.8287833333333334
2.820833999999999
Reward 4.959790679733874
Current State [[0.04  0.04  0.41  0.13  0.145 0.83  0.056 0.003 0.441 0.15 ]]
Logits tf.Tensor([[-0.06616658 -0.22161382  0.5733567 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26655227 0.22817735 0.50527036]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.4, 0.169, 0.145, 0.72, 0.034, 0.006, 0.604, 0.19]
0.7209076666666666
5.6904761666666674
Reward 16.261522947284888
Current State [[0.04  0.15  0.4   0.169 0.145 0.72  0.034 0.006 0.604 0.19 ]]
Logits tf.Tensor([[-0.06765456 -0.2542936   0.62499267]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26118228 0.21671423 0.5221035 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.02, 0.15, 0.36, 0.123, 0.145, 0.72, 0.034, 0.006, 0.604, 0.19]
0.7209076666666666
5.6904761666666674
Reward 16.261522947284888
Current State [[0.02  0.15  0.36  0.123 0.145 0.72  0.034 0.006 0.604 0.19 ]]
Logits tf.Tensor([[-0.06709423 -0.25487998  0.6178006 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26230502 0.2173964  0.5202986 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.05, 0.08, 0.39, 0.151, 0.145, 0.85, 0.04, 0.002, 0.507, 0.12]
0.8484665
1.679762
Reward 11.987030216950622
Current State [[0.05  0.08  0.39  0.151 0.145 0.85  0.04  0.002 0.507 0.12 ]]
Logits tf.Tensor([[-0.06545838 -0.23449741  0.610204  ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26248026 0.22165827 0.51586145]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.39, 0.124, 0.145, 0.8, 0.037, 0.002, 0.581, 0.19]
0.8028771666666666
1.9857138333333337
Reward 17.475903377551177
Current State [[0.05  0.15  0.39  0.124 0.145 0.8   0.037 0.002 0.581 0.19 ]]
Logits tf.Tensor([[-0.07080096 -0.26906994  0.6393689 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25943795 0.21277785 0.52778417]], shape=(1, 3), dtype=float32)
Selected action 2
[0.02, 0.15, 0.37, 0.153, 0.145, 0.8, 0.037, 0.002, 0.581, 0.19]
0.8028771666666666
1.9857138333333337
Reward 17.475903377551177
Current State [[0.02  0.15  0.37  0.153 0.145 0.8   0.037 0.002 0.581 0.19 ]]
Logits tf.Tensor([[-0.0673391  -0.25872356  0.6386114 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2596333  0.21440908 0.52595764]], shape=(1, 3), dtype=float32)
Selected action 0
[0.03, 0.04, 0.34, 0.135, 0.145, 0.76, 0.029, 0.003, 0.554, 0.18]
0.7611039999999999
2.9601193333333327
Reward 4.7982669116681755
Current State [[0.03  0.04  0.34  0.135 0.145 0.76  0.029 0.003 0.554 0.18 ]]
Logits tf.Tensor([[-0.06199061 -0.22612807  0.5798861 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26676136 0.22638048 0.50685817]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.38, 0.121, 0.145, 0.84, 0.034, 0.001, 0.442, 0.01]
0.8418743333333333
0.8273806666666667
Reward 21.25263749154502
Current State [[0.03  0.15  0.38  0.121 0.145 0.84  0.034 0.001 0.442 0.01 ]]
Logits tf.Tensor([[-0.061368   -0.22392043  0.60243297]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2637039  0.22414081 0.5121553 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.03, 0.08, 0.37, 0.158, 0.145, 0.84, 0.034, 0.001, 0.442, 0.01]
0.8418743333333333
0.8273806666666667
Reward 15.25263749154502
Current State [[0.03  0.08  0.37  0.158 0.145 0.84  0.034 0.001 0.442 0.01 ]]
Logits tf.Tensor([[-0.05888957 -0.20416641  0.5813481 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26583624 0.2298906  0.5042732 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.37, 0.155, 0.145, 0.85, 0.048, 0.001, 0.523, 0.2]
0.853626
1.0458335
Reward 19.829752513722696
Current State [[0.03  0.15  0.37  0.155 0.145 0.85  0.048 0.001 0.523 0.2  ]]
Logits tf.Tensor([[-0.06767204 -0.26237914  0.6349434 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26027417 0.21422535 0.5255005 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.04, 0.37, 0.135, 0.145, 0.86, 0.039, 0.002, 0.525, 0.13]
0.8580606666666667
2.248215333333334
Reward 5.366364894482477
Current State [[0.05  0.04  0.37  0.135 0.145 0.86  0.039 0.002 0.525 0.13 ]]
Logits tf.Tensor([[-0.06744691 -0.23326698  0.60236615]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2630838  0.22288422 0.514032  ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.03, 0.08, 0.36, 0.147, 0.145, 0.86, 0.039, 0.002, 0.525, 0.13]
0.8580606666666667
2.248215333333334
Reward 11.366364894482476
Current State [[0.03  0.08  0.36  0.147 0.145 0.86  0.039 0.002 0.525 0.13 ]]
Logits tf.Tensor([[-0.0647286  -0.23603633  0.61307514]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26232192 0.22102258 0.5166555 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.38, 0.163, 0.145, 0.88, 0.042, 0.002, 0.492, 0.21]
0.882118
1.7511903333333332
Reward 17.97972785717466
Current State [[0.04  0.15  0.38  0.163 0.145 0.88  0.042 0.002 0.492 0.21 ]]
Logits tf.Tensor([[-0.06280623 -0.2635568   0.63260627]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26159847 0.214018   0.5243835 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.37, 0.126, 0.145, 0.85, 0.075, 0.01, 0.41200000000000003, 0.23]
0.8493365
9.777976166666667
Reward 16.108817197603123
Episode: 103 | Average Reward: 279 | Episode Reward: 294 | Loss: 669.874 | Steps: 19 | Worker: 0
Current State [[-0.00806858 -0.00413689  0.00270595 -0.00953251 -0.00672273 -0.00397491
  -0.00312673  0.00325469  0.00264969 -0.00062818]]
Logits tf.Tensor([[-0.01013703 -0.01830064  0.02851558]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.32989377 0.3272116  0.34289467]], shape=(1, 3), dtype=float32)
Selected action 1
[0.04, 0.08, 0.38, 0.13, 0.145, 0.82, 0.038, 0.003, 0.557, 0.25]
0.8200689999999998
2.824405333333333
Reward 10.944367432694019
Current State [[0.04  0.08  0.38  0.13  0.145 0.82  0.038 0.003 0.557 0.25 ]]
Logits tf.Tensor([[-0.06905586 -0.26078072  0.6207426 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2618591  0.21617357 0.52196735]], shape=(1, 3), dtype=float32)
Selected action 1
[0.05, 0.08, 0.39, 0.157, 0.145, 0.82, 0.038, 0.003, 0.557, 0.25]
0.8200689999999998
2.824405333333333
Reward 10.944367432694019
Current State [[0.05  0.08  0.39  0.157 0.145 0.82  0.038 0.003 0.557 0.25 ]]
Logits tf.Tensor([[-0.06994835 -0.25934902  0.6232023 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26126975 0.21618894 0.5225413 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.01, 0.15, 0.36, 0.144, 0.145, 0.83, 0.043, 0.002, 0.5389999999999999, 0.24]
0.8347401666666665
2.4113094999999998
Reward 17.198726448066992
Current State [[0.01  0.15  0.36  0.144 0.145 0.83  0.043 0.002 0.539 0.24 ]]
Logits tf.Tensor([[-0.06747475 -0.26852465  0.63894105]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26010606 0.21273336 0.5271606 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.39, 0.125, 0.145, 0.8, 0.032, 0.002, 0.5429999999999999, 0.15]
0.7958811666666666
2.2315476666666663
Reward 17.247713228279846
Current State [[0.03  0.15  0.39  0.125 0.145 0.8   0.032 0.002 0.543 0.15 ]]
Logits tf.Tensor([[-0.06797343 -0.25407577  0.6335224 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2599458  0.21580406 0.52425015]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.37, 0.13, 0.145, 0.8, 0.032, 0.002, 0.5429999999999999, 0.15]
0.7958811666666666
2.2315476666666663
Reward 17.247713228279846
Current State [[0.04  0.15  0.37  0.13  0.145 0.8   0.032 0.002 0.543 0.15 ]]
Logits tf.Tensor([[-0.07014821 -0.25621817  0.63193595]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2598638  0.21574298 0.52439326]], shape=(1, 3), dtype=float32)
Selected action 0
[0.01, 0.04, 0.37, 0.139, 0.145, 0.8, 0.035, 0.002, 0.5730000000000001, 0.13]
0.8040635000000002
2.1839288333333333
Reward 5.302083374820113
Current State [[0.01  0.04  0.37  0.139 0.145 0.8   0.035 0.002 0.573 0.13 ]]
Logits tf.Tensor([[-0.06624831 -0.2240975   0.6116158 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26153058 0.22334151 0.51512796]], shape=(1, 3), dtype=float32)
Selected action 0
[0.03, 0.04, 0.34, 0.114, 0.145, 0.81, 0.053, 0.001, 0.5269999999999999, 0.24]
0.8090398333333332
1.3113088333333331
Reward 6.602068539657144
Current State [[0.03  0.04  0.34  0.114 0.145 0.81  0.053 0.001 0.527 0.24 ]]
Logits tf.Tensor([[-0.07393701 -0.24596204  0.59223276]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26394108 0.22222732 0.5138316 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.35, 0.151, 0.145, 0.81, 0.053, 0.001, 0.5269999999999999, 0.24]
0.8090398333333332
1.3113088333333331
Reward 6.602068539657144
Current State [[0.04  0.04  0.35  0.151 0.145 0.81  0.053 0.001 0.527 0.24 ]]
Logits tf.Tensor([[-0.07462226 -0.24300964  0.5949855 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26326197 0.22246337 0.51427466]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.33, 0.149, 0.145, 0.8, 0.032, 0.002, 0.5690000000000001, 0.11]
0.8032513333333333
1.8273811666666673
Reward 17.650107045634613
Current State [[0.04  0.15  0.33  0.149 0.145 0.8   0.032 0.002 0.569 0.11 ]]
Logits tf.Tensor([[-0.07440419 -0.24999548  0.6391069 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2577249  0.21622111 0.526054  ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.36, 0.129, 0.145, 0.93, 0.045, 0.001, 0.534, 0.06]
0.9322518333333334
1.1357140000000001
Reward 19.86040859747311
Current State [[0.05  0.15  0.36  0.129 0.145 0.93  0.045 0.001 0.534 0.06 ]]
Logits tf.Tensor([[-0.08013377 -0.26311636  0.66634756]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25365603 0.21124035 0.5351036 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.15, 0.37, 0.148, 0.145, 0.93, 0.045, 0.001, 0.534, 0.06]
0.9322518333333334
1.1357140000000001
Reward 19.86040859747311
Current State [[0.06  0.15  0.37  0.148 0.145 0.93  0.045 0.001 0.534 0.06 ]]
Logits tf.Tensor([[-0.08094105 -0.26233277  0.6690872 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2530897  0.21110427 0.535806  ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.04, 0.08, 0.37, 0.165, 0.145, 0.88, 0.031, 0.002, 0.499, 0.11]
0.8789391666666667
2.1107136666666664
Reward 11.535141753880138
Current State [[0.04  0.08  0.37  0.165 0.145 0.88  0.031 0.002 0.499 0.11 ]]
Logits tf.Tensor([[-0.06508482 -0.2334653   0.6176113 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26148996 0.22096743 0.51754266]], shape=(1, 3), dtype=float32)
Selected action 2
[0.02, 0.15, 0.34, 0.12, 0.145, 0.69, 0.021, 0.007, 0.9, 0.16]
0.6897501666666666
7.290475999999999
Reward 16.13812929945637
Current State [[0.02  0.15  0.34  0.12  0.145 0.69  0.021 0.007 0.9   0.16 ]]
Logits tf.Tensor([[-0.09396154 -0.28240737  0.7346544 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24281321 0.20110892 0.5560779 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.04, 0.08, 0.36, 0.144, 0.145, 0.69, 0.021, 0.01, 0.43200000000000005, 0.02]
0.6918696666666668
9.679166833333333
Reward 10.051180979774742
Current State [[0.04  0.08  0.36  0.144 0.145 0.69  0.021 0.01  0.432 0.02 ]]
Logits tf.Tensor([[-0.05380781 -0.18909775  0.5398568 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2714386  0.23709148 0.49146986]], shape=(1, 3), dtype=float32)
Selected action 1
[0.03, 0.08, 0.36, 0.147, 0.145, 0.69, 0.021, 0.01, 0.43200000000000005, 0.02]
0.6918696666666668
9.679166833333333
Reward 10.051180979774742
Current State [[0.03  0.08  0.36  0.147 0.145 0.69  0.021 0.01  0.432 0.02 ]]
Logits tf.Tensor([[-0.05229568 -0.18629861  0.53963333]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.27158716 0.23752673 0.4908861 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.02, 0.08, 0.35, 0.156, 0.145, 0.84, 0.035, 0.002, 0.5690000000000001, 0.11]
0.8431256666666667
1.5785713333333333
Reward 12.1415340471778
Current State [[0.02  0.08  0.35  0.156 0.145 0.84  0.035 0.002 0.569 0.11 ]]
Logits tf.Tensor([[-0.07001556 -0.23490538  0.63099957]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2588136  0.21947058 0.5217158 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.02, 0.15, 0.31, 0.116, 0.145, 0.76, 0.019, 0.003, 0.641, 0.09]
0.7575729999999999
2.8005953333333338
Reward 16.856642781230494
Current State [[0.02  0.15  0.31  0.116 0.145 0.76  0.019 0.003 0.641 0.09 ]]
Logits tf.Tensor([[-0.07380714 -0.2470154   0.64689595]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25661814 0.21580622 0.5275756 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.03, 0.08, 0.34, 0.146, 0.145, 0.76, 0.019, 0.003, 0.641, 0.09]
0.7575729999999999
2.8005953333333338
Reward 10.856642781230494
Current State [[0.03  0.08  0.34  0.146 0.145 0.76  0.019 0.003 0.641 0.09 ]]
Logits tf.Tensor([[-0.07193417 -0.23066784  0.6328809 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2579516  0.22009039 0.521958  ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.34, 0.13, 0.145, 0.9, 0.034, 0.0, 0.46299999999999997, 0.03]
0.9003811666666667
0.4613103333333334
Reward 30.31399693710754
Current State [[0.03  0.15  0.34  0.13  0.145 0.9   0.034 0.    0.463 0.03 ]]
Logits tf.Tensor([[-0.06848421 -0.2400089   0.6274772 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2598742  0.21891269 0.5212131 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.03, 0.04, 0.32, 0.124, 0.145, 0.82, 0.019, 0.003, 0.5509999999999999, 0.08]
0.8232174999999998
2.9404758333333327
Reward 4.898266309366813
Episode: 104 | Average Reward: 279 | Episode Reward: 272 | Loss: 607.259 | Steps: 19 | Worker: 0
Current State [[-5.17005314e-04  3.10966196e-03 -4.35074795e-03 -6.20918189e-03
  -4.18254424e-03 -2.83279632e-03 -7.21401411e-03 -7.65085407e-03
  -4.64841162e-03 -6.15577640e-05]]
Logits tf.Tensor([[-0.01352224 -0.0182531   0.03187756]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.32876065 0.32720903 0.34403035]], shape=(1, 3), dtype=float32)
Selected action 1
[0.04, 0.08, 0.34, 0.137, 0.145, 0.82, 0.019, 0.003, 0.5509999999999999, 0.08]
0.8232174999999998
2.9404758333333327
Reward 10.898266309366813
Current State [[0.04  0.08  0.34  0.137 0.145 0.82  0.019 0.003 0.551 0.08 ]]
Logits tf.Tensor([[-0.07111827 -0.23146462  0.6215949 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25967413 0.22120304 0.51912284]], shape=(1, 3), dtype=float32)
Selected action 1
[0.05, 0.08, 0.36, 0.148, 0.145, 0.71, 0.025, 0.004, 0.585, 0.12]
0.7057051666666667
3.7708335
Reward 10.503208448756734
Current State [[0.05  0.08  0.36  0.148 0.145 0.71  0.025 0.004 0.585 0.12 ]]
Logits tf.Tensor([[-0.07513049 -0.22962365  0.60553706]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26095727 0.22360104 0.51544166]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.35, 0.145, 0.145, 0.77, 0.03, 0.002, 0.607, 0.1]
0.7741841666666667
1.602975833333333
Reward 17.871305835772233
Current State [[0.03  0.15  0.35  0.145 0.145 0.77  0.03  0.002 0.607 0.1  ]]
Logits tf.Tensor([[-0.07985678 -0.24672204  0.65082103]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2549199  0.21574216 0.52933794]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.34, 0.126, 0.145, 0.84, 0.034, 0.001, 0.532, 0.17]
0.8368673333333334
1.452381
Reward 18.371941469675676
Current State [[0.04  0.15  0.34  0.126 0.145 0.84  0.034 0.001 0.532 0.17 ]]
Logits tf.Tensor([[-0.07607998 -0.2645959   0.64279675]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2577111  0.21343307 0.52885586]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.34, 0.148, 0.145, 0.84, 0.034, 0.001, 0.532, 0.17]
0.8368673333333334
1.452381
Reward 18.371941469675676
Current State [[0.03  0.15  0.34  0.148 0.145 0.84  0.034 0.001 0.532 0.17 ]]
Logits tf.Tensor([[-0.07447679 -0.25942975  0.6434109 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2576495 0.2141437 0.5282068]], shape=(1, 3), dtype=float32)
Selected action 1
[0.03, 0.08, 0.34, 0.16, 0.145, 0.85, 0.021, 0.004, 0.546, 0.1]
0.8464071666666667
3.7386911666666673
Reward 10.666619530767075
Current State [[0.03  0.08  0.34  0.16  0.145 0.85  0.021 0.004 0.546 0.1  ]]
Logits tf.Tensor([[-0.06921613 -0.23237647  0.6270013 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25936267 0.22031692 0.5203204 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.02, 0.08, 0.31, 0.127, 0.145, 0.73, 0.016, 0.004, 0.528, 0.06]
0.7256541666666666
4.3309524999999995
Reward 10.423547196318662
Current State [[0.02  0.08  0.31  0.127 0.145 0.73  0.016 0.004 0.528 0.06 ]]
Logits tf.Tensor([[-0.06474029 -0.20976302  0.58299387]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26481593 0.22906646 0.50611764]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.35, 0.158, 0.145, 0.73, 0.016, 0.004, 0.528, 0.06]
0.7256541666666666
4.3309524999999995
Reward 16.423547196318662
Current State [[0.04  0.15  0.35  0.158 0.145 0.73  0.016 0.004 0.528 0.06 ]]
Logits tf.Tensor([[-0.06907256 -0.22473307  0.6103783 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26118907 0.2235386  0.5152723 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.33, 0.169, 0.145, 0.76, 0.019, 0.012, 0.472, 0.05]
0.7630335000000001
12.074404500000002
Reward 4.020439619918357
Current State [[0.04  0.04  0.33  0.169 0.145 0.76  0.019 0.012 0.472 0.05 ]]
Logits tf.Tensor([[-0.05979992 -0.19803375  0.55977726]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26816574 0.23354422 0.4982901 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.02, 0.15, 0.32, 0.137, 0.145, 0.73, 0.024, 0.005, 0.542, 0.1]
0.7259844999999999
4.966666333333333
Reward 16.33809672588861
Current State [[0.02  0.15  0.32  0.137 0.145 0.73  0.024 0.005 0.542 0.1  ]]
Logits tf.Tensor([[-0.06990343 -0.23243414  0.6097257 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2615654  0.22232796 0.51610667]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.15, 0.34, 0.165, 0.145, 0.73, 0.024, 0.005, 0.542, 0.1]
0.7259844999999999
4.966666333333333
Reward 16.33809672588861
Current State [[0.06  0.15  0.34  0.165 0.145 0.73  0.024 0.005 0.542 0.1  ]]
Logits tf.Tensor([[-0.07546671 -0.2393336   0.61479133]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26020762 0.22087854 0.51891387]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.15, 0.34, 0.162, 0.145, 0.91, 0.03, 0.002, 0.511, 0.02]
0.9077796666666667
2.0880956666666664
Reward 17.625977333761533
Current State [[0.06  0.15  0.34  0.162 0.145 0.91  0.03  0.002 0.511 0.02 ]]
Logits tf.Tensor([[-0.07967371 -0.24816203  0.65511495]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25445408 0.2149987  0.5305472 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.15, 0.35, 0.145, 0.145, 0.8, 0.027, 0.004, 0.538, 0.05]
0.804826
3.6380948333333336
Reward 16.644793049385516
Current State [[0.06  0.15  0.35  0.145 0.145 0.8   0.027 0.004 0.538 0.05 ]]
Logits tf.Tensor([[-0.07736632 -0.24077302  0.63673615]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25696382 0.21822545 0.5248108 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.35, 0.118, 0.145, 0.8, 0.027, 0.002, 0.595, 0.08]
0.8038926666666666
2.2208331666666665
Reward 17.272791747083904
Current State [[0.04  0.15  0.35  0.118 0.145 0.8   0.027 0.002 0.595 0.08 ]]
Logits tf.Tensor([[-0.07984302 -0.25053212  0.6547922 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25459513 0.21464498 0.5307599 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.04, 0.36, 0.153, 0.145, 0.8, 0.027, 0.002, 0.595, 0.08]
0.8038926666666666
2.2208331666666665
Reward 5.272791747083904
Current State [[0.05  0.04  0.36  0.153 0.145 0.8   0.027 0.002 0.595 0.08 ]]
Logits tf.Tensor([[-0.07710867 -0.2261773   0.6259838 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25763237 0.22195287 0.52041477]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.36, 0.162, 0.145, 0.78, 0.023, 0.003, 0.663, 0.07]
0.7839685000000002
2.766071666666667
Reward 16.913585997523853
Current State [[0.05  0.15  0.36  0.162 0.145 0.78  0.023 0.003 0.663 0.07 ]]
Logits tf.Tensor([[-0.0854929 -0.2511856  0.6764581]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25064173 0.21237038 0.5369879 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.02, 0.08, 0.36, 0.136, 0.145, 0.76, 0.027, 0.004, 0.601, 0.09]
0.7618833333333332
3.7369046666666663
Reward 10.572244124673531
Current State [[0.02  0.08  0.36  0.136 0.145 0.76  0.027 0.004 0.601 0.09 ]]
Logits tf.Tensor([[-0.07340157 -0.22597095  0.6260117 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25832644 0.22177307 0.51990044]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.38, 0.171, 0.145, 0.76, 0.027, 0.004, 0.601, 0.09]
0.7618833333333332
3.7369046666666663
Reward 16.57224412467353
Current State [[0.03  0.15  0.38  0.171 0.145 0.76  0.027 0.004 0.601 0.09 ]]
Logits tf.Tensor([[-0.07705799 -0.23963185  0.649797  ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2551985  0.21690683 0.5278946 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.02, 0.04, 0.39, 0.144, 0.145, 0.74, 0.035, 0.003, 0.851, 0.17]
0.7371178333333334
3.2446423333333336
Reward 4.669957617869655
Current State [[0.02  0.04  0.39  0.144 0.145 0.74  0.035 0.003 0.851 0.17 ]]
Logits tf.Tensor([[-0.09202313 -0.26023787  0.7071673 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24576594 0.20771457 0.5465195 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.04, 0.08, 0.41, 0.137, 0.145, 0.67, 0.027, 0.006, 0.8380000000000001, 0.13]
0.6691703333333333
6.2565479999999996
Reward 10.18523025352707
Episode: 105 | Average Reward: 279 | Episode Reward: 265 | Loss: 541.193 | Steps: 19 | Worker: 0
Current State [[-0.00702721  0.00875549  0.00183601 -0.00552081  0.00727054 -0.00260466
   0.00880468 -0.00803436  0.00129121  0.00080276]]
Logits tf.Tensor([[-0.02004066 -0.02196734  0.04347337]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3264081  0.32577983 0.34781212]], shape=(1, 3), dtype=float32)
Selected action 0
[0.03, 0.04, 0.36, 0.158, 0.145, 0.77, 0.033, 0.001, 0.727, 0.12]
0.7682326666666666
1.2458331666666669
Reward 6.600180344249291
Current State [[0.03  0.04  0.36  0.158 0.145 0.77  0.033 0.001 0.727 0.12 ]]
Logits tf.Tensor([[-0.09376948 -0.23835616  0.67141557]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24908017 0.21554896 0.5353709 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.02, 0.15, 0.32, 0.136, 0.145, 0.77, 0.033, 0.001, 0.727, 0.12]
0.7682326666666666
1.2458331666666669
Reward 18.600180344249292
Current State [[0.02  0.15  0.32  0.136 0.145 0.77  0.033 0.001 0.727 0.12 ]]
Logits tf.Tensor([[-0.09748966 -0.26247448  0.69583654]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2463877  0.20891376 0.54469854]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.36, 0.147, 0.145, 0.89, 0.052, 0.001, 0.465, 0.1]
0.8929596666666665
1.1708333333333336
Reward 19.482620721623388
Current State [[0.05  0.15  0.36  0.147 0.145 0.89  0.052 0.001 0.465 0.1  ]]
Logits tf.Tensor([[-0.0853748 -0.25326    0.6421721]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25539866 0.21592702 0.5286743 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.04, 0.08, 0.38, 0.138, 0.145, 0.93, 0.044, 0.001, 0.45199999999999996, 0.1]
0.9310906666666666
1.4785716666666666
Reward 12.67548404589348
Current State [[0.04  0.08  0.38  0.138 0.145 0.93  0.044 0.001 0.452 0.1  ]]
Logits tf.Tensor([[-0.07709149 -0.2394388   0.6249291 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25853345 0.21979114 0.5216754 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.4, 0.169, 0.145, 0.93, 0.044, 0.001, 0.45199999999999996, 0.1]
0.9310906666666666
1.4785716666666666
Reward 6.67548404589348
Current State [[0.04  0.04  0.4   0.169 0.145 0.93  0.044 0.001 0.452 0.1  ]]
Logits tf.Tensor([[-0.07468628 -0.22628014  0.6161771 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25941855 0.222928   0.51765347]], shape=(1, 3), dtype=float32)
Selected action 1
[0.05, 0.08, 0.4, 0.15, 0.145, 0.79, 0.045, 0.002, 0.49400000000000005, 0.16]
0.7934924999999999
2.129165833333333
Reward 11.323472865447211
Current State [[0.05  0.08  0.4   0.15  0.145 0.79  0.045 0.002 0.494 0.16 ]]
Logits tf.Tensor([[-0.07842925 -0.23576869  0.6080992 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26033396 0.22243294 0.5172331 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.41, 0.111, 0.145, 0.83, 0.059, 0.003, 0.44299999999999995, 0.14]
0.8325288333333334
2.5261908333333336
Reward 17.121823801603448
Current State [[0.05  0.15  0.41  0.111 0.145 0.83  0.059 0.003 0.443 0.14 ]]
Logits tf.Tensor([[-0.08181351 -0.2550727   0.6232337 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25874147 0.21758078 0.52367777]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.4, 0.142, 0.145, 0.83, 0.059, 0.003, 0.44299999999999995, 0.14]
0.8325288333333334
2.5261908333333336
Reward 17.121823801603448
Current State [[0.04  0.15  0.4   0.142 0.145 0.83  0.059 0.003 0.443 0.14 ]]
Logits tf.Tensor([[-0.07935379 -0.24782586  0.62340766]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2587807 0.218658  0.5225613]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.39, 0.131, 0.145, 0.85, 0.043, 0.002, 0.49000000000000005, 0.12]
0.8492636666666666
2.0678573333333334
Reward 17.507045479854238
Current State [[0.04  0.15  0.39  0.131 0.145 0.85  0.043 0.002 0.49  0.12 ]]
Logits tf.Tensor([[-0.08056702 -0.2516096   0.6440905 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25596333 0.21572222 0.5283145 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.39, 0.155, 0.145, 0.88, 0.044, 0.002, 0.506, 0.14]
0.8828635000000001
1.5386905000000002
Reward 18.358455128364664
Current State [[0.05  0.15  0.39  0.155 0.145 0.88  0.044 0.002 0.506 0.14 ]]
Logits tf.Tensor([[-0.08322841 -0.2596588   0.65898645]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25388187 0.21281826 0.53329986]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.15, 0.4, 0.151, 0.145, 0.88, 0.044, 0.002, 0.506, 0.14]
0.8828635000000001
1.5386905000000002
Reward 18.358455128364664
Current State [[0.06  0.15  0.4   0.151 0.145 0.88  0.044 0.002 0.506 0.14 ]]
Logits tf.Tensor([[-0.08430079 -0.26247674  0.6606096 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2536109  0.2122204  0.53416866]], shape=(1, 3), dtype=float32)
Selected action 2
[0.02, 0.15, 0.37, 0.14, 0.145, 0.85, 0.043, 0.002, 0.495, 0.18]
0.8487966666666669
1.5910716666666669
Reward 18.138130320474716
Current State [[0.02  0.15  0.37  0.14  0.145 0.85  0.043 0.002 0.495 0.18 ]]
Logits tf.Tensor([[-0.07698625 -0.25694332  0.6423407 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.257178   0.21482238 0.5279996 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.39, 0.129, 0.145, 0.79, 0.068, 0.001, 0.41200000000000003, 0.11]
0.7887781666666667
1.4535715
Reward 18.18769724996155
Current State [[0.05  0.15  0.39  0.129 0.145 0.79  0.068 0.001 0.412 0.11 ]]
Logits tf.Tensor([[-0.08286047 -0.23946767  0.60109735]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26063758 0.22285552 0.5165069 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.4, 0.119, 0.145, 0.84, 0.031, 0.002, 0.512, 0.11]
0.8388071666666667
2.2071428333333336
Reward 5.358604873955013
Current State [[0.04  0.04  0.4   0.119 0.145 0.84  0.031 0.002 0.512 0.11 ]]
Logits tf.Tensor([[-0.07450867 -0.22709997  0.61508596]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25964665 0.2229016  0.51745176]], shape=(1, 3), dtype=float32)
Selected action 1
[0.05, 0.08, 0.39, 0.146, 0.145, 0.84, 0.031, 0.002, 0.512, 0.11]
0.8388071666666667
2.2071428333333336
Reward 11.358604873955013
Current State [[0.05  0.08  0.39  0.146 0.145 0.84  0.031 0.002 0.512 0.11 ]]
Logits tf.Tensor([[-0.07742351 -0.23452911  0.62765515]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25782368 0.22033966 0.52183664]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.37, 0.132, 0.145, 0.88, 0.045, 0.001, 0.516, 0.12]
0.8821765000000001
1.1321426666666665
Reward 19.58846953065855
Current State [[0.03  0.15  0.37  0.132 0.145 0.88  0.045 0.001 0.516 0.12 ]]
Logits tf.Tensor([[-0.08371118 -0.25707677  0.65940094]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2535948  0.21323016 0.53317505]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.39, 0.13, 0.145, 0.79, 0.033, 0.002, 0.545, 0.15]
0.7944628333333335
2.4059523333333335
Reward 17.124804712385185
Current State [[0.05  0.15  0.39  0.13  0.145 0.79  0.033 0.002 0.545 0.15 ]]
Logits tf.Tensor([[-0.08219229 -0.25740555  0.64375305]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25601888 0.21487103 0.5291101 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.37, 0.123, 0.145, 0.79, 0.033, 0.002, 0.545, 0.15]
0.7944628333333335
2.4059523333333335
Reward 17.124804712385185
Current State [[0.03  0.15  0.37  0.123 0.145 0.79  0.033 0.002 0.545 0.15 ]]
Logits tf.Tensor([[-0.08013194 -0.25327897  0.6404895 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2566258  0.21582587 0.5275483 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.38, 0.179, 0.145, 0.85, 0.039, 0.002, 0.5, 0.2]
0.8492531666666666
2.3934531666666667
Reward 17.239140582644954
Current State [[0.05  0.15  0.38  0.179 0.145 0.85  0.039 0.002 0.5   0.2  ]]
Logits tf.Tensor([[-0.07781592 -0.2617878   0.6456853 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25683185 0.21367362 0.5294945 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.02, 0.08, 0.38, 0.14, 0.145, 0.89, 0.043, 0.002, 0.589, 0.26]
0.8856690000000002
1.5833328333333332
Reward 12.2789334288629
Episode: 106 | Average Reward: 279 | Episode Reward: 300 | Loss: 749.354 | Steps: 19 | Worker: 0
Current State [[-0.00429026  0.00644163 -0.0048486  -0.00067772 -0.00708175 -0.00629517
  -0.00770947 -0.00372018  0.00622248 -0.00931022]]
Logits tf.Tensor([[-0.01752887 -0.01794514  0.03605182]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3273723 0.3272361 0.3453916]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.39, 0.152, 0.145, 0.89, 0.043, 0.002, 0.589, 0.26]
0.8856690000000002
1.5833328333333332
Reward 18.2789334288629
Current State [[0.05  0.15  0.39  0.152 0.145 0.89  0.043 0.002 0.589 0.26 ]]
Logits tf.Tensor([[-0.09725992 -0.29159644  0.6993236 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24744321 0.20373999 0.5488168 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.39, 0.155, 0.145, 0.79, 0.036, 0.001, 0.511, 0.16]
0.7910048333333334
1.4369049999999999
Reward 18.23035126297959
Current State [[0.05  0.15  0.39  0.155 0.145 0.79  0.036 0.001 0.511 0.16 ]]
Logits tf.Tensor([[-0.08829837 -0.2522664   0.6424174 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2547553  0.21622844 0.52901626]], shape=(1, 3), dtype=float32)
Selected action 0
[0.02, 0.04, 0.33, 0.125, 0.145, 0.89, 0.042, 0.003, 0.5, 0.13]
0.8880045
2.582143166666667
Reward 5.188138612219672
Current State [[0.02  0.04  0.33  0.125 0.145 0.89  0.042 0.003 0.5   0.13 ]]
Logits tf.Tensor([[-0.08467466 -0.23399682  0.6174323 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25777903 0.2220229  0.52019805]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.39, 0.142, 0.145, 0.87, 0.02, 0.002, 0.514, 0.02]
0.8668146666666666
2.239881
Reward 17.391943398541137
Current State [[0.05  0.15  0.39  0.142 0.145 0.87  0.02  0.002 0.514 0.02 ]]
Logits tf.Tensor([[-0.08748585 -0.23765363  0.6677059 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2507156  0.21575671 0.5335277 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.02, 0.08, 0.38, 0.174, 0.145, 0.87, 0.02, 0.002, 0.514, 0.02]
0.8668146666666666
2.239881
Reward 11.391943398541137
Current State [[0.02  0.08  0.38  0.174 0.145 0.87  0.02  0.002 0.514 0.02 ]]
Logits tf.Tensor([[-0.08084858 -0.21351357  0.6443026 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25375548 0.2222285  0.524016  ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.15, 0.39, 0.142, 0.145, 0.74, 0.032, 0.003, 0.633, 0.2]
0.7394584999999998
3.084524333333334
Reward 16.723371088823185
Current State [[0.06  0.15  0.39  0.142 0.145 0.74  0.032 0.003 0.633 0.2  ]]
Logits tf.Tensor([[-0.09869809 -0.27149245  0.6688203 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25026754 0.21055274 0.5391797 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.01, 0.15, 0.37, 0.135, 0.145, 0.8, 0.039, 0.001, 0.511, 0.15]
0.8000656666666668
1.4654761666666665
Reward 18.205579928646486
Current State [[0.01  0.15  0.37  0.135 0.145 0.8   0.039 0.001 0.511 0.15 ]]
Logits tf.Tensor([[-0.0849826  -0.24433033  0.64137757]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25508636 0.21751207 0.52740157]], shape=(1, 3), dtype=float32)
Selected action 0
[0.03, 0.04, 0.35, 0.138, 0.145, 0.8, 0.039, 0.001, 0.511, 0.15]
0.8000656666666668
1.4654761666666665
Reward 6.205579928646488
Current State [[0.03  0.04  0.35  0.138 0.145 0.8   0.039 0.001 0.511 0.15 ]]
Logits tf.Tensor([[-0.08405728 -0.22410487  0.6048513 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2590098  0.2251616  0.51582855]], shape=(1, 3), dtype=float32)
Selected action 1
[0.05, 0.08, 0.34, 0.174, 0.145, 0.78, 0.022, 0.003, 0.5780000000000001, 0.1]
0.7754511666666667
3.1190474999999993
Reward 10.761515898215047
Current State [[0.05  0.08  0.34  0.174 0.145 0.78  0.022 0.003 0.578 0.1  ]]
Logits tf.Tensor([[-0.08956391 -0.22931501  0.6377865 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25386095 0.22075105 0.525388  ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.04, 0.4, 0.124, 0.145, 0.79, 0.023, 0.003, 0.5519999999999999, 0.11]
0.791841
2.8327373333333328
Reward 4.896373141906884
Current State [[0.05  0.04  0.4   0.124 0.145 0.79  0.023 0.003 0.552 0.11 ]]
Logits tf.Tensor([[-0.08483987 -0.22624268  0.62515783]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25627053 0.22247861 0.52125084]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.04, 0.39, 0.152, 0.145, 0.79, 0.023, 0.003, 0.5519999999999999, 0.11]
0.791841
2.8327373333333328
Reward 4.896373141906884
Current State [[0.05  0.04  0.39  0.152 0.145 0.79  0.023 0.003 0.552 0.11 ]]
Logits tf.Tensor([[-0.08484641 -0.22260745  0.6246139 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25613436 0.22317165 0.52069396]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.37, 0.156, 0.145, 0.65, 0.016, 0.013, 0.986, 0.12]
0.6501261666666667
13.156547333333334
Reward 3.969787706168059
Current State [[0.04  0.04  0.37  0.156 0.145 0.65  0.016 0.013 0.986 0.12 ]]
Logits tf.Tensor([[-0.11713162 -0.26301157  0.7739875 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23244366 0.2008921  0.5666643 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.35, 0.138, 0.145, 0.65, 0.017, 0.008, 0.9099999999999999, 0.08]
0.6490338333333334
8.042262666666666
Reward 16.085649096731238
Current State [[0.05  0.15  0.35  0.138 0.145 0.65  0.017 0.008 0.91  0.08 ]]
Logits tf.Tensor([[-0.11818144 -0.25983298  0.75888103]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23409598 0.20317748 0.5627265 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.34, 0.146, 0.145, 0.65, 0.017, 0.008, 0.9099999999999999, 0.08]
0.6490338333333334
8.042262666666666
Reward 16.085649096731238
Current State [[0.05  0.15  0.34  0.146 0.145 0.65  0.017 0.008 0.91  0.08 ]]
Logits tf.Tensor([[-0.11814632 -0.26074684  0.75894445]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2341374  0.20302066 0.56284195]], shape=(1, 3), dtype=float32)
Selected action 1
[0.04, 0.08, 0.35, 0.148, 0.145, 0.84, 0.043, 0.001, 0.523, 0.19]
0.8431129999999999
1.2803571666666664
Reward 12.84368921597303
Current State [[0.04  0.08  0.35  0.148 0.145 0.84  0.043 0.001 0.523 0.19 ]]
Logits tf.Tensor([[-0.08945382 -0.24669243  0.63323236]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25546312 0.21829328 0.52624357]], shape=(1, 3), dtype=float32)
Selected action 1
[0.02, 0.08, 0.3, 0.14, 0.145, 0.86, 0.031, 0.001, 0.5599999999999999, 0.15]
0.8597653333333334
1.3369048333333333
Reward 12.753247594279712
Current State [[0.02  0.08  0.3   0.14  0.145 0.86  0.031 0.001 0.56  0.15 ]]
Logits tf.Tensor([[-0.08871541 -0.24418001  0.642207  ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.254258   0.21764927 0.52809274]], shape=(1, 3), dtype=float32)
Selected action 2
[0.01, 0.15, 0.32, 0.123, 0.145, 0.79, 0.019, 0.004, 0.6, 0.08]
0.7866958333333333
3.574999166666667
Reward 16.639878446484758
Current State [[0.01  0.15  0.32  0.123 0.145 0.79  0.019 0.004 0.6   0.08 ]]
Logits tf.Tensor([[-0.08789579 -0.23995872  0.66282403]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25141683 0.21595052 0.53263265]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.15, 0.33, 0.166, 0.145, 0.79, 0.019, 0.004, 0.6, 0.08]
0.7866958333333333
3.574999166666667
Reward 16.639878446484758
Current State [[0.06  0.15  0.33  0.166 0.145 0.79  0.019 0.004 0.6   0.08 ]]
Logits tf.Tensor([[-0.09535926 -0.24760926  0.6683251 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24969147 0.21442844 0.5358801 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.32, 0.166, 0.145, 0.87, 0.031, 0.001, 0.5309999999999999, 0.15]
0.8697520000000002
0.9035716666666667
Reward 20.84546761421551
Current State [[0.04  0.15  0.32  0.166 0.145 0.87  0.031 0.001 0.531 0.15 ]]
Logits tf.Tensor([[-0.09163343 -0.2583999   0.6641702 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25152683 0.21289161 0.5355816 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.15, 0.34, 0.131, 0.145, 0.64, 0.023, 0.01, 0.42300000000000004, 0.05]
0.6397366666666665
10.214881166666665
Reward 16.018346097866665
Episode: 107 | Average Reward: 279 | Episode Reward: 264 | Loss: 542.007 | Steps: 19 | Worker: 0
Current State [[ 0.00134966 -0.00265436 -0.00307953 -0.00725773 -0.00957593 -0.00054253
  -0.00149414  0.00594717  0.00435806 -0.00620591]]
Logits tf.Tensor([[-0.01861021 -0.02236591  0.03778974]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.32741025 0.32618293 0.34640685]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.32, 0.164, 0.145, 0.64, 0.023, 0.01, 0.42300000000000004, 0.05]
0.6397366666666665
10.214881166666665
Reward 16.018346097866665
Current State [[0.04  0.15  0.32  0.164 0.145 0.64  0.023 0.01  0.423 0.05 ]]
Logits tf.Tensor([[-0.08014166 -0.19969673  0.5621001 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2639879  0.23424049 0.5017716 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.39, 0.146, 0.145, 0.73, 0.028, 0.003, 0.485, 0.09]
0.7278514999999999
2.583333833333333
Reward 4.906173303443007
Current State [[0.04  0.04  0.39  0.146 0.145 0.73  0.028 0.003 0.485 0.09 ]]
Logits tf.Tensor([[-0.08530413 -0.20312934  0.5904774 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25944242 0.23060575 0.50995183]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.34, 0.138, 0.145, 0.78, 0.036, 0.003, 0.612, 0.19]
0.7848155
2.961905333333333
Reward 4.8324287643208725
Current State [[0.04  0.04  0.34  0.138 0.145 0.78  0.036 0.003 0.612 0.19 ]]
Logits tf.Tensor([[-0.10114122 -0.24273156  0.64357245]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25164735 0.21842405 0.5299286 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.06, 0.04, 0.34, 0.151, 0.145, 0.78, 0.036, 0.003, 0.612, 0.19]
0.7848155
2.961905333333333
Reward 4.8324287643208725
Current State [[0.06  0.04  0.34  0.151 0.145 0.78  0.036 0.003 0.612 0.19 ]]
Logits tf.Tensor([[-0.10406145 -0.24541976  0.6444443 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.251129   0.21802473 0.5308463 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.06, 0.04, 0.34, 0.129, 0.145, 0.7, 0.015, 0.002, 0.462, 0.05]
0.697645
2.4422615
Reward 4.923485399723527
Current State [[0.06  0.04  0.34  0.129 0.145 0.7   0.015 0.002 0.462 0.05 ]]
Logits tf.Tensor([[-0.08270383 -0.19566172  0.5654132 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.26280344 0.23473293 0.50246364]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.04, 0.34, 0.131, 0.145, 0.68, 0.014, 0.004, 0.596, 0.06]
0.6833901666666666
3.8874998333333326
Reward 4.456889296933658
Current State [[0.05  0.04  0.34  0.131 0.145 0.68  0.014 0.004 0.596 0.06 ]]
Logits tf.Tensor([[-0.09306463 -0.20597443  0.60863715]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25572744 0.2284237  0.5158489 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.03, 0.04, 0.32, 0.157, 0.145, 0.91, 0.029, 0.003, 0.454, 0.08]
0.9135151666666667
2.5482135
Reward 5.256373815535715
Current State [[0.03  0.04  0.32  0.157 0.145 0.91  0.029 0.003 0.454 0.08 ]]
Logits tf.Tensor([[-0.08508192 -0.22178972  0.60983855]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25801292 0.22504535 0.5169417 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.34, 0.142, 0.145, 0.91, 0.029, 0.003, 0.454, 0.08]
0.9135151666666667
2.5482135
Reward 17.256373815535717
Current State [[0.04  0.15  0.34  0.142 0.145 0.91  0.029 0.003 0.454 0.08 ]]
Logits tf.Tensor([[-0.09193597 -0.24742259  0.65323776]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25234643 0.2160082  0.53164536]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.33, 0.136, 0.145, 0.86, 0.031, 0.002, 0.512, 0.13]
0.863885
2.007738333333333
Reward 17.603733450075627
Current State [[0.03  0.15  0.33  0.136 0.145 0.86  0.031 0.002 0.512 0.13 ]]
Logits tf.Tensor([[-0.09573109 -0.2532858   0.6620744 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25076365 0.21420985 0.5350265 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.02, 0.15, 0.33, 0.123, 0.145, 0.78, 0.021, 0.004, 0.554, 0.06]
0.7832916666666667
3.938095333333334
Reward 16.55159975550012
Current State [[0.02  0.15  0.33  0.123 0.145 0.78  0.021 0.004 0.554 0.06 ]]
Logits tf.Tensor([[-0.09324266 -0.2323792   0.6531915 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2512832  0.21864381 0.530073  ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.04, 0.35, 0.151, 0.145, 0.78, 0.021, 0.004, 0.554, 0.06]
0.7832916666666667
3.938095333333334
Reward 4.551599755500122
Current State [[0.05  0.04  0.35  0.151 0.145 0.78  0.021 0.004 0.554 0.06 ]]
Logits tf.Tensor([[-0.09320691 -0.21443145  0.6250446 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25402123 0.22502087 0.5209579 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.36, 0.155, 0.145, 0.72, 0.025, 0.006, 0.631, 0.14]
0.7176571666666668
5.728571333333333
Reward 16.256029973087976
Current State [[0.03  0.15  0.36  0.155 0.145 0.72  0.025 0.006 0.631 0.14 ]]
Logits tf.Tensor([[-0.1014606  -0.24800038  0.6667894 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24877591 0.21486564 0.5363584 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.35, 0.139, 0.145, 0.88, 0.038, 0.003, 0.522, 0.09]
0.8754238333333333
2.948809166666666
Reward 16.973504788793676
Current State [[0.04  0.15  0.35  0.139 0.145 0.88  0.038 0.003 0.522 0.09 ]]
Logits tf.Tensor([[-0.10105306 -0.2540953   0.6757327 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24798112 0.212791   0.5392279 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.35, 0.143, 0.145, 0.88, 0.038, 0.003, 0.522, 0.09]
0.8754238333333333
2.948809166666666
Reward 16.973504788793676
Current State [[0.04  0.15  0.35  0.143 0.145 0.88  0.038 0.003 0.522 0.09 ]]
Logits tf.Tensor([[-0.10101356 -0.2535049   0.67589545]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24793556 0.21286914 0.53919536]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.35, 0.152, 0.145, 0.76, 0.024, 0.004, 0.7190000000000001, 0.09]
0.7639918333333334
4.4863095
Reward 16.434621381609276
Current State [[0.04  0.15  0.35  0.152 0.145 0.76  0.024 0.004 0.719 0.09 ]]
Logits tf.Tensor([[-0.11327049 -0.25622568  0.71227694]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24096832 0.20886962 0.5501621 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.15, 0.36, 0.138, 0.145, 0.83, 0.035, 0.003, 0.669, 0.17]
0.8313591666666665
2.7726195
Reward 16.986833521946927
Current State [[0.06  0.15  0.36  0.138 0.145 0.83  0.035 0.003 0.669 0.17 ]]
Logits tf.Tensor([[-0.11561301 -0.2818997   0.716666  ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2412339  0.20427768 0.5544884 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.36, 0.149, 0.145, 0.83, 0.035, 0.003, 0.669, 0.17]
0.8313591666666665
2.7726195
Reward 16.986833521946927
Current State [[0.05  0.15  0.36  0.149 0.145 0.83  0.035 0.003 0.669 0.17 ]]
Logits tf.Tensor([[-0.11404412 -0.27807748  0.7169558 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24129373 0.20478928 0.553917  ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.08, 0.08, 0.39, 0.176, 0.145, 0.83, 0.042, 0.003, 0.658, 0.22]
0.8339525
3.3511903333333337
Reward 10.762527016944087
Current State [[0.08  0.08  0.39  0.176 0.145 0.83  0.042 0.003 0.658 0.22 ]]
Logits tf.Tensor([[-0.11504887 -0.27418715  0.6972098 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24355379 0.20772175 0.5487245 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.43, 0.132, 0.145, 0.77, 0.034, 0.004, 0.774, 0.18]
0.7715196666666666
4.477380999999999
Reward 4.4427952123165015
Current State [[0.04  0.04  0.43  0.132 0.145 0.77  0.034 0.004 0.774 0.18 ]]
Logits tf.Tensor([[-0.1138621  -0.2593215   0.71157485]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24110892 0.2084688  0.55042225]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.41, 0.128, 0.145, 0.63, 0.03, 0.005, 0.763, 0.16]
0.6342448333333333
5.4142858333333335
Reward 16.224464981255423
Episode: 108 | Average Reward: 279 | Episode Reward: 233 | Loss: 510.219 | Steps: 19 | Worker: 0
Current State [[-0.00466317 -0.0050059   0.00447649 -0.00083926 -0.00831528 -0.00453995
  -0.00053209  0.00117414 -0.00908364 -0.00248516]]
Logits tf.Tensor([[-0.01875758 -0.02009976  0.03366591]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3276024  0.327163   0.34523457]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.39, 0.158, 0.145, 0.63, 0.03, 0.005, 0.763, 0.16]
0.6342448333333333
5.4142858333333335
Reward 16.224464981255423
Current State [[0.03  0.15  0.39  0.158 0.145 0.63  0.03  0.005 0.763 0.16 ]]
Logits tf.Tensor([[-0.11508777 -0.25686276  0.7043652 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2417167  0.20976573 0.5485176 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.03, 0.08, 0.38, 0.151, 0.145, 0.73, 0.027, 0.004, 0.818, 0.14]
0.7284019999999999
3.7226193333333333
Reward 10.538246088858676
Current State [[0.03  0.08  0.38  0.151 0.145 0.73  0.027 0.004 0.818 0.14 ]]
Logits tf.Tensor([[-0.12253486 -0.25641692  0.7332846 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23651871 0.20688131 0.5566    ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.4, 0.137, 0.145, 0.74, 0.038, 0.002, 0.5780000000000001, 0.03]
0.7373649999999999
2.1583331666666665
Reward 5.177612559023396
Current State [[0.04  0.04  0.4   0.137 0.145 0.74  0.038 0.002 0.578 0.03 ]]
Logits tf.Tensor([[-0.10266516 -0.20845729  0.63874406]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2500936  0.22498712 0.5249193 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.41, 0.151, 0.145, 0.74, 0.038, 0.002, 0.5780000000000001, 0.03]
0.7373649999999999
2.1583331666666665
Reward 17.177612559023395
Current State [[0.04  0.15  0.41  0.151 0.145 0.74  0.038 0.002 0.578 0.03 ]]
Logits tf.Tensor([[-0.10773279 -0.23055638  0.672311  ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24594273 0.21751659 0.5365407 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.4, 0.146, 0.145, 0.85, 0.037, 0.002, 0.502, 0.14]
0.8484148333333335
2.274404666666667
Reward 17.32513589697111
Current State [[0.04  0.15  0.4   0.146 0.145 0.85  0.037 0.002 0.502 0.14 ]]
Logits tf.Tensor([[-0.09978507 -0.25625423  0.674934  ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24843854 0.21245418 0.53910726]], shape=(1, 3), dtype=float32)
Selected action 1
[0.05, 0.08, 0.41, 0.142, 0.145, 0.82, 0.056, 0.003, 0.45599999999999996, 0.15]
0.819275
2.7232141666666663
Reward 10.991335698577547
Current State [[0.05  0.08  0.41  0.142 0.145 0.82  0.056 0.003 0.456 0.15 ]]
Logits tf.Tensor([[-0.09903429 -0.23800842  0.62951165]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.253658   0.220746   0.52559596]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.04, 0.4, 0.152, 0.145, 0.82, 0.056, 0.003, 0.45599999999999996, 0.15]
0.819275
2.7232141666666663
Reward 4.991335698577547
Current State [[0.05  0.04  0.4   0.152 0.145 0.82  0.056 0.003 0.456 0.15 ]]
Logits tf.Tensor([[-0.09817643 -0.22724473  0.61575   ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25504303 0.22416086 0.5207961 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.37, 0.145, 0.145, 0.8, 0.061, 0.003, 0.445, 0.15]
0.8013378333333333
3.4928565
Reward 16.67945808919877
Current State [[0.03  0.15  0.37  0.145 0.145 0.8   0.061 0.003 0.445 0.15 ]]
Logits tf.Tensor([[-0.09962525 -0.24625634  0.6360238 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25313583 0.21861127 0.52825296]], shape=(1, 3), dtype=float32)
Selected action 1
[0.03, 0.08, 0.36, 0.135, 0.145, 0.81, 0.041, 0.002, 0.532, 0.17]
0.8123053333333333
2.3761910000000004
Reward 11.178613105056503
Current State [[0.03  0.08  0.36  0.135 0.145 0.81  0.041 0.002 0.532 0.17 ]]
Logits tf.Tensor([[-0.09972778 -0.24380022  0.6456886 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25168985 0.2179194  0.53039074]], shape=(1, 3), dtype=float32)
Selected action 0
[0.03, 0.04, 0.36, 0.151, 0.145, 0.86, 0.046, 0.001, 0.5, 0.2]
0.8644533333333333
1.489285166666667
Reward 6.395579383118586
Current State [[0.03  0.04  0.36  0.151 0.145 0.86  0.046 0.001 0.5   0.2  ]]
Logits tf.Tensor([[-0.09666353 -0.23954844  0.6337164 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25363183 0.21986172 0.5265065 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.02, 0.08, 0.37, 0.148, 0.145, 0.86, 0.046, 0.001, 0.5, 0.2]
0.8644533333333333
1.489285166666667
Reward 12.395579383118587
Current State [[0.02  0.08  0.37  0.148 0.145 0.86  0.046 0.001 0.5   0.2  ]]
Logits tf.Tensor([[-0.09678308 -0.24639317  0.64876604]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25197536 0.21696177 0.53106284]], shape=(1, 3), dtype=float32)
Selected action 1
[0.09, 0.08, 0.4, 0.155, 0.145, 0.78, 0.032, 0.003, 0.509, 0.14]
0.7778436666666668
2.5964285
Reward 10.985648675682414
Current State [[0.09  0.08  0.4   0.155 0.145 0.78  0.032 0.003 0.509 0.14 ]]
Logits tf.Tensor([[-0.10210743 -0.24312596  0.6359121 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25250858 0.2192969  0.52819455]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.37, 0.132, 0.145, 0.89, 0.054, 0.001, 0.475, 0.07]
0.8852888333333335
1.338095333333333
Reward 6.862053531887288
Current State [[0.04  0.04  0.37  0.132 0.145 0.89  0.054 0.001 0.475 0.07 ]]
Logits tf.Tensor([[-0.10227615 -0.22859073  0.63520604]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25176218 0.22188745 0.5263503 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.02, 0.15, 0.38, 0.136, 0.145, 0.89, 0.054, 0.001, 0.475, 0.07]
0.8852888333333335
1.338095333333333
Reward 18.862053531887288
Current State [[0.02  0.15  0.38  0.136 0.145 0.89  0.054 0.001 0.475 0.07 ]]
Logits tf.Tensor([[-0.10341839 -0.24669996  0.6744191 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24732457 0.2143092  0.5383662 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.38, 0.143, 0.145, 0.78, 0.028, 0.005, 0.514, 0.13]
0.7763463333333334
5.344047333333334
Reward 16.33453930278769
Current State [[0.04  0.15  0.38  0.143 0.145 0.78  0.028 0.005 0.514 0.13 ]]
Logits tf.Tensor([[-0.0965433  -0.24684447  0.6530285 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25147477 0.21638115 0.5321441 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.02, 0.15, 0.37, 0.121, 0.145, 0.81, 0.041, 0.002, 0.517, 0.2]
0.8109048333333334
2.4065476666666674
Reward 17.15593730807179
Current State [[0.02  0.15  0.37  0.121 0.145 0.81  0.041 0.002 0.517 0.2  ]]
Logits tf.Tensor([[-0.09816737 -0.26274782  0.66122544]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2509267  0.21284844 0.53622484]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.37, 0.145, 0.145, 0.81, 0.041, 0.002, 0.517, 0.2]
0.8109048333333334
2.4065476666666674
Reward 17.15593730807179
Current State [[0.03  0.15  0.37  0.145 0.145 0.81  0.041 0.002 0.517 0.2  ]]
Logits tf.Tensor([[-0.09938257 -0.26213598  0.6626777 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25047046 0.21284997 0.5366796 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.15, 0.39, 0.142, 0.145, 0.84, 0.031, 0.003, 0.504, 0.1]
0.8410058333333333
2.9874998333333327
Reward 16.905108504249487
Current State [[0.06  0.15  0.39  0.142 0.145 0.84  0.031 0.003 0.504 0.1  ]]
Logits tf.Tensor([[-0.10188617 -0.25282475  0.6717709 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24828808 0.21350306 0.5382089 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.37, 0.13, 0.145, 0.91, 0.044, 0.001, 0.5349999999999999, 0.13]
0.9140133333333333
1.474999833333333
Reward 18.61754940944071
Current State [[0.03  0.15  0.37  0.13  0.145 0.91  0.044 0.001 0.535 0.13 ]]
Logits tf.Tensor([[-0.10711916 -0.26740357  0.700627  ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24421525 0.20804732 0.5477375 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.05, 0.08, 0.39, 0.158, 0.145, 0.81, 0.047, 0.002, 0.491, 0.24]
0.8065564999999998
2.0202381666666667
Reward 11.451140618659258
Episode: 109 | Average Reward: 279 | Episode Reward: 263 | Loss: 579.99 | Steps: 19 | Worker: 0
Current State [[-0.000629    0.00070472  0.0039622  -0.00231513  0.00797348 -0.009823
   0.00379248 -0.00089395 -0.00163064  0.00942468]]
Logits tf.Tensor([[-0.02229049 -0.02469537  0.04450749]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.32608578 0.32530254 0.34861162]], shape=(1, 3), dtype=float32)
Selected action 1
[0.04, 0.08, 0.38, 0.146, 0.145, 0.81, 0.047, 0.002, 0.491, 0.24]
0.8065564999999998
2.0202381666666667
Reward 11.451140618659258
Current State [[0.04  0.08  0.38  0.146 0.145 0.81  0.047 0.002 0.491 0.24 ]]
Logits tf.Tensor([[-0.09999643 -0.2510848   0.63691205]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25321344 0.21770576 0.5290808 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.36, 0.139, 0.145, 0.87, 0.046, 0.001, 0.504, 0.13]
0.8740345
1.2523810000000002
Reward 19.079770599702
Current State [[0.03  0.15  0.36  0.139 0.145 0.87  0.046 0.001 0.504 0.13 ]]
Logits tf.Tensor([[-0.10835025 -0.25789535  0.6823672 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24593727 0.2117765  0.5422862 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.37, 0.128, 0.145, 0.84, 0.031, 0.002, 0.5820000000000001, 0.22]
0.8405883333333333
2.441070833333333
Reward 17.190232207400044
Current State [[0.03  0.15  0.37  0.128 0.145 0.84  0.031 0.002 0.582 0.22 ]]
Logits tf.Tensor([[-0.10820462 -0.2785321   0.6997836 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24469149 0.20637    0.5489385 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.04, 0.42, 0.152, 0.145, 0.84, 0.031, 0.002, 0.5820000000000001, 0.22]
0.8405883333333333
2.441070833333333
Reward 5.190232207400045
Current State [[0.05  0.04  0.42  0.152 0.145 0.84  0.031 0.002 0.582 0.22 ]]
Logits tf.Tensor([[-0.10555917 -0.2536081   0.67407376]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24733739 0.21330103 0.5393616 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.39, 0.14, 0.145, 0.72, 0.028, 0.004, 0.576, 0.13]
0.7162381666666667
3.9190476666666663
Reward 16.485251762329487
Current State [[0.03  0.15  0.39  0.14  0.145 0.72  0.028 0.004 0.576 0.13 ]]
Logits tf.Tensor([[-0.1054948  -0.24476561  0.6635272 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24828391 0.2160051  0.535711  ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.04, 0.08, 0.37, 0.125, 0.145, 0.79, 0.039, 0.003, 0.616, 0.15]
0.7929151666666666
3.3642858333333336
Reward 10.706095116553513
Current State [[0.04  0.08  0.37  0.125 0.145 0.79  0.039 0.003 0.616 0.15 ]]
Logits tf.Tensor([[-0.11340428 -0.25226438  0.6788603 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24517366 0.21338685 0.54143953]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.36, 0.158, 0.145, 0.79, 0.039, 0.003, 0.616, 0.15]
0.7929151666666666
3.3642858333333336
Reward 4.706095116553512
Current State [[0.04  0.04  0.36  0.158 0.145 0.79  0.039 0.003 0.616 0.15 ]]
Logits tf.Tensor([[-0.11154331 -0.23960166  0.666903  ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24643365 0.21681282 0.53675354]], shape=(1, 3), dtype=float32)
Selected action 1
[0.03, 0.08, 0.34, 0.143, 0.145, 0.77, 0.022, 0.003, 0.592, 0.07]
0.7680120000000001
3.0095246666666666
Reward 10.789920645676542
Current State [[0.03  0.08  0.34  0.143 0.145 0.77  0.022 0.003 0.592 0.07 ]]
Logits tf.Tensor([[-0.10425162 -0.22631244  0.6596378 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2480341  0.21953364 0.53243226]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.15, 0.36, 0.126, 0.145, 0.86, 0.025, 0.003, 0.654, 0.09]
0.8616796666666667
3.2142858333333333
Reward 16.84601468570473
Current State [[0.06  0.15  0.36  0.126 0.145 0.86  0.025 0.003 0.654 0.09 ]]
Logits tf.Tensor([[-0.12097379 -0.27246726  0.7346597 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2374007  0.20402773 0.5585716 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.02, 0.04, 0.37, 0.159, 0.145, 0.86, 0.025, 0.003, 0.654, 0.09]
0.8616796666666667
3.2142858333333333
Reward 4.8460146857047315
Current State [[0.02  0.04  0.37  0.159 0.145 0.86  0.025 0.003 0.654 0.09 ]]
Logits tf.Tensor([[-0.10985116 -0.23696724  0.7029385 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24184856 0.21297944 0.54517204]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.38, 0.148, 0.145, 0.91, 0.042, 0.002, 0.45199999999999996, 0.14]
0.9119953333333335
1.9934525000000003
Reward 17.74059713399881
Current State [[0.04  0.15  0.38  0.148 0.145 0.91  0.042 0.002 0.452 0.14 ]]
Logits tf.Tensor([[-0.10262912 -0.2581848   0.6754897 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24793519 0.21221751 0.53984725]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.04, 0.36, 0.156, 0.145, 0.66, 0.017, 0.01, 0.9730000000000001, 0.08]
0.6597738333333333
9.678571
Reward 4.03886853930841
Current State [[0.05  0.04  0.36  0.156 0.145 0.66  0.017 0.01  0.973 0.08 ]]
Logits tf.Tensor([[-0.13742442 -0.25425285  0.7912336 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22620097 0.20125954 0.5725395 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.36, 0.138, 0.145, 0.75, 0.015, 0.006, 0.772, 0.08]
0.7531984999999999
6.236309333333333
Reward 16.23853884853175
Current State [[0.05  0.15  0.36  0.138 0.145 0.75  0.015 0.006 0.772 0.08 ]]
Logits tf.Tensor([[-0.12565236 -0.26417932  0.7440644 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23491414 0.20452559 0.5605603 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.33, 0.151, 0.145, 0.75, 0.015, 0.006, 0.772, 0.08]
0.7531984999999999
6.236309333333333
Reward 16.23853884853175
Current State [[0.04  0.15  0.33  0.151 0.145 0.75  0.015 0.006 0.772 0.08 ]]
Logits tf.Tensor([[-0.12273777 -0.26268032  0.73973626]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23593684 0.2051254  0.5589378 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.04, 0.08, 0.34, 0.132, 0.145, 0.84, 0.028, 0.003, 0.6639999999999999, 0.06]
0.8378966666666667
3.2517860000000005
Reward 10.800667960740972
Current State [[0.04  0.08  0.34  0.132 0.145 0.84  0.028 0.003 0.664 0.06 ]]
Logits tf.Tensor([[-0.11734863 -0.24743734  0.7078968 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24035814 0.21103863 0.54860324]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.32, 0.144, 0.145, 0.88, 0.035, 0.001, 0.504, 0.11]
0.8816846666666666
0.8833338333333333
Reward 21.1073617715752
Current State [[0.03  0.15  0.32  0.144 0.145 0.88  0.035 0.001 0.504 0.11 ]]
Logits tf.Tensor([[-0.10634806 -0.2550191   0.67681134]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2468997  0.21279114 0.5403092 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.02, 0.15, 0.29, 0.12, 0.145, 0.88, 0.035, 0.001, 0.504, 0.11]
0.8816846666666666
0.8833338333333333
Reward 21.1073617715752
Current State [[0.02  0.15  0.29  0.12  0.145 0.88  0.035 0.001 0.504 0.11 ]]
Logits tf.Tensor([[-0.10645247 -0.257746    0.6708368 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24782152 0.21302623 0.53915226]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.32, 0.153, 0.145, 0.84, 0.026, 0.002, 0.6, 0.08]
0.839525
1.6214286666666669
Reward 18.05405900424264
Current State [[0.03  0.15  0.32  0.153 0.145 0.84  0.026 0.002 0.6   0.08 ]]
Logits tf.Tensor([[-0.11182659 -0.25281915  0.7033833 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2422395  0.21038398 0.54737645]], shape=(1, 3), dtype=float32)
Selected action 1
[0.05, 0.08, 0.34, 0.126, 0.145, 0.88, 0.029, 0.001, 0.526, 0.08]
0.8809861666666665
1.2958331666666667
Reward 12.970858514234394
Current State [[0.05  0.08  0.34  0.126 0.145 0.88  0.029 0.001 0.526 0.08 ]]
Logits tf.Tensor([[-0.10653186 -0.24376674  0.6644711 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24791142 0.2161206  0.535968  ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.04, 0.38, 0.147, 0.145, 0.88, 0.029, 0.001, 0.526, 0.08]
0.8809861666666665
1.2958331666666667
Reward 6.970858514234394
Episode: 110 | Average Reward: 279 | Episode Reward: 262 | Loss: 556.45 | Steps: 19 | Worker: 0
Current State [[-0.00620259 -0.00146512  0.00345868  0.00701242  0.00913    -0.00886964
  -0.00693425 -0.00314138  0.00987047 -0.0014553 ]]
Logits tf.Tensor([[-0.02263569 -0.02064727  0.04833994]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.32514554 0.32579273 0.34906167]], shape=(1, 3), dtype=float32)
Selected action 1
[0.05, 0.08, 0.34, 0.152, 0.145, 0.91, 0.033, 0.001, 0.545, 0.12]
0.9114058333333332
0.8315483333333333
Reward 15.859381655994579
Current State [[0.05  0.08  0.34  0.152 0.145 0.91  0.033 0.001 0.545 0.12 ]]
Logits tf.Tensor([[-0.11325191 -0.25296533  0.6855023 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24435674 0.21249443 0.5431488 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.37, 0.133, 0.145, 0.72, 0.031, 0.004, 0.528, 0.12]
0.7154496666666667
3.630356833333333
Reward 4.544046859231738
Current State [[0.04  0.04  0.37  0.133 0.145 0.72  0.031 0.004 0.528 0.12 ]]
Logits tf.Tensor([[-0.10139804 -0.21774809  0.61617815]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2538314  0.22595145 0.5202172 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.34, 0.126, 0.145, 0.78, 0.036, 0.002, 0.609, 0.16]
0.7803148333333334
1.9601195000000002
Reward 17.44559278240238
Current State [[0.04  0.15  0.34  0.126 0.145 0.78  0.036 0.002 0.609 0.16 ]]
Logits tf.Tensor([[-0.11928885 -0.2672221   0.6938665 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24286577 0.20946898 0.54766524]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.34, 0.167, 0.145, 0.78, 0.036, 0.002, 0.609, 0.16]
0.7803148333333334
1.9601195000000002
Reward 17.44559278240238
Current State [[0.05  0.15  0.34  0.167 0.145 0.78  0.036 0.002 0.609 0.16 ]]
Logits tf.Tensor([[-0.12092648 -0.2651029   0.6968288 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24206369 0.20956302 0.5483733 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.06, 0.08, 0.35, 0.157, 0.145, 0.89, 0.037, 0.001, 0.506, 0.11]
0.894568
1.4333326666666664
Reward 12.64312671539016
Current State [[0.06  0.08  0.35  0.157 0.145 0.89  0.037 0.001 0.506 0.11 ]]
Logits tf.Tensor([[-0.11138485 -0.24602406  0.6674281 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24673596 0.21565494 0.5376091 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.35, 0.141, 0.145, 0.82, 0.022, 0.004, 0.511, 0.06]
0.8232816666666666
3.683333
Reward 16.654465616992486
Current State [[0.05  0.15  0.35  0.141 0.145 0.82  0.022 0.004 0.511 0.06 ]]
Logits tf.Tensor([[-0.10643803 -0.24219556  0.6716704 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24688895 0.21554746 0.53756356]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.34, 0.147, 0.145, 0.82, 0.022, 0.004, 0.511, 0.06]
0.8232816666666666
3.683333
Reward 16.654465616992486
Current State [[0.04  0.15  0.34  0.147 0.145 0.82  0.022 0.004 0.511 0.06 ]]
Logits tf.Tensor([[-0.10508589 -0.2393631   0.67022157]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24718167 0.21612273 0.5366956 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.35, 0.162, 0.145, 0.86, 0.034, 0.002, 0.5269999999999999, 0.16]
0.8625061666666666
1.6047616666666669
Reward 18.159658095407124
Current State [[0.05  0.15  0.35  0.162 0.145 0.86  0.034 0.002 0.527 0.16 ]]
Logits tf.Tensor([[-0.11233342 -0.2643281   0.69018364]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24449024 0.21001537 0.5454944 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.34, 0.122, 0.145, 0.89, 0.028, 0.002, 0.554, 0.11]
0.8855123333333333
1.5184525000000002
Reward 18.41076069368483
Current State [[0.04  0.15  0.34  0.122 0.145 0.89  0.028 0.002 0.554 0.11 ]]
Logits tf.Tensor([[-0.1137549  -0.26664934  0.70634896]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24219197 0.20785406 0.54995394]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.15, 0.36, 0.172, 0.145, 0.89, 0.028, 0.002, 0.554, 0.11]
0.8855123333333333
1.5184525000000002
Reward 18.41076069368483
Current State [[0.07  0.15  0.36  0.172 0.145 0.89  0.028 0.002 0.554 0.11 ]]
Logits tf.Tensor([[-0.1175596 -0.2660098  0.7129667]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24058303 0.20739292 0.552024  ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.03, 0.04, 0.33, 0.157, 0.145, 0.68, 0.025, 0.014, 0.488, 0.16]
0.6843079999999998
13.511905
Reward 3.9742858215769705
Current State [[0.03  0.04  0.33  0.157 0.145 0.68  0.025 0.014 0.488 0.16 ]]
Logits tf.Tensor([[-0.0898198  -0.20946242  0.57894033]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2604809  0.23110841 0.5084107 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.02, 0.08, 0.34, 0.135, 0.145, 0.92, 0.038, 0.002, 0.517, 0.09]
0.924466
2.327381166666667
Reward 11.441311610584489
Current State [[0.02  0.08  0.34  0.135 0.145 0.92  0.038 0.002 0.517 0.09 ]]
Logits tf.Tensor([[-0.10819034 -0.24381451  0.675383  ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24615675 0.21493688 0.5389064 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.06, 0.04, 0.35, 0.133, 0.145, 0.76, 0.039, 0.006, 0.5309999999999999, 0.13]
0.7576566666666665
6.180356833333334
Reward 4.245584060031512
Current State [[0.06  0.04  0.35  0.133 0.145 0.76  0.039 0.006 0.531 0.13 ]]
Logits tf.Tensor([[-0.10786133 -0.2308816   0.6268868 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25193977 0.22277667 0.5252835 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.04, 0.08, 0.34, 0.159, 0.145, 0.76, 0.039, 0.006, 0.5309999999999999, 0.13]
0.7576566666666665
6.180356833333334
Reward 10.245584060031511
Current State [[0.04  0.08  0.34  0.159 0.145 0.76  0.039 0.006 0.531 0.13 ]]
Logits tf.Tensor([[-0.10704473 -0.23201422  0.6387774 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25058272 0.22114524 0.528272  ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.15, 0.36, 0.144, 0.145, 0.84, 0.032, 0.003, 0.633, 0.09]
0.8442843333333332
2.6345245
Reward 17.080188082111395
Current State [[0.07  0.15  0.36  0.144 0.145 0.84  0.032 0.003 0.633 0.09 ]]
Logits tf.Tensor([[-0.1262384 -0.2694121  0.7274486]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23725398 0.20560512 0.5571409 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.1, 0.15, 0.37, 0.122, 0.145, 0.74, 0.025, 0.002, 0.799, 0.13]
0.7400411666666666
1.9392856666666667
Reward 17.36608708161677
Current State [[0.1   0.15  0.37  0.122 0.145 0.74  0.025 0.002 0.799 0.13 ]]
Logits tf.Tensor([[-0.14225814 -0.29091534  0.7606843 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23101541 0.19910397 0.5698806 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.04, 0.45, 0.154, 0.145, 0.74, 0.025, 0.002, 0.799, 0.13]
0.7400411666666666
1.9392856666666667
Reward 5.3660870816167705
Current State [[0.05  0.04  0.45  0.154 0.145 0.74  0.025 0.002 0.799 0.13 ]]
Logits tf.Tensor([[-0.12937084 -0.2461166   0.7399397 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23391391 0.20813927 0.5579468 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.05, 0.08, 0.42, 0.18, 0.145, 0.74, 0.032, 0.005, 0.741, 0.14]
0.7428058333333333
4.544642166666666
Reward 10.407026141413638
Current State [[0.05  0.08  0.42  0.18  0.145 0.74  0.032 0.005 0.741 0.14 ]]
Logits tf.Tensor([[-0.12758984 -0.25354987  0.7234445 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23675822 0.2087379  0.55450386]], shape=(1, 3), dtype=float32)
Selected action 0
[0.02, 0.04, 0.42, 0.124, 0.145, 0.77, 0.036, 0.004, 0.726, 0.16]
0.7743268333333332
3.8369048333333335
Reward 4.563649925884607
Current State [[0.02  0.04  0.42  0.124 0.145 0.77  0.036 0.004 0.726 0.16 ]]
Logits tf.Tensor([[-0.1210362  -0.25057802  0.7109108 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23944722 0.21035385 0.5501989 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.4, 0.159, 0.145, 0.77, 0.036, 0.004, 0.726, 0.16]
0.7743268333333332
3.8369048333333335
Reward 16.563649925884608
Episode: 111 | Average Reward: 278 | Episode Reward: 257 | Loss: 480.693 | Steps: 19 | Worker: 0
Current State [[-0.00605382 -0.0021241   0.00726371  0.00463691  0.00565898  0.00094308
  -0.00428662  0.00864099  0.0071329   0.00745315]]
Logits tf.Tensor([[-0.02180567 -0.02750134  0.05193783]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.32564262 0.3237931  0.35056424]], shape=(1, 3), dtype=float32)
Selected action 1
[0.03, 0.08, 0.38, 0.143, 0.145, 0.65, 0.028, 0.003, 0.8240000000000001, 0.14]
0.6450126666666666
2.668452500000001
Reward 10.731872802781382
Current State [[0.03  0.08  0.38  0.143 0.145 0.65  0.028 0.003 0.824 0.14 ]]
Logits tf.Tensor([[-0.13015449 -0.24908037  0.72913826]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23532936 0.20894271 0.5557279 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.15, 0.38, 0.142, 0.145, 0.76, 0.023, 0.005, 0.706, 0.11]
0.7587788333333333
5.085714333333333
Reward 16.350102648781693
Current State [[0.06  0.15  0.38  0.142 0.145 0.76  0.023 0.005 0.706 0.11 ]]
Logits tf.Tensor([[-0.13004372 -0.26861244  0.7328459 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23581554 0.2053018  0.55888265]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.15, 0.39, 0.164, 0.145, 0.8, 0.075, 0.002, 0.40199999999999997, 0.19]
0.8018905000000001
2.3190476666666666
Reward 17.19689737779626
Current State [[0.07  0.15  0.39  0.164 0.145 0.8   0.075 0.002 0.402 0.19 ]]
Logits tf.Tensor([[-0.11258042 -0.26212728  0.63859165]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25121963 0.21632473 0.5324556 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.15, 0.39, 0.153, 0.145, 0.8, 0.075, 0.002, 0.40199999999999997, 0.19]
0.8018905000000001
2.3190476666666666
Reward 17.19689737779626
Current State [[0.06  0.15  0.39  0.153 0.145 0.8   0.075 0.002 0.402 0.19 ]]
Logits tf.Tensor([[-0.11178567 -0.26084673  0.63802004]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25137594 0.21656454 0.5320595 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.39, 0.159, 0.145, 0.94, 0.044, 0.001, 0.43899999999999995, 0.07]
0.9417456666666665
0.899405
Reward 21.47760073610531
Current State [[0.05  0.15  0.39  0.159 0.145 0.94  0.044 0.001 0.439 0.07 ]]
Logits tf.Tensor([[-0.11276431 -0.2525847   0.690032  ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2438259  0.21201013 0.544164  ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.38, 0.142, 0.145, 0.84, 0.058, 0.002, 0.43200000000000005, 0.14]
0.8401468333333335
2.2678575
Reward 17.31292579166498
Current State [[0.05  0.15  0.38  0.142 0.145 0.84  0.058 0.002 0.432 0.14 ]]
Logits tf.Tensor([[-0.11246419 -0.2537821   0.6578803 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24821757 0.2155058  0.53627664]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.04, 0.4, 0.138, 0.145, 0.84, 0.058, 0.002, 0.43200000000000005, 0.14]
0.8401468333333335
2.2678575
Reward 5.31292579166498
Current State [[0.05  0.04  0.4   0.138 0.145 0.84  0.058 0.002 0.432 0.14 ]]
Logits tf.Tensor([[-0.1068394  -0.22887696  0.62414885]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.252382   0.22338714 0.52423084]], shape=(1, 3), dtype=float32)
Selected action 0
[0.03, 0.04, 0.33, 0.129, 0.145, 0.72, 0.035, 0.006, 0.614, 0.21]
0.7180015000000002
5.844047833333334
Reward 4.246630109294569
Current State [[0.03  0.04  0.33  0.129 0.145 0.72  0.035 0.006 0.614 0.21 ]]
Logits tf.Tensor([[-0.11097284 -0.24388106  0.6433563 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2498919  0.21879174 0.53131634]], shape=(1, 3), dtype=float32)
Selected action 2
[0.02, 0.15, 0.36, 0.123, 0.145, 0.85, 0.041, 0.002, 0.504, 0.12]
0.8548909999999998
1.5559521666666667
Reward 18.224575653596975
Current State [[0.02  0.15  0.36  0.123 0.145 0.85  0.041 0.002 0.504 0.12 ]]
Logits tf.Tensor([[-0.11097999 -0.25327113  0.6827453 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24515882 0.21264306 0.54219806]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.39, 0.152, 0.145, 0.85, 0.041, 0.002, 0.504, 0.12]
0.8548909999999998
1.5559521666666667
Reward 18.224575653596975
Current State [[0.05  0.15  0.39  0.152 0.145 0.85  0.041 0.002 0.504 0.12 ]]
Logits tf.Tensor([[-0.11523099 -0.25675866  0.6898641 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2436089  0.21146011 0.544931  ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.02, 0.15, 0.37, 0.136, 0.145, 0.82, 0.038, 0.002, 0.558, 0.19]
0.8243498333333333
1.6547616666666665
Reward 17.950537054063375
Current State [[0.02  0.15  0.37  0.136 0.145 0.82  0.038 0.002 0.558 0.19 ]]
Logits tf.Tensor([[-0.11370991 -0.26591176  0.6942505 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24377503 0.20935763 0.5468673 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.02, 0.15, 0.33, 0.122, 0.145, 0.76, 0.029, 0.003, 0.5509999999999999, 0.17]
0.7622424999999999
3.0309526666666664
Reward 16.773886546211806
Current State [[0.02  0.15  0.33  0.122 0.145 0.76  0.029 0.003 0.551 0.17 ]]
Logits tf.Tensor([[-0.10971871 -0.25479227  0.6656474 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24774885 0.21429251 0.5379586 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.02, 0.04, 0.42, 0.167, 0.145, 0.76, 0.029, 0.003, 0.5509999999999999, 0.17]
0.7622424999999999
3.0309526666666664
Reward 4.7738865462118065
Current State [[0.02  0.04  0.42  0.167 0.145 0.76  0.029 0.003 0.551 0.17 ]]
Logits tf.Tensor([[-0.10299911 -0.22514866  0.64741963]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24981871 0.22109355 0.5290877 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.02, 0.15, 0.34, 0.138, 0.145, 0.81, 0.033, 0.001, 0.449, 0.01]
0.8142398333333333
0.8726186666666667
Reward 20.632933244622023
Current State [[0.02  0.15  0.34  0.138 0.145 0.81  0.033 0.001 0.449 0.01 ]]
Logits tf.Tensor([[-0.10355628 -0.22104292  0.6466991 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2495824  0.22191678 0.52850085]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.37, 0.121, 0.145, 0.82, 0.045, 0.001, 0.5469999999999999, 0.19]
0.817007
1.4726195
Reward 18.25387612132106
Current State [[0.03  0.15  0.37  0.121 0.145 0.82  0.045 0.001 0.547 0.19 ]]
Logits tf.Tensor([[-0.11675483 -0.26974177  0.6906446 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24388993 0.20929192 0.5468182 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.02, 0.15, 0.34, 0.123, 0.145, 0.85, 0.038, 0.002, 0.53, 0.12]
0.8527895
2.3029768333333336
Reward 17.312167935973374
Current State [[0.02  0.15  0.34  0.123 0.145 0.85  0.038 0.002 0.53  0.12 ]]
Logits tf.Tensor([[-0.11305806 -0.25622258  0.68957293]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24402057 0.211471   0.54450846]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.15, 0.39, 0.153, 0.145, 0.85, 0.038, 0.002, 0.53, 0.12]
0.8527895
2.3029768333333336
Reward 17.312167935973374
Current State [[0.07  0.15  0.39  0.153 0.145 0.85  0.038 0.002 0.53  0.12 ]]
Logits tf.Tensor([[-0.12011291 -0.26417592  0.70024484]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24171256 0.20928276 0.5490047 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.05, 0.08, 0.38, 0.164, 0.145, 0.87, 0.04, 0.002, 0.518, 0.2]
0.8665426666666669
2.1559516666666667
Reward 11.464229714853559
Current State [[0.05  0.08  0.38  0.164 0.145 0.87  0.04  0.002 0.518 0.2  ]]
Logits tf.Tensor([[-0.11155888 -0.25512016  0.67431396]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24626969 0.21333547 0.54039484]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.15, 0.4, 0.111, 0.145, 0.85, 0.074, 0.01, 0.422, 0.23]
0.8494158333333334
9.619047499999997
Reward 16.11426382433928
Current State [[0.06  0.15  0.4   0.111 0.145 0.85  0.074 0.01  0.422 0.23 ]]
Logits tf.Tensor([[-0.11534187 -0.28255814  0.65867543]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24909846 0.21074145 0.5401601 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.05, 0.08, 0.38, 0.155, 0.145, 0.85, 0.074, 0.01, 0.422, 0.23]
0.8494158333333334
9.619047499999997
Reward 10.114263824339279
Episode: 112 | Average Reward: 278 | Episode Reward: 296 | Loss: 691.076 | Steps: 19 | Worker: 0
Current State [[ 0.00615146  0.00963585  0.00524584  0.00934598  0.00838121  0.0025878
   0.00164909  0.00494041 -0.00161757 -0.00344781]]
Logits tf.Tensor([[-0.02787695 -0.0295946   0.05815672]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3238209  0.32326517 0.35291392]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.37, 0.164, 0.145, 0.82, 0.04, 0.003, 0.5519999999999999, 0.25]
0.8229733333333333
2.8934525
Reward 16.918031853332568
Current State [[0.03  0.15  0.37  0.164 0.145 0.82  0.04  0.003 0.552 0.25 ]]
Logits tf.Tensor([[-0.11771286 -0.277447    0.70064676]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24276862 0.20692877 0.5503026 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.02, 0.15, 0.37, 0.127, 0.145, 0.84, 0.045, 0.002, 0.5429999999999999, 0.27]
0.8396511666666666
2.4339285
Reward 17.193142207481873
Current State [[0.02  0.15  0.37  0.127 0.145 0.84  0.045 0.002 0.543 0.27 ]]
Logits tf.Tensor([[-0.11779353 -0.28566653  0.70270425]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2428899  0.20535399 0.5517561 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.38, 0.16, 0.145, 0.84, 0.045, 0.002, 0.5429999999999999, 0.27]
0.8396511666666666
2.4339285
Reward 17.193142207481873
Current State [[0.05  0.15  0.38  0.16  0.145 0.84  0.045 0.002 0.543 0.27 ]]
Logits tf.Tensor([[-0.12055026 -0.2880658   0.70517963]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2421712  0.20481955 0.5530093 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.01, 0.08, 0.37, 0.149, 0.145, 0.77, 0.033, 0.002, 0.546, 0.17]
0.76979
2.4755961666666666
Reward 11.036912238671782
Current State [[0.01  0.08  0.37  0.149 0.145 0.77  0.033 0.002 0.546 0.17 ]]
Logits tf.Tensor([[-0.11001404 -0.23719943  0.6613843 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24731915 0.21778192 0.53489894]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.37, 0.134, 0.145, 0.79, 0.034, 0.002, 0.576, 0.14]
0.7920056666666666
2.3386905000000007
Reward 17.16378417338567
Current State [[0.03  0.15  0.37  0.134 0.145 0.79  0.034 0.002 0.576 0.14 ]]
Logits tf.Tensor([[-0.12119025 -0.25978306  0.7002997 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24128552 0.21005893 0.54865557]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.37, 0.148, 0.145, 0.79, 0.034, 0.002, 0.576, 0.14]
0.7920056666666666
2.3386905000000007
Reward 17.16378417338567
Current State [[0.03  0.15  0.37  0.148 0.145 0.79  0.034 0.002 0.576 0.14 ]]
Logits tf.Tensor([[-0.12123534 -0.25818735  0.70121187]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24107568 0.2102209  0.54870343]], shape=(1, 3), dtype=float32)
Selected action 0
[0.03, 0.04, 0.35, 0.147, 0.145, 0.82, 0.053, 0.001, 0.519, 0.24]
0.8155055
1.2833328333333334
Reward 6.708732401735847
Current State [[0.03  0.04  0.35  0.147 0.145 0.82  0.053 0.001 0.519 0.24 ]]
Logits tf.Tensor([[-0.11507978 -0.24844106  0.6494697 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24855988 0.2175269  0.5339132 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.34, 0.117, 0.145, 0.76, 0.032, 0.002, 0.579, 0.1]
0.7630331666666668
1.9761908333333331
Reward 17.387719838878446
Current State [[0.04  0.15  0.34  0.117 0.145 0.76  0.032 0.002 0.579 0.1  ]]
Logits tf.Tensor([[-0.12218003 -0.25330564  0.68771887]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24243669 0.21264304 0.54492027]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.42, 0.132, 0.145, 0.92, 0.044, 0.001, 0.545, 0.06]
0.9221955000000002
1.1559521666666663
Reward 7.708777024205311
Current State [[0.04  0.04  0.42  0.132 0.145 0.92  0.044 0.001 0.545 0.06 ]]
Logits tf.Tensor([[-0.12113766 -0.2409846   0.7027015 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24002172 0.21291277 0.5470655 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.37, 0.16, 0.145, 0.92, 0.044, 0.001, 0.545, 0.06]
0.9221955000000002
1.1559521666666663
Reward 19.70877702420531
Current State [[0.03  0.15  0.37  0.16  0.145 0.92  0.044 0.001 0.545 0.06 ]]
Logits tf.Tensor([[-0.12598862 -0.25931132  0.7321742 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23618296 0.20670323 0.5571138 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.07, 0.04, 0.41, 0.158, 0.145, 0.86, 0.031, 0.003, 0.511, 0.11]
0.8612110000000001
2.600595333333333
Reward 5.12918490463185
Current State [[0.07  0.04  0.41  0.158 0.145 0.86  0.031 0.003 0.511 0.11 ]]
Logits tf.Tensor([[-0.11401433 -0.23704864  0.6701956 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24540427 0.21699463 0.5376011 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.15, 0.38, 0.147, 0.145, 0.7, 0.023, 0.006, 0.858, 0.15]
0.6972075
6.2535715000000005
Reward 16.2026516973038
Current State [[0.06  0.15  0.38  0.147 0.145 0.7   0.023 0.006 0.858 0.15 ]]
Logits tf.Tensor([[-0.14574665 -0.28499377  0.7845495 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2270007  0.19749355 0.57550573]], shape=(1, 3), dtype=float32)
Selected action 2
[0.02, 0.15, 0.34, 0.138, 0.145, 0.7, 0.023, 0.006, 0.858, 0.15]
0.6972075
6.2535715000000005
Reward 16.2026516973038
Current State [[0.02  0.15  0.34  0.138 0.145 0.7   0.023 0.006 0.858 0.15 ]]
Logits tf.Tensor([[-0.1417338  -0.27917156  0.77561325]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22861162 0.19925529 0.5721331 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.04, 0.08, 0.36, 0.147, 0.145, 0.7, 0.019, 0.012, 0.422, 0.02]
0.7032848333333335
11.823213833333336
Reward 10.006741144002781
Current State [[0.04  0.08  0.36  0.147 0.145 0.7   0.019 0.012 0.422 0.02 ]]
Logits tf.Tensor([[-0.09284656 -0.19433306  0.5892078 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.25763696 0.23277332 0.50958973]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.3, 0.135, 0.145, 0.87, 0.032, 0.001, 0.522, 0.1]
0.8691381666666668
1.4898808333333333
Reward 6.411840750430548
Current State [[0.04  0.04  0.3   0.135 0.145 0.87  0.032 0.001 0.522 0.1  ]]
Logits tf.Tensor([[-0.11419665 -0.23802947  0.653469  ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24763153 0.21878928 0.53357923]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.32, 0.158, 0.145, 0.87, 0.032, 0.001, 0.522, 0.1]
0.8691381666666668
1.4898808333333333
Reward 18.41184075043055
Current State [[0.04  0.15  0.32  0.158 0.145 0.87  0.032 0.001 0.522 0.1  ]]
Logits tf.Tensor([[-0.11955369 -0.25720948  0.6984544 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24169883 0.21061604 0.5476851 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.28, 0.138, 0.145, 0.89, 0.029, 0.001, 0.548, 0.06]
0.8890816666666665
1.3988098333333334
Reward 18.70954325917443
Current State [[0.04  0.15  0.28  0.138 0.145 0.89  0.029 0.001 0.548 0.06 ]]
Logits tf.Tensor([[-0.12390643 -0.26098686  0.70544267]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24016948 0.20940377 0.5504267 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.15, 0.33, 0.206, 0.145, 0.92, 0.037, 0.001, 0.43899999999999995, 0.01]
0.9212791666666666
0.5392851666666666
Reward 27.59055256210317
Current State [[0.06  0.15  0.33  0.206 0.145 0.92  0.037 0.001 0.439 0.01 ]]
Logits tf.Tensor([[-0.11736591 -0.24104436  0.6823314 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24339598 0.21508025 0.54152375]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.32, 0.12, 0.145, 0.81, 0.014, 0.002, 0.538, 0.04]
0.8148928333333333
1.8339281666666667
Reward 17.674100134754312
Current State [[0.03  0.15  0.32  0.12  0.145 0.81  0.014 0.002 0.538 0.04 ]]
Logits tf.Tensor([[-0.11196262 -0.2399657   0.68335587]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24420042 0.2148599  0.5409397 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.33, 0.147, 0.145, 0.81, 0.014, 0.002, 0.538, 0.04]
0.8148928333333333
1.8339281666666667
Reward 5.67410013475431
Episode: 113 | Average Reward: 279 | Episode Reward: 290 | Loss: 645.687 | Steps: 19 | Worker: 0
Current State [[-0.00094019  0.00203657  0.00453692 -0.00120858 -0.00302317  0.00860129
   0.00872954  0.0061993   0.00704004 -0.00423027]]
Logits tf.Tensor([[-0.03001102 -0.03146528  0.06216754]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.32309055 0.32262105 0.3542884 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.05, 0.08, 0.35, 0.162, 0.145, 0.78, 0.023, 0.003, 0.49400000000000005, 0.07]
0.7756771666666665
2.7053568333333327
Reward 10.928208660378374
Current State [[0.05  0.08  0.35  0.162 0.145 0.78  0.023 0.003 0.494 0.07 ]]
Logits tf.Tensor([[-0.11179699 -0.22674133  0.6523778 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24760827 0.22072192 0.53166986]], shape=(1, 3), dtype=float32)
Selected action 1
[0.04, 0.08, 0.35, 0.117, 0.145, 0.9, 0.044, 0.001, 0.49400000000000005, 0.14]
0.9017478333333332
1.0755951666666665
Reward 13.977172448857537
Current State [[0.04  0.08  0.35  0.117 0.145 0.9   0.044 0.001 0.494 0.14 ]]
Logits tf.Tensor([[-0.12097286 -0.25994757  0.6845791 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24341674 0.2118334  0.5447499 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.03, 0.08, 0.35, 0.149, 0.145, 0.9, 0.044, 0.001, 0.49400000000000005, 0.14]
0.9017478333333332
1.0755951666666665
Reward 13.977172448857537
Current State [[0.03  0.08  0.35  0.149 0.145 0.9   0.044 0.001 0.494 0.14 ]]
Logits tf.Tensor([[-0.11906573 -0.25348133  0.685516  ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24330974 0.21270783 0.54398245]], shape=(1, 3), dtype=float32)
Selected action 1
[0.06, 0.08, 0.36, 0.165, 0.145, 0.75, 0.02, 0.003, 0.616, 0.07]
0.7537465
2.5845243333333334
Reward 10.95010610982671
Current State [[0.06  0.08  0.36  0.165 0.145 0.75  0.02  0.003 0.616 0.07 ]]
Logits tf.Tensor([[-0.12497723 -0.23803614  0.6924582 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24051283 0.21480154 0.54468566]], shape=(1, 3), dtype=float32)
Selected action 1
[0.04, 0.08, 0.34, 0.143, 0.145, 0.86, 0.021, 0.005, 0.591, 0.08]
0.8601275000000002
4.869643166666667
Reward 10.460295706620737
Current State [[0.04  0.08  0.34  0.143 0.145 0.86  0.021 0.005 0.591 0.08 ]]
Logits tf.Tensor([[-0.12239695 -0.25161386  0.7106169 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23929031 0.21028434 0.55042535]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.35, 0.154, 0.145, 0.85, 0.028, 0.002, 0.5860000000000001, 0.14]
0.8539073333333334
1.9559525
Reward 17.635111329092535
Current State [[0.05  0.15  0.35  0.154 0.145 0.85  0.028 0.002 0.586 0.14 ]]
Logits tf.Tensor([[-0.12920353 -0.27554595  0.7321107 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23639934 0.20421638 0.5593843 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.34, 0.154, 0.145, 0.85, 0.028, 0.002, 0.5860000000000001, 0.14]
0.8539073333333334
1.9559525
Reward 17.635111329092535
Current State [[0.03  0.15  0.34  0.154 0.145 0.85  0.028 0.002 0.586 0.14 ]]
Logits tf.Tensor([[-0.12625487 -0.27082214  0.72979605]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23700933 0.20510708 0.5578836 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.36, 0.143, 0.145, 0.83, 0.025, 0.003, 0.506, 0.04]
0.8336225
2.6261905000000003
Reward 17.06631738127468
Current State [[0.05  0.15  0.36  0.143 0.145 0.83  0.025 0.003 0.506 0.04 ]]
Logits tf.Tensor([[-0.11886267 -0.24670339  0.6958462 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24163274 0.21263528 0.54573196]], shape=(1, 3), dtype=float32)
Selected action 0
[0.07, 0.04, 0.38, 0.129, 0.145, 0.79, 0.025, 0.004, 0.488, 0.09]
0.7890721666666666
3.8785716666666668
Reward 4.57042971186691
Current State [[0.07  0.04  0.38  0.129 0.145 0.79  0.025 0.004 0.488 0.09 ]]
Logits tf.Tensor([[-0.1119443  -0.23050441  0.6432126 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24899507 0.22115703 0.5298479 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.02, 0.15, 0.33, 0.165, 0.145, 0.79, 0.025, 0.004, 0.488, 0.09]
0.7890721666666666
3.8785716666666668
Reward 16.57042971186691
Current State [[0.02  0.15  0.33  0.165 0.145 0.79  0.025 0.004 0.488 0.09 ]]
Logits tf.Tensor([[-0.11112948 -0.23890696  0.67120856]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.245904   0.21640761 0.53768843]], shape=(1, 3), dtype=float32)
Selected action 0
[0.06, 0.04, 0.33, 0.16, 0.145, 0.88, 0.03, 0.002, 0.517, 0.02]
0.8823405000000001
2.061309666666667
Reward 5.592651268373385
Current State [[0.06  0.04  0.33  0.16  0.145 0.88  0.03  0.002 0.517 0.02 ]]
Logits tf.Tensor([[-0.12083054 -0.23194723  0.6718565 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24365526 0.2180311  0.5383137 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.06, 0.04, 0.37, 0.127, 0.145, 0.8, 0.016, 0.002, 0.5509999999999999, 0.07]
0.7960688333333334
2.227381
Reward 5.251243672528261
Current State [[0.06  0.04  0.37  0.127 0.145 0.8   0.016 0.002 0.551 0.07 ]]
Logits tf.Tensor([[-0.11564482 -0.23323618  0.66957265]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2449814  0.21780297 0.53721565]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.34, 0.153, 0.145, 0.8, 0.016, 0.002, 0.5509999999999999, 0.07]
0.7960688333333334
2.227381
Reward 5.251243672528261
Current State [[0.04  0.04  0.34  0.153 0.145 0.8   0.016 0.002 0.551 0.07 ]]
Logits tf.Tensor([[-0.11305609 -0.2252948   0.6646279 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24568474 0.2196006  0.53471464]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.34, 0.159, 0.145, 0.9, 0.045, 0.001, 0.44400000000000006, 0.13]
0.8964648333333333
1.0107138333333332
Reward 20.308363199482194
Current State [[0.04  0.15  0.34  0.159 0.145 0.9   0.045 0.001 0.444 0.13 ]]
Logits tf.Tensor([[-0.11955234 -0.2629463   0.6892724 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24320957 0.21071987 0.5460706 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.15, 0.36, 0.147, 0.145, 0.84, 0.032, 0.002, 0.6799999999999999, 0.11]
0.8409693333333335
1.9410713333333331
Reward 17.618540313067342
Current State [[0.06  0.15  0.36  0.147 0.145 0.84  0.032 0.002 0.68  0.11 ]]
Logits tf.Tensor([[-0.1423885  -0.28328732  0.7671979 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22978616 0.199587   0.57062685]], shape=(1, 3), dtype=float32)
Selected action 1
[0.05, 0.08, 0.38, 0.126, 0.145, 0.73, 0.025, 0.005, 0.6679999999999999, 0.12]
0.73377
5.257142333333333
Reward 10.312038128349108
Current State [[0.05  0.08  0.38  0.126 0.145 0.73  0.025 0.005 0.668 0.12 ]]
Logits tf.Tensor([[-0.12942986 -0.25358856  0.7046763 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23889187 0.21099877 0.5501094 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.1, 0.15, 0.39, 0.18, 0.145, 0.73, 0.025, 0.005, 0.6679999999999999, 0.12]
0.73377
5.257142333333333
Reward 16.31203812834911
Current State [[0.1   0.15  0.39  0.18  0.145 0.73  0.025 0.005 0.668 0.12 ]]
Logits tf.Tensor([[-0.14138916 -0.27570042  0.7322641 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23419397 0.20476    0.56104606]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.42, 0.153, 0.145, 0.8, 0.035, 0.003, 0.8949999999999999, 0.17]
0.7958793333333335
2.8833330000000004
Reward 4.880915756689991
Current State [[0.04  0.04  0.42  0.153 0.145 0.8   0.035 0.003 0.895 0.17 ]]
Logits tf.Tensor([[-0.15383431 -0.28498933  0.81204355]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22201626 0.19472641 0.5832574 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.41, 0.133, 0.145, 0.66, 0.027, 0.005, 0.7889999999999999, 0.14]
0.6554128333333332
5.283928833333333
Reward 16.251212397661334
Current State [[0.04  0.15  0.41  0.133 0.145 0.66  0.027 0.005 0.789 0.14 ]]
Logits tf.Tensor([[-0.14261055 -0.26937026  0.7565874 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23049036 0.20304942 0.56646025]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.4, 0.15, 0.145, 0.66, 0.027, 0.005, 0.7889999999999999, 0.14]
0.6554128333333332
5.283928833333333
Reward 16.251212397661334
Episode: 114 | Average Reward: 278 | Episode Reward: 251 | Loss: 490.042 | Steps: 19 | Worker: 0
Current State [[-0.00372366  0.00180153 -0.0083874  -0.00492228  0.00402927 -0.00300351
  -0.00666015  0.00465584 -0.00611636  0.00611449]]
Logits tf.Tensor([[-0.02499379 -0.0238608   0.04784958]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.325024   0.32539248 0.3495835 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.01, 0.15, 0.35, 0.104, 0.145, 0.74, 0.03, 0.002, 0.776, 0.15]
0.7363365
1.7809521666666668
Reward 17.520554014436037
Current State [[0.01  0.15  0.35  0.104 0.145 0.74  0.03  0.002 0.776 0.15 ]]
Logits tf.Tensor([[-0.14575978 -0.2842641   0.77145654]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2286773  0.19910006 0.57222265]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.15, 0.39, 0.134, 0.145, 0.85, 0.043, 0.004, 0.5980000000000001, 0.12]
0.8474668333333334
3.8059521666666662
Reward 16.6508932074889
Current State [[0.06  0.15  0.39  0.134 0.145 0.85  0.043 0.004 0.598 0.12 ]]
Logits tf.Tensor([[-0.1397223  -0.28305084  0.7500332 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23250388 0.20145749 0.56603867]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.39, 0.18, 0.145, 0.85, 0.043, 0.004, 0.5980000000000001, 0.12]
0.8474668333333334
3.8059521666666662
Reward 16.6508932074889
Current State [[0.05  0.15  0.39  0.18  0.145 0.85  0.043 0.004 0.598 0.12 ]]
Logits tf.Tensor([[-0.13836387 -0.27528703  0.752777  ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23202145 0.20233132 0.5656472 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.42, 0.141, 0.145, 0.84, 0.039, 0.003, 0.521, 0.2]
0.8356023333333333
2.5059523333333336
Reward 5.139725467496074
Current State [[0.04  0.04  0.42  0.141 0.145 0.84  0.039 0.003 0.521 0.2  ]]
Logits tf.Tensor([[-0.11905793 -0.2544189   0.6835538 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24361952 0.21277742 0.5436031 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.02, 0.08, 0.37, 0.142, 0.145, 0.81, 0.045, 0.002, 0.504, 0.2]
0.8070795
1.715475833333333
Reward 11.806856684725332
Current State [[0.02  0.08  0.37  0.142 0.145 0.81  0.045 0.002 0.504 0.2  ]]
Logits tf.Tensor([[-0.11861853 -0.25371078  0.6732292 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24503155 0.21406823 0.5409002 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.39, 0.15, 0.145, 0.81, 0.058, 0.003, 0.442, 0.18]
0.8134560000000001
3.0148815000000004
Reward 16.85361505158144
Current State [[0.05  0.15  0.39  0.15  0.145 0.81  0.058 0.003 0.442 0.18 ]]
Logits tf.Tensor([[-0.12204651 -0.26792002  0.67783237]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24452637 0.21133608 0.54413754]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.39, 0.148, 0.145, 0.81, 0.058, 0.003, 0.442, 0.18]
0.8134560000000001
3.0148815000000004
Reward 16.85361505158144
Current State [[0.03  0.15  0.39  0.148 0.145 0.81  0.058 0.003 0.442 0.18 ]]
Logits tf.Tensor([[-0.11908172 -0.2632612   0.67727077]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24490774 0.21202454 0.5430677 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.37, 0.138, 0.145, 0.84, 0.047, 0.001, 0.46900000000000003, 0.12]
0.8408336666666666
1.013096
Reward 19.92097197290427
Current State [[0.03  0.15  0.37  0.138 0.145 0.84  0.047 0.001 0.469 0.12 ]]
Logits tf.Tensor([[-0.12275126 -0.25951272  0.69408804]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24180797 0.21089965 0.54729235]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.37, 0.123, 0.145, 0.9, 0.044, 0.001, 0.502, 0.1]
0.9002510000000001
1.3898808333333332
Reward 18.780260033678942
Current State [[0.03  0.15  0.37  0.123 0.145 0.9   0.044 0.001 0.502 0.1  ]]
Logits tf.Tensor([[-0.12741697 -0.2700788   0.72425616]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23749517 0.20591953 0.5565853 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.04, 0.41, 0.156, 0.145, 0.9, 0.044, 0.001, 0.502, 0.1]
0.9002510000000001
1.3898808333333332
Reward 6.7802600336789425
Current State [[0.05  0.04  0.41  0.156 0.145 0.9   0.044 0.001 0.502 0.1  ]]
Logits tf.Tensor([[-0.12377833 -0.24520567  0.69562954]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24068482 0.21316381 0.54615134]], shape=(1, 3), dtype=float32)
Selected action 1
[0.02, 0.08, 0.36, 0.131, 0.145, 0.81, 0.041, 0.003, 0.512, 0.22]
0.8104723333333334
2.580952666666667
Reward 11.050831455549034
Current State [[0.02  0.08  0.36  0.131 0.145 0.81  0.041 0.003 0.512 0.22 ]]
Logits tf.Tensor([[-0.11744781 -0.25877422  0.6730378 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24553902 0.21317841 0.5412826 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.38, 0.119, 0.145, 0.77, 0.07, 0.001, 0.41100000000000003, 0.1]
0.770031
1.2815473333333331
Reward 18.510294091245274
Current State [[0.05  0.15  0.38  0.119 0.145 0.77  0.07  0.001 0.411 0.1  ]]
Logits tf.Tensor([[-0.12536663 -0.24948958  0.65314406]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24621463 0.21747431 0.53631103]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.39, 0.158, 0.145, 0.77, 0.07, 0.001, 0.41100000000000003, 0.1]
0.770031
1.2815473333333331
Reward 18.510294091245274
Current State [[0.05  0.15  0.39  0.158 0.145 0.77  0.07  0.001 0.411 0.1  ]]
Logits tf.Tensor([[-0.12499173 -0.24486816  0.6570774 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24551803 0.21778187 0.53670007]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.15, 0.38, 0.175, 0.145, 0.92, 0.041, 0.001, 0.43099999999999994, 0.11]
0.9184383333333334
0.6053569999999999
Reward 25.616675457206792
Current State [[0.06  0.15  0.38  0.175 0.145 0.92  0.041 0.001 0.431 0.11 ]]
Logits tf.Tensor([[-0.12284672 -0.2647409   0.70514894]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24059051 0.20876352 0.55064595]], shape=(1, 3), dtype=float32)
Selected action 1
[0.05, 0.08, 0.38, 0.142, 0.145, 0.91, 0.051, 0.001, 0.511, 0.12]
0.9078665
0.6874998333333332
Reward 17.75740592572711
Current State [[0.05  0.08  0.38  0.142 0.145 0.91  0.051 0.001 0.511 0.12 ]]
Logits tf.Tensor([[-0.13011779 -0.2631669   0.7100767 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23853599 0.20881967 0.5526443 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.36, 0.154, 0.145, 0.83, 0.039, 0.003, 0.529, 0.19]
0.8283825
2.5065476666666666
Reward 17.126093693634484
Current State [[0.03  0.15  0.36  0.154 0.145 0.83  0.039 0.003 0.529 0.19 ]]
Logits tf.Tensor([[-0.12471499 -0.27418932  0.7112911 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23990628 0.20659782 0.5534959 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.36, 0.142, 0.145, 0.83, 0.039, 0.003, 0.529, 0.19]
0.8283825
2.5065476666666666
Reward 17.126093693634484
Current State [[0.03  0.15  0.36  0.142 0.145 0.83  0.039 0.003 0.529 0.19 ]]
Logits tf.Tensor([[-0.12481301 -0.2759409   0.71077657]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24004352 0.20637448 0.55358195]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.15, 0.38, 0.142, 0.145, 0.88, 0.037, 0.001, 0.5, 0.12]
0.8788796666666667
1.4285715
Reward 18.592015447383442
Current State [[0.06  0.15  0.38  0.142 0.145 0.88  0.037 0.001 0.5   0.12 ]]
Logits tf.Tensor([[-0.12833765 -0.27368122  0.72037816]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23801763 0.20581983 0.55616254]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.38, 0.133, 0.145, 0.85, 0.071, 0.009, 0.42699999999999994, 0.21]
0.8469801666666665
9.403571833333334
Reward 16.12093077051262
Current State [[0.05  0.15  0.38  0.133 0.145 0.85  0.071 0.009 0.427 0.21 ]]
Logits tf.Tensor([[-0.1260917 -0.2825171  0.6823763]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24392255 0.20860142 0.54747605]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.15, 0.39, 0.15, 0.145, 0.85, 0.071, 0.009, 0.42699999999999994, 0.21]
0.8469801666666665
9.403571833333334
Reward 16.12093077051262
Episode: 115 | Average Reward: 279 | Episode Reward: 323 | Loss: 869.379 | Steps: 19 | Worker: 0
Current State [[ 0.00341754  0.00769976 -0.00491973  0.00543279 -0.00761501  0.00755483
   0.00528345 -0.00317519  0.00982952  0.00276483]]
Logits tf.Tensor([[-0.035277   -0.03361785  0.06883504]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.32140025 0.32193393 0.35666582]], shape=(1, 3), dtype=float32)
Selected action 1
[0.05, 0.08, 0.38, 0.169, 0.145, 0.88, 0.043, 0.001, 0.544, 0.18]
0.8792658333333333
0.7863091666666667
Reward 16.036155612370322
Current State [[0.05  0.08  0.38  0.169 0.145 0.88  0.043 0.001 0.544 0.18 ]]
Logits tf.Tensor([[-0.1359955  -0.27149135  0.7266094 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23570411 0.20583634 0.5584595 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.02, 0.15, 0.36, 0.13, 0.145, 0.88, 0.044, 0.002, 0.484, 0.16]
0.8759718333333333
1.6452384999999998
Reward 18.132498437404656
Current State [[0.02  0.15  0.36  0.13  0.145 0.88  0.044 0.002 0.484 0.16 ]]
Logits tf.Tensor([[-0.12893464 -0.27551216  0.72020656]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23802173 0.20556957 0.5564087 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.06, 0.08, 0.39, 0.164, 0.145, 0.88, 0.044, 0.002, 0.484, 0.16]
0.8759718333333333
1.6452384999999998
Reward 12.132498437404656
Current State [[0.06  0.08  0.39  0.164 0.145 0.88  0.044 0.002 0.484 0.16 ]]
Logits tf.Tensor([[-0.13051233 -0.26363254  0.70401216]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23928721 0.20946243 0.55125034]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.39, 0.15, 0.145, 0.79, 0.02, 0.003, 0.5559999999999999, 0.03]
0.7940373333333335
2.9755961666666666
Reward 16.840641987796975
Current State [[0.05  0.15  0.39  0.15  0.145 0.79  0.02  0.003 0.556 0.03 ]]
Logits tf.Tensor([[-0.13081147 -0.24993181  0.7245955 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23584725 0.20936184 0.5547909 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.38, 0.134, 0.145, 0.78, 0.041, 0.003, 0.55, 0.2]
0.7848856666666666
2.6130953333333338
Reward 16.989169200828073
Current State [[0.04  0.15  0.38  0.134 0.145 0.78  0.041 0.003 0.55  0.2  ]]
Logits tf.Tensor([[-0.1340974  -0.28183088  0.71669567]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23785941 0.20519204 0.5569486 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.03, 0.08, 0.34, 0.152, 0.145, 0.78, 0.041, 0.003, 0.55, 0.2]
0.7848856666666666
2.6130953333333338
Reward 10.989169200828073
Current State [[0.03  0.08  0.34  0.152 0.145 0.78  0.041 0.003 0.55  0.2  ]]
Logits tf.Tensor([[-0.12994866 -0.2606632   0.68946624]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2411591  0.21160944 0.54723144]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.37, 0.142, 0.145, 0.86, 0.05, 0.002, 0.495, 0.21]
0.8573136666666666
2.3583336666666668
Reward 17.2800940216629
Current State [[0.03  0.15  0.37  0.142 0.145 0.86  0.05  0.002 0.495 0.21 ]]
Logits tf.Tensor([[-0.1314706  -0.28378773  0.7207448 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23789406 0.20428342 0.5578225 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.02, 0.15, 0.36, 0.133, 0.145, 0.73, 0.019, 0.003, 0.599, 0.11]
0.7335826666666668
3.1488096666666663
Reward 16.694535091413606
Current State [[0.02  0.15  0.36  0.133 0.145 0.73  0.019 0.003 0.599 0.11 ]]
Logits tf.Tensor([[-0.12929007 -0.25640363  0.7137899 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23786044 0.2094679  0.5526716 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.38, 0.152, 0.145, 0.73, 0.019, 0.003, 0.599, 0.11]
0.7335826666666668
3.1488096666666663
Reward 4.6945350914136075
Current State [[0.04  0.04  0.38  0.152 0.145 0.73  0.019 0.003 0.599 0.11 ]]
Logits tf.Tensor([[-0.12587479 -0.23514363  0.68538475]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24112478 0.21616578 0.5427094 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.04, 0.08, 0.37, 0.148, 0.145, 0.77, 0.024, 0.005, 0.714, 0.17]
0.7702258333333334
4.972023999999999
Reward 10.372849575138009
Current State [[0.04  0.08  0.37  0.148 0.145 0.77  0.024 0.005 0.714 0.17 ]]
Logits tf.Tensor([[-0.14390597 -0.27563423  0.7535868 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23094565 0.20244215 0.56661224]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.38, 0.126, 0.145, 0.67, 0.02, 0.005, 0.9189999999999999, 0.15]
0.6686251666666665
5.404762000000001
Reward 16.249934630044326
Current State [[0.03  0.15  0.38  0.126 0.145 0.67  0.02  0.005 0.919 0.15 ]]
Logits tf.Tensor([[-0.1609132  -0.29416305  0.83261716]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.21853153 0.19126894 0.5901996 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.0, 0.04, 0.26, 0.1, 0.145, 0.63, 0.015, 0.007, 0.7969999999999999, 0.11]
0.6278605
7.224405333333334
Reward 4.108990910804107
Current State [[0.    0.04  0.26  0.1   0.145 0.63  0.015 0.007 0.797 0.11 ]]
Logits tf.Tensor([[-0.1425086  -0.24508494  0.7182429 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23433216 0.21148695 0.55418086]], shape=(1, 3), dtype=float32)
Selected action 2
[0.02, 0.15, 0.3, 0.117, 0.145, 0.63, 0.015, 0.007, 0.7969999999999999, 0.11]
0.6278605
7.224405333333334
Reward 16.108990910804106
Current State [[0.02  0.15  0.3   0.117 0.145 0.63  0.015 0.007 0.797 0.11 ]]
Logits tf.Tensor([[-0.14574184 -0.26613313  0.75164497]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23042762 0.204291   0.56528133]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.37, 0.157, 0.145, 0.89, 0.04, 0.001, 0.515, 0.11]
0.8880519999999998
0.9464286666666667
Reward 8.670278338278653
Current State [[0.04  0.04  0.37  0.157 0.145 0.89  0.04  0.001 0.515 0.11 ]]
Logits tf.Tensor([[-0.1290594  -0.24870479  0.70092666]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23920462 0.2122307  0.54856473]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.04, 0.33, 0.124, 0.145, 0.78, 0.03, 0.003, 0.5780000000000001, 0.14]
0.7799958333333332
2.6779755
Reward 4.94843322698224
Current State [[0.05  0.04  0.33  0.124 0.145 0.78  0.03  0.003 0.578 0.14 ]]
Logits tf.Tensor([[-0.13048315 -0.25245672  0.68510544]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2412151  0.21351677 0.5452681 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.34, 0.161, 0.145, 0.78, 0.03, 0.003, 0.5780000000000001, 0.14]
0.7799958333333332
2.6779755
Reward 16.94843322698224
Current State [[0.05  0.15  0.34  0.161 0.145 0.78  0.03  0.003 0.578 0.14 ]]
Logits tf.Tensor([[-0.13699514 -0.27216405  0.7240513 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2358934  0.206069   0.55803764]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.32, 0.141, 0.145, 0.8, 0.016, 0.002, 0.5599999999999999, 0.05]
0.7956553333333332
1.6119051666666668
Reward 17.926691344557838
Current State [[0.04  0.15  0.32  0.141 0.145 0.8   0.016 0.002 0.56  0.05 ]]
Logits tf.Tensor([[-0.12959276 -0.2544599   0.71803266]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23715162 0.20931336 0.55353504]], shape=(1, 3), dtype=float32)
Selected action 1
[0.03, 0.08, 0.31, 0.127, 0.145, 0.88, 0.035, 0.001, 0.48200000000000004, 0.12]
0.8766621666666666
0.5702381666666666
Reward 19.817511075187202
Current State [[0.03  0.08  0.31  0.127 0.145 0.88  0.035 0.001 0.482 0.12 ]]
Logits tf.Tensor([[-0.1243738  -0.25668284  0.68292254]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24284172 0.2127464  0.5444119 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.32, 0.153, 0.145, 0.88, 0.035, 0.001, 0.48200000000000004, 0.12]
0.8766621666666666
0.5702381666666666
Reward 25.817511075187202
Current State [[0.04  0.15  0.32  0.153 0.145 0.88  0.035 0.001 0.482 0.12 ]]
Logits tf.Tensor([[-0.12982696 -0.26956472  0.71282995]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23854305 0.20743373 0.5540232 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.08, 0.08, 0.34, 0.177, 0.145, 0.75, 0.022, 0.002, 0.45999999999999996, 0.02]
0.7497698333333335
2.0380956666666665
Reward 11.300683882760893
Episode: 116 | Average Reward: 279 | Episode Reward: 282 | Loss: 605.249 | Steps: 19 | Worker: 0
Current State [[-0.00300203 -0.00165901 -0.00072436 -0.00195796  0.00443031  0.00479476
  -0.00396121  0.00423467  0.00313841 -0.0036922 ]]
Logits tf.Tensor([[-0.03211481 -0.02871405  0.06218507]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.32234192 0.32344002 0.35421807]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.15, 0.35, 0.135, 0.145, 0.73, 0.029, 0.002, 0.49400000000000005, 0.09]
0.7310959999999999
2.1494050000000002
Reward 17.170665926693538
Current State [[0.07  0.15  0.35  0.135 0.145 0.73  0.029 0.002 0.494 0.09 ]]
Logits tf.Tensor([[-0.13488825 -0.2561509   0.68458766]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24066742 0.2131835  0.5461491 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.06, 0.08, 0.35, 0.124, 0.145, 0.86, 0.038, 0.001, 0.553, 0.14]
0.856937
1.2363086666666667
Reward 13.050912426965724
Current State [[0.06  0.08  0.35  0.124 0.145 0.86  0.038 0.001 0.553 0.14 ]]
Logits tf.Tensor([[-0.14343072 -0.27419293  0.7275393 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23437572 0.20564744 0.5599769 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.33, 0.146, 0.145, 0.86, 0.038, 0.001, 0.553, 0.14]
0.856937
1.2363086666666667
Reward 19.050912426965724
Current State [[0.03  0.15  0.33  0.146 0.145 0.86  0.038 0.001 0.553 0.14 ]]
Logits tf.Tensor([[-0.1433829  -0.28068802  0.7483342 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23196372 0.20220377 0.5658325 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.34, 0.14, 0.145, 0.77, 0.016, 0.002, 0.521, 0.06]
0.7694106666666667
2.443452
Reward 17.054765631447225
Current State [[0.03  0.15  0.34  0.14  0.145 0.77  0.016 0.002 0.521 0.06 ]]
Logits tf.Tensor([[-0.12850209 -0.24672042  0.70437723]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23875275 0.21213229 0.54911494]], shape=(1, 3), dtype=float32)
Selected action 1
[0.03, 0.08, 0.34, 0.119, 0.145, 0.87, 0.028, 0.003, 0.475, 0.09]
0.8710428333333335
2.7952380000000003
Reward 11.0399266762277
Current State [[0.03  0.08  0.34  0.119 0.145 0.87  0.028 0.003 0.475 0.09 ]]
Logits tf.Tensor([[-0.1266686  -0.25150588  0.69192225]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24096717 0.21268739 0.5463455 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.05, 0.08, 0.35, 0.153, 0.145, 0.87, 0.028, 0.003, 0.475, 0.09]
0.8710428333333335
2.7952380000000003
Reward 11.0399266762277
Current State [[0.05  0.08  0.35  0.153 0.145 0.87  0.028 0.003 0.475 0.09 ]]
Logits tf.Tensor([[-0.12934463 -0.2511542   0.69639117]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23987272 0.21236339 0.5477639 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.33, 0.136, 0.145, 0.81, 0.029, 0.004, 0.479, 0.08]
0.8088436666666666
4.082738166666667
Reward 16.54834021347294
Current State [[0.03  0.15  0.33  0.136 0.145 0.81  0.029 0.004 0.479 0.08 ]]
Logits tf.Tensor([[-0.12902147 -0.25430626  0.70010597]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23960337 0.21138902 0.5490076 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.02, 0.04, 0.3, 0.119, 0.145, 0.88, 0.031, 0.002, 0.43600000000000005, 0.08]
0.8769348333333333
1.9059530000000002
Reward 5.753861403396035
Current State [[0.02  0.04  0.3   0.119 0.145 0.88  0.031 0.002 0.436 0.08 ]]
Logits tf.Tensor([[-0.11983402 -0.23876977  0.65342027]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24662915 0.21897335 0.53439754]], shape=(1, 3), dtype=float32)
Selected action 2
[0.02, 0.15, 0.33, 0.118, 0.145, 0.79, 0.02, 0.005, 0.525, 0.04]
0.7860260000000001
4.808333833333333
Reward 16.40712700802667
Current State [[0.02  0.15  0.33  0.118 0.145 0.79  0.02  0.005 0.525 0.04 ]]
Logits tf.Tensor([[-0.12854068 -0.24753544  0.7088825 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23819628 0.21147363 0.55033004]], shape=(1, 3), dtype=float32)
Selected action 1
[0.05, 0.08, 0.34, 0.138, 0.145, 0.79, 0.02, 0.005, 0.525, 0.04]
0.7860260000000001
4.808333833333333
Reward 10.40712700802667
Current State [[0.05  0.08  0.34  0.138 0.145 0.79  0.02  0.005 0.525 0.04 ]]
Logits tf.Tensor([[-0.12954693 -0.2388962   0.69056135]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23997141 0.21511453 0.54491407]], shape=(1, 3), dtype=float32)
Selected action 2
[0.02, 0.15, 0.33, 0.13, 0.145, 0.8, 0.032, 0.002, 0.54, 0.07]
0.801144
1.888691166666667
Reward 17.573462243517838
Current State [[0.02  0.15  0.33  0.13  0.145 0.8   0.032 0.002 0.54  0.07 ]]
Logits tf.Tensor([[-0.1357718  -0.25620475  0.7211608 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23571232 0.20896758 0.5553201 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.04, 0.37, 0.12, 0.145, 0.83, 0.03, 0.005, 0.584, 0.11]
0.8298176666666667
4.8047621666666664
Reward 4.44438386635568
Current State [[0.05  0.04  0.37  0.12  0.145 0.83  0.03  0.005 0.584 0.11 ]]
Logits tf.Tensor([[-0.13834363 -0.25826687  0.7192903 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23559545 0.20897044 0.5554341 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.34, 0.154, 0.145, 0.83, 0.03, 0.005, 0.584, 0.11]
0.8298176666666667
4.8047621666666664
Reward 16.44438386635568
Current State [[0.03  0.15  0.34  0.154 0.145 0.83  0.03  0.005 0.584 0.11 ]]
Logits tf.Tensor([[-0.1420087 -0.2726328  0.75101  ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23147938 0.20313418 0.5653864 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.36, 0.136, 0.145, 0.75, 0.03, 0.003, 0.602, 0.14]
0.7510161666666667
3.2761903333333326
Reward 4.678663625301136
Current State [[0.04  0.04  0.36  0.136 0.145 0.75  0.03  0.003 0.602 0.14 ]]
Logits tf.Tensor([[-0.13698557 -0.24949984  0.6998138 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2379508  0.21262915 0.54942006]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.36, 0.126, 0.145, 0.75, 0.03, 0.006, 0.625, 0.13]
0.7469553333333333
5.680356500000001
Reward 16.280316218905845
Current State [[0.03  0.15  0.36  0.126 0.145 0.75  0.03  0.006 0.625 0.13 ]]
Logits tf.Tensor([[-0.14384161 -0.2734214   0.74066466]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23254447 0.20428206 0.5631735 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.02, 0.08, 0.36, 0.16, 0.145, 0.75, 0.03, 0.006, 0.625, 0.13]
0.7469553333333333
5.680356500000001
Reward 10.280316218905845
Current State [[0.02  0.08  0.36  0.16  0.145 0.75  0.03  0.006 0.625 0.13 ]]
Logits tf.Tensor([[-0.13821776 -0.2515462   0.7213874 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23501293 0.20983303 0.555154  ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.37, 0.151, 0.145, 0.85, 0.034, 0.002, 0.6900000000000001, 0.14]
0.8469425000000002
2.099999833333334
Reward 17.47092804349639
Current State [[0.04  0.15  0.37  0.151 0.145 0.85  0.034 0.002 0.69  0.14 ]]
Logits tf.Tensor([[-0.15867388 -0.2960988   0.8051928 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22254792 0.1939727  0.5834794 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.39, 0.137, 0.145, 0.76, 0.036, 0.005, 0.76, 0.17]
0.7564545
4.749404666666666
Reward 16.390285552871326
Current State [[0.04  0.15  0.39  0.137 0.145 0.76  0.036 0.005 0.76  0.17 ]]
Logits tf.Tensor([[-0.16364847 -0.30081335  0.8028497 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22219509 0.19371556 0.58408934]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.04, 0.4, 0.165, 0.145, 0.76, 0.036, 0.005, 0.76, 0.17]
0.7564545
4.749404666666666
Reward 4.390285552871325
Current State [[0.05  0.04  0.4   0.165 0.145 0.76  0.036 0.005 0.76  0.17 ]]
Logits tf.Tensor([[-0.15742512 -0.27644444  0.7724458 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22614342 0.20076801 0.5730886 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.03, 0.04, 0.38, 0.173, 0.145, 0.82, 0.034, 0.002, 0.722, 0.09]
0.8173
1.9023808333333332
Reward 5.600459617513406
Episode: 117 | Average Reward: 279 | Episode Reward: 251 | Loss: 437.088 | Steps: 19 | Worker: 0
Current State [[ 0.00964496 -0.00872545  0.00513924  0.00338324  0.00770692  0.00566891
   0.00345472  0.00277371  0.00208373 -0.00694225]]
Logits tf.Tensor([[-0.03621966 -0.03308553  0.06901618]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.32111886 0.32212687 0.35675424]], shape=(1, 3), dtype=float32)
Selected action 2
[0.02, 0.15, 0.31, 0.138, 0.145, 0.7, 0.02, 0.003, 0.8109999999999999, 0.08]
0.6962366666666667
2.8023803333333337
Reward 16.760769809056328
Current State [[0.02  0.15  0.31  0.138 0.145 0.7   0.02  0.003 0.811 0.08 ]]
Logits tf.Tensor([[-0.1636624  -0.27609652  0.79977614]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22151591 0.19795907 0.58052504]], shape=(1, 3), dtype=float32)
Selected action 1
[0.05, 0.08, 0.37, 0.132, 0.145, 0.81, 0.049, 0.002, 0.499, 0.08]
0.8099278333333333
2.0380955000000003
Reward 11.44219165090686
Current State [[0.05  0.08  0.37  0.132 0.145 0.81  0.049 0.002 0.499 0.08 ]]
Logits tf.Tensor([[-0.14281788 -0.25079322  0.7025769 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23659979 0.21238372 0.5510165 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.03, 0.04, 0.38, 0.152, 0.145, 0.81, 0.049, 0.002, 0.499, 0.08]
0.8099278333333333
2.0380955000000003
Reward 5.442191650906861
Current State [[0.03  0.04  0.38  0.152 0.145 0.81  0.049 0.002 0.499 0.08 ]]
Logits tf.Tensor([[-0.13745885 -0.23488851  0.69104564]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23826215 0.21614337 0.5455945 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.39, 0.144, 0.145, 0.8, 0.045, 0.003, 0.542, 0.2]
0.7979723333333334
2.5988096666666674
Reward 5.019282110774637
Current State [[0.04  0.04  0.39  0.144 0.145 0.8   0.045 0.003 0.542 0.2  ]]
Logits tf.Tensor([[-0.14138153 -0.2609309   0.7046932 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23709036 0.21037507 0.5525346 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.03, 0.04, 0.35, 0.129, 0.145, 0.77, 0.04, 0.001, 0.528, 0.17]
0.773444
1.4702379999999995
Reward 6.098354659404862
Current State [[0.03  0.04  0.35  0.129 0.145 0.77  0.04  0.001 0.528 0.17 ]]
Logits tf.Tensor([[-0.13651834 -0.24894139  0.6820237 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24033503 0.2147793  0.5448857 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.4, 0.152, 0.145, 0.77, 0.04, 0.001, 0.528, 0.17]
0.773444
1.4702379999999995
Reward 18.098354659404862
Current State [[0.05  0.15  0.4   0.152 0.145 0.77  0.04  0.001 0.528 0.17 ]]
Logits tf.Tensor([[-0.14527325 -0.27599472  0.7268921 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23421687 0.20551646 0.5602667 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.4, 0.136, 0.145, 0.84, 0.06, 0.002, 0.437, 0.16]
0.8351430000000001
2.2184525
Reward 17.341457547651213
Current State [[0.04  0.15  0.4   0.136 0.145 0.84  0.06  0.002 0.437 0.16 ]]
Logits tf.Tensor([[-0.1425378  -0.27511987  0.71565014]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23614348 0.2068218  0.55703473]], shape=(1, 3), dtype=float32)
Selected action 2
[0.02, 0.15, 0.37, 0.125, 0.145, 0.81, 0.036, 0.002, 0.52, 0.11]
0.807695
1.7458333333333336
Reward 17.76679914209224
Current State [[0.02  0.15  0.37  0.125 0.145 0.81  0.036 0.002 0.52  0.11 ]]
Logits tf.Tensor([[-0.13998702 -0.26398358  0.7296656 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2342214  0.20690718 0.5588714 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.39, 0.149, 0.145, 0.87, 0.047, 0.001, 0.49000000000000005, 0.1]
0.8739941666666666
1.395237833333333
Reward 18.65635717269079
Current State [[0.03  0.15  0.39  0.149 0.145 0.87  0.047 0.001 0.49  0.1  ]]
Logits tf.Tensor([[-0.1443515  -0.26881993  0.74431115]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23175824 0.20463467 0.5636071 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.02, 0.04, 0.39, 0.152, 0.145, 0.87, 0.047, 0.001, 0.49000000000000005, 0.1]
0.8739941666666666
1.395237833333333
Reward 6.6563571726907895
Current State [[0.02  0.04  0.39  0.152 0.145 0.87  0.047 0.001 0.49  0.1  ]]
Logits tf.Tensor([[-0.13647634 -0.24202749  0.7059758 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23686117 0.21313441 0.5500044 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.02, 0.15, 0.36, 0.138, 0.145, 0.85, 0.043, 0.002, 0.506, 0.09]
0.8472170000000001
1.6255945000000003
Reward 18.072200201416276
Current State [[0.02  0.15  0.36  0.138 0.145 0.85  0.043 0.002 0.506 0.09 ]]
Logits tf.Tensor([[-0.14243013 -0.2647333   0.73756033]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23278788 0.20598933 0.5612228 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.02, 0.15, 0.35, 0.143, 0.145, 0.81, 0.062, 0.002, 0.41900000000000004, 0.09]
0.8143388333333336
2.4815476666666667
Reward 17.115385290800862
Current State [[0.02  0.15  0.35  0.143 0.145 0.81  0.062 0.002 0.419 0.09 ]]
Logits tf.Tensor([[-0.13762462 -0.25140554  0.6906616 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2391289 0.2134114 0.5474597]], shape=(1, 3), dtype=float32)
Selected action 0
[0.03, 0.04, 0.4, 0.156, 0.145, 0.81, 0.062, 0.002, 0.41900000000000004, 0.09]
0.8143388333333336
2.4815476666666667
Reward 5.115385290800863
Current State [[0.03  0.04  0.4   0.156 0.145 0.81  0.062 0.002 0.419 0.09 ]]
Logits tf.Tensor([[-0.13220824 -0.22715753  0.6627288 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24249946 0.22053362 0.5369669 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.4, 0.163, 0.145, 0.84, 0.032, 0.001, 0.484, 0.16]
0.8434015
1.3410716666666667
Reward 6.670731323519351
Current State [[0.04  0.04  0.4   0.163 0.145 0.84  0.032 0.001 0.484 0.16 ]]
Logits tf.Tensor([[-0.13194303 -0.24683726  0.69495857]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23936705 0.21338624 0.5472467 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.39, 0.133, 0.145, 0.84, 0.043, 0.002, 0.508, 0.19]
0.8426026666666667
1.9940473333333333
Reward 17.565442510797183
Current State [[0.05  0.15  0.39  0.133 0.145 0.84  0.043 0.002 0.508 0.19 ]]
Logits tf.Tensor([[-0.14576958 -0.289186    0.74021643]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23300421 0.20187326 0.56512254]], shape=(1, 3), dtype=float32)
Selected action 0
[0.03, 0.04, 0.38, 0.167, 0.145, 0.84, 0.043, 0.002, 0.508, 0.19]
0.8426026666666667
1.9940473333333333
Reward 5.565442510797182
Current State [[0.03  0.04  0.38  0.167 0.145 0.84  0.043 0.002 0.508 0.19 ]]
Logits tf.Tensor([[-0.13693336 -0.25353414  0.70205647]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23787047 0.21169053 0.550439  ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.03, 0.08, 0.35, 0.126, 0.145, 0.86, 0.036, 0.004, 0.499, 0.13]
0.8617131666666666
3.611309666666666
Reward 10.718597214200777
Current State [[0.03  0.08  0.35  0.126 0.145 0.86  0.036 0.004 0.499 0.13 ]]
Logits tf.Tensor([[-0.13648091 -0.26014     0.710054  ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2372347  0.20963982 0.5531255 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.02, 0.04, 0.38, 0.146, 0.145, 0.85, 0.032, 0.002, 0.548, 0.14]
0.8502386666666667
2.2089288333333332
Reward 5.381938783574
Current State [[0.02  0.04  0.38  0.146 0.145 0.85  0.032 0.002 0.548 0.14 ]]
Logits tf.Tensor([[-0.13683838 -0.25147825  0.72010267]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2354254  0.20992582 0.55464876]], shape=(1, 3), dtype=float32)
Selected action 1
[0.04, 0.08, 0.4, 0.145, 0.145, 0.74, 0.03, 0.004, 0.5780000000000001, 0.1]
0.7381565000000001
3.6244044999999994
Reward 10.571338509138837
Current State [[0.04  0.08  0.4   0.145 0.145 0.74  0.03  0.004 0.578 0.1  ]]
Logits tf.Tensor([[-0.14091213 -0.2467314   0.7124557 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2354533  0.21181078 0.5527359 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.03, 0.08, 0.38, 0.118, 0.145, 0.74, 0.03, 0.004, 0.5780000000000001, 0.1]
0.7381565000000001
3.6244044999999994
Reward 10.571338509138837
Episode: 118 | Average Reward: 278 | Episode Reward: 230 | Loss: 400.459 | Steps: 19 | Worker: 0
Current State [[ 0.00647087  0.00610015 -0.00398377 -0.00341775 -0.00925856  0.00835436
  -0.00976527 -0.00604549  0.00344487 -0.00657216]]
Logits tf.Tensor([[-0.03783548 -0.03064336  0.06728052]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.32071248 0.3230274  0.3562601 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.4, 0.15, 0.145, 0.81, 0.035, 0.001, 0.5559999999999999, 0.13]
0.8136926666666667
1.0999996666666665
Reward 19.337768960292273
Current State [[0.05  0.15  0.4   0.15  0.145 0.81  0.035 0.001 0.556 0.13 ]]
Logits tf.Tensor([[-0.15096596 -0.27795583  0.7544637 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22968775 0.2022958  0.56801647]], shape=(1, 3), dtype=float32)
Selected action 2
[0.02, 0.15, 0.37, 0.142, 0.145, 0.86, 0.04, 0.003, 0.542, 0.24]
0.8644996666666669
2.655357666666667
Reward 17.103506096348365
Current State [[0.02  0.15  0.37  0.142 0.145 0.86  0.04  0.003 0.542 0.24 ]]
Logits tf.Tensor([[-0.14628336 -0.2966742   0.75901276]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23078509 0.19856094 0.570654  ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.39, 0.149, 0.145, 0.86, 0.04, 0.003, 0.542, 0.24]
0.8644996666666669
2.655357666666667
Reward 17.103506096348365
Current State [[0.05  0.15  0.39  0.149 0.145 0.86  0.04  0.003 0.542 0.24 ]]
Logits tf.Tensor([[-0.1502968  -0.30337244  0.7633451 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2298084  0.19719046 0.57300115]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.04, 0.41, 0.135, 0.145, 0.81, 0.037, 0.002, 0.549, 0.14]
0.8116861666666666
2.2607144999999997
Reward 5.258948579835875
Current State [[0.05  0.04  0.41  0.135 0.145 0.81  0.037 0.002 0.549 0.14 ]]
Logits tf.Tensor([[-0.1437362  -0.25731328  0.71782315]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23477024 0.20956422 0.55566555]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.37, 0.119, 0.145, 0.73, 0.034, 0.004, 0.564, 0.18]
0.725726
4.339880333333334
Reward 16.422224304369074
Current State [[0.03  0.15  0.37  0.119 0.145 0.73  0.034 0.004 0.564 0.18 ]]
Logits tf.Tensor([[-0.14478925 -0.27628496  0.7217271 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23499592 0.20604043 0.55896366]], shape=(1, 3), dtype=float32)
Selected action 1
[0.05, 0.08, 0.38, 0.156, 0.145, 0.73, 0.034, 0.004, 0.564, 0.18]
0.725726
4.339880333333334
Reward 10.422224304369076
Current State [[0.05  0.08  0.38  0.156 0.145 0.73  0.034 0.004 0.564 0.18 ]]
Logits tf.Tensor([[-0.14357132 -0.26214123  0.70492375]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2367246  0.21025635 0.55301905]], shape=(1, 3), dtype=float32)
Selected action 2
[0.02, 0.15, 0.39, 0.143, 0.145, 0.83, 0.033, 0.001, 0.491, 0.11]
0.8314033333333334
1.1142856666666665
Reward 19.377994850243997
Current State [[0.02  0.15  0.39  0.143 0.145 0.83  0.033 0.001 0.491 0.11 ]]
Logits tf.Tensor([[-0.13829069 -0.2620115   0.7319695 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23412852 0.20688216 0.55898935]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.35, 0.127, 0.145, 0.77, 0.019, 0.006, 0.521, 0.09]
0.7742053333333333
6.495237666666667
Reward 16.232411826943093
Current State [[0.04  0.15  0.35  0.127 0.145 0.77  0.019 0.006 0.521 0.09 ]]
Logits tf.Tensor([[-0.13666841 -0.25923964  0.7145917 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.236561   0.20927201 0.55416703]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.37, 0.162, 0.145, 0.77, 0.019, 0.006, 0.521, 0.09]
0.7742053333333333
6.495237666666667
Reward 16.232411826943093
Current State [[0.04  0.15  0.37  0.162 0.145 0.77  0.019 0.006 0.521 0.09 ]]
Logits tf.Tensor([[-0.1368795  -0.25533873  0.71993077]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23563105 0.20930824 0.5550607 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.05, 0.08, 0.37, 0.152, 0.145, 0.91, 0.04, 0.002, 0.48, 0.13]
0.9111680000000001
2.4017856666666666
Reward 11.35539537324511
Current State [[0.05  0.08  0.37  0.152 0.145 0.91  0.04  0.002 0.48  0.13 ]]
Logits tf.Tensor([[-0.1426226  -0.26734275  0.72636837]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2343431  0.20686492 0.55879194]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.15, 0.38, 0.136, 0.145, 0.7, 0.018, 0.009, 0.976, 0.08]
0.6964918333333333
8.572023
Reward 16.087708768522287
Current State [[0.06  0.15  0.38  0.136 0.145 0.7   0.018 0.009 0.976 0.08 ]]
Logits tf.Tensor([[-0.18682735 -0.2972735   0.8919278 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.20676321 0.18514293 0.6080939 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.04, 0.37, 0.152, 0.145, 0.7, 0.018, 0.009, 0.976, 0.08]
0.6964918333333333
8.572023
Reward 4.087708768522286
Current State [[0.05  0.04  0.37  0.152 0.145 0.7   0.018 0.009 0.976 0.08 ]]
Logits tf.Tensor([[-0.18331479 -0.277691    0.8667352 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.20974322 0.19085382 0.5994029 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.01, 0.04, 0.36, 0.153, 0.145, 0.79, 0.019, 0.003, 0.693, 0.08]
0.7908256666666666
3.289284833333333
Reward 4.726336120206681
Current State [[0.01  0.04  0.36  0.153 0.145 0.79  0.019 0.003 0.693 0.08 ]]
Logits tf.Tensor([[-0.1475885  -0.24668905  0.757932  ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2283694  0.20682313 0.5648075 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.15, 0.36, 0.143, 0.145, 0.79, 0.024, 0.005, 0.602, 0.07]
0.7857164999999999
4.573809333333333
Reward 16.44065456863034
Current State [[0.06  0.15  0.36  0.143 0.145 0.79  0.024 0.005 0.602 0.07 ]]
Logits tf.Tensor([[-0.15222514 -0.27194193  0.75798255]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22872776 0.20292076 0.5683515 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.32, 0.116, 0.145, 0.84, 0.035, 0.002, 0.506, 0.13]
0.8363968333333334
2.2351189999999996
Reward 5.3307511956560845
Current State [[0.04  0.04  0.32  0.116 0.145 0.84  0.035 0.002 0.506 0.13 ]]
Logits tf.Tensor([[-0.13827816 -0.25429416  0.68966466]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23928787 0.21307652 0.5476356 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.02, 0.15, 0.28, 0.108, 0.145, 0.84, 0.035, 0.002, 0.506, 0.13]
0.8363968333333334
2.2351189999999996
Reward 17.330751195656084
Current State [[0.02  0.15  0.28  0.108 0.145 0.84  0.035 0.002 0.506 0.13 ]]
Logits tf.Tensor([[-0.14231257 -0.27633247  0.72067446]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2355822  0.20603377 0.55838406]], shape=(1, 3), dtype=float32)
Selected action 1
[0.07, 0.08, 0.33, 0.18, 0.145, 0.87, 0.027, 0.002, 0.5549999999999999, 0.11]
0.8678761666666666
2.110713833333333
Reward 11.50939421710921
Current State [[0.07  0.08  0.33  0.18  0.145 0.87  0.027 0.002 0.555 0.11 ]]
Logits tf.Tensor([[-0.14925142 -0.26724616  0.73958135]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23142847 0.20567064 0.5629009 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.33, 0.118, 0.145, 0.91, 0.032, 0.001, 0.479, 0.04]
0.9098301666666665
0.668453
Reward 24.126102328942068
Current State [[0.05  0.15  0.33  0.118 0.145 0.91  0.032 0.001 0.479 0.04 ]]
Logits tf.Tensor([[-0.14571111 -0.27400163  0.7403695 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23227715 0.20431046 0.5634124 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.15, 0.34, 0.183, 0.145, 0.91, 0.032, 0.001, 0.479, 0.04]
0.9098301666666665
0.668453
Reward 24.126102328942068
Current State [[0.08  0.15  0.34  0.183 0.145 0.91  0.032 0.001 0.479 0.04 ]]
Logits tf.Tensor([[-0.14997563 -0.27143934  0.7470409 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23052634 0.20415947 0.5653142 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.15, 0.34, 0.165, 0.145, 0.91, 0.034, 0.001, 0.507, 0.12]
0.9145076666666667
0.8392856666666667
Reward 21.80875539012031
Episode: 119 | Average Reward: 278 | Episode Reward: 294 | Loss: 674.343 | Steps: 19 | Worker: 0
Current State [[ 0.00172084  0.00277388  0.0005565   0.00920477 -0.00634892 -0.00044972
  -0.0028412   0.00683756 -0.0022301   0.00877181]]
Logits tf.Tensor([[-0.03573451 -0.03242237  0.0625466 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3218963  0.32296425 0.35513946]], shape=(1, 3), dtype=float32)
Selected action 1
[0.04, 0.08, 0.33, 0.15, 0.145, 0.85, 0.025, 0.002, 0.457, 0.1]
0.8534153333333333
2.225000333333333
Reward 11.375446451248273
Current State [[0.04  0.08  0.33  0.15  0.145 0.85  0.025 0.002 0.457 0.1  ]]
Logits tf.Tensor([[-0.1331531  -0.25046837  0.6931785 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23956537 0.21304661 0.54738796]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.34, 0.143, 0.145, 0.85, 0.025, 0.002, 0.457, 0.1]
0.8534153333333333
2.225000333333333
Reward 17.375446451248273
Current State [[0.04  0.15  0.34  0.143 0.145 0.85  0.025 0.002 0.457 0.1  ]]
Logits tf.Tensor([[-0.13749254 -0.2661451   0.7212586 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2358774  0.20740214 0.5567205 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.32, 0.122, 0.145, 0.75, 0.029, 0.002, 0.5690000000000001, 0.15]
0.7530926666666667
1.6273811666666664
Reward 17.76742163102874
Current State [[0.03  0.15  0.32  0.122 0.145 0.75  0.029 0.002 0.569 0.15 ]]
Logits tf.Tensor([[-0.14725019 -0.2748251   0.7285664 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23358688 0.20560957 0.56080353]], shape=(1, 3), dtype=float32)
Selected action 1
[0.04, 0.08, 0.34, 0.122, 0.145, 0.89, 0.037, 0.002, 0.51, 0.12]
0.8938094999999998
1.5577383333333334
Reward 12.35851502800241
Current State [[0.04  0.08  0.34  0.122 0.145 0.89  0.037 0.002 0.51  0.12 ]]
Logits tf.Tensor([[-0.14573283 -0.27103668  0.7299982 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23348893 0.20599066 0.5605204 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.02, 0.08, 0.33, 0.174, 0.145, 0.89, 0.037, 0.002, 0.51, 0.12]
0.8938094999999998
1.5577383333333334
Reward 12.35851502800241
Current State [[0.02  0.08  0.33  0.174 0.145 0.89  0.037 0.002 0.51  0.12 ]]
Logits tf.Tensor([[-0.1424104  -0.25997657  0.7295365 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23360972 0.20769812 0.5586922 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.02, 0.08, 0.34, 0.131, 0.145, 0.92, 0.04, 0.001, 0.489, 0.11]
0.9190741666666667
1.3190469999999999
Reward 13.072924923095435
Current State [[0.02  0.08  0.34  0.131 0.145 0.92  0.04  0.001 0.489 0.11 ]]
Logits tf.Tensor([[-0.14256337 -0.26645023  0.729342  ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23392124 0.2066647  0.559414  ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.35, 0.129, 0.145, 0.9, 0.034, 0.001, 0.506, 0.12]
0.9048499999999999
1.1702378333333334
Reward 19.549988723340793
Current State [[0.05  0.15  0.35  0.129 0.145 0.9   0.034 0.001 0.506 0.12 ]]
Logits tf.Tensor([[-0.15015782 -0.28805923  0.75974756]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22960678 0.2000299  0.5703633 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.33, 0.152, 0.145, 0.9, 0.034, 0.001, 0.506, 0.12]
0.9048499999999999
1.1702378333333334
Reward 19.549988723340793
Current State [[0.03  0.15  0.33  0.152 0.145 0.9   0.034 0.001 0.506 0.12 ]]
Logits tf.Tensor([[-0.1474494  -0.28048778  0.7560485 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23022096 0.2015427  0.56823635]], shape=(1, 3), dtype=float32)
Selected action 1
[0.02, 0.08, 0.32, 0.128, 0.145, 0.86, 0.026, 0.001, 0.5309999999999999, 0.15]
0.8649113333333333
1.2803570000000002
Reward 12.944880174971658
Current State [[0.02  0.08  0.32  0.128 0.145 0.86  0.026 0.001 0.531 0.15 ]]
Logits tf.Tensor([[-0.14016925 -0.26642877  0.72512466]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23490222 0.20703955 0.5580582 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.34, 0.12, 0.145, 0.86, 0.027, 0.003, 0.501, 0.1]
0.8560580000000001
2.8761901666666665
Reward 16.97692050642393
Current State [[0.04  0.15  0.34  0.12  0.145 0.86  0.027 0.003 0.501 0.1  ]]
Logits tf.Tensor([[-0.14338605 -0.276143    0.7410714 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23270164 0.2037717  0.56352663]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.15, 0.37, 0.126, 0.145, 0.91, 0.039, 0.002, 0.524, 0.12]
0.906966
2.111309833333333
Reward 17.600238245332953
Current State [[0.08  0.15  0.37  0.126 0.145 0.91  0.039 0.002 0.524 0.12 ]]
Logits tf.Tensor([[-0.15852612 -0.29992837  0.7757241 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22658041 0.19670352 0.57671607]], shape=(1, 3), dtype=float32)
Selected action 1
[0.07, 0.08, 0.36, 0.153, 0.145, 0.91, 0.039, 0.002, 0.524, 0.12]
0.906966
2.111309833333333
Reward 11.600238245332951
Current State [[0.07  0.08  0.36  0.153 0.145 0.91  0.039 0.002 0.524 0.12 ]]
Logits tf.Tensor([[-0.15318893 -0.2782222   0.7489856 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23002124 0.20298627 0.5669925 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.05, 0.08, 0.35, 0.144, 0.145, 0.78, 0.04, 0.006, 0.497, 0.14]
0.779052
5.637500666666666
Reward 10.30658490059597
Current State [[0.05  0.08  0.35  0.144 0.145 0.78  0.04  0.006 0.497 0.14 ]]
Logits tf.Tensor([[-0.14124832 -0.2575892   0.694645  ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23826286 0.21209486 0.5496423 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.04, 0.37, 0.142, 0.145, 0.82, 0.033, 0.002, 0.6599999999999999, 0.14]
0.8203128333333332
2.4964291666666663
Reward 5.117391593662226
Current State [[0.05  0.04  0.37  0.142 0.145 0.82  0.033 0.002 0.66  0.14 ]]
Logits tf.Tensor([[-0.15829329 -0.27343208  0.7644127 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22689463 0.20221813 0.57088727]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.33, 0.138, 0.145, 0.82, 0.033, 0.002, 0.6599999999999999, 0.14]
0.8203128333333332
2.4964291666666663
Reward 17.117391593662227
Current State [[0.03  0.15  0.33  0.138 0.145 0.82  0.033 0.002 0.66  0.14 ]]
Logits tf.Tensor([[-0.16188459 -0.2921927   0.79202765]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22353011 0.19622028 0.5802496 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.37, 0.144, 0.145, 0.7, 0.019, 0.002, 0.724, 0.09]
0.6975055
2.4089283333333333
Reward 16.940800197333502
Current State [[0.04  0.15  0.37  0.144 0.145 0.7   0.019 0.002 0.724 0.09 ]]
Logits tf.Tensor([[-0.16173795 -0.27360845  0.7811258 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22414072 0.20041767 0.5754416 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.15, 0.4, 0.127, 0.145, 0.79, 0.034, 0.004, 0.726, 0.14]
0.7866893333333332
3.8249999999999997
Reward 16.579683616309755
Current State [[0.06  0.15  0.4   0.127 0.145 0.79  0.034 0.004 0.726 0.14 ]]
Logits tf.Tensor([[-0.17306192 -0.30572093  0.8176577 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.21886937 0.19167784 0.5894528 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.15, 0.4, 0.159, 0.145, 0.79, 0.037, 0.003, 0.716, 0.18]
0.7907638333333331
3.341071833333334
Reward 16.71033293614135
Current State [[0.07  0.15  0.4   0.159 0.145 0.79  0.037 0.003 0.716 0.18 ]]
Logits tf.Tensor([[-0.17460822 -0.31170338  0.8166906 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.21898037 0.1909262  0.59009343]], shape=(1, 3), dtype=float32)
Selected action 0
[0.03, 0.04, 0.38, 0.162, 0.145, 0.79, 0.037, 0.003, 0.716, 0.18]
0.7907638333333331
3.341071833333334
Reward 4.710332936141349
Current State [[0.03  0.04  0.38  0.162 0.145 0.79  0.037 0.003 0.716 0.18 ]]
Logits tf.Tensor([[-0.16135843 -0.2766173   0.7785683 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22467217 0.20021334 0.5751145 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.02, 0.15, 0.36, 0.128, 0.145, 0.69, 0.029, 0.003, 0.7889999999999999, 0.13]
0.6941305
2.772024333333334
Reward 16.769222973308295
Episode: 120 | Average Reward: 278 | Episode Reward: 286 | Loss: 624.334 | Steps: 19 | Worker: 0
Current State [[ 1.26135307e-03  1.12278922e-03  3.11540166e-03 -6.86128333e-03
  -3.92196195e-03  5.71824229e-03  8.56650018e-03  9.03165814e-03
   1.79483422e-03 -6.45430972e-05]]
Logits tf.Tensor([[-0.04007214 -0.03523378  0.0705431 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.32032648 0.32188004 0.35779345]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.33, 0.114, 0.145, 0.77, 0.022, 0.006, 0.6900000000000001, 0.08]
0.7651193333333334
5.652976333333334
Reward 16.29540910293993
Current State [[0.03  0.15  0.33  0.114 0.145 0.77  0.022 0.006 0.69  0.08 ]]
Logits tf.Tensor([[-0.16287674 -0.2789559   0.786855  ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22344269 0.1989544  0.5776029 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.41, 0.142, 0.145, 0.77, 0.022, 0.006, 0.6900000000000001, 0.08]
0.7651193333333334
5.652976333333334
Reward 4.295409102939931
Current State [[0.04  0.04  0.41  0.142 0.145 0.77  0.022 0.006 0.69  0.08 ]]
Logits tf.Tensor([[-0.15749429 -0.25388274  0.7668932 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22581339 0.20506369 0.5691229 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.39, 0.154, 0.145, 0.79, 0.073, 0.003, 0.413, 0.19]
0.7939204999999999
2.897023666666667
Reward 16.87219927066943
Current State [[0.03  0.15  0.39  0.154 0.145 0.79  0.073 0.003 0.413 0.19 ]]
Logits tf.Tensor([[-0.14783232 -0.2722468   0.70334566]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23666295 0.20897664 0.5543604 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.4, 0.115, 0.145, 0.88, 0.04, 0.002, 0.487, 0.09]
0.8828138333333334
1.550594833333333
Reward 18.333870780130912
Current State [[0.04  0.15  0.4   0.115 0.145 0.88  0.04  0.002 0.487 0.09 ]]
Logits tf.Tensor([[-0.1514606 -0.2760678  0.7575729]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22910734 0.20226596 0.56862664]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.43, 0.175, 0.145, 0.88, 0.04, 0.002, 0.487, 0.09]
0.8828138333333334
1.550594833333333
Reward 6.333870780130911
Current State [[0.04  0.04  0.43  0.175 0.145 0.88  0.04  0.002 0.487 0.09 ]]
Logits tf.Tensor([[-0.14495896 -0.24473853  0.7295419 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2324114  0.21034089 0.55724776]], shape=(1, 3), dtype=float32)
Selected action 1
[0.03, 0.08, 0.39, 0.152, 0.145, 0.82, 0.055, 0.003, 0.449, 0.14]
0.8155231666666666
3.4196421666666668
Reward 10.718028371990453
Current State [[0.03  0.08  0.39  0.152 0.145 0.82  0.055 0.003 0.449 0.14 ]]
Logits tf.Tensor([[-0.14435661 -0.25212374  0.70119834]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23656844 0.21239981 0.55103177]], shape=(1, 3), dtype=float32)
Selected action 1
[0.03, 0.08, 0.4, 0.131, 0.145, 0.81, 0.037, 0.002, 0.545, 0.16]
0.8140981666666668
1.9863093333333335
Reward 11.502916982288939
Current State [[0.03  0.08  0.4   0.131 0.145 0.81  0.037 0.002 0.545 0.16 ]]
Logits tf.Tensor([[-0.14938875 -0.26590657  0.73564845]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23185241 0.20635195 0.56179565]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.38, 0.163, 0.145, 0.81, 0.037, 0.002, 0.545, 0.16]
0.8140981666666668
1.9863093333333335
Reward 17.502916982288937
Current State [[0.03  0.15  0.38  0.163 0.145 0.81  0.037 0.002 0.545 0.16 ]]
Logits tf.Tensor([[-0.15417562 -0.2777799   0.7568486 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22880165 0.20219874 0.5689995 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.41, 0.175, 0.145, 0.86, 0.04, 0.002, 0.514, 0.1]
0.8552068333333335
1.525596
Reward 6.285537065773397
Current State [[0.04  0.04  0.41  0.175 0.145 0.86  0.04  0.002 0.514 0.1  ]]
Logits tf.Tensor([[-0.14764066 -0.2473256   0.7308801 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2318863  0.20988551 0.5582282 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.03, 0.04, 0.39, 0.135, 0.145, 0.84, 0.04, 0.002, 0.49000000000000005, 0.15]
0.8424051666666666
2.2017854999999997
Reward 5.370859464009283
Current State [[0.03  0.04  0.39  0.135 0.145 0.84  0.04  0.002 0.49  0.15 ]]
Logits tf.Tensor([[-0.14235286 -0.252157    0.7080047 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23604427 0.21149795 0.55245775]], shape=(1, 3), dtype=float32)
Selected action 2
[0.02, 0.15, 0.34, 0.173, 0.145, 0.84, 0.04, 0.002, 0.49000000000000005, 0.15]
0.8424051666666666
2.2017854999999997
Reward 17.370859464009282
Current State [[0.02  0.15  0.34  0.173 0.145 0.84  0.04  0.002 0.49  0.15 ]]
Logits tf.Tensor([[-0.14833231 -0.27033705  0.73866695]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23185837 0.2052281  0.5629135 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.04, 0.38, 0.157, 0.145, 0.77, 0.07, 0.001, 0.40599999999999997, 0.12]
0.7674761666666666
0.9714281666666669
Reward 7.658505673041256
Current State [[0.05  0.04  0.38  0.157 0.145 0.77  0.07  0.001 0.406 0.12 ]]
Logits tf.Tensor([[-0.14364485 -0.23322645  0.65541494]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24167648 0.22096811 0.5373554 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.03, 0.04, 0.38, 0.143, 0.145, 0.9, 0.035, 0.001, 0.45599999999999996, 0.08]
0.8954255
1.0904761666666667
Reward 7.8622749202009095
Current State [[0.03  0.04  0.38  0.143 0.145 0.9   0.035 0.001 0.456 0.08 ]]
Logits tf.Tensor([[-0.13939905 -0.24464111  0.708328  ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23615865 0.21256796 0.5512734 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.36, 0.161, 0.145, 0.9, 0.035, 0.001, 0.45599999999999996, 0.08]
0.8954255
1.0904761666666667
Reward 19.86227492020091
Current State [[0.03  0.15  0.36  0.161 0.145 0.9   0.035 0.001 0.456 0.08 ]]
Logits tf.Tensor([[-0.14647138 -0.26616222  0.7461258 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23101853 0.20495841 0.5640231 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.02, 0.15, 0.37, 0.148, 0.145, 0.87, 0.045, 0.001, 0.507, 0.13]
0.8740533333333335
1.0910716666666667
Reward 19.730424270710614
Current State [[0.02  0.15  0.37  0.148 0.145 0.87  0.045 0.001 0.507 0.13 ]]
Logits tf.Tensor([[-0.15318021 -0.27686965  0.7601247 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22850871 0.20192268 0.5695686 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.38, 0.132, 0.145, 0.78, 0.025, 0.003, 0.643, 0.12]
0.7763258333333334
2.8142854999999996
Reward 16.880141921498478
Current State [[0.05  0.15  0.38  0.132 0.145 0.78  0.025 0.003 0.643 0.12 ]]
Logits tf.Tensor([[-0.1630341  -0.28534386  0.7820247 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22432396 0.19849849 0.5771776 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.38, 0.167, 0.145, 0.78, 0.025, 0.003, 0.643, 0.12]
0.7763258333333334
2.8142854999999996
Reward 16.880141921498478
Current State [[0.05  0.15  0.38  0.167 0.145 0.78  0.025 0.003 0.643 0.12 ]]
Logits tf.Tensor([[-0.16334999 -0.2814564   0.78467405]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22375333 0.19882756 0.5774191 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.15, 0.39, 0.152, 0.145, 0.86, 0.038, 0.002, 0.502, 0.19]
0.8582413333333333
1.8035718333333333
Reward 17.834561035815387
Current State [[0.06  0.15  0.39  0.152 0.145 0.86  0.038 0.002 0.502 0.19 ]]
Logits tf.Tensor([[-0.15462251 -0.29290646  0.75832486]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22922601 0.19962175 0.5711522 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.15, 0.4, 0.14, 0.145, 0.79, 0.03, 0.003, 0.5549999999999999, 0.11]
0.7853475
2.8190481666666667
Reward 16.89219617256792
Current State [[0.06  0.15  0.4   0.14  0.145 0.79  0.03  0.003 0.555 0.11 ]]
Logits tf.Tensor([[-0.15605542 -0.2764001   0.7550601 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22863884 0.20271458 0.5686466 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.04, 0.08, 0.39, 0.167, 0.145, 0.79, 0.03, 0.003, 0.5549999999999999, 0.11]
0.7853475
2.8190481666666667
Reward 10.89219617256792
Episode: 121 | Average Reward: 278 | Episode Reward: 265 | Loss: 585.441 | Steps: 19 | Worker: 0
Current State [[ 0.00065928  0.00038412 -0.00648258 -0.00585132  0.00175616  0.00348241
   0.00313828  0.00152556  0.00491374  0.00718728]]
Logits tf.Tensor([[-0.04160244 -0.03390427  0.07242799]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.31964058 0.3221107  0.35824874]], shape=(1, 3), dtype=float32)
Selected action 0
[0.06, 0.04, 0.39, 0.183, 0.145, 0.82, 0.036, 0.001, 0.519, 0.08]
0.8175166666666666
0.8547615
Reward 8.800820660136703
Current State [[0.06  0.04  0.39  0.183 0.145 0.82  0.036 0.001 0.519 0.08 ]]
Logits tf.Tensor([[-0.15130697 -0.2432149   0.7211584 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23228848 0.21189103 0.5558205 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.36, 0.148, 0.145, 0.82, 0.036, 0.001, 0.519, 0.08]
0.8175166666666666
0.8547615
Reward 20.8008206601367
Current State [[0.03  0.15  0.36  0.148 0.145 0.82  0.036 0.001 0.519 0.08 ]]
Logits tf.Tensor([[-0.15326564 -0.263764    0.74901146]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22932635 0.20533602 0.56533766]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.4, 0.194, 0.145, 0.79, 0.035, 0.003, 0.591, 0.18]
0.7942506666666669
3.321428333333333
Reward 16.72079461019572
Current State [[0.05  0.15  0.4   0.194 0.145 0.79  0.035 0.003 0.591 0.18 ]]
Logits tf.Tensor([[-0.16371733 -0.28680173  0.7771802 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22489755 0.19885196 0.57625055]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.39, 0.186, 0.145, 0.79, 0.035, 0.003, 0.591, 0.18]
0.7942506666666669
3.321428333333333
Reward 16.72079461019572
Current State [[0.05  0.15  0.39  0.186 0.145 0.79  0.035 0.003 0.591 0.18 ]]
Logits tf.Tensor([[-0.16389963 -0.28770506  0.775188  ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22516446 0.19894443 0.57589114]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.38, 0.164, 0.145, 0.86, 0.045, 0.001, 0.5349999999999999, 0.19]
0.8573713333333334
0.867262
Reward 21.03653717448936
Current State [[0.03  0.15  0.38  0.164 0.145 0.86  0.045 0.001 0.535 0.19 ]]
Logits tf.Tensor([[-0.16067082 -0.29050794  0.7750847 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22586738 0.19836539 0.5757672 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.36, 0.208, 0.145, 0.86, 0.045, 0.001, 0.5349999999999999, 0.19]
0.8573713333333334
0.867262
Reward 21.03653717448936
Current State [[0.03  0.15  0.36  0.208 0.145 0.86  0.045 0.001 0.535 0.19 ]]
Logits tf.Tensor([[-0.16098174 -0.2843157   0.7735136 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22573893 0.19954602 0.5747151 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.02, 0.15, 0.36, 0.176, 0.145, 0.86, 0.054, 0.002, 0.496, 0.22]
0.855275
2.046428833333333
Reward 17.54261526082886
Current State [[0.02  0.15  0.36  0.176 0.145 0.86  0.054 0.002 0.496 0.22 ]]
Logits tf.Tensor([[-0.1567532  -0.2871921   0.75612944]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22887464 0.20088555 0.57023984]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.04, 0.36, 0.128, 0.145, 0.76, 0.019, 0.007, 0.5589999999999999, 0.08]
0.7591931666666666
7.305951833333333
Reward 4.173583597737232
Current State [[0.05  0.04  0.36  0.128 0.145 0.76  0.019 0.007 0.559 0.08 ]]
Logits tf.Tensor([[-0.14424574 -0.24237786  0.70542413]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23554884 0.2135319  0.55091923]], shape=(1, 3), dtype=float32)
Selected action 1
[0.02, 0.08, 0.35, 0.198, 0.145, 0.76, 0.019, 0.007, 0.5589999999999999, 0.08]
0.7591931666666666
7.305951833333333
Reward 10.173583597737231
Current State [[0.02  0.08  0.35  0.198 0.145 0.76  0.019 0.007 0.559 0.08 ]]
Logits tf.Tensor([[-0.14276269 -0.23587674  0.72019976]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23357601 0.21280868 0.5536153 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.02, 0.08, 0.36, 0.131, 0.145, 0.88, 0.043, 0.003, 0.479, 0.18]
0.8814593333333334
2.5214290000000004
Reward 11.214632795125834
Current State [[0.02  0.08  0.36  0.131 0.145 0.88  0.043 0.003 0.479 0.18 ]]
Logits tf.Tensor([[-0.14695138 -0.26897126  0.7272594 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23352954 0.20670417 0.5597663 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.37, 0.186, 0.145, 0.88, 0.043, 0.003, 0.479, 0.18]
0.8814593333333334
2.5214290000000004
Reward 17.214632795125834
Current State [[0.04  0.15  0.37  0.186 0.145 0.88  0.043 0.003 0.479 0.18 ]]
Logits tf.Tensor([[-0.15444158 -0.2827854   0.7566481 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22901206 0.20142777 0.5695601 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.15, 0.4, 0.204, 0.145, 0.72, 0.022, 0.006, 0.89, 0.18]
0.7243393333333334
6.035715000000001
Reward 16.235562671075055
Current State [[0.07  0.15  0.4   0.204 0.145 0.72  0.022 0.006 0.89  0.18 ]]
Logits tf.Tensor([[-0.1853436  -0.31958354  0.8757439 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.20991242 0.18354325 0.6065444 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.04, 0.08, 0.37, 0.19, 0.145, 0.72, 0.022, 0.006, 0.89, 0.18]
0.7243393333333334
6.035715000000001
Reward 10.235562671075055
Current State [[0.04  0.08  0.37  0.19  0.145 0.72  0.022 0.006 0.89  0.18 ]]
Logits tf.Tensor([[-0.17712304 -0.3019479   0.84733886]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.21421316 0.18907556 0.5967113 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.02, 0.15, 0.31, 0.166, 0.145, 0.83, 0.035, 0.002, 0.558, 0.1]
0.8308033333333334
1.5142865
Reward 18.22027564645904
Current State [[0.02  0.15  0.31  0.166 0.145 0.83  0.035 0.002 0.558 0.1  ]]
Logits tf.Tensor([[-0.15681927 -0.27008802  0.76087856]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22745721 0.203099   0.56944376]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.35, 0.224, 0.145, 0.83, 0.035, 0.002, 0.558, 0.1]
0.8308033333333334
1.5142865
Reward 18.22027564645904
Current State [[0.05  0.15  0.35  0.224 0.145 0.83  0.035 0.002 0.558 0.1  ]]
Logits tf.Tensor([[-0.16188157 -0.27072743  0.77272177]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22506951 0.2018578  0.57307273]], shape=(1, 3), dtype=float32)
Selected action 2
[0.01, 0.15, 0.31, 0.206, 0.145, 0.84, 0.033, 0.001, 0.529, 0.12]
0.8424569999999999
0.9494054999999999
Reward 20.311065859989924
Current State [[0.01  0.15  0.31  0.206 0.145 0.84  0.033 0.001 0.529 0.12 ]]
Logits tf.Tensor([[-0.15211958 -0.26348436  0.75400436]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22886837 0.20474847 0.5663832 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.34, 0.222, 0.145, 0.84, 0.033, 0.001, 0.529, 0.12]
0.8424569999999999
0.9494054999999999
Reward 20.311065859989924
Current State [[0.04  0.15  0.34  0.222 0.145 0.84  0.033 0.001 0.529 0.12 ]]
Logits tf.Tensor([[-0.15674984 -0.2685206   0.76116323]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22736014 0.20331664 0.56932324]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.34, 0.204, 0.145, 0.88, 0.035, 0.001, 0.46699999999999997, 0.01]
0.8822668333333333
0.5928570000000001
Reward 25.331008247807453
Current State [[0.03  0.15  0.34  0.204 0.145 0.88  0.035 0.001 0.467 0.01 ]]
Logits tf.Tensor([[-0.15020384 -0.24975556  0.74612576]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2295771 0.2078231 0.5625998]], shape=(1, 3), dtype=float32)
Selected action 2
[0.02, 0.15, 0.33, 0.206, 0.145, 0.88, 0.035, 0.001, 0.46699999999999997, 0.01]
0.8822668333333333
0.5928570000000001
Reward 25.331008247807453
Current State [[0.02  0.15  0.33  0.206 0.145 0.88  0.035 0.001 0.467 0.01 ]]
Logits tf.Tensor([[-0.14875989 -0.24749516  0.7435971 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23005119 0.20842236 0.5615264 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.04, 0.38, 0.214, 0.145, 0.74, 0.022, 0.002, 0.5389999999999999, 0.06]
0.74062
2.174405
Reward 5.172842158341275
Episode: 122 | Average Reward: 279 | Episode Reward: 324 | Loss: 852.735 | Steps: 19 | Worker: 0
Current State [[ 0.00875168 -0.00019735 -0.00473459 -0.00853938  0.00562271 -0.00569848
   0.00130899 -0.00993367 -0.00857776 -0.0041955 ]]
Logits tf.Tensor([[-0.04399091 -0.0288376   0.06607267]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.31932378 0.3241994  0.35647678]], shape=(1, 3), dtype=float32)
Selected action 1
[0.02, 0.08, 0.34, 0.0, 0.145, 0.74, 0.022, 0.002, 0.5389999999999999, 0.06]
0.74062
2.174405
Reward 11.172842158341275
Current State [[0.02  0.08  0.34  0.    0.145 0.74  0.022 0.002 0.539 0.06 ]]
Logits tf.Tensor([[-0.14444833 -0.2492077   0.6982267 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23679215 0.2132411  0.54996675]], shape=(1, 3), dtype=float32)
Selected action 2
[0.02, 0.08, 0.34, 0.0, 0.145, 0.74, 0.022, 0.002, 0.5389999999999999, 0.06]
0.74062
2.174405
Reward 17.172842158341275
Current State [[0.02  0.08  0.34  0.    0.145 0.74  0.022 0.002 0.539 0.06 ]]
Logits tf.Tensor([[-0.14444833 -0.2492077   0.6982267 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23679215 0.2132411  0.54996675]], shape=(1, 3), dtype=float32)
Selected action 0
[0.02, 0.04, 0.3, 0.229, 0.14, 0.81, 0.036, 0.002, 0.492, 0.09]
0.814624
2.310714333333334
Reward 5.228450420630796
Current State [[0.02  0.04  0.3   0.229 0.14  0.81  0.036 0.002 0.492 0.09 ]]
Logits tf.Tensor([[-0.14678085 -0.22805288  0.6940888 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23583098 0.21742268 0.5467464 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.09, 0.08, 0.25, 0.203, 0.143, 0.81, 0.036, 0.002, 0.492, 0.09]
0.814624
2.310714333333334
Reward 11.228450420630796
Current State [[0.09  0.08  0.25  0.203 0.143 0.81  0.036 0.002 0.492 0.09 ]]
Logits tf.Tensor([[-0.16048224 -0.25729138  0.69970804]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2341186 0.2125163 0.5533651]], shape=(1, 3), dtype=float32)
Selected action 0
[0.1, 0.04, 0.26, 0.235, 0.138, 0.81, 0.036, 0.002, 0.492, 0.09]
0.814624
2.310714333333334
Reward 5.228450420630796
Current State [[0.1   0.04  0.26  0.235 0.138 0.81  0.036 0.002 0.492 0.09 ]]
Logits tf.Tensor([[-0.1594678  -0.24680117  0.68716073]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23539694 0.21571109 0.548892  ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.1, 0.15, 0.26, 0.228, 0.147, 0.91, 0.03, 0.002, 0.45499999999999996, 0.11]
0.9070611666666668
1.6815476666666667
Reward 18.170216928260984
Current State [[0.1   0.15  0.26  0.228 0.147 0.91  0.03  0.002 0.455 0.11 ]]
Logits tf.Tensor([[-0.16317534 -0.28510395  0.7428727 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2293717  0.20304249 0.56758577]], shape=(1, 3), dtype=float32)
Selected action 2
[0.1, 0.15, 0.23, 0.206, 0.148, 0.91, 0.03, 0.002, 0.45499999999999996, 0.11]
0.9070611666666668
1.6815476666666667
Reward 18.170216928260984
Current State [[0.1   0.15  0.23  0.206 0.148 0.91  0.03  0.002 0.455 0.11 ]]
Logits tf.Tensor([[-0.16386852 -0.2897855   0.73608696]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23035201 0.20309862 0.5665493 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.1, 0.08, 0.27, 0.217, 0.142, 0.91, 0.03, 0.002, 0.45499999999999996, 0.11]
0.9070611666666668
1.6815476666666667
Reward 12.170216928260984
Current State [[0.1   0.08  0.27  0.217 0.142 0.91  0.03  0.002 0.455 0.11 ]]
Logits tf.Tensor([[-0.15854543 -0.2712509   0.7156825 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23307645 0.2082337  0.55868983]], shape=(1, 3), dtype=float32)
Selected action 1
[0.13, 0.08, 0.26, 0.263, 0.139, 0.98, 0.036, 0.001, 0.386, 0.07]
0.9848936666666667
1.0005961666666667
Reward 15.00483007802005
Current State [[0.13  0.08  0.26  0.263 0.139 0.98  0.036 0.001 0.386 0.07 ]]
Logits tf.Tensor([[-0.16193083 -0.26981133  0.7047548 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23382254 0.20991063 0.5562668 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.09, 0.08, 0.31, 0.2, 0.141, 0.98, 0.036, 0.001, 0.386, 0.07]
0.9848936666666667
1.0005961666666667
Reward 15.00483007802005
Current State [[0.09  0.08  0.31  0.2   0.141 0.98  0.036 0.001 0.386 0.07 ]]
Logits tf.Tensor([[-0.15502313 -0.26926878  0.71298176]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23396234 0.20870349 0.5573342 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.03, 0.04, 0.29, 0.24, 0.144, 0.98, 0.033, 0.001, 0.44299999999999995, 0.02]
0.9750035
1.0166665
Reward 8.819642790013935
Current State [[0.03  0.04  0.29  0.24  0.144 0.98  0.033 0.001 0.443 0.02 ]]
Logits tf.Tensor([[-0.14790273 -0.24090439  0.7182001 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23316443 0.21245758 0.554378  ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.08, 0.04, 0.25, 0.167, 0.143, 0.98, 0.033, 0.001, 0.44299999999999995, 0.02]
0.9750035
1.0166665
Reward 8.819642790013935
Current State [[0.08  0.04  0.25  0.167 0.143 0.98  0.033 0.001 0.443 0.02 ]]
Logits tf.Tensor([[-0.15634292 -0.26304096  0.70659345]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.234252   0.21054499 0.55520296]], shape=(1, 3), dtype=float32)
Selected action 1
[0.15, 0.08, 0.26, 0.253, 0.144, 0.98, 0.033, 0.001, 0.44299999999999995, 0.02]
0.9750035
1.0166665
Reward 14.819642790013935
Current State [[0.15  0.08  0.26  0.253 0.144 0.98  0.033 0.001 0.443 0.02 ]]
Logits tf.Tensor([[-0.1700327  -0.27481905  0.7313552 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22917195 0.2063732  0.56445485]], shape=(1, 3), dtype=float32)
Selected action 1
[0.13, 0.08, 0.26, 0.228, 0.143, 0.88, 0.032, 0.003, 0.48200000000000004, 0.11]
0.8786430000000001
2.642262166666667
Reward 11.135518442338583
Current State [[0.13  0.08  0.26  0.228 0.143 0.88  0.032 0.003 0.482 0.11 ]]
Logits tf.Tensor([[-0.16597852 -0.27552897  0.71903384]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23152159 0.20749822 0.56098014]], shape=(1, 3), dtype=float32)
Selected action 2
[0.14, 0.15, 0.28, 0.226, 0.14, 0.88, 0.032, 0.003, 0.48200000000000004, 0.11]
0.8786430000000001
2.642262166666667
Reward 17.135518442338583
Current State [[0.14  0.15  0.28  0.226 0.14  0.88  0.032 0.003 0.482 0.11 ]]
Logits tf.Tensor([[-0.1722063 -0.2919457  0.749989 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22717172 0.20153573 0.5712925 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.24, 0.192, 0.142, 0.88, 0.032, 0.003, 0.48200000000000004, 0.11]
0.8786430000000001
2.642262166666667
Reward 17.135518442338583
Current State [[0.05  0.15  0.24  0.192 0.142 0.88  0.032 0.003 0.482 0.11 ]]
Logits tf.Tensor([[-0.15927131 -0.2784694   0.73749924]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23045169 0.20455627 0.5649921 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.01, 0.04, 0.37, 0.1, 0.14, 0.79, 0.025, 0.003, 0.55, 0.03]
0.7906951666666667
2.8238081666666663
Reward 4.898485404962251
Current State [[0.01  0.04  0.37  0.1   0.14  0.79  0.025 0.003 0.55  0.03 ]]
Logits tf.Tensor([[-0.14594787 -0.2319153   0.71639097]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23330045 0.21408212 0.55261743]], shape=(1, 3), dtype=float32)
Selected action 2
[0.18, 0.15, 0.27, 0.221, 0.138, 0.79, 0.025, 0.003, 0.55, 0.03]
0.7906951666666667
2.8238081666666663
Reward 16.89848540496225
Current State [[0.18  0.15  0.27  0.221 0.138 0.79  0.025 0.003 0.55  0.03 ]]
Logits tf.Tensor([[-0.17475973 -0.28818795  0.7512404 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2263898  0.20211364 0.57149655]], shape=(1, 3), dtype=float32)
Selected action 0
[0.08, 0.04, 0.24, 0.197, 0.138, 0.79, 0.025, 0.003, 0.55, 0.03]
0.7906951666666667
2.8238081666666663
Reward 4.898485404962251
Current State [[0.08  0.04  0.24  0.197 0.138 0.79  0.025 0.003 0.55  0.03 ]]
Logits tf.Tensor([[-0.15929446 -0.24126548  0.69787526]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2337661  0.2153684  0.55086553]], shape=(1, 3), dtype=float32)
Selected action 2
[0.12, 0.15, 0.25, 0.249, 0.148, 0.79, 0.025, 0.003, 0.55, 0.03]
0.7906951666666667
2.8238081666666663
Reward 16.89848540496225
Episode: 123 | Average Reward: 278 | Episode Reward: 250 | Loss: 496.028 | Steps: 19 | Worker: 0
Current State [[-0.00032753 -0.00789246 -0.00473554 -0.00369397 -0.00490867  0.00406253
   0.00141017  0.00289682 -0.00739249  0.00024802]]
Logits tf.Tensor([[-0.04216431 -0.03062388  0.06495698]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.32003313 0.32374787 0.35621905]], shape=(1, 3), dtype=float32)
Selected action 1
[0.14, 0.08, 0.27, 0.242, 0.142, 0.95, 0.041, 0.001, 0.608, 0.1]
0.9506866666666667
1.3732143333333335
Reward 13.045862337945035
Current State [[0.14  0.08  0.27  0.242 0.142 0.95  0.041 0.001 0.608 0.1  ]]
Logits tf.Tensor([[-0.19164866 -0.301847    0.8029226 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.21742809 0.19474089 0.58783096]], shape=(1, 3), dtype=float32)
Selected action 1
[0.09, 0.08, 0.34, 0.221, 0.143, 0.95, 0.041, 0.001, 0.608, 0.1]
0.9506866666666667
1.3732143333333335
Reward 13.045862337945035
Current State [[0.09  0.08  0.34  0.221 0.143 0.95  0.041 0.001 0.608 0.1  ]]
Logits tf.Tensor([[-0.18624702 -0.28934455  0.81667423]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.21606332 0.19489753 0.58903915]], shape=(1, 3), dtype=float32)
Selected action 2
[0.11, 0.15, 0.26, 0.181, 0.119, 0.95, 0.041, 0.001, 0.608, 0.1]
0.9506866666666667
1.3732143333333335
Reward 19.045862337945035
Current State [[0.11  0.15  0.26  0.181 0.119 0.95  0.041 0.001 0.608 0.1  ]]
Logits tf.Tensor([[-0.19491425 -0.31770334  0.81573576]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2158971  0.19095023 0.5931527 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.19, 0.15, 0.27, 0.0, 0.14, 0.78, 0.061, 0.006, 0.39, 0.15]
0.7835441666666668
6.023809333333333
Reward 16.274748320529362
Current State [[0.19  0.15  0.27  0.    0.14  0.78  0.061 0.006 0.39  0.15 ]]
Logits tf.Tensor([[-0.19050802 -0.32329834  0.6699892 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23584993 0.20652166 0.55762845]], shape=(1, 3), dtype=float32)
Selected action 2
[0.2, 0.15, 0.29, 0.183, 0.139, 0.78, 0.061, 0.006, 0.39, 0.15]
0.7835441666666668
6.023809333333333
Reward 16.274748320529362
Current State [[0.2   0.15  0.29  0.183 0.139 0.78  0.061 0.006 0.39  0.15 ]]
Logits tf.Tensor([[-0.18386409 -0.29737377  0.68869936]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23333232 0.20829472 0.558373  ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.2, 0.15, 0.29, 0.183, 0.139, 0.78, 0.061, 0.006, 0.39, 0.15]
0.7835441666666668
6.023809333333333
Reward 16.274748320529362
Current State [[0.2   0.15  0.29  0.183 0.139 0.78  0.061 0.006 0.39  0.15 ]]
Logits tf.Tensor([[-0.18386409 -0.29737377  0.68869936]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23333232 0.20829472 0.558373  ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.09, 0.08, 0.34, 0.222, 0.139, 0.94, 0.07, 0.001, 0.386, 0.17]
0.9416923333333335
1.1142854999999998
Reward 14.022448362310463
Current State [[0.09  0.08  0.34  0.222 0.139 0.94  0.07  0.001 0.386 0.17 ]]
Logits tf.Tensor([[-0.17009425 -0.2790017   0.7183369 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2310469  0.20720597 0.56174713]], shape=(1, 3), dtype=float32)
Selected action 2
[0.15, 0.15, 0.26, 0.214, 0.149, 0.94, 0.07, 0.001, 0.386, 0.17]
0.9416923333333335
1.1142854999999998
Reward 20.022448362310463
Current State [[0.15  0.15  0.26  0.214 0.149 0.94  0.07  0.001 0.386 0.17 ]]
Logits tf.Tensor([[-0.19044866 -0.31258005  0.73380655]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2270136 0.2009143 0.5720721]], shape=(1, 3), dtype=float32)
Selected action 2
[0.24, 0.15, 0.26, 0.219, 0.141, 0.94, 0.07, 0.001, 0.386, 0.17]
0.9416923333333335
1.1142854999999998
Reward 20.022448362310463
Current State [[0.24  0.15  0.26  0.219 0.141 0.94  0.07  0.001 0.386 0.17 ]]
Logits tf.Tensor([[-0.20700347 -0.33262998  0.7331205 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22511151 0.19853579 0.5763527 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.18, 0.04, 0.27, 0.237, 0.143, 0.94, 0.07, 0.001, 0.386, 0.17]
0.9416923333333335
1.1142854999999998
Reward 8.022448362310463
Current State [[0.18  0.04  0.27  0.237 0.143 0.94  0.07  0.001 0.386 0.17 ]]
Logits tf.Tensor([[-0.18440974 -0.2914753   0.6911756 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23262595 0.20900668 0.5583674 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.08, 0.08, 0.23, 0.15, 0.123, 0.84, 0.05, 0.001, 0.446, 0.08]
0.8382623333333333
1.1196425
Reward 13.39408643291479
Current State [[0.08  0.08  0.23  0.15  0.123 0.84  0.05  0.001 0.446 0.08 ]]
Logits tf.Tensor([[-0.16467156 -0.2624942   0.67821336]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23641396 0.21438245 0.5492036 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.18, 0.04, 0.26, 0.238, 0.143, 0.84, 0.05, 0.001, 0.446, 0.08]
0.8382623333333333
1.1196425
Reward 7.39408643291479
Current State [[0.18  0.04  0.26  0.238 0.143 0.84  0.05  0.001 0.446 0.08 ]]
Logits tf.Tensor([[-0.17436823 -0.26451716  0.6844757 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23396052 0.21379198 0.5522475 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.1, 0.15, 0.25, 0.1, 0.143, 0.84, 0.05, 0.001, 0.446, 0.08]
0.8382623333333333
1.1196425
Reward 19.39408643291479
Current State [[0.1   0.15  0.25  0.1   0.143 0.84  0.05  0.001 0.446 0.08 ]]
Logits tf.Tensor([[-0.17288972 -0.28879178  0.71403134]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23157765 0.20623437 0.56218797]], shape=(1, 3), dtype=float32)
Selected action 2
[0.17, 0.15, 0.28, 0.217, 0.144, 0.96, 0.039, 0.001, 0.396, 0.06]
0.9629241666666668
0.6726189999999999
Reward 24.78541365205637
Current State [[0.17  0.15  0.28  0.217 0.144 0.96  0.039 0.001 0.396 0.06 ]]
Logits tf.Tensor([[-0.18135929 -0.29599264  0.7391654 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22715399 0.20255162 0.57029444]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.15, 0.25, 0.238, 0.144, 0.96, 0.039, 0.001, 0.396, 0.06]
0.9629241666666668
0.6726189999999999
Reward 24.78541365205637
Current State [[0.08  0.15  0.25  0.238 0.144 0.96  0.039 0.001 0.396 0.06 ]]
Logits tf.Tensor([[-0.1636717 -0.273814   0.7314962]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23023155 0.20621994 0.5635485 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.13, 0.08, 0.26, 0.246, 0.143, 0.96, 0.039, 0.001, 0.396, 0.06]
0.9629241666666668
0.6726189999999999
Reward 18.78541365205637
Current State [[0.13  0.08  0.26  0.246 0.143 0.96  0.039 0.001 0.396 0.06 ]]
Logits tf.Tensor([[-0.16591124 -0.2685226   0.70727706]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23271991 0.21002452 0.55725557]], shape=(1, 3), dtype=float32)
Selected action 2
[0.09, 0.15, 0.24, 0.21, 0.144, 0.94, 0.031, 0.0, 0.466, 0.08]
0.9357545
0.3422618333333333
Reward 39.912109499541565
Current State [[0.09  0.15  0.24  0.21  0.144 0.94  0.031 0.    0.466 0.08 ]]
Logits tf.Tensor([[-0.16915825 -0.28713623  0.7526273 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22714415 0.20186657 0.5709893 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.05, 0.08, 0.32, 0.2, 0.139, 0.94, 0.031, 0.0, 0.466, 0.08]
0.9357545
0.3422618333333333
Reward 33.912109499541565
Current State [[0.05  0.08  0.32  0.2   0.139 0.94  0.031 0.    0.466 0.08 ]]
Logits tf.Tensor([[-0.15801062 -0.26135567  0.74061996]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22946027 0.20693089 0.5636088 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.12, 0.15, 0.26, 0.215, 0.144, 0.94, 0.031, 0.0, 0.466, 0.08]
0.9357545
0.3422618333333333
Reward 39.912109499541565
Current State [[0.12  0.15  0.26  0.215 0.144 0.94  0.031 0.    0.466 0.08 ]]
Logits tf.Tensor([[-0.17356312 -0.2917034   0.7579161 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22589517 0.20072399 0.5733809 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.18, 0.15, 0.28, 0.2, 0.144, 0.94, 0.031, 0.0, 0.466, 0.08]
0.9357545
0.3422618333333333
Reward 39.912109499541565
Episode: 124 | Average Reward: 280 | Episode Reward: 418 | Loss: 1715.881 | Steps: 19 | Worker: 0
Current State [[ 0.00249039  0.00190572 -0.00653255 -0.00602864 -0.00278533  0.00326143
   0.00420688  0.00920713 -0.00558304 -0.00955116]]
Logits tf.Tensor([[-0.04573207 -0.03104137  0.06815735]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3189358  0.32365578 0.35740846]], shape=(1, 3), dtype=float32)
Selected action 1
[0.2, 0.08, 0.28, 0.229, 0.139, 0.87, 0.083, 0.005, 0.366, 0.13]
0.8714313333333333
4.780952166666667
Reward 10.48326494734183
Current State [[0.2   0.08  0.28  0.229 0.139 0.87  0.083 0.005 0.366 0.13 ]]
Logits tf.Tensor([[-0.19838521 -0.28430197  0.68499553]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23058823 0.21160404 0.55780774]], shape=(1, 3), dtype=float32)
Selected action 0
[0.01, 0.04, 0.32, 0.21, 0.14, 0.87, 0.083, 0.005, 0.366, 0.13]
0.8714313333333333
4.780952166666667
Reward 4.48326494734183
Current State [[0.01  0.04  0.32  0.21  0.14  0.87  0.083 0.005 0.366 0.13 ]]
Logits tf.Tensor([[-0.15883105 -0.23265344  0.6717686 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23676871 0.21991947 0.54331183]], shape=(1, 3), dtype=float32)
Selected action 0
[0.02, 0.04, 0.42, 0.167, 0.139, 1.01, 0.044, 0.001, 0.43899999999999995, 0.22]
1.0138823333333336
0.5767856666666666
Reward 16.12632337261611
Current State [[2.00e-02 4.00e-02 4.20e-01 1.67e-01 1.39e-01 1.01e+00 4.40e-02 1.00e-03
  4.39e-01 2.20e-01]]
Logits tf.Tensor([[-0.16396618 -0.27553207  0.7627772 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22620846 0.20232818 0.57146335]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.15, 0.25, 0.193, 0.149, 1.01, 0.044, 0.001, 0.43899999999999995, 0.22]
1.0138823333333336
0.5767856666666666
Reward 28.12632337261611
Current State [[7.00e-02 1.50e-01 2.50e-01 1.93e-01 1.49e-01 1.01e+00 4.40e-02 1.00e-03
  4.39e-01 2.20e-01]]
Logits tf.Tensor([[-0.18350403 -0.31758586  0.7765417 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22289914 0.1949294  0.5821715 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.1, 0.15, 0.25, 0.212, 0.139, 1.01, 0.044, 0.001, 0.43899999999999995, 0.22]
1.0138823333333336
0.5767856666666666
Reward 28.12632337261611
Current State [[1.00e-01 1.50e-01 2.50e-01 2.12e-01 1.39e-01 1.01e+00 4.40e-02 1.00e-03
  4.39e-01 2.20e-01]]
Logits tf.Tensor([[-0.18990651 -0.32102793  0.7748767 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22215657 0.19485603 0.58298737]], shape=(1, 3), dtype=float32)
Selected action 0
[0.08, 0.04, 0.24, 0.229, 0.144, 1.01, 0.044, 0.001, 0.43899999999999995, 0.22]
1.0138823333333336
0.5767856666666666
Reward 16.12632337261611
Current State [[8.00e-02 4.00e-02 2.40e-01 2.29e-01 1.44e-01 1.01e+00 4.40e-02 1.00e-03
  4.39e-01 2.20e-01]]
Logits tf.Tensor([[-0.17370872 -0.28909257  0.7286995 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22953902 0.2045248  0.56593615]], shape=(1, 3), dtype=float32)
Selected action 2
[0.14, 0.15, 0.26, 0.162, 0.145, 0.84, 0.042, 0.002, 0.40599999999999997, 0.04]
0.8391959999999999
1.5398828333333334
Reward 18.200317491615255
Current State [[0.14  0.15  0.26  0.162 0.145 0.84  0.042 0.002 0.406 0.04 ]]
Logits tf.Tensor([[-0.178075   -0.2740447   0.70722216]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23082982 0.20970693 0.55946326]], shape=(1, 3), dtype=float32)
Selected action 2
[0.32, 0.15, 0.29, 0.231, 0.139, 0.84, 0.042, 0.002, 0.40599999999999997, 0.04]
0.8391959999999999
1.5398828333333334
Reward 18.200317491615255
Current State [[0.32  0.15  0.29  0.231 0.139 0.84  0.042 0.002 0.406 0.04 ]]
Logits tf.Tensor([[-0.20745948 -0.30719012  0.7229127 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22519815 0.20382261 0.57097924]], shape=(1, 3), dtype=float32)
Selected action 2
[0.12, 0.15, 0.26, 0.1, 0.138, 0.84, 0.042, 0.002, 0.40599999999999997, 0.04]
0.8391959999999999
1.5398828333333334
Reward 18.200317491615255
Current State [[0.12  0.15  0.26  0.1   0.138 0.84  0.042 0.002 0.406 0.04 ]]
Logits tf.Tensor([[-0.17668171 -0.27920464  0.70111954]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23211755 0.20949942 0.558383  ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.23, 0.15, 0.23, 0.23, 0.132, 0.84, 0.042, 0.002, 0.40599999999999997, 0.04]
0.8391959999999999
1.5398828333333334
Reward 18.200317491615255
Current State [[0.23  0.15  0.23  0.23  0.132 0.84  0.042 0.002 0.406 0.04 ]]
Logits tf.Tensor([[-0.19051626 -0.28793603  0.7027885 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22986573 0.20852849 0.56160575]], shape=(1, 3), dtype=float32)
Selected action 0
[0.06, 0.04, 0.24, 0.232, 0.146, 0.95, 0.046, 0.001, 0.43899999999999995, 0.07]
0.9540473333333335
0.7488103333333332
Reward 11.344851827781953
Current State [[0.06  0.04  0.24  0.232 0.146 0.95  0.046 0.001 0.439 0.07 ]]
Logits tf.Tensor([[-0.16653547 -0.25044578  0.70765173]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23167239 0.21302596 0.55530167]], shape=(1, 3), dtype=float32)
Selected action 2
[0.14, 0.15, 0.27, 0.235, 0.145, 0.95, 0.046, 0.001, 0.43899999999999995, 0.07]
0.9540473333333335
0.7488103333333332
Reward 23.34485182778195
Current State [[0.14  0.15  0.27  0.235 0.145 0.95  0.046 0.001 0.439 0.07 ]]
Logits tf.Tensor([[-0.18874402 -0.28859192  0.7600003 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2228442  0.20166846 0.5754873 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.03, 0.04, 0.29, 0.1, 0.146, 0.95, 0.046, 0.001, 0.43899999999999995, 0.07]
0.9540473333333335
0.7488103333333332
Reward 11.344851827781953
Current State [[0.03  0.04  0.29  0.1   0.146 0.95  0.046 0.001 0.439 0.07 ]]
Logits tf.Tensor([[-0.16236563 -0.2590137   0.71208143]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23226514 0.2108678  0.55686706]], shape=(1, 3), dtype=float32)
Selected action 2
[0.16, 0.15, 0.27, 0.213, 0.139, 0.95, 0.046, 0.001, 0.43899999999999995, 0.07]
0.9540473333333335
0.7488103333333332
Reward 23.34485182778195
Current State [[0.16  0.15  0.27  0.213 0.139 0.95  0.046 0.001 0.439 0.07 ]]
Logits tf.Tensor([[-0.19394213 -0.29688263  0.7577432 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22260551 0.20083039 0.5765641 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.11, 0.15, 0.21, 0.067, 0.144, 0.79, 0.024, 0.003, 0.475, 0.04]
0.7932796666666667
3.472023
Reward 16.67545452068
Current State [[0.11  0.15  0.21  0.067 0.144 0.79  0.024 0.003 0.475 0.04 ]]
Logits tf.Tensor([[-0.17124957 -0.27911156  0.7024562 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23290889 0.20909433 0.55799675]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.15, 0.24, 0.247, 0.137, 0.79, 0.024, 0.003, 0.475, 0.04]
0.7932796666666667
3.472023
Reward 16.67545452068
Current State [[0.06  0.15  0.24  0.247 0.137 0.79  0.024 0.003 0.475 0.04 ]]
Logits tf.Tensor([[-0.16160046 -0.2436236   0.7155776 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23119482 0.21298839 0.5558168 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.21, 0.227, 0.138, 0.79, 0.024, 0.003, 0.475, 0.04]
0.7932796666666667
3.472023
Reward 16.67545452068
Current State [[0.05  0.15  0.21  0.227 0.138 0.79  0.024 0.003 0.475 0.04 ]]
Logits tf.Tensor([[-0.15992899 -0.24523532  0.7072536 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23264328 0.21362028 0.55373645]], shape=(1, 3), dtype=float32)
Selected action 2
[0.12, 0.15, 0.26, 0.226, 0.139, 0.76, 0.032, 0.003, 0.382, 0.03]
0.7553216666666666
3.3404776666666667
Reward 16.665437380264564
Current State [[0.12  0.15  0.26  0.226 0.139 0.76  0.032 0.003 0.382 0.03 ]]
Logits tf.Tensor([[-0.16251133 -0.2416181   0.6727734 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2364395  0.21845621 0.54510427]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.15, 0.24, 0.232, 0.144, 0.76, 0.032, 0.003, 0.382, 0.03]
0.7553216666666666
3.3404776666666667
Reward 16.665437380264564
Current State [[0.07  0.15  0.24  0.232 0.144 0.76  0.032 0.003 0.382 0.03 ]]
Logits tf.Tensor([[-0.15411997 -0.23081988  0.66796434]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23801562 0.2204424  0.541542  ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.18, 0.15, 0.25, 0.211, 0.142, 0.76, 0.032, 0.003, 0.382, 0.03]
0.7553216666666666
3.3404776666666667
Reward 16.665437380264564
Episode: 125 | Average Reward: 280 | Episode Reward: 345 | Loss: 970.29 | Steps: 19 | Worker: 0
Current State [[-0.00590057 -0.0053403  -0.00549756  0.00669151  0.00075559 -0.00116021
   0.00737577  0.00742946 -0.00718211 -0.00106151]]
Logits tf.Tensor([[-0.04690387 -0.02866275  0.06753642]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.31850642 0.32436964 0.35712394]], shape=(1, 3), dtype=float32)
Selected action 0
[0.14, 0.04, 0.27, 0.224, 0.142, 0.76, 0.032, 0.003, 0.382, 0.03]
0.7553216666666666
3.3404776666666667
Reward 4.665437380264563
Current State [[0.14  0.04  0.27  0.224 0.142 0.76  0.032 0.003 0.382 0.03 ]]
Logits tf.Tensor([[-0.16297248 -0.22569895  0.6429801 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23934734 0.22479512 0.53585756]], shape=(1, 3), dtype=float32)
Selected action 0
[0.19, 0.04, 0.26, 0.254, 0.144, 0.7, 0.031, 0.003, 0.45899999999999996, 0.04]
0.7007469999999998
3.457143666666666
Reward 4.5673218095342145
Current State [[0.19  0.04  0.26  0.254 0.144 0.7   0.031 0.003 0.459 0.04 ]]
Logits tf.Tensor([[-0.17244983 -0.23692816  0.6630708 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23565061 0.22093575 0.54341364]], shape=(1, 3), dtype=float32)
Selected action 0
[0.17, 0.04, 0.27, 0.222, 0.141, 0.7, 0.031, 0.003, 0.45899999999999996, 0.04]
0.7007469999999998
3.457143666666666
Reward 4.5673218095342145
Current State [[0.17  0.04  0.27  0.222 0.141 0.7   0.031 0.003 0.459 0.04 ]]
Logits tf.Tensor([[-0.17195351 -0.2351279   0.66155946]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23583966 0.22140147 0.5427588 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.01, 0.04, 0.29, 0.2, 0.145, 0.7, 0.031, 0.003, 0.45899999999999996, 0.04]
0.7007469999999998
3.457143666666666
Reward 4.5673218095342145
Current State [[0.01  0.04  0.29  0.2   0.145 0.7   0.031 0.003 0.459 0.04 ]]
Logits tf.Tensor([[-0.14931577 -0.19965367  0.6601551 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23822986 0.22653468 0.53523546]], shape=(1, 3), dtype=float32)
Selected action 1
[0.09, 0.08, 0.28, 0.211, 0.145, 0.7, 0.031, 0.003, 0.45899999999999996, 0.04]
0.7007469999999998
3.457143666666666
Reward 10.567321809534214
Current State [[0.09  0.08  0.28  0.211 0.145 0.7   0.031 0.003 0.459 0.04 ]]
Logits tf.Tensor([[-0.1646158  -0.22571878  0.6760446 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23481767 0.22089916 0.5442832 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.09, 0.15, 0.23, 0.222, 0.14, 0.89, 0.03, 0.002, 0.453, 0.1]
0.8866081666666668
2.4267856666666665
Reward 17.288682924996394
Current State [[0.09  0.15  0.23  0.222 0.14  0.89  0.03  0.002 0.453 0.1  ]]
Logits tf.Tensor([[-0.17826156 -0.27871424  0.7440171 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22627287 0.20464753 0.56907964]], shape=(1, 3), dtype=float32)
Selected action 1
[0.15, 0.08, 0.27, 0.24, 0.142, 0.89, 0.03, 0.002, 0.453, 0.1]
0.8866081666666668
2.4267856666666665
Reward 11.288682924996394
Current State [[0.15  0.08  0.27  0.24  0.142 0.89  0.03  0.002 0.453 0.1  ]]
Logits tf.Tensor([[-0.18233243 -0.27317384  0.729841  ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22712353 0.2074007  0.56547576]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.2, 0.25, 0.136, 0.89, 0.03, 0.002, 0.453, 0.1]
0.8866081666666668
2.4267856666666665
Reward 17.288682924996394
Current State [[0.03  0.15  0.2   0.25  0.136 0.89  0.03  0.002 0.453 0.1  ]]
Logits tf.Tensor([[-0.17004314 -0.2644691   0.7370307 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22794835 0.2074091  0.56464255]], shape=(1, 3), dtype=float32)
Selected action 1
[0.05, 0.08, 0.29, 0.1, 0.139, 0.89, 0.03, 0.002, 0.453, 0.1]
0.8866081666666668
2.4267856666666665
Reward 11.288682924996394
Current State [[0.05  0.08  0.29  0.1   0.139 0.89  0.03  0.002 0.453 0.1  ]]
Logits tf.Tensor([[-0.16732569 -0.2685298   0.72268564]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23047286 0.2082895  0.56123763]], shape=(1, 3), dtype=float32)
Selected action 2
[0.24, 0.15, 0.22, 0.229, 0.14, 0.83, 0.032, 0.001, 0.386, 0.02]
0.829997
0.7934521666666667
Reward 21.469781611795263
Current State [[0.24  0.15  0.22  0.229 0.14  0.83  0.032 0.001 0.386 0.02 ]]
Logits tf.Tensor([[-0.1913085 -0.2846063  0.6991643]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23003297 0.20954211 0.5604249 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.13, 0.15, 0.27, 0.227, 0.144, 0.83, 0.032, 0.001, 0.386, 0.02]
0.829997
0.7934521666666667
Reward 21.469781611795263
Current State [[0.13  0.15  0.27  0.227 0.144 0.83  0.032 0.001 0.386 0.02 ]]
Logits tf.Tensor([[-0.1745738 -0.2548704  0.7080563]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2304099  0.21263207 0.556958  ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.13, 0.04, 0.26, 0.246, 0.149, 0.79, 0.044, 0.002, 0.453, 0.03]
0.7926606666666667
1.7309514999999998
Reward 5.742823722569033
Current State [[0.13  0.04  0.26  0.246 0.149 0.79  0.044 0.002 0.453 0.03 ]]
Logits tf.Tensor([[-0.17569615 -0.23611823  0.68629926]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23205905 0.21845277 0.5494882 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.19, 0.15, 0.28, 0.24, 0.143, 0.79, 0.044, 0.002, 0.453, 0.03]
0.7926606666666667
1.7309514999999998
Reward 17.74282372256903
Current State [[0.19  0.15  0.28  0.24  0.143 0.79  0.044 0.002 0.453 0.03 ]]
Logits tf.Tensor([[-0.1896709  -0.27529413  0.7336217 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2254534 0.2069527 0.5675939]], shape=(1, 3), dtype=float32)
Selected action 1
[0.16, 0.08, 0.29, 0.189, 0.144, 0.79, 0.044, 0.002, 0.453, 0.03]
0.7926606666666667
1.7309514999999998
Reward 11.742823722569032
Current State [[0.16  0.08  0.29  0.189 0.144 0.79  0.044 0.002 0.453 0.03 ]]
Logits tf.Tensor([[-0.18463013 -0.25742543  0.7052284 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22911732 0.21303125 0.55785143]], shape=(1, 3), dtype=float32)
Selected action 1
[0.13, 0.08, 0.26, 0.05, 0.138, 0.74, 0.027, 0.006, 0.632, 0.04]
0.7412275000000002
5.9017865
Reward 10.257264206544635
Current State [[0.13  0.08  0.26  0.05  0.138 0.74  0.027 0.006 0.632 0.04 ]]
Logits tf.Tensor([[-0.19153675 -0.2822965   0.7441565 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22410384 0.20465995 0.5712362 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.12, 0.15, 0.24, 0.239, 0.147, 0.74, 0.027, 0.006, 0.632, 0.04]
0.7412275000000002
5.9017865
Reward 16.257264206544633
Current State [[0.12  0.15  0.24  0.239 0.147 0.74  0.027 0.006 0.632 0.04 ]]
Logits tf.Tensor([[-0.18591629 -0.2797905   0.78318644]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.21997477 0.20026442 0.5797608 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.27, 0.15, 0.28, 0.234, 0.143, 0.74, 0.027, 0.006, 0.632, 0.04]
0.7412275000000002
5.9017865
Reward 16.257264206544633
Current State [[0.27  0.15  0.28  0.234 0.143 0.74  0.027 0.006 0.632 0.04 ]]
Logits tf.Tensor([[-0.20248061 -0.31615812  0.80002725]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.21656021 0.1932899  0.5901499 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.03, 0.04, 0.31, 0.1, 0.144, 0.89, 0.036, 0.001, 0.675, 0.14]
0.8896184999999999
1.3023806666666669
Reward 6.990139004508676
Current State [[0.03  0.04  0.31  0.1   0.144 0.89  0.036 0.001 0.675 0.14 ]]
Logits tf.Tensor([[-0.19206426 -0.28911874  0.813214  ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.21550918 0.19557595 0.5889149 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.03, 0.04, 0.31, 0.25, 0.138, 0.89, 0.036, 0.001, 0.675, 0.14]
0.8896184999999999
1.3023806666666669
Reward 6.990139004508676
Current State [[0.03  0.04  0.31  0.25  0.138 0.89  0.036 0.001 0.675 0.14 ]]
Logits tf.Tensor([[-0.19317694 -0.26750028  0.820665  ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.21346807 0.19817768 0.5883543 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.09, 0.15, 0.2, 0.2, 0.144, 0.89, 0.036, 0.001, 0.675, 0.14]
0.8896184999999999
1.3023806666666669
Reward 18.990139004508677
Episode: 126 | Average Reward: 280 | Episode Reward: 239 | Loss: 535.221 | Steps: 19 | Worker: 0
Current State [[ 0.00819753  0.00673446 -0.00784509 -0.005567    0.00420491  0.0017375
   0.00328344 -0.00559914  0.00390964 -0.00079271]]
Logits tf.Tensor([[-0.05284791 -0.03405372  0.08253331]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3160611  0.32205737 0.36188146]], shape=(1, 3), dtype=float32)
Selected action 0
[0.19, 0.04, 0.27, 0.242, 0.148, 0.89, 0.036, 0.001, 0.675, 0.14]
0.8896184999999999
1.3023806666666669
Reward 6.990139004508676
Current State [[0.19  0.04  0.27  0.242 0.148 0.89  0.036 0.001 0.675 0.14 ]]
Logits tf.Tensor([[-0.21410964 -0.31158966  0.8265699 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2110479  0.19144589 0.5975062 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.11, 0.15, 0.26, 0.24, 0.14, 0.81, 0.035, 0.001, 0.646, 0.11]
0.8109516666666665
1.1511921666666667
Reward 19.119651219392352
Current State [[0.11  0.15  0.26  0.24  0.14  0.81  0.035 0.001 0.646 0.11 ]]
Logits tf.Tensor([[-0.20081516 -0.3005619   0.82109797]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.21351226 0.19324282 0.5932449 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.11, 0.15, 0.26, 0.24, 0.14, 0.81, 0.035, 0.001, 0.646, 0.11]
0.8109516666666665
1.1511921666666667
Reward 7.119651219392352
Current State [[0.11  0.15  0.26  0.24  0.14  0.81  0.035 0.001 0.646 0.11 ]]
Logits tf.Tensor([[-0.20081516 -0.3005619   0.82109797]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.21351226 0.19324282 0.5932449 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.04, 0.35, 0.204, 0.14, 0.81, 0.035, 0.001, 0.646, 0.11]
0.8109516666666665
1.1511921666666667
Reward 7.119651219392352
Current State [[0.05  0.04  0.35  0.204 0.14  0.81  0.035 0.001 0.646 0.11 ]]
Logits tf.Tensor([[-0.19168968 -0.261479    0.7942791 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.21677878 0.20216577 0.58105546]], shape=(1, 3), dtype=float32)
Selected action 2
[0.1, 0.15, 0.24, 0.244, 0.145, 0.81, 0.035, 0.001, 0.646, 0.11]
0.8109516666666665
1.1511921666666667
Reward 19.119651219392352
Current State [[0.1   0.15  0.24  0.244 0.145 0.81  0.035 0.001 0.646 0.11 ]]
Logits tf.Tensor([[-0.19817929 -0.2977584   0.8188632 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.21412252 0.19382763 0.59204984]], shape=(1, 3), dtype=float32)
Selected action 2
[0.2, 0.15, 0.28, 0.232, 0.139, 0.94, 0.053, 0.0, 0.395, 0.13]
0.9443713333333332
0.4547610000000001
Reward 31.78555726729266
Current State [[0.2   0.15  0.28  0.232 0.139 0.94  0.053 0.    0.395 0.13 ]]
Logits tf.Tensor([[-0.2117819  -0.3112977   0.75759625]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22018768 0.19933055 0.58048177]], shape=(1, 3), dtype=float32)
Selected action 2
[0.11, 0.15, 0.26, 0.247, 0.136, 0.94, 0.053, 0.0, 0.395, 0.13]
0.9443713333333332
0.4547610000000001
Reward 31.78555726729266
Current State [[0.11  0.15  0.26  0.247 0.136 0.94  0.053 0.    0.395 0.13 ]]
Logits tf.Tensor([[-0.19381472 -0.28946447  0.7507089 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22319585 0.20283642 0.5739677 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.32, 0.206, 0.138, 0.94, 0.053, 0.0, 0.395, 0.13]
0.9443713333333332
0.4547610000000001
Reward 19.78555726729266
Current State [[0.04  0.04  0.32  0.206 0.138 0.94  0.053 0.    0.395 0.13 ]]
Logits tf.Tensor([[-0.17008793 -0.2532529   0.7170188 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22997527 0.21162309 0.55840164]], shape=(1, 3), dtype=float32)
Selected action 2
[0.24, 0.15, 0.29, 0.218, 0.14, 0.95, 0.056, 0.001, 0.398, 0.16]
0.9480728333333333
0.9874995000000001
Reward 20.827303377563545
Current State [[0.24  0.15  0.29  0.218 0.14  0.95  0.056 0.001 0.398 0.16 ]]
Logits tf.Tensor([[-0.22212137 -0.33027118  0.7660346 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.21816106 0.19579802 0.5860409 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.02, 0.04, 0.35, 0.22, 0.139, 0.95, 0.056, 0.001, 0.398, 0.16]
0.9480728333333333
0.9874995000000001
Reward 8.827303377563545
Current State [[0.02  0.04  0.35  0.22  0.139 0.95  0.056 0.001 0.398 0.16 ]]
Logits tf.Tensor([[-0.16850951 -0.25272107  0.7295727 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22861701 0.21015318 0.56122977]], shape=(1, 3), dtype=float32)
Selected action 0
[0.13, 0.04, 0.25, 0.212, 0.149, 0.95, 0.056, 0.001, 0.398, 0.16]
0.9480728333333333
0.9874995000000001
Reward 8.827303377563545
Current State [[0.13  0.04  0.25  0.212 0.149 0.95  0.056 0.001 0.398 0.16 ]]
Logits tf.Tensor([[-0.18854797 -0.28450635  0.7119047 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2288739  0.20793232 0.5631938 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.11, 0.04, 0.25, 0.222, 0.145, 0.95, 0.056, 0.001, 0.398, 0.16]
0.9480728333333333
0.9874995000000001
Reward 8.827303377563545
Current State [[0.11  0.04  0.25  0.222 0.145 0.95  0.056 0.001 0.398 0.16 ]]
Logits tf.Tensor([[-0.18463527 -0.27806273  0.7103735 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22945458 0.20898817 0.5615573 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.13, 0.08, 0.27, 0.237, 0.15, 0.78, 0.028, 0.002, 0.532, 0.17]
0.7849928333333334
2.0148808333333332
Reward 11.404493565034286
Current State [[0.13  0.08  0.27  0.237 0.15  0.78  0.028 0.002 0.532 0.17 ]]
Logits tf.Tensor([[-0.18483135 -0.2740749   0.74081314]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22532079 0.20608354 0.56859565]], shape=(1, 3), dtype=float32)
Selected action 0
[0.03, 0.04, 0.22, 0.4, 0.143, 0.78, 0.028, 0.002, 0.532, 0.17]
0.7849928333333334
2.0148808333333332
Reward 5.404493565034286
Current State [[0.03  0.04  0.22  0.4   0.143 0.78  0.028 0.002 0.532 0.17 ]]
Logits tf.Tensor([[-0.16150708 -0.22708619  0.7165136 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23027375 0.21565713 0.5540691 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.25, 0.15, 0.3, 0.218, 0.145, 0.78, 0.028, 0.002, 0.532, 0.17]
0.7849928333333334
2.0148808333333332
Reward 17.404493565034286
Current State [[0.25  0.15  0.3   0.218 0.145 0.78  0.028 0.002 0.532 0.17 ]]
Logits tf.Tensor([[-0.20196941 -0.32606867  0.77287215]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2205539  0.1948135  0.58463264]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.04, 0.32, 0.3, 0.139, 0.78, 0.028, 0.002, 0.532, 0.17]
0.7849928333333334
2.0148808333333332
Reward 5.404493565034286
Current State [[0.05  0.04  0.32  0.3   0.139 0.78  0.028 0.002 0.532 0.17 ]]
Logits tf.Tensor([[-0.17350908 -0.23755336  0.7320102 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22669676 0.21263327 0.56066996]], shape=(1, 3), dtype=float32)
Selected action 0
[0.09, 0.04, 0.26, 0.208, 0.139, 0.68, 0.056, 0.001, 0.442, 0.0]
0.6810196666666667
0.8732118333333333
Reward 7.592927137698684
Current State [[0.09  0.04  0.26  0.208 0.139 0.68  0.056 0.001 0.442 0.   ]]
Logits tf.Tensor([[-0.17131896 -0.21243796  0.6487641 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23638411 0.22686133 0.5367546 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.09, 0.15, 0.28, 0.238, 0.147, 0.68, 0.056, 0.001, 0.442, 0.0]
0.6810196666666667
0.8732118333333333
Reward 19.592927137698684
Current State [[0.09  0.15  0.28  0.238 0.147 0.68  0.056 0.001 0.442 0.   ]]
Logits tf.Tensor([[-0.17498705 -0.23426133  0.6981305 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23058411 0.21731362 0.55210227]], shape=(1, 3), dtype=float32)
Selected action 2
[0.2, 0.15, 0.27, 0.212, 0.148, 0.68, 0.056, 0.001, 0.442, 0.0]
0.6810196666666667
0.8732118333333333
Reward 19.592927137698684
Current State [[0.2   0.15  0.27  0.212 0.148 0.68  0.056 0.001 0.442 0.   ]]
Logits tf.Tensor([[-0.18703866 -0.26601005  0.7005388 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2297106  0.21226782 0.5580216 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.23, 0.15, 0.26, 0.234, 0.139, 0.68, 0.056, 0.001, 0.442, 0.0]
0.6810196666666667
0.8732118333333333
Reward 19.592927137698684
Episode: 127 | Average Reward: 280 | Episode Reward: 296 | Loss: 670.216 | Steps: 19 | Worker: 0
Current State [[-0.00959171 -0.00341337 -0.00562532 -0.00930181  0.00361092  0.0078624
   0.00700532 -0.00411218  0.00153632 -0.00660248]]
Logits tf.Tensor([[-0.05107082 -0.03046096  0.07912397]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.31646833 0.3230584  0.36047333]], shape=(1, 3), dtype=float32)
Selected action 0
[0.19, 0.04, 0.28, 0.235, 0.137, 0.87, 0.071, 0.015, 0.387, 0.17]
0.8663306666666667
15.465475666666668
Reward 3.993984050518029
Current State [[0.19  0.04  0.28  0.235 0.137 0.87  0.071 0.015 0.387 0.17 ]]
Logits tf.Tensor([[-0.19423153 -0.29034266  0.69116443]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23082389 0.20967191 0.5595042 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.25, 0.15, 0.28, 0.242, 0.143, 0.87, 0.071, 0.015, 0.387, 0.17]
0.8663306666666667
15.465475666666668
Reward 15.99398405051803
Current State [[0.25  0.15  0.28  0.242 0.143 0.87  0.071 0.015 0.387 0.17 ]]
Logits tf.Tensor([[-0.21086262 -0.3294097   0.7391828 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22351179 0.19852541 0.5779628 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.0, 0.08, 0.16, 0.0, 0.141, 0.87, 0.071, 0.015, 0.387, 0.17]
0.8663306666666667
15.465475666666668
Reward 9.99398405051803
Current State [[0.    0.08  0.16  0.    0.141 0.87  0.071 0.015 0.387 0.17 ]]
Logits tf.Tensor([[-0.17099454 -0.2958348   0.6644567 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2387494  0.21072927 0.5505213 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.17, 0.15, 0.27, 0.189, 0.146, 0.88, 0.034, 0.002, 0.43, 0.1]
0.8784730000000001
1.6345239999999999
Reward 18.159560840812198
Current State [[0.17  0.15  0.27  0.189 0.146 0.88  0.034 0.002 0.43  0.1  ]]
Logits tf.Tensor([[-0.19318591 -0.30276766  0.75121677]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22383957 0.20060699 0.5755535 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.11, 0.15, 0.26, 0.216, 0.138, 0.88, 0.034, 0.002, 0.43, 0.1]
0.8784730000000001
1.6345239999999999
Reward 18.159560840812198
Current State [[0.11  0.15  0.26  0.216 0.138 0.88  0.034 0.002 0.43  0.1  ]]
Logits tf.Tensor([[-0.18094125 -0.28455007  0.74536145]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22590022 0.20366663 0.57043314]], shape=(1, 3), dtype=float32)
Selected action 2
[0.1, 0.15, 0.25, 0.224, 0.142, 0.88, 0.034, 0.002, 0.43, 0.1]
0.8784730000000001
1.6345239999999999
Reward 18.159560840812198
Current State [[0.1   0.15  0.25  0.224 0.142 0.88  0.034 0.002 0.43  0.1  ]]
Logits tf.Tensor([[-0.17884007 -0.28150946  0.7441978 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2262776  0.20419864 0.56952375]], shape=(1, 3), dtype=float32)
Selected action 0
[0.15, 0.04, 0.26, 0.224, 0.138, 0.66, 0.033, 0.001, 0.42800000000000005, 0.0]
0.6617328333333333
0.8458306666666667
Reward 7.608684040903562
Current State [[0.15  0.04  0.26  0.224 0.138 0.66  0.033 0.001 0.428 0.   ]]
Logits tf.Tensor([[-0.16493036 -0.22023246  0.6386451 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23925094 0.22637908 0.53437   ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.27, 0.15, 0.27, 0.188, 0.138, 0.66, 0.033, 0.001, 0.42800000000000005, 0.0]
0.6617328333333333
0.8458306666666667
Reward 19.60868404090356
Current State [[0.27  0.15  0.27  0.188 0.138 0.66  0.033 0.001 0.428 0.   ]]
Logits tf.Tensor([[-0.1845604 -0.2820722  0.68459  ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23299296 0.21134597 0.55566114]], shape=(1, 3), dtype=float32)
Selected action 1
[0.16, 0.08, 0.31, 0.225, 0.139, 0.66, 0.033, 0.001, 0.42800000000000005, 0.0]
0.6617328333333333
0.8458306666666667
Reward 13.608684040903562
Current State [[0.16  0.08  0.31  0.225 0.139 0.66  0.033 0.001 0.428 0.   ]]
Logits tf.Tensor([[-0.17004256 -0.23154202  0.66416276]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23566361 0.22160709 0.5427293 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.18, 0.08, 0.28, 0.226, 0.143, 0.66, 0.033, 0.001, 0.42800000000000005, 0.0]
0.6617328333333333
0.8458306666666667
Reward 13.608684040903562
Current State [[0.18  0.08  0.28  0.226 0.143 0.66  0.033 0.001 0.428 0.   ]]
Logits tf.Tensor([[-0.17052285 -0.23684233  0.66066945]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23630124 0.22113821 0.5425606 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.11, 0.08, 0.32, 0.18, 0.145, 0.81, 0.036, 0.001, 0.409, 0.0]
0.8149893333333333
0.627383
Reward 17.56513511899386
Current State [[0.11  0.08  0.32  0.18  0.145 0.81  0.036 0.001 0.409 0.   ]]
Logits tf.Tensor([[-0.17020634 -0.24391256  0.70247173]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23136064 0.2149212  0.5537181 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.15, 0.23, 0.206, 0.14, 0.81, 0.036, 0.001, 0.409, 0.0]
0.8149893333333333
0.627383
Reward 23.56513511899386
Current State [[0.08  0.15  0.23  0.206 0.14  0.81  0.036 0.001 0.409 0.   ]]
Logits tf.Tensor([[-0.17065167 -0.25190347  0.7061459 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2312057  0.21316276 0.5556315 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.18, 0.15, 0.29, 0.234, 0.138, 0.81, 0.036, 0.001, 0.409, 0.0]
0.8149893333333333
0.627383
Reward 23.56513511899386
Current State [[0.18  0.15  0.29  0.234 0.138 0.81  0.036 0.001 0.409 0.   ]]
Logits tf.Tensor([[-0.18567766 -0.2684031   0.72564995]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22684859 0.20883769 0.5643137 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.09, 0.08, 0.26, 0.257, 0.142, 0.77, 0.041, 0.0, 0.421, 0.0]
0.7665970000000001
0.37321433333333337
Reward 25.51608162844621
Current State [[0.09  0.08  0.26  0.257 0.142 0.77  0.041 0.    0.421 0.   ]]
Logits tf.Tensor([[-0.16817023 -0.22748615  0.6849308 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23313704 0.21971047 0.54715246]], shape=(1, 3), dtype=float32)
Selected action 2
[0.12, 0.15, 0.26, 0.236, 0.141, 0.77, 0.041, 0.0, 0.421, 0.0]
0.7665970000000001
0.37321433333333337
Reward 31.51608162844621
Current State [[0.12  0.15  0.26  0.236 0.141 0.77  0.041 0.    0.421 0.   ]]
Logits tf.Tensor([[-0.17615084 -0.25277102  0.71222883]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22949313 0.21256611 0.5579408 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.15, 0.23, 0.223, 0.143, 0.77, 0.041, 0.0, 0.421, 0.0]
0.7665970000000001
0.37321433333333337
Reward 31.51608162844621
Current State [[0.08  0.15  0.23  0.223 0.143 0.77  0.041 0.    0.421 0.   ]]
Logits tf.Tensor([[-0.17038777 -0.24621211  0.70318   ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23135182 0.21445829 0.55418986]], shape=(1, 3), dtype=float32)
Selected action 2
[0.12, 0.15, 0.21, 0.183, 0.14, 0.77, 0.041, 0.0, 0.421, 0.0]
0.7665970000000001
0.37321433333333337
Reward 31.51608162844621
Current State [[0.12  0.15  0.21  0.183 0.14  0.77  0.041 0.    0.421 0.   ]]
Logits tf.Tensor([[-0.17615122 -0.26159278  0.696774  ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2319104  0.21291853 0.5551711 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.09, 0.04, 0.21, 0.207, 0.138, 0.71, 0.022, 0.002, 0.43600000000000005, 0.02]
0.7067145000000001
1.7011918333333333
Reward 5.530246693794471
Current State [[0.09  0.04  0.21  0.207 0.138 0.71  0.022 0.002 0.436 0.02 ]]
Logits tf.Tensor([[-0.15681846 -0.21967652  0.6396443 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24057202 0.22591558 0.53351235]], shape=(1, 3), dtype=float32)
Selected action 2
[0.1, 0.15, 0.24, 0.233, 0.142, 0.71, 0.022, 0.002, 0.43600000000000005, 0.02]
0.7067145000000001
1.7011918333333333
Reward 17.53024669379447
Current State [[0.1   0.15  0.24  0.233 0.142 0.71  0.022 0.002 0.436 0.02 ]]
Logits tf.Tensor([[-0.16317333 -0.24242367  0.6933285 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23371494 0.21590786 0.55037725]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.2, 0.3, 0.143, 0.71, 0.022, 0.002, 0.43600000000000005, 0.02]
0.7067145000000001
1.7011918333333333
Reward 17.53024669379447
Episode: 128 | Average Reward: 281 | Episode Reward: 364 | Loss: 1252.236 | Steps: 19 | Worker: 0
Current State [[ 1.30059723e-03 -5.09519514e-03  6.68844742e-03 -5.73459851e-03
  -6.80545106e-03 -2.33971653e-03 -5.01190947e-03 -9.90660374e-03
  -7.49387174e-05 -3.48414804e-03]]
Logits tf.Tensor([[-0.04902229 -0.02925044  0.07244611]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.31754878 0.32388982 0.3585614 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.25, 0.208, 0.143, 0.79, 0.036, 0.0, 0.442, 0.03]
0.7870864999999999
0.4369035
Reward 28.607367039144904
Current State [[0.05  0.15  0.25  0.208 0.143 0.79  0.036 0.    0.442 0.03 ]]
Logits tf.Tensor([[-0.17034177 -0.25150105  0.7251135 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22880693 0.2109707  0.5602224 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.15, 0.21, 0.232, 0.14, 0.79, 0.036, 0.0, 0.442, 0.03]
0.7870864999999999
0.4369035
Reward 28.607367039144904
Current State [[0.07  0.15  0.21  0.232 0.14  0.79  0.036 0.    0.442 0.03 ]]
Logits tf.Tensor([[-0.17072392 -0.25609934  0.71641403]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23007876 0.21125084 0.5586704 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.15, 0.24, 0.208, 0.138, 0.79, 0.036, 0.0, 0.442, 0.03]
0.7870864999999999
0.4369035
Reward 28.607367039144904
Current State [[0.07  0.15  0.24  0.208 0.138 0.79  0.036 0.    0.442 0.03 ]]
Logits tf.Tensor([[-0.17338228 -0.25663346  0.7217809 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22894531 0.21065718 0.5603975 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.23, 0.236, 0.139, 0.94, 0.02, 0.002, 0.34199999999999997, 0.06]
0.943385
1.8458328333333334
Reward 18.01860646218492
Current State [[0.05  0.15  0.23  0.236 0.139 0.94  0.02  0.002 0.342 0.06 ]]
Logits tf.Tensor([[-0.16063832 -0.2639219   0.71730065]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23213668 0.2093574  0.55850595]], shape=(1, 3), dtype=float32)
Selected action 2
[0.1, 0.15, 0.25, 0.248, 0.136, 0.94, 0.02, 0.002, 0.34199999999999997, 0.06]
0.943385
1.8458328333333334
Reward 18.01860646218492
Current State [[0.1   0.15  0.25  0.248 0.136 0.94  0.02  0.002 0.342 0.06 ]]
Logits tf.Tensor([[-0.16998675 -0.2719432   0.7219023 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23026603 0.20794608 0.5617879 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.02, 0.04, 0.3, 0.212, 0.139, 0.94, 0.02, 0.002, 0.34199999999999997, 0.06]
0.943385
1.8458328333333334
Reward 6.018606462184918
Current State [[0.02  0.04  0.3   0.212 0.139 0.94  0.02  0.002 0.342 0.06 ]]
Logits tf.Tensor([[-0.14477788 -0.23514324  0.68743896]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23741657 0.21690316 0.5456802 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.04, 0.34, 0.2, 0.138, 0.84, 0.021, 0.003, 0.382, 0.07]
0.8357453333333335
2.5607145
Reward 5.107191042755029
Current State [[0.05  0.04  0.34  0.2   0.138 0.84  0.021 0.003 0.382 0.07 ]]
Logits tf.Tensor([[-0.15039448 -0.23171869  0.6870093 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23628062 0.21782586 0.5458935 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.18, 0.15, 0.25, 0.239, 0.147, 0.84, 0.021, 0.003, 0.382, 0.07]
0.8357453333333335
2.5607145
Reward 17.10719104275503
Current State [[0.18  0.15  0.25  0.239 0.147 0.84  0.021 0.003 0.382 0.07 ]]
Logits tf.Tensor([[-0.18047497 -0.2820168   0.71720725]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22949716 0.20733769 0.5631651 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.08, 0.08, 0.26, 0.175, 0.141, 0.84, 0.021, 0.003, 0.382, 0.07]
0.8357453333333335
2.5607145
Reward 11.10719104275503
Current State [[0.08  0.08  0.26  0.175 0.141 0.84  0.021 0.003 0.382 0.07 ]]
Logits tf.Tensor([[-0.15767606 -0.25290263  0.68349767]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23650424 0.2150218  0.54847395]], shape=(1, 3), dtype=float32)
Selected action 2
[0.1, 0.15, 0.23, 0.2, 0.125, 0.86, 0.022, 0.002, 0.38, 0.08]
0.8640728333333334
1.5892849999999998
Reward 18.193328393287093
Current State [[0.1   0.15  0.23  0.2   0.125 0.86  0.022 0.002 0.38  0.08 ]]
Logits tf.Tensor([[-0.1705789  -0.2742619   0.70570874]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23237024 0.20948434 0.55814546]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.21, 0.25, 0.143, 0.86, 0.022, 0.002, 0.38, 0.08]
0.8640728333333334
1.5892849999999998
Reward 18.193328393287093
Current State [[0.05  0.15  0.21  0.25  0.143 0.86  0.022 0.002 0.38  0.08 ]]
Logits tf.Tensor([[-0.16065532 -0.25760752  0.70900136]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23289987 0.21137977 0.5557204 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.14, 0.15, 0.27, 0.1, 0.144, 0.86, 0.022, 0.002, 0.38, 0.08]
0.8640728333333334
1.5892849999999998
Reward 18.193328393287093
Current State [[0.14  0.15  0.27  0.1   0.144 0.86  0.022 0.002 0.38  0.08 ]]
Logits tf.Tensor([[-0.17941271 -0.29918757  0.7181848 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23037113 0.2043669  0.5652619 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.02, 0.04, 0.3, 0.211, 0.145, 0.91, 0.041, 0.002, 0.47000000000000003, 0.08]
0.9109821666666666
1.936905333333333
Reward 5.806132747091777
Current State [[0.02  0.04  0.3   0.211 0.145 0.91  0.041 0.002 0.47  0.08 ]]
Logits tf.Tensor([[-0.16850722 -0.2511865   0.7426335 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22687033 0.20886733 0.56426233]], shape=(1, 3), dtype=float32)
Selected action 1
[0.1, 0.08, 0.27, 0.1, 0.145, 0.91, 0.041, 0.002, 0.47000000000000003, 0.08]
0.9109821666666666
1.936905333333333
Reward 11.806132747091777
Current State [[0.1   0.08  0.27  0.1   0.145 0.91  0.041 0.002 0.47  0.08 ]]
Logits tf.Tensor([[-0.1858623 -0.2941463  0.7479774]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22514245 0.2020367  0.57282084]], shape=(1, 3), dtype=float32)
Selected action 2
[0.1, 0.15, 0.24, 0.186, 0.145, 0.91, 0.041, 0.002, 0.47000000000000003, 0.08]
0.9109821666666666
1.936905333333333
Reward 17.806132747091777
Current State [[0.1   0.15  0.24  0.186 0.145 0.91  0.041 0.002 0.47  0.08 ]]
Logits tf.Tensor([[-0.18884364 -0.29767182  0.7724571 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22163218 0.19877847 0.57958937]], shape=(1, 3), dtype=float32)
Selected action 0
[0.07, 0.04, 0.26, 0.2, 0.146, 0.91, 0.041, 0.002, 0.47000000000000003, 0.08]
0.9109821666666666
1.936905333333333
Reward 5.806132747091777
Current State [[0.07  0.04  0.26  0.2   0.146 0.91  0.041 0.002 0.47  0.08 ]]
Logits tf.Tensor([[-0.17618965 -0.2651908   0.73421466]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22726387 0.20791109 0.56482506]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.15, 0.24, 0.233, 0.138, 0.79, 0.036, 0.003, 0.523, 0.03]
0.7919076666666667
3.461309666666667
Reward 16.67677191560526
Current State [[0.07  0.15  0.24  0.233 0.138 0.79  0.036 0.003 0.523 0.03 ]]
Logits tf.Tensor([[-0.17973852 -0.26604792  0.7593803 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22346184 0.20498389 0.5715543 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.18, 0.15, 0.27, 0.248, 0.142, 0.79, 0.036, 0.003, 0.523, 0.03]
0.7919076666666667
3.461309666666667
Reward 16.67677191560526
Current State [[0.18  0.15  0.27  0.248 0.142 0.79  0.036 0.003 0.523 0.03 ]]
Logits tf.Tensor([[-0.19254014 -0.2909128   0.7724853 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22069378 0.2000172  0.579289  ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.15, 0.24, 0.2, 0.144, 0.96, 0.04, 0.001, 0.617, 0.09]
0.9551138333333333
1.3553575000000002
Reward 19.1211780971275
Current State [[0.08  0.15  0.24  0.2   0.144 0.96  0.04  0.001 0.617 0.09 ]]
Logits tf.Tensor([[-0.20595671 -0.31941515  0.85440093]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.20919867 0.1867603  0.604041  ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.11, 0.08, 0.26, 0.209, 0.139, 0.96, 0.04, 0.001, 0.617, 0.09]
0.9551138333333333
1.3553575000000002
Reward 13.121178097127501
Episode: 129 | Average Reward: 281 | Episode Reward: 322 | Loss: 665.0 | Steps: 19 | Worker: 0
Current State [[ 0.0028141  -0.00800761  0.00581616 -0.00877724 -0.00772148 -0.00438173
   0.00068599 -0.00468098 -0.00721096 -0.0009021 ]]
Logits tf.Tensor([[-0.04801933 -0.03030219  0.06831925]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3183445  0.3240349  0.35762063]], shape=(1, 3), dtype=float32)
Selected action 2
[0.16, 0.15, 0.28, 0.235, 0.145, 0.96, 0.04, 0.001, 0.617, 0.09]
0.9551138333333333
1.3553575000000002
Reward 19.1211780971275
Current State [[0.16  0.15  0.28  0.235 0.145 0.96  0.04  0.001 0.617 0.09 ]]
Logits tf.Tensor([[-0.21673742 -0.33706105  0.8754825 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.20544353 0.18215312 0.61240333]], shape=(1, 3), dtype=float32)
Selected action 2
[0.12, 0.15, 0.25, 0.215, 0.138, 0.98, 0.058, 0.0, 0.396, 0.09]
0.976904
0.45476183333333337
Reward 32.6468900209254
Current State [[0.12  0.15  0.25  0.215 0.138 0.98  0.058 0.    0.396 0.09 ]]
Logits tf.Tensor([[-0.1997596  -0.30937016  0.77014583]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22056173 0.1976637  0.5817746 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.12, 0.15, 0.25, 0.215, 0.138, 0.98, 0.058, 0.0, 0.396, 0.09]
0.976904
0.45476183333333337
Reward 32.6468900209254
Current State [[0.12  0.15  0.25  0.215 0.138 0.98  0.058 0.    0.396 0.09 ]]
Logits tf.Tensor([[-0.1997596  -0.30937016  0.77014583]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22056173 0.1976637  0.5817746 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.13, 0.15, 0.26, 0.191, 0.138, 0.98, 0.058, 0.0, 0.396, 0.09]
0.976904
0.45476183333333337
Reward 32.6468900209254
Current State [[0.13  0.15  0.26  0.191 0.138 0.98  0.058 0.    0.396 0.09 ]]
Logits tf.Tensor([[-0.20214573 -0.31514913  0.7713328 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22025053 0.19671623 0.5830332 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.19, 0.15, 0.28, 0.225, 0.139, 0.93, 0.056, 0.0, 0.403, 0.15]
0.9258066666666666
0.38214249999999994
Reward 36.03390527566009
Current State [[0.19  0.15  0.28  0.225 0.139 0.93  0.056 0.    0.403 0.15 ]]
Logits tf.Tensor([[-0.21065342 -0.32455498  0.7699727 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.21937183 0.19575551 0.5848727 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.09, 0.08, 0.36, 0.247, 0.141, 0.93, 0.056, 0.0, 0.403, 0.15]
0.9258066666666666
0.38214249999999994
Reward 30.033905275660093
Current State [[0.09  0.08  0.36  0.247 0.141 0.93  0.056 0.    0.403 0.15 ]]
Logits tf.Tensor([[-0.18289474 -0.28084087  0.76108533]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22336943 0.20252857 0.574102  ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.15, 0.25, 0.218, 0.135, 0.93, 0.056, 0.0, 0.403, 0.15]
0.9258066666666666
0.38214249999999994
Reward 36.03390527566009
Current State [[0.08  0.15  0.25  0.218 0.135 0.93  0.056 0.    0.403 0.15 ]]
Logits tf.Tensor([[-0.18971345 -0.30223984  0.75920904]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22338887 0.19961444 0.5769967 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.21, 0.15, 0.28, 0.23, 0.142, 0.7, 0.049, 0.001, 0.409, 0.0]
0.6951656666666667
0.741668
Reward 20.662980212777747
Current State [[0.21  0.15  0.28  0.23  0.142 0.7   0.049 0.001 0.409 0.   ]]
Logits tf.Tensor([[-0.18611854 -0.2707305   0.70225066]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22988343 0.2112327  0.55888385]], shape=(1, 3), dtype=float32)
Selected action 1
[0.21, 0.08, 0.29, 0.245, 0.14, 0.7, 0.049, 0.001, 0.409, 0.0]
0.6951656666666667
0.741668
Reward 14.662980212777747
Current State [[0.21  0.08  0.29  0.245 0.14  0.7   0.049 0.001 0.409 0.   ]]
Logits tf.Tensor([[-0.18203914 -0.252203    0.678685  ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23271435 0.21694587 0.55033976]], shape=(1, 3), dtype=float32)
Selected action 1
[0.12, 0.08, 0.25, 0.234, 0.145, 0.7, 0.049, 0.001, 0.409, 0.0]
0.6951656666666667
0.741668
Reward 14.662980212777747
Current State [[0.12  0.08  0.25  0.234 0.145 0.7   0.049 0.001 0.409 0.   ]]
Logits tf.Tensor([[-0.17032129 -0.23251238  0.66705096]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2352946  0.22110713 0.5435983 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.12, 0.15, 0.25, 0.226, 0.145, 0.95, 0.052, 0.002, 0.387, 0.17]
0.9458438333333332
1.7285709999999999
Reward 18.212323268100267
Current State [[0.12  0.15  0.25  0.226 0.145 0.95  0.052 0.002 0.387 0.17 ]]
Logits tf.Tensor([[-0.19528258 -0.31509936  0.7621813 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22260986 0.19747339 0.5799167 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.18, 0.15, 0.28, 0.186, 0.139, 0.95, 0.052, 0.002, 0.387, 0.17]
0.9458438333333332
1.7285709999999999
Reward 18.212323268100267
Current State [[0.18  0.15  0.28  0.186 0.139 0.95  0.052 0.002 0.387 0.17 ]]
Logits tf.Tensor([[-0.20774856 -0.33334184  0.7652458 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22085643 0.19478951 0.5843541 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.19, 0.15, 0.27, 0.1, 0.145, 0.95, 0.052, 0.002, 0.387, 0.17]
0.9458438333333332
1.7285709999999999
Reward 18.212323268100267
Current State [[0.19  0.15  0.27  0.1   0.145 0.95  0.052 0.002 0.387 0.17 ]]
Logits tf.Tensor([[-0.21136564 -0.35018748  0.7605926 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22155762 0.19284002 0.58560234]], shape=(1, 3), dtype=float32)
Selected action 0
[0.18, 0.04, 0.28, 0.251, 0.142, 0.95, 0.039, 0.0, 0.393, 0.16]
0.9521601666666666
0.40833366666666665
Reward 22.90267762343288
Current State [[0.18  0.04  0.28  0.251 0.142 0.95  0.039 0.    0.393 0.16 ]]
Logits tf.Tensor([[-0.19059801 -0.2966857   0.72770166]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22704707 0.20419382 0.5687591 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.07, 0.08, 0.34, 0.217, 0.142, 0.95, 0.039, 0.0, 0.393, 0.16]
0.9521601666666666
0.40833366666666665
Reward 28.90267762343288
Current State [[0.07  0.08  0.34  0.217 0.142 0.95  0.039 0.    0.393 0.16 ]]
Logits tf.Tensor([[-0.17356348 -0.28268534  0.75301933]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22611725 0.20274152 0.5711412 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.08, 0.08, 0.27, 0.205, 0.139, 0.87, 0.031, 0.003, 0.47300000000000003, 0.12]
0.8743131666666668
3.174404333333334
Reward 10.878266472154156
Current State [[0.08  0.08  0.27  0.205 0.139 0.87  0.031 0.003 0.473 0.12 ]]
Logits tf.Tensor([[-0.17638662 -0.2767182   0.74487627]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22639808 0.20478553 0.5688164 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.1, 0.08, 0.32, 0.225, 0.141, 0.87, 0.031, 0.003, 0.47300000000000003, 0.12]
0.8743131666666668
3.174404333333334
Reward 10.878266472154156
Current State [[0.1   0.08  0.32  0.225 0.141 0.87  0.031 0.003 0.473 0.12 ]]
Logits tf.Tensor([[-0.17941463 -0.27686036  0.7598373 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2239532  0.20315951 0.5728873 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.15, 0.15, 0.27, 0.193, 0.14, 0.87, 0.031, 0.003, 0.47300000000000003, 0.12]
0.8743131666666668
3.174404333333334
Reward 16.878266472154156
Current State [[0.15  0.15  0.27  0.193 0.14  0.87  0.031 0.003 0.473 0.12 ]]
Logits tf.Tensor([[-0.1934284  -0.30958807  0.7746243 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22108507 0.19683936 0.58207554]], shape=(1, 3), dtype=float32)
Selected action 0
[0.2, 0.04, 0.28, 0.233, 0.14, 0.87, 0.031, 0.003, 0.47300000000000003, 0.12]
0.8743131666666668
3.174404333333334
Reward 4.878266472154156
Current State [[0.2   0.04  0.28  0.233 0.14  0.87  0.031 0.003 0.473 0.12 ]]
Logits tf.Tensor([[-0.19184041 -0.29144186  0.737684  ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22530122 0.20394224 0.5707565 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.1, 0.08, 0.25, 0.203, 0.141, 0.83, 0.063, 0.002, 0.40800000000000003, 0.1]
0.8323191666666666
2.456548833333333
Reward 11.164538894743224
Episode: 130 | Average Reward: 283 | Episode Reward: 430 | Loss: 1174.146 | Steps: 19 | Worker: 0
Current State [[ 0.00563039 -0.00361923  0.00614284  0.00440503 -0.00626255 -0.00117232
  -0.00036392  0.00365846 -0.00863895 -0.0006481 ]]
Logits tf.Tensor([[-0.04894091 -0.0326726   0.07200158]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.31796893 0.32318407 0.35884702]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.27, 0.162, 0.139, 0.83, 0.063, 0.002, 0.40800000000000003, 0.1]
0.8323191666666666
2.456548833333333
Reward 17.164538894743224
Current State [[0.05  0.15  0.27  0.162 0.139 0.83  0.063 0.002 0.408 0.1  ]]
Logits tf.Tensor([[-0.18350135 -0.276899    0.73577386]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22633122 0.20614955 0.5675193 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.3, 0.15, 0.28, 0.231, 0.139, 0.83, 0.063, 0.002, 0.40800000000000003, 0.1]
0.8323191666666666
2.456548833333333
Reward 17.164538894743224
Current State [[0.3   0.15  0.28  0.231 0.139 0.83  0.063 0.002 0.408 0.1  ]]
Logits tf.Tensor([[-0.22391787 -0.32825387  0.75072074]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.21972558 0.1979557  0.5823187 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.15, 0.27, 0.214, 0.145, 0.83, 0.063, 0.002, 0.40800000000000003, 0.1]
0.8323191666666666
2.456548833333333
Reward 17.164538894743224
Current State [[0.08  0.15  0.27  0.214 0.145 0.83  0.063 0.002 0.408 0.1  ]]
Logits tf.Tensor([[-0.18706542 -0.27627963  0.7414659 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22494966 0.20575012 0.56930023]], shape=(1, 3), dtype=float32)
Selected action 2
[0.11, 0.15, 0.26, 0.206, 0.142, 0.98, 0.044, 0.001, 0.461, 0.21]
0.9769113333333334
0.9934521666666666
Reward 20.997768766388383
Current State [[0.11  0.15  0.26  0.206 0.142 0.98  0.044 0.001 0.461 0.21 ]]
Logits tf.Tensor([[-0.20455167 -0.3328886   0.8087894 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.21578014 0.18979093 0.5944289 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.18, 0.15, 0.27, 0.235, 0.135, 0.98, 0.044, 0.001, 0.461, 0.21]
0.9769113333333334
0.9934521666666666
Reward 20.997768766388383
Current State [[0.18  0.15  0.27  0.235 0.135 0.98  0.044 0.001 0.461 0.21 ]]
Logits tf.Tensor([[-0.21742415 -0.34288234  0.8110089 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.21373127 0.18853077 0.59773797]], shape=(1, 3), dtype=float32)
Selected action 1
[0.06, 0.08, 0.29, 0.207, 0.138, 0.98, 0.044, 0.001, 0.461, 0.21]
0.9769113333333334
0.9934521666666666
Reward 14.997768766388385
Current State [[0.06  0.08  0.29  0.207 0.138 0.98  0.044 0.001 0.461 0.21 ]]
Logits tf.Tensor([[-0.18799843 -0.30303484  0.7834487 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22059967 0.19662793 0.5827724 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.14, 0.15, 0.24, 0.0, 0.147, 0.82, 0.048, 0.001, 0.387, 0.11]
0.8194273333333335
1.0232161666666666
Reward 19.728717710096227
Current State [[0.14  0.15  0.24  0.    0.147 0.82  0.048 0.001 0.387 0.11 ]]
Logits tf.Tensor([[-0.19644591 -0.32101622  0.7100829 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22943199 0.20256005 0.56800795]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.33, 0.229, 0.137, 0.82, 0.048, 0.001, 0.387, 0.11]
0.8194273333333335
1.0232161666666666
Reward 7.728717710096227
Current State [[0.04  0.04  0.33  0.229 0.137 0.82  0.048 0.001 0.387 0.11 ]]
Logits tf.Tensor([[-0.16450018 -0.23500656  0.69562703]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23280811 0.21695895 0.55023295]], shape=(1, 3), dtype=float32)
Selected action 0
[0.12, 0.04, 0.26, 0.236, 0.143, 0.82, 0.048, 0.001, 0.387, 0.11]
0.8194273333333335
1.0232161666666666
Reward 7.728717710096227
Current State [[0.12  0.04  0.26  0.236 0.143 0.82  0.048 0.001 0.387 0.11 ]]
Logits tf.Tensor([[-0.17631379 -0.25415584  0.6829193 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23329277 0.2158216  0.5508857 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.15, 0.26, 0.239, 0.143, 0.73, 0.056, 0.001, 0.42300000000000004, 0.0]
0.7258506666666666
1.361904333333333
Reward 18.135398823291872
Current State [[0.07  0.15  0.26  0.239 0.143 0.73  0.056 0.001 0.423 0.   ]]
Logits tf.Tensor([[-0.17774254 -0.2423427   0.71400064]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22847638 0.21418339 0.55734026]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.15, 0.25, 0.25, 0.123, 0.73, 0.056, 0.001, 0.42300000000000004, 0.0]
0.7258506666666666
1.361904333333333
Reward 18.135398823291872
Current State [[0.08  0.15  0.25  0.25  0.123 0.73  0.056 0.001 0.423 0.   ]]
Logits tf.Tensor([[-0.17919163 -0.24431644  0.706367  ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22929001 0.2148334  0.5558766 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.01, 0.15, 0.17, 0.0, 0.139, 0.73, 0.056, 0.001, 0.42300000000000004, 0.0]
0.7258506666666666
1.361904333333333
Reward 18.135398823291872
Current State [[0.01  0.15  0.17  0.    0.139 0.73  0.056 0.001 0.423 0.   ]]
Logits tf.Tensor([[-0.16961049 -0.2577833   0.6704859 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23628412 0.21634236 0.54737353]], shape=(1, 3), dtype=float32)
Selected action 0
[0.02, 0.04, 0.32, 0.2, 0.144, 0.82, 0.033, 0.0, 0.46699999999999997, 0.03]
0.8168945000000001
0.4773788333333335
Reward 15.62140594466227
Current State [[0.02  0.04  0.32  0.2   0.144 0.82  0.033 0.    0.467 0.03 ]]
Logits tf.Tensor([[-0.16667399 -0.22976932  0.72663486]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22820346 0.21424973 0.5575468 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.15, 0.21, 0.05, 0.142, 0.82, 0.033, 0.0, 0.46699999999999997, 0.03]
0.8168945000000001
0.4773788333333335
Reward 27.62140594466227
Current State [[0.08  0.15  0.21  0.05  0.142 0.82  0.033 0.    0.467 0.03 ]]
Logits tf.Tensor([[-0.18461947 -0.29032928  0.7348008 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22688487 0.20412509 0.56899005]], shape=(1, 3), dtype=float32)
Selected action 2
[0.1, 0.15, 0.24, 0.1, 0.139, 0.82, 0.033, 0.0, 0.46699999999999997, 0.03]
0.8168945000000001
0.4773788333333335
Reward 27.62140594466227
Current State [[0.1   0.15  0.24  0.1   0.139 0.82  0.033 0.    0.467 0.03 ]]
Logits tf.Tensor([[-0.1871498  -0.28736025  0.74518186]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2249682  0.20351683 0.571515  ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.11, 0.15, 0.25, 0.227, 0.138, 0.97, 0.032, 0.001, 0.475, 0.06]
0.9732261666666666
0.5339291666666667
Reward 28.843909305608445
Current State [[0.11  0.15  0.25  0.227 0.138 0.97  0.032 0.001 0.475 0.06 ]]
Logits tf.Tensor([[-0.1973185  -0.30211222  0.8026382 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.21651235 0.19497158 0.58851606]], shape=(1, 3), dtype=float32)
Selected action 1
[0.03, 0.08, 0.28, 0.2, 0.139, 0.97, 0.032, 0.001, 0.475, 0.06]
0.9732261666666666
0.5339291666666667
Reward 22.843909305608445
Current State [[0.03  0.08  0.28  0.2   0.139 0.97  0.032 0.001 0.475 0.06 ]]
Logits tf.Tensor([[-0.17919233 -0.27267355  0.77884865]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22136922 0.20161313 0.57701766]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.15, 0.21, 0.2, 0.147, 0.97, 0.032, 0.001, 0.475, 0.06]
0.9732261666666666
0.5339291666666667
Reward 28.843909305608445
Current State [[0.07  0.15  0.21  0.2   0.147 0.97  0.032 0.001 0.475 0.06 ]]
Logits tf.Tensor([[-0.1899301  -0.29896614  0.79314023]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.21884961 0.19624205 0.58490837]], shape=(1, 3), dtype=float32)
Selected action 2
[0.16, 0.15, 0.27, 0.231, 0.142, 0.88, 0.022, 0.001, 0.472, 0.09]
0.8792381666666667
1.1351191666666665
Reward 19.558703719469086
Current State [[0.16  0.15  0.27  0.231 0.142 0.88  0.022 0.001 0.472 0.09 ]]
Logits tf.Tensor([[-0.19452709 -0.30023885  0.7823045 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.21950468 0.19748484 0.5830105 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.13, 0.04, 0.26, 0.236, 0.144, 0.88, 0.022, 0.001, 0.472, 0.09]
0.8792381666666667
1.1351191666666665
Reward 7.558703719469087
Episode: 131 | Average Reward: 284 | Episode Reward: 376 | Loss: 1191.674 | Steps: 19 | Worker: 0
Current State [[-0.00709059 -0.00293039  0.00084772 -0.00868354 -0.0025398  -0.00328381
   0.00163213 -0.00745967  0.00021433  0.00955596]]
Logits tf.Tensor([[-0.0515407  -0.03171545  0.07767998]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3166597 0.3230002 0.3603401]], shape=(1, 3), dtype=float32)
Selected action 1
[0.03, 0.08, 0.3, 0.0, 0.144, 0.8, 0.029, 0.001, 0.47800000000000004, 0.09]
0.7975450000000001
0.6904761666666667
Reward 16.33498529032422
Current State [[0.03  0.08  0.3   0.    0.144 0.8   0.029 0.001 0.478 0.09 ]]
Logits tf.Tensor([[-0.17302403 -0.27458724  0.7290344 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22893274 0.20682335 0.564244  ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.03, 0.04, 0.33, 0.221, 0.138, 0.8, 0.029, 0.001, 0.47800000000000004, 0.09]
0.7975450000000001
0.6904761666666667
Reward 10.334985290324218
Current State [[0.03  0.04  0.33  0.221 0.138 0.8   0.029 0.001 0.478 0.09 ]]
Logits tf.Tensor([[-0.17188063 -0.23743752  0.73422027]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22669566 0.21231087 0.5609935 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.15, 0.24, 0.214, 0.144, 0.8, 0.029, 0.001, 0.47800000000000004, 0.09]
0.7975450000000001
0.6904761666666667
Reward 22.33498529032422
Current State [[0.06  0.15  0.24  0.214 0.144 0.8   0.029 0.001 0.478 0.09 ]]
Logits tf.Tensor([[-0.18314007 -0.271103    0.7586523 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22319591 0.20440166 0.5724024 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.1, 0.04, 0.25, 0.231, 0.138, 0.87, 0.027, 0.003, 0.43899999999999995, 0.07]
0.8691376666666667
3.0083328333333337
Reward 4.9379510648159295
Current State [[0.1   0.04  0.25  0.231 0.138 0.87  0.027 0.003 0.439 0.07 ]]
Logits tf.Tensor([[-0.17900111 -0.25795633  0.71898097]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22837694 0.21103884 0.5605842 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.04, 0.33, 0.204, 0.138, 0.87, 0.027, 0.003, 0.43899999999999995, 0.07]
0.8691376666666667
3.0083328333333337
Reward 4.9379510648159295
Current State [[0.05  0.04  0.33  0.204 0.138 0.87  0.027 0.003 0.439 0.07 ]]
Logits tf.Tensor([[-0.17154986 -0.24770851  0.73621947]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22699125 0.2103458  0.56266296]], shape=(1, 3), dtype=float32)
Selected action 1
[0.09, 0.08, 0.24, 0.238, 0.142, 0.94, 0.032, 0.001, 0.41600000000000004, 0.08]
0.9388638333333331
1.3708333333333333
Reward 13.001056202036942
Current State [[0.09  0.08  0.24  0.238 0.142 0.94  0.032 0.001 0.416 0.08 ]]
Logits tf.Tensor([[-0.18325976 -0.27442867  0.7452803 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22503896 0.20542987 0.5695312 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.15, 0.24, 0.233, 0.146, 0.94, 0.032, 0.001, 0.41600000000000004, 0.08]
0.9388638333333331
1.3708333333333333
Reward 19.001056202036942
Current State [[0.06  0.15  0.24  0.233 0.146 0.94  0.032 0.001 0.416 0.08 ]]
Logits tf.Tensor([[-0.18414526 -0.28302148  0.7734262 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2216697  0.20080057 0.5775297 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.14, 0.15, 0.27, 0.231, 0.147, 0.94, 0.032, 0.001, 0.41600000000000004, 0.08]
0.9388638333333331
1.3708333333333333
Reward 19.001056202036942
Current State [[0.14  0.15  0.27  0.231 0.147 0.94  0.032 0.001 0.416 0.08 ]]
Logits tf.Tensor([[-0.19959374 -0.3000106   0.7833244 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.21849789 0.19762267 0.5838794 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.02, 0.04, 0.3, 0.21, 0.139, 0.96, 0.026, 0.001, 0.44000000000000006, 0.05]
0.9572598333333334
0.9369048333333333
Reward 9.284411578993607
Current State [[0.02  0.04  0.3   0.21  0.139 0.96  0.026 0.001 0.44  0.05 ]]
Logits tf.Tensor([[-0.17169848 -0.25328916  0.7554844 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22476818 0.2071574  0.5680744 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.03, 0.04, 0.33, 0.224, 0.143, 0.96, 0.026, 0.001, 0.44000000000000006, 0.05]
0.9572598333333334
0.9369048333333333
Reward 9.284411578993607
Current State [[0.03  0.04  0.33  0.224 0.143 0.96  0.026 0.001 0.44  0.05 ]]
Logits tf.Tensor([[-0.17313391 -0.25257257  0.765472  ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22321181 0.20616615 0.570622  ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.15, 0.15, 0.27, 0.242, 0.141, 0.96, 0.026, 0.001, 0.44000000000000006, 0.05]
0.9572598333333334
0.9369048333333333
Reward 21.284411578993605
Current State [[0.15  0.15  0.27  0.242 0.141 0.96  0.026 0.001 0.44  0.05 ]]
Logits tf.Tensor([[-0.20257677 -0.30064967  0.79785115]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.21616817 0.19597434 0.58785754]], shape=(1, 3), dtype=float32)
Selected action 0
[0.11, 0.04, 0.25, 0.229, 0.141, 0.88, 0.031, 0.004, 0.496, 0.06]
0.8842308333333333
4.131548
Reward 4.614535218428567
Current State [[0.11  0.04  0.25  0.229 0.141 0.88  0.031 0.004 0.496 0.06 ]]
Logits tf.Tensor([[-0.19016285 -0.26810992  0.7496437 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22299032 0.20626904 0.57074064]], shape=(1, 3), dtype=float32)
Selected action 0
[0.03, 0.04, 0.33, 0.205, 0.143, 0.88, 0.031, 0.004, 0.496, 0.06]
0.8842308333333333
4.131548
Reward 4.614535218428567
Current State [[0.03  0.04  0.33  0.205 0.143 0.88  0.031 0.004 0.496 0.06 ]]
Logits tf.Tensor([[-0.17789783 -0.2508825   0.76675797]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22214605 0.20651032 0.5713436 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.06, 0.04, 0.23, 0.195, 0.143, 0.88, 0.031, 0.004, 0.496, 0.06]
0.8842308333333333
4.131548
Reward 4.614535218428567
Current State [[0.06  0.04  0.23  0.195 0.143 0.88  0.031 0.004 0.496 0.06 ]]
Logits tf.Tensor([[-0.18214515 -0.26223838  0.74178493]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22511362 0.20778666 0.56709975]], shape=(1, 3), dtype=float32)
Selected action 0
[0.13, 0.04, 0.26, 0.224, 0.139, 0.8, 0.028, 0.003, 0.5730000000000001, 0.07]
0.7953276666666665
2.7261904999999995
Reward 4.9505410967065
Current State [[0.13  0.04  0.26  0.224 0.139 0.8   0.028 0.003 0.573 0.07 ]]
Logits tf.Tensor([[-0.19605632 -0.27117616  0.7642384 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22025953 0.20431985 0.5754206 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.19, 0.15, 0.28, 0.226, 0.141, 0.8, 0.028, 0.003, 0.5730000000000001, 0.07]
0.7953276666666665
2.7261904999999995
Reward 16.9505410967065
Current State [[0.19  0.15  0.28  0.226 0.141 0.8   0.028 0.003 0.573 0.07 ]]
Logits tf.Tensor([[-0.20889375 -0.31308275  0.8126012 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.21374837 0.192599   0.59365267]], shape=(1, 3), dtype=float32)
Selected action 1
[0.11, 0.08, 0.33, 0.19, 0.142, 0.85, 0.037, 0.004, 0.634, 0.16]
0.8516266666666666
3.602976333333333
Reward 10.709001321879486
Current State [[0.11  0.08  0.33  0.19  0.142 0.85  0.037 0.004 0.634 0.16 ]]
Logits tf.Tensor([[-0.21295531 -0.31031933  0.83735883]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.20982946 0.1903627  0.5998078 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.2, 0.08, 0.26, 0.229, 0.139, 0.85, 0.037, 0.004, 0.634, 0.16]
0.8516266666666666
3.602976333333333
Reward 10.709001321879486
Current State [[0.2   0.08  0.26  0.229 0.139 0.85  0.037 0.004 0.634 0.16 ]]
Logits tf.Tensor([[-0.21783307 -0.32916838  0.82836026]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.21090673 0.18868533 0.60040796]], shape=(1, 3), dtype=float32)
Selected action 2
[0.13, 0.15, 0.25, 0.19, 0.14, 0.85, 0.037, 0.004, 0.634, 0.16]
0.8516266666666666
3.602976333333333
Reward 16.709001321879484
Current State [[0.13  0.15  0.25  0.19  0.14  0.85  0.037 0.004 0.634 0.16 ]]
Logits tf.Tensor([[-0.2152725  -0.33416176  0.84753245]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.20910071 0.18566178 0.6052375 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.06, 0.08, 0.23, 0.24, 0.141, 0.85, 0.037, 0.004, 0.634, 0.16]
0.8516266666666666
3.602976333333333
Reward 10.709001321879486
Episode: 132 | Average Reward: 283 | Episode Reward: 234 | Loss: 385.994 | Steps: 19 | Worker: 0
Current State [[-0.00751628 -0.00509255  0.00503734 -0.00597626  0.00760783  0.0095686
  -0.00412141 -0.00070492  0.00329299  0.00129957]]
Logits tf.Tensor([[-0.0508565  -0.03476034  0.08751209]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3159932  0.32112062 0.3628862 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.18, 0.04, 0.27, 0.239, 0.142, 0.86, 0.035, 0.001, 0.613, 0.12]
0.8623025
1.2898811666666667
Reward 6.9030620135456076
Current State [[0.18  0.04  0.27  0.239 0.142 0.86  0.035 0.001 0.613 0.12 ]]
Logits tf.Tensor([[-0.21368155 -0.30497435  0.81034666]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.21289559 0.19432051 0.5927839 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.27, 0.15, 0.28, 0.23, 0.145, 0.86, 0.035, 0.001, 0.613, 0.12]
0.8623025
1.2898811666666667
Reward 18.903062013545608
Current State [[0.27  0.15  0.28  0.23  0.145 0.86  0.035 0.001 0.613 0.12 ]]
Logits tf.Tensor([[-0.22744234 -0.3557529   0.85821396]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.20657049 0.18169528 0.6117342 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.21, 0.15, 0.27, 0.226, 0.14, 0.86, 0.035, 0.001, 0.613, 0.12]
0.8623025
1.2898811666666667
Reward 18.903062013545608
Current State [[0.21  0.15  0.27  0.226 0.14  0.86  0.035 0.001 0.613 0.12 ]]
Logits tf.Tensor([[-0.22258915 -0.34147638  0.85171217]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.20764746 0.18437183 0.60798067]], shape=(1, 3), dtype=float32)
Selected action 1
[0.09, 0.08, 0.28, 0.222, 0.141, 0.86, 0.035, 0.001, 0.613, 0.12]
0.8623025
1.2898811666666667
Reward 12.903062013545608
Current State [[0.09  0.08  0.28  0.222 0.141 0.86  0.035 0.001 0.613 0.12 ]]
Logits tf.Tensor([[-0.20626591 -0.29385763  0.82439876]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.21190648 0.19413489 0.5939586 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.11, 0.04, 0.27, 0.24, 0.138, 0.87, 0.051, 0.004, 0.40199999999999997, 0.17]
0.8655348333333334
4.411904833333335
Reward 4.540361071932134
Current State [[0.11  0.04  0.27  0.24  0.138 0.87  0.051 0.004 0.402 0.17 ]]
Logits tf.Tensor([[-0.18536565 -0.27414623  0.7141439 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22865279 0.2092279  0.5621193 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.03, 0.15, 0.25, 0.225, 0.14, 0.87, 0.051, 0.004, 0.40199999999999997, 0.17]
0.8655348333333334
4.411904833333335
Reward 16.540361071932132
Current State [[0.03  0.15  0.25  0.225 0.14  0.87  0.051 0.004 0.402 0.17 ]]
Logits tf.Tensor([[-0.18109034 -0.28382498  0.75301474]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22485547 0.20290202 0.57224256]], shape=(1, 3), dtype=float32)
Selected action 1
[0.12, 0.08, 0.28, 0.212, 0.144, 0.97, 0.058, 0.0, 0.40700000000000003, 0.16]
0.9731419999999998
0.2654758333333333
Reward 44.11790910188464
Current State [[0.12  0.08  0.28  0.212 0.144 0.97  0.058 0.    0.407 0.16 ]]
Logits tf.Tensor([[-0.20288916 -0.3064761   0.7672728 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22026579 0.19859113 0.581143  ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.12, 0.04, 0.26, 0.188, 0.14, 0.97, 0.058, 0.0, 0.40700000000000003, 0.16]
0.9731419999999998
0.2654758333333333
Reward 38.11790910188464
Current State [[0.12  0.04  0.26  0.188 0.14  0.97  0.058 0.    0.407 0.16 ]]
Logits tf.Tensor([[-0.19990478 -0.30242676  0.7436784 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22362714 0.20183654 0.5745363 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.23, 0.15, 0.28, 0.226, 0.144, 0.97, 0.058, 0.0, 0.40700000000000003, 0.16]
0.9731419999999998
0.2654758333333333
Reward 50.11790910188464
Current State [[0.23  0.15  0.28  0.226 0.144 0.97  0.058 0.    0.407 0.16 ]]
Logits tf.Tensor([[-0.23190126 -0.343566    0.7987014 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.21289739 0.1904035  0.59669906]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.04, 0.35, 0.211, 0.145, 0.97, 0.053, 0.0, 0.404, 0.17]
0.9668954999999999
0.452381
Reward 20.51588381434142
Current State [[0.05  0.04  0.35  0.211 0.145 0.97  0.053 0.    0.404 0.17 ]]
Logits tf.Tensor([[-0.18405129 -0.27945387  0.76548   ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22254343 0.20229352 0.57516307]], shape=(1, 3), dtype=float32)
Selected action 1
[0.04, 0.08, 0.29, 0.205, 0.144, 0.97, 0.053, 0.0, 0.404, 0.17]
0.9668954999999999
0.452381
Reward 26.51588381434142
Current State [[0.04  0.08  0.29  0.205 0.144 0.97  0.053 0.    0.404 0.17 ]]
Logits tf.Tensor([[-0.18543935 -0.28888392  0.7652568 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22275504 0.20086397 0.57638097]], shape=(1, 3), dtype=float32)
Selected action 0
[0.19, 0.04, 0.28, 0.236, 0.138, 0.97, 0.053, 0.0, 0.404, 0.17]
0.9668954999999999
0.452381
Reward 20.51588381434142
Current State [[0.19  0.04  0.28  0.236 0.138 0.97  0.053 0.    0.404 0.17 ]]
Logits tf.Tensor([[-0.21103238 -0.3104168   0.750612  ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22117096 0.20024699 0.57858205]], shape=(1, 3), dtype=float32)
Selected action 1
[0.03, 0.08, 0.31, 0.225, 0.139, 0.94, 0.04, 0.0, 0.369, 0.01]
0.9420914999999999
0.1779766666666667
Reward 53.11575087266204
Current State [[0.03  0.08  0.31  0.225 0.139 0.94  0.04  0.    0.369 0.01 ]]
Logits tf.Tensor([[-0.17133048 -0.24713597  0.73941994]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22659379 0.21005163 0.5633546 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.1, 0.15, 0.25, 0.222, 0.138, 0.94, 0.04, 0.0, 0.369, 0.01]
0.9420914999999999
0.1779766666666667
Reward 59.11575087266204
Current State [[0.1   0.15  0.25  0.222 0.138 0.94  0.04  0.    0.369 0.01 ]]
Logits tf.Tensor([[-0.19076578 -0.2783479   0.7532853 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22289005 0.20419933 0.5729106 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.1, 0.15, 0.22, 0.2, 0.14, 0.94, 0.04, 0.0, 0.369, 0.01]
0.9420914999999999
0.1779766666666667
Reward 59.11575087266204
Current State [[0.1   0.15  0.22  0.2   0.14  0.94  0.04  0.    0.369 0.01 ]]
Logits tf.Tensor([[-0.19103844 -0.28280455  0.74511176]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22409147 0.2044428  0.57146573]], shape=(1, 3), dtype=float32)
Selected action 2
[0.2, 0.15, 0.26, 0.3, 0.146, 0.94, 0.04, 0.0, 0.369, 0.01]
0.9420914999999999
0.1779766666666667
Reward 59.11575087266204
Current State [[0.2   0.15  0.26  0.3   0.146 0.94  0.04  0.    0.369 0.01 ]]
Logits tf.Tensor([[-0.20620483 -0.28935257  0.7655313 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2191664  0.20168024 0.57915336]], shape=(1, 3), dtype=float32)
Selected action 0
[0.16, 0.04, 0.27, 0.231, 0.142, 0.96, 0.048, 0.001, 0.43099999999999994, 0.13]
0.9645201666666666
0.7505950000000001
Reward 11.440943450594473
Current State [[0.16  0.04  0.27  0.231 0.142 0.96  0.048 0.001 0.431 0.13 ]]
Logits tf.Tensor([[-0.20326918 -0.2988184   0.75614846]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22128548 0.2011205  0.577594  ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.18, 0.15, 0.28, 0.218, 0.141, 0.96, 0.048, 0.001, 0.43099999999999994, 0.13]
0.9645201666666666
0.7505950000000001
Reward 23.440943450594474
Current State [[0.18  0.15  0.28  0.218 0.141 0.96  0.048 0.001 0.431 0.13 ]]
Logits tf.Tensor([[-0.21893416 -0.32792696  0.80181646]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.21404046 0.19193797 0.59402156]], shape=(1, 3), dtype=float32)
Selected action 1
[0.08, 0.08, 0.3, 0.225, 0.144, 0.97, 0.056, 0.003, 0.389, 0.18]
0.9681688333333334
2.7898821666666667
Reward 11.202694049179382
Current State [[0.08  0.08  0.3   0.225 0.144 0.97  0.056 0.003 0.389 0.18 ]]
Logits tf.Tensor([[-0.191561  -0.2962143  0.7628091]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2223373  0.20024513 0.57741755]], shape=(1, 3), dtype=float32)
Selected action 2
[0.13, 0.15, 0.24, 0.223, 0.14, 0.97, 0.056, 0.003, 0.389, 0.18]
0.9681688333333334
2.7898821666666667
Reward 17.20269404917938
Episode: 133 | Average Reward: 286 | Episode Reward: 572 | Loss: 3239.746 | Steps: 19 | Worker: 0
Saving best model to ./Training/, episode score: 572.3446274369206
Current State [[ 0.009592    0.00257681  0.00381286  0.00904875  0.00024283 -0.00994024
  -0.00943001 -0.00033768  0.00394565  0.00165587]]
Logits tf.Tensor([[-0.05007275 -0.0322456   0.07749976]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.31705225 0.32275507 0.3601927 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.08, 0.08, 0.25, 0.229, 0.144, 0.97, 0.056, 0.003, 0.389, 0.18]
0.9681688333333334
2.7898821666666667
Reward 11.202694049179382
Current State [[0.08  0.08  0.25  0.229 0.144 0.97  0.056 0.003 0.389 0.18 ]]
Logits tf.Tensor([[-0.18951304 -0.29507372  0.7459547 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2248088 0.2022874 0.5729038]], shape=(1, 3), dtype=float32)
Selected action 0
[0.07, 0.04, 0.26, 0.231, 0.137, 0.97, 0.056, 0.003, 0.389, 0.18]
0.9681688333333334
2.7898821666666667
Reward 5.202694049179381
Current State [[0.07  0.04  0.26  0.231 0.137 0.97  0.056 0.003 0.389 0.18 ]]
Logits tf.Tensor([[-0.18348928 -0.28309336  0.7289891 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22749594 0.20592834 0.5665757 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.02, 0.04, 0.37, 0.239, 0.139, 0.89, 0.057, 0.007, 0.368, 0.18]
0.8884631666666667
6.765477166666667
Reward 4.279631701453442
Current State [[0.02  0.04  0.37  0.239 0.139 0.89  0.057 0.007 0.368 0.18 ]]
Logits tf.Tensor([[-0.16543154 -0.25188205  0.7227211 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23000053 0.21095209 0.55904734]], shape=(1, 3), dtype=float32)
Selected action 0
[0.06, 0.04, 0.38, 0.0, 0.139, 0.89, 0.057, 0.007, 0.368, 0.18]
0.8884631666666667
6.765477166666667
Reward 4.279631701453442
Current State [[0.06  0.04  0.38  0.    0.139 0.89  0.057 0.007 0.368 0.18 ]]
Logits tf.Tensor([[-0.18289323 -0.29879248  0.71117973]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23064683 0.205406   0.5639472 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.18, 0.15, 0.25, 0.207, 0.145, 0.89, 0.057, 0.007, 0.368, 0.18]
0.8884631666666667
6.765477166666667
Reward 16.279631701453443
Current State [[0.18  0.15  0.25  0.207 0.145 0.89  0.057 0.007 0.368 0.18 ]]
Logits tf.Tensor([[-0.20860477 -0.31992954  0.7405065 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22331095 0.19978473 0.5769043 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.11, 0.15, 0.26, 0.258, 0.147, 0.72, 0.066, 0.001, 0.46399999999999997, 0.0]
0.7221988333333332
0.9577373333333334
Reward 19.428049735120613
Current State [[0.11  0.15  0.26  0.258 0.147 0.72  0.066 0.001 0.464 0.   ]]
Logits tf.Tensor([[-0.19045568 -0.2572581   0.737818  ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22393821 0.20946732 0.5665945 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.13, 0.04, 0.27, 0.237, 0.143, 0.72, 0.066, 0.001, 0.46399999999999997, 0.0]
0.7221988333333332
0.9577373333333334
Reward 7.428049735120612
Current State [[0.13  0.04  0.27  0.237 0.143 0.72  0.066 0.001 0.464 0.   ]]
Logits tf.Tensor([[-0.18957505 -0.23727155  0.6951326 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2285349  0.21789046 0.5535747 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.03, 0.04, 0.32, 0.22, 0.143, 0.96, 0.038, 0.001, 0.45599999999999996, 0.09]
0.9630783333333334
0.5374996666666667
Reward 16.499555730371785
Current State [[0.03  0.04  0.32  0.22  0.143 0.96  0.038 0.001 0.456 0.09 ]]
Logits tf.Tensor([[-0.17776263 -0.26217672  0.7690133 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2223983  0.20439531 0.5732064 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.25, 0.1, 0.143, 0.96, 0.038, 0.001, 0.45599999999999996, 0.09]
0.9630783333333334
0.5374996666666667
Reward 28.499555730371785
Current State [[0.04  0.15  0.25  0.1   0.143 0.96  0.038 0.001 0.456 0.09 ]]
Logits tf.Tensor([[-0.18906702 -0.3075843   0.78887916]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.21991432 0.1953359  0.5847498 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.25, 0.19, 0.147, 0.96, 0.038, 0.001, 0.45599999999999996, 0.09]
0.9630783333333334
0.5374996666666667
Reward 28.499555730371785
Current State [[0.04  0.15  0.25  0.19  0.147 0.96  0.038 0.001 0.456 0.09 ]]
Logits tf.Tensor([[-0.18692225 -0.29436833  0.7952236 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.21889958 0.19659917 0.58450127]], shape=(1, 3), dtype=float32)
Selected action 2
[0.19, 0.15, 0.28, 0.244, 0.143, 0.78, 0.02, 0.004, 0.8380000000000001, 0.07]
0.7760014999999999
4.234523833333333
Reward 16.487284188382517
Current State [[0.19  0.15  0.28  0.244 0.143 0.78  0.02  0.004 0.838 0.07 ]]
Logits tf.Tensor([[-0.2251752  -0.34300548  0.9220499 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.19848008 0.17641841 0.62510145]], shape=(1, 3), dtype=float32)
Selected action 1
[0.09, 0.08, 0.27, 0.205, 0.145, 0.78, 0.02, 0.004, 0.8380000000000001, 0.07]
0.7760014999999999
4.234523833333333
Reward 10.487284188382517
Current State [[0.09  0.08  0.27  0.205 0.145 0.78  0.02  0.004 0.838 0.07 ]]
Logits tf.Tensor([[-0.21332918 -0.305872    0.885463  ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.20357683 0.18558274 0.61084044]], shape=(1, 3), dtype=float32)
Selected action 2
[0.25, 0.15, 0.26, 0.1, 0.143, 0.93, 0.047, 0.0, 0.45599999999999996, 0.17]
0.9299114999999999
0.48869016666666665
Reward 29.749973705812504
Current State [[0.25  0.15  0.26  0.1   0.143 0.93  0.047 0.    0.456 0.17 ]]
Logits tf.Tensor([[-0.23314528 -0.36496228  0.79031384]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.21462427 0.18811847 0.59725726]], shape=(1, 3), dtype=float32)
Selected action 2
[0.16, 0.15, 0.27, 0.24, 0.143, 0.93, 0.047, 0.0, 0.45599999999999996, 0.17]
0.9299114999999999
0.48869016666666665
Reward 29.749973705812504
Current State [[0.16  0.15  0.27  0.24  0.143 0.93  0.047 0.    0.456 0.17 ]]
Logits tf.Tensor([[-0.21133609 -0.3214696   0.7982634 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.21550721 0.19303295 0.5914599 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.07, 0.04, 0.22, 0.244, 0.145, 0.93, 0.047, 0.0, 0.45599999999999996, 0.17]
0.9299114999999999
0.48869016666666665
Reward 17.749973705812504
Current State [[0.07  0.04  0.22  0.244 0.145 0.93  0.047 0.    0.456 0.17 ]]
Logits tf.Tensor([[-0.18540363 -0.27895075  0.74075   ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22545503 0.2053208  0.5692242 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.15, 0.23, 0.206, 0.145, 0.83, 0.018, 0.001, 0.46900000000000003, 0.07]
0.8301800000000001
0.9714283333333333
Reward 20.086562597448733
Current State [[0.08  0.15  0.23  0.206 0.145 0.83  0.018 0.001 0.469 0.07 ]]
Logits tf.Tensor([[-0.18054385 -0.27504212  0.7555315 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22422613 0.20400752 0.5717663 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.19, 0.15, 0.22, 0.183, 0.139, 0.83, 0.018, 0.001, 0.46900000000000003, 0.07]
0.8301800000000001
0.9714283333333333
Reward 20.086562597448733
Current State [[0.19  0.15  0.22  0.183 0.139 0.83  0.018 0.001 0.469 0.07 ]]
Logits tf.Tensor([[-0.19590473 -0.30415547  0.7527046 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22323826 0.20033458 0.5764271 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.18, 0.15, 0.28, 0.2, 0.14, 0.83, 0.018, 0.001, 0.46900000000000003, 0.07]
0.8301800000000001
0.9714283333333333
Reward 20.086562597448733
Current State [[0.18  0.15  0.28  0.2   0.14  0.83  0.018 0.001 0.469 0.07 ]]
Logits tf.Tensor([[-0.19587098 -0.29601228  0.7686306 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22083881 0.199795   0.57936615]], shape=(1, 3), dtype=float32)
Selected action 2
[0.22, 0.15, 0.27, 0.22, 0.143, 0.78, 0.026, 0.0, 0.352, 0.0]
0.7843046666666668
0.37559283333333343
Reward 31.9237652219632
Current State [[0.22  0.15  0.27  0.22  0.143 0.78  0.026 0.    0.352 0.   ]]
Logits tf.Tensor([[-0.19089022 -0.27041054  0.7003617 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22926635 0.21174105 0.5589926 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.14, 0.15, 0.27, 0.246, 0.142, 0.78, 0.026, 0.0, 0.352, 0.0]
0.7843046666666668
0.37559283333333343
Reward 31.9237652219632
Episode: 134 | Average Reward: 287 | Episode Reward: 369 | Loss: 1400.973 | Steps: 19 | Worker: 0
Current State [[-0.00136212 -0.00257438  0.00358808 -0.00118135  0.00693052  0.00551915
   0.00444411 -0.00523313 -0.00552995 -0.00159018]]
Logits tf.Tensor([[-0.05211466 -0.0346239   0.08359435]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.31615624 0.3217347  0.36210907]], shape=(1, 3), dtype=float32)
Selected action 0
[0.09, 0.04, 0.24, 0.216, 0.142, 0.78, 0.026, 0.0, 0.352, 0.0]
0.7843046666666668
0.37559283333333343
Reward 19.9237652219632
Current State [[0.09  0.04  0.24  0.216 0.142 0.78  0.026 0.    0.352 0.   ]]
Logits tf.Tensor([[-0.15476638 -0.22283185  0.6429094 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24069859 0.22486046 0.534441  ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.16, 0.15, 0.25, 0.221, 0.139, 0.83, 0.033, 0.001, 0.507, 0.1]
0.8250825
0.6333331666666666
Reward 23.598347913251647
Current State [[0.16  0.15  0.25  0.221 0.139 0.83  0.033 0.001 0.507 0.1  ]]
Logits tf.Tensor([[-0.19512732 -0.30596846  0.77871364]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2201103 0.1970165 0.5828732]], shape=(1, 3), dtype=float32)
Selected action 1
[0.11, 0.08, 0.26, 0.181, 0.141, 0.83, 0.033, 0.001, 0.507, 0.1]
0.8250825
0.6333331666666666
Reward 17.598347913251647
Current State [[0.11  0.08  0.26  0.181 0.141 0.83  0.033 0.001 0.507 0.1  ]]
Logits tf.Tensor([[-0.18667981 -0.2823686   0.75051147]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22413746 0.2036842  0.57217836]], shape=(1, 3), dtype=float32)
Selected action 2
[0.1, 0.15, 0.23, 0.22, 0.138, 0.83, 0.033, 0.001, 0.507, 0.1]
0.8250825
0.6333331666666666
Reward 23.598347913251647
Current State [[0.1   0.15  0.23  0.22  0.138 0.83  0.033 0.001 0.507 0.1  ]]
Logits tf.Tensor([[-0.18736719 -0.29310194  0.77192193]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2217539  0.19950382 0.5787423 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.12, 0.04, 0.27, 0.23, 0.144, 0.7, 0.014, 0.002, 0.42300000000000004, 0.05]
0.6973311666666667
2.0625
Reward 5.16122168440553
Current State [[0.12  0.04  0.27  0.23  0.144 0.7   0.014 0.002 0.423 0.05 ]]
Logits tf.Tensor([[-0.15993112 -0.2271508   0.6597764 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23782198 0.22236113 0.53981686]], shape=(1, 3), dtype=float32)
Selected action 0
[0.02, 0.04, 0.31, 0.206, 0.145, 0.7, 0.014, 0.002, 0.42300000000000004, 0.05]
0.6973311666666667
2.0625
Reward 5.16122168440553
Current State [[0.02  0.04  0.31  0.206 0.145 0.7   0.014 0.002 0.423 0.05 ]]
Logits tf.Tensor([[-0.14515921 -0.2084515   0.6656314 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23875722 0.22411402 0.53712875]], shape=(1, 3), dtype=float32)
Selected action 2
[0.16, 0.15, 0.23, 0.2, 0.142, 0.98, 0.036, 0.001, 0.386, 0.07]
0.9848936666666667
1.0005961666666667
Reward 21.00483007802005
Current State [[0.16  0.15  0.23  0.2   0.142 0.98  0.036 0.001 0.386 0.07 ]]
Logits tf.Tensor([[-0.19891146 -0.31435823  0.7608277 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22212432 0.19790564 0.57997   ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.09, 0.04, 0.26, 0.241, 0.141, 0.98, 0.036, 0.001, 0.386, 0.07]
0.9848936666666667
1.0005961666666667
Reward 9.00483007802005
Current State [[0.09  0.04  0.26  0.241 0.141 0.98  0.036 0.001 0.386 0.07 ]]
Logits tf.Tensor([[-0.17296161 -0.2685356   0.7254362 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22912045 0.20823637 0.5626432 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.2, 0.333, 0.139, 0.98, 0.036, 0.001, 0.386, 0.07]
0.9848936666666667
1.0005961666666667
Reward 21.00483007802005
Current State [[0.04  0.15  0.2   0.333 0.139 0.98  0.036 0.001 0.386 0.07 ]]
Logits tf.Tensor([[-0.17736563 -0.27104583  0.76048046]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22396179 0.20393378 0.57210445]], shape=(1, 3), dtype=float32)
Selected action 1
[0.04, 0.08, 0.27, 0.233, 0.144, 0.97, 0.033, 0.001, 0.44400000000000006, 0.02]
0.9701156666666667
0.9404768333333332
Reward 15.35864740772594
Current State [[0.04  0.08  0.27  0.233 0.144 0.97  0.033 0.001 0.444 0.02 ]]
Logits tf.Tensor([[-0.17414883 -0.26501814  0.7661134 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22352414 0.20410818 0.57236767]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.15, 0.24, 0.21, 0.146, 0.97, 0.033, 0.001, 0.44400000000000006, 0.02]
0.9701156666666667
0.9404768333333332
Reward 21.35864740772594
Current State [[0.08  0.15  0.24  0.21  0.146 0.97  0.033 0.001 0.444 0.02 ]]
Logits tf.Tensor([[-0.1858456  -0.29188764  0.78656286]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22008532 0.19794185 0.58197284]], shape=(1, 3), dtype=float32)
Selected action 2
[0.1, 0.15, 0.21, 0.217, 0.139, 0.97, 0.033, 0.001, 0.44400000000000006, 0.02]
0.9701156666666667
0.9404768333333332
Reward 21.35864740772594
Current State [[0.1   0.15  0.21  0.217 0.139 0.97  0.033 0.001 0.444 0.02 ]]
Logits tf.Tensor([[-0.18999377 -0.29556647  0.7774022 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22070703 0.19859418 0.5806988 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.1, 0.15, 0.26, 0.24, 0.145, 0.97, 0.033, 0.001, 0.44400000000000006, 0.02]
0.9701156666666667
0.9404768333333332
Reward 21.35864740772594
Current State [[0.1   0.15  0.26  0.24  0.145 0.97  0.033 0.001 0.444 0.02 ]]
Logits tf.Tensor([[-0.18957207 -0.29092866  0.7931568 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.21856263 0.19749552 0.5839419 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.2, 0.15, 0.28, 0.253, 0.142, 0.82, 0.037, 0.002, 0.518, 0.04]
0.8156741666666666
1.6910710000000002
Reward 17.868067565367564
Current State [[0.2   0.15  0.28  0.253 0.142 0.82  0.037 0.002 0.518 0.04 ]]
Logits tf.Tensor([[-0.20128931 -0.30253875  0.7910606 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.21733114 0.19640379 0.5862651 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.02, 0.04, 0.31, 0.233, 0.144, 0.82, 0.037, 0.002, 0.518, 0.04]
0.8156741666666666
1.6910710000000002
Reward 5.868067565367565
Current State [[0.02  0.04  0.31  0.233 0.144 0.82  0.037 0.002 0.518 0.04 ]]
Logits tf.Tensor([[-0.17244379 -0.23759265  0.75057805]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22452673 0.21036538 0.5651079 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.19, 0.15, 0.27, 0.227, 0.143, 0.82, 0.037, 0.002, 0.518, 0.04]
0.8156741666666666
1.6910710000000002
Reward 17.868067565367564
Current State [[0.19  0.15  0.27  0.227 0.143 0.82  0.037 0.002 0.518 0.04 ]]
Logits tf.Tensor([[-0.20028934 -0.3040228   0.7871922 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.21805823 0.19657199 0.58536977]], shape=(1, 3), dtype=float32)
Selected action 2
[0.22, 0.15, 0.28, 0.22, 0.142, 0.75, 0.033, 0.005, 0.735, 0.14]
0.7476934999999999
4.675595166666667
Reward 16.392851456091513
Current State [[0.22  0.15  0.28  0.22  0.142 0.75  0.033 0.005 0.735 0.14 ]]
Logits tf.Tensor([[-0.21241364 -0.3571311   0.8601218 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.20885341 0.1807139  0.6104327 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.21, 0.15, 0.28, 0.229, 0.142, 0.75, 0.033, 0.005, 0.735, 0.14]
0.7476934999999999
4.675595166666667
Reward 16.392851456091513
Current State [[0.21  0.15  0.28  0.229 0.142 0.75  0.033 0.005 0.735 0.14 ]]
Logits tf.Tensor([[-0.2116473  -0.35346276  0.8605757 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.20878358 0.18117848 0.6100379 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.06, 0.04, 0.36, 0.221, 0.143, 0.73, 0.026, 0.013, 0.63, 0.15]
0.7323613333333334
12.879166666666665
Reward 3.997097686290063
Current State [[0.06  0.04  0.36  0.221 0.143 0.73  0.026 0.013 0.63  0.15 ]]
Logits tf.Tensor([[-0.18216497 -0.26790312  0.77576077]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2210375  0.20287585 0.57608664]], shape=(1, 3), dtype=float32)
Selected action 2
[0.11, 0.15, 0.18, 0.2, 0.138, 0.73, 0.026, 0.013, 0.63, 0.15]
0.7323613333333334
12.879166666666665
Reward 15.997097686290063
Episode: 135 | Average Reward: 287 | Episode Reward: 319 | Loss: 742.307 | Steps: 19 | Worker: 0
Current State [[ 0.00012053 -0.00607597 -0.00356604  0.00608275  0.00085826  0.00261644
   0.00426753  0.00627356  0.00530669  0.001217  ]]
Logits tf.Tensor([[-0.04880882 -0.03626799  0.08127555]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.31730473 0.3213091  0.36138615]], shape=(1, 3), dtype=float32)
Selected action 0
[0.21, 0.04, 0.27, 0.15, 0.139, 0.73, 0.026, 0.013, 0.63, 0.15]
0.7323613333333334
12.879166666666665
Reward 3.997097686290063
Current State [[0.21  0.04  0.27  0.15  0.139 0.73  0.026 0.013 0.63  0.15 ]]
Logits tf.Tensor([[-0.18748394 -0.31765044  0.75465757]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22505195 0.19758417 0.5773639 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.22, 0.04, 0.29, 0.193, 0.145, 0.82, 0.037, 0.01, 0.40800000000000003, 0.14]
0.8187908333333331
9.766667000000002
Reward 4.097416438998971
Current State [[0.22  0.04  0.29  0.193 0.145 0.82  0.037 0.01  0.408 0.14 ]]
Logits tf.Tensor([[-0.18347046 -0.29603514  0.69413126]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2326304  0.2078645  0.55950516]], shape=(1, 3), dtype=float32)
Selected action 1
[0.11, 0.08, 0.27, 0.236, 0.133, 0.82, 0.037, 0.01, 0.40800000000000003, 0.14]
0.8187908333333331
9.766667000000002
Reward 10.097416438998971
Current State [[0.11  0.08  0.27  0.236 0.133 0.82  0.037 0.01  0.408 0.14 ]]
Logits tf.Tensor([[-0.16659802 -0.27378878  0.70144373]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23361236 0.20986667 0.556521  ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.0, 0.04, 0.17, 0.0, 0.138, 0.82, 0.037, 0.01, 0.40800000000000003, 0.14]
0.8187908333333331
9.766667000000002
Reward 4.097416438998971
Current State [[0.    0.04  0.17  0.    0.138 0.82  0.037 0.01  0.408 0.14 ]]
Logits tf.Tensor([[-0.14982289 -0.27809644  0.6486899 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24379267 0.21444313 0.54176426]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.46, 0.211, 0.144, 0.78, 0.066, 0.002, 0.375, 0.08]
0.7815473333333334
2.380955
Reward 5.1158072042329366
Current State [[0.04  0.04  0.46  0.211 0.144 0.78  0.066 0.002 0.375 0.08 ]]
Logits tf.Tensor([[-0.16105345 -0.2338902   0.70889455]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23166707 0.21539307 0.5529399 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.06, 0.08, 0.28, 0.212, 0.141, 0.78, 0.066, 0.002, 0.375, 0.08]
0.7815473333333334
2.380955
Reward 11.115807204232937
Current State [[0.06  0.08  0.28  0.212 0.141 0.78  0.066 0.002 0.375 0.08 ]]
Logits tf.Tensor([[-0.1660026  -0.24916524  0.6834182 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23482482 0.21608615 0.549089  ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.12, 0.08, 0.26, 0.162, 0.143, 0.78, 0.066, 0.002, 0.375, 0.08]
0.7815473333333334
2.380955
Reward 11.115807204232937
Current State [[0.12  0.08  0.26  0.162 0.143 0.78  0.066 0.002 0.375 0.08 ]]
Logits tf.Tensor([[-0.17671871 -0.27033478  0.67751753]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23473012 0.21375284 0.551517  ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.12, 0.15, 0.26, 0.247, 0.138, 0.74, 0.05, 0.002, 0.4, 0.02]
0.7393301666666666
1.9613061666666671
Reward 17.343867794229254
Current State [[0.12  0.15  0.26  0.247 0.138 0.74  0.05  0.002 0.4   0.02 ]]
Logits tf.Tensor([[-0.17364201 -0.25910336  0.7048839 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23119052 0.21225338 0.5565561 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.4, 0.2, 0.138, 0.74, 0.05, 0.002, 0.4, 0.02]
0.7393301666666666
1.9613061666666671
Reward 5.343867794229256
Current State [[0.04  0.04  0.4   0.2   0.138 0.74  0.05  0.002 0.4   0.02 ]]
Logits tf.Tensor([[-0.15636835 -0.22095066  0.6895973 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23431903 0.21966447 0.5460165 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.39, 0.223, 0.138, 0.74, 0.05, 0.002, 0.4, 0.02]
0.7393301666666666
1.9613061666666671
Reward 5.343867794229256
Current State [[0.04  0.04  0.39  0.223 0.138 0.74  0.05  0.002 0.4   0.02 ]]
Logits tf.Tensor([[-0.15657806 -0.21784455  0.68896955]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23420162 0.2202836  0.5455148 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.1, 0.15, 0.27, 0.186, 0.138, 0.74, 0.05, 0.002, 0.4, 0.02]
0.7393301666666666
1.9613061666666671
Reward 17.343867794229254
Current State [[0.1   0.15  0.27  0.186 0.138 0.74  0.05  0.002 0.4   0.02 ]]
Logits tf.Tensor([[-0.1728422  -0.26182473  0.70346016]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2316497 0.2119274 0.5564229]], shape=(1, 3), dtype=float32)
Selected action 2
[0.12, 0.15, 0.26, 0.225, 0.138, 0.91, 0.046, 0.001, 0.422, 0.17]
0.914373
0.5464291666666666
Reward 27.217805255416106
Current State [[0.12  0.15  0.26  0.225 0.138 0.91  0.046 0.001 0.422 0.17 ]]
Logits tf.Tensor([[-0.18865305 -0.31510442  0.7657772 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22329366 0.19677018 0.57993615]], shape=(1, 3), dtype=float32)
Selected action 2
[0.09, 0.15, 0.25, 0.224, 0.143, 0.91, 0.046, 0.001, 0.422, 0.17]
0.914373
0.5464291666666666
Reward 27.217805255416106
Current State [[0.09  0.15  0.25  0.224 0.143 0.91  0.046 0.001 0.422 0.17 ]]
Logits tf.Tensor([[-0.18270916 -0.3095107   0.7653424 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2241356  0.19744293 0.5784215 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.12, 0.04, 0.26, 0.234, 0.148, 0.91, 0.046, 0.001, 0.422, 0.17]
0.914373
0.5464291666666666
Reward 15.217805255416106
Current State [[0.12  0.04  0.26  0.234 0.148 0.91  0.046 0.001 0.422 0.17 ]]
Logits tf.Tensor([[-0.17682788 -0.28975344  0.72515553]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22947869 0.20497428 0.56554705]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.15, 0.26, 0.206, 0.15, 0.94, 0.055, 0.0, 0.41500000000000004, 0.19]
0.9362085
0.20118966666666666
Reward 56.79912975281241
Current State [[0.07  0.15  0.26  0.206 0.15  0.94  0.055 0.    0.415 0.19 ]]
Logits tf.Tensor([[-0.1846601  -0.31770033  0.7774369 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22258781 0.19486003 0.5825522 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.07, 0.04, 0.38, 0.162, 0.148, 0.94, 0.055, 0.0, 0.41500000000000004, 0.19]
0.9362085
0.20118966666666666
Reward 44.79912975281241
Current State [[0.07  0.04  0.38  0.162 0.148 0.94  0.055 0.    0.415 0.19 ]]
Logits tf.Tensor([[-0.17605913 -0.29468733  0.7583247 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22554107 0.20031157 0.57414734]], shape=(1, 3), dtype=float32)
Selected action 1
[0.21, 0.08, 0.29, 0.244, 0.143, 0.94, 0.055, 0.0, 0.41500000000000004, 0.19]
0.9362085
0.20118966666666666
Reward 50.79912975281241
Current State [[0.21  0.08  0.29  0.244 0.143 0.94  0.055 0.    0.415 0.19 ]]
Logits tf.Tensor([[-0.2040574  -0.3251212   0.75615215]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22231011 0.19696172 0.5807282 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.13, 0.04, 0.27, 0.242, 0.137, 0.88, 0.065, 0.007, 0.43200000000000005, 0.07]
0.8808435
6.816666333333333
Reward 4.271405398956506
Current State [[0.13  0.04  0.27  0.242 0.137 0.88  0.065 0.007 0.432 0.07 ]]
Logits tf.Tensor([[-0.18459529 -0.27527174  0.7202581 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22805627 0.20828678 0.5636569 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.21, 0.15, 0.28, 0.157, 0.139, 0.88, 0.065, 0.007, 0.43200000000000005, 0.07]
0.8808435
6.816666333333333
Reward 16.271405398956507
Current State [[0.21  0.15  0.28  0.157 0.139 0.88  0.065 0.007 0.432 0.07 ]]
Logits tf.Tensor([[-0.21111864 -0.32906076  0.7639565 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2202588  0.19575445 0.58398676]], shape=(1, 3), dtype=float32)
Selected action 2
[0.1, 0.15, 0.25, 0.19, 0.141, 0.88, 0.065, 0.007, 0.43200000000000005, 0.07]
0.8808435
6.816666333333333
Reward 16.271405398956507
Episode: 136 | Average Reward: 288 | Episode Reward: 353 | Loss: 1465.23 | Steps: 19 | Worker: 0
Current State [[-7.13699647e-03  9.63061202e-03  9.75445545e-03 -6.71726180e-04
   4.36284129e-05  5.26788182e-03 -3.13209902e-03  3.87685464e-03
  -8.95519819e-03  3.88948141e-03]]
Logits tf.Tensor([[-0.04502678 -0.03606837  0.07764333]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.31852102 0.32138732 0.36009166]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.15, 0.25, 0.224, 0.143, 0.94, 0.052, 0.001, 0.41100000000000003, 0.15]
0.9379065
0.8571426666666666
Reward 21.84506124966014
Current State [[0.07  0.15  0.25  0.224 0.143 0.94  0.052 0.001 0.411 0.15 ]]
Logits tf.Tensor([[-0.17110963 -0.31148356  0.7614452 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22675605 0.19705853 0.57618546]], shape=(1, 3), dtype=float32)
Selected action 2
[0.29, 0.15, 0.29, 0.237, 0.141, 0.94, 0.052, 0.001, 0.41100000000000003, 0.15]
0.9379065
0.8571426666666666
Reward 21.84506124966014
Current State [[0.29  0.15  0.29  0.237 0.141 0.94  0.052 0.001 0.411 0.15 ]]
Logits tf.Tensor([[-0.20940861 -0.35702085  0.7713675 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22078514 0.19048579 0.588729  ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.04, 0.08, 0.29, 0.232, 0.144, 0.9, 0.039, 0.001, 0.45499999999999996, 0.18]
0.8991043333333333
1.138095333333333
Reward 13.658237187227709
Current State [[0.04  0.08  0.29  0.232 0.144 0.9   0.039 0.001 0.455 0.18 ]]
Logits tf.Tensor([[-0.15764925 -0.28691658  0.7487363 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22966868 0.20181882 0.5685125 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.04, 0.35, 0.167, 0.14, 0.9, 0.039, 0.001, 0.45499999999999996, 0.18]
0.8991043333333333
1.138095333333333
Reward 7.6582371872277095
Current State [[0.05  0.04  0.35  0.167 0.14  0.9   0.039 0.001 0.455 0.18 ]]
Logits tf.Tensor([[-0.15699719 -0.28681046  0.7436385 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23044518 0.20239067 0.5671641 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.15, 0.25, 0.234, 0.137, 0.9, 0.039, 0.001, 0.45499999999999996, 0.18]
0.8991043333333333
1.138095333333333
Reward 19.65823718722771
Current State [[0.08  0.15  0.25  0.234 0.137 0.9   0.039 0.001 0.455 0.18 ]]
Logits tf.Tensor([[-0.16981095 -0.3126144   0.76648676]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22637516 0.19625017 0.57737464]], shape=(1, 3), dtype=float32)
Selected action 2
[0.1, 0.15, 0.26, 0.231, 0.144, 0.87, 0.041, 0.001, 0.454, 0.13]
0.8652185
0.8863096666666667
Reward 20.945156465010555
Current State [[0.1   0.15  0.26  0.231 0.144 0.87  0.041 0.001 0.454 0.13 ]]
Logits tf.Tensor([[-0.17128563 -0.30351675  0.7603315 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22651342 0.19845712 0.57502943]], shape=(1, 3), dtype=float32)
Selected action 2
[0.12, 0.15, 0.25, 0.232, 0.143, 0.87, 0.041, 0.001, 0.454, 0.13]
0.8652185
0.8863096666666667
Reward 20.945156465010555
Current State [[0.12  0.15  0.25  0.232 0.143 0.87  0.041 0.001 0.454 0.13 ]]
Logits tf.Tensor([[-0.17418048 -0.30786592  0.7577964 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2265319  0.19818485 0.5752833 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.03, 0.04, 0.31, 0.219, 0.144, 0.87, 0.041, 0.001, 0.454, 0.13]
0.8652185
0.8863096666666667
Reward 8.945156465010557
Current State [[0.03  0.04  0.31  0.219 0.144 0.87  0.041 0.001 0.454 0.13 ]]
Logits tf.Tensor([[-0.15328953 -0.26472107  0.72781944]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23211941 0.20764303 0.5602376 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.37, 0.213, 0.148, 0.81, 0.045, 0.001, 0.43, 0.07]
0.8143511666666668
0.9059526666666665
Reward 8.391321887121403
Current State [[0.04  0.04  0.37  0.213 0.148 0.81  0.045 0.001 0.43  0.07 ]]
Logits tf.Tensor([[-0.1509428  -0.24397224  0.71554655]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23311587 0.21240741 0.55447674]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.15, 0.25, 0.218, 0.146, 0.81, 0.045, 0.001, 0.43, 0.07]
0.8143511666666668
0.9059526666666665
Reward 20.391321887121403
Current State [[0.07  0.15  0.25  0.218 0.146 0.81  0.045 0.001 0.43  0.07 ]]
Logits tf.Tensor([[-0.16310608 -0.27758825  0.7291106 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.230821   0.2058526  0.56332636]], shape=(1, 3), dtype=float32)
Selected action 1
[0.08, 0.08, 0.26, 0.231, 0.141, 0.81, 0.045, 0.001, 0.43, 0.07]
0.8143511666666668
0.9059526666666665
Reward 14.391321887121403
Current State [[0.08  0.08  0.26  0.231 0.141 0.81  0.045 0.001 0.43  0.07 ]]
Logits tf.Tensor([[-0.16001782 -0.26252046  0.7030178 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23403195 0.21123156 0.5547365 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.08, 0.26, 0.231, 0.141, 0.81, 0.045, 0.001, 0.43, 0.07]
0.8143511666666668
0.9059526666666665
Reward 20.391321887121403
Current State [[0.08  0.08  0.26  0.231 0.141 0.81  0.045 0.001 0.43  0.07 ]]
Logits tf.Tensor([[-0.16001782 -0.26252046  0.7030178 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23403195 0.21123156 0.5547365 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.16, 0.15, 0.27, 0.213, 0.139, 0.85, 0.035, 0.001, 0.449, 0.05]
0.8492255
0.6803561666666667
Reward 23.119497977381368
Current State [[0.16  0.15  0.27  0.213 0.139 0.85  0.035 0.001 0.449 0.05 ]]
Logits tf.Tensor([[-0.1773855  -0.30127993  0.75140035]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22650535 0.20011137 0.5733833 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.15, 0.23, 0.221, 0.146, 0.85, 0.035, 0.001, 0.449, 0.05]
0.8492255
0.6803561666666667
Reward 23.119497977381368
Current State [[0.06  0.15  0.23  0.221 0.146 0.85  0.035 0.001 0.449 0.05 ]]
Logits tf.Tensor([[-0.16210626 -0.28060785  0.7428244 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22935723 0.20372666 0.5669161 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.2, 0.15, 0.15, 0.192, 0.139, 0.85, 0.035, 0.001, 0.449, 0.05]
0.8492255
0.6803561666666667
Reward 23.119497977381368
Current State [[0.2   0.15  0.15  0.192 0.139 0.85  0.035 0.001 0.449 0.05 ]]
Logits tf.Tensor([[-0.17948975 -0.3199205   0.7213281 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23091494 0.20066133 0.56842375]], shape=(1, 3), dtype=float32)
Selected action 2
[0.12, 0.15, 0.27, 0.224, 0.135, 0.87, 0.021, 0.001, 0.492, 0.09]
0.8716670000000002
0.9410718333333334
Reward 20.58411689004682
Current State [[0.12  0.15  0.27  0.224 0.135 0.87  0.021 0.001 0.492 0.09 ]]
Logits tf.Tensor([[-0.17260818 -0.30412468  0.7740267 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22452797 0.19685823 0.57861376]], shape=(1, 3), dtype=float32)
Selected action 2
[0.12, 0.15, 0.26, 0.223, 0.139, 0.87, 0.021, 0.001, 0.492, 0.09]
0.8716670000000002
0.9410718333333334
Reward 20.58411689004682
Current State [[0.12  0.15  0.26  0.223 0.139 0.87  0.021 0.001 0.492 0.09 ]]
Logits tf.Tensor([[-0.17196053 -0.3047915   0.7728018 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2248295  0.19686364 0.57830685]], shape=(1, 3), dtype=float32)
Selected action 1
[0.22, 0.08, 0.26, 0.223, 0.139, 0.87, 0.021, 0.001, 0.492, 0.09]
0.8716670000000002
0.9410718333333334
Reward 14.584116890046818
Current State [[0.22  0.08  0.26  0.223 0.139 0.87  0.021 0.001 0.492 0.09 ]]
Logits tf.Tensor([[-0.17994572 -0.3119752   0.74650943]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22717692 0.19907856 0.57374454]], shape=(1, 3), dtype=float32)
Selected action 2
[0.15, 0.15, 0.27, 0.227, 0.138, 0.87, 0.021, 0.001, 0.492, 0.09]
0.8716670000000002
0.9410718333333334
Reward 20.58411689004682
Current State [[0.15  0.15  0.27  0.227 0.138 0.87  0.021 0.001 0.492 0.09 ]]
Logits tf.Tensor([[-0.17575447 -0.3106759   0.7756034 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22406414 0.1957838  0.5801521 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.09, 0.15, 0.27, 0.235, 0.142, 0.8, 0.018, 0.001, 0.43, 0.07]
0.7971360000000001
1.3791661666666666
Reward 18.381846327526773
Episode: 137 | Average Reward: 289 | Episode Reward: 363 | Loss: 1062.1 | Steps: 19 | Worker: 0
Current State [[ 0.00871919 -0.00229214 -0.00625272 -0.00460562  0.00583703 -0.0060684
   0.00347677 -0.00544367 -0.00139639 -0.00263466]]
Logits tf.Tensor([[-0.04544502 -0.03480812  0.07451714]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3186593  0.32206693 0.3592738 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.15, 0.24, 0.236, 0.144, 0.8, 0.018, 0.001, 0.43, 0.07]
0.7971360000000001
1.3791661666666666
Reward 18.381846327526773
Current State [[0.07  0.15  0.24  0.236 0.144 0.8   0.018 0.001 0.43  0.07 ]]
Logits tf.Tensor([[-0.1450964  -0.27442726  0.71639305]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23555093 0.20697464 0.55747443]], shape=(1, 3), dtype=float32)
Selected action 2
[0.17, 0.15, 0.24, 0.233, 0.144, 0.86, 0.027, 0.001, 0.457, 0.13]
0.8647091666666668
1.0994050000000004
Reward 19.63567470192644
Current State [[0.17  0.15  0.24  0.233 0.144 0.86  0.027 0.001 0.457 0.13 ]]
Logits tf.Tensor([[-0.16699034 -0.32056668  0.74857163]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22957821 0.19689438 0.5735274 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.07, 0.08, 0.25, 0.229, 0.138, 0.86, 0.027, 0.001, 0.457, 0.13]
0.8647091666666668
1.0994050000000004
Reward 13.63567470192644
Current State [[0.07  0.08  0.25  0.229 0.138 0.86  0.027 0.001 0.457 0.13 ]]
Logits tf.Tensor([[-0.14937764 -0.28390676  0.72026104]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23473209 0.20518576 0.56008214]], shape=(1, 3), dtype=float32)
Selected action 2
[0.13, 0.15, 0.26, 0.173, 0.139, 0.86, 0.027, 0.001, 0.457, 0.13]
0.8647091666666668
1.0994050000000004
Reward 19.63567470192644
Current State [[0.13  0.15  0.26  0.173 0.139 0.86  0.027 0.001 0.457 0.13 ]]
Logits tf.Tensor([[-0.16408478 -0.3193676   0.74874103]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23001589 0.1969334  0.57305074]], shape=(1, 3), dtype=float32)
Selected action 0
[0.02, 0.04, 0.31, 0.225, 0.139, 0.99, 0.048, 0.001, 0.438, 0.14]
0.9920498333333333
0.5178571666666666
Reward 17.896985422378954
Current State [[0.02  0.04  0.31  0.225 0.139 0.99  0.048 0.001 0.438 0.14 ]]
Logits tf.Tensor([[-0.14956646 -0.28860837  0.75097257]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23088712 0.20091602 0.5681969 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.11, 0.08, 0.27, 0.209, 0.138, 0.99, 0.048, 0.001, 0.438, 0.14]
0.9920498333333333
0.5178571666666666
Reward 23.896985422378954
Current State [[0.11  0.08  0.27  0.209 0.138 0.99  0.048 0.001 0.438 0.14 ]]
Logits tf.Tensor([[-0.16721094 -0.32083857  0.75659657]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22849548 0.19595574 0.57554877]], shape=(1, 3), dtype=float32)
Selected action 2
[0.12, 0.15, 0.21, 0.209, 0.141, 0.99, 0.048, 0.001, 0.438, 0.14]
0.9920498333333333
0.5178571666666666
Reward 29.896985422378954
Current State [[0.12  0.15  0.21  0.209 0.141 0.99  0.048 0.001 0.438 0.14 ]]
Logits tf.Tensor([[-0.17731817 -0.34114146  0.7733259 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22541472 0.19135275 0.5832325 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.14, 0.15, 0.27, 0.235, 0.143, 0.97, 0.033, 0.001, 0.46299999999999997, 0.14]
0.9690423333333332
0.7910713333333333
Reward 22.919910480010756
Current State [[0.14  0.15  0.27  0.235 0.143 0.97  0.033 0.001 0.463 0.14 ]]
Logits tf.Tensor([[-0.17328359 -0.3346255   0.7906932 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22355838 0.1902484  0.5861932 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.18, 0.15, 0.25, 0.238, 0.143, 0.97, 0.033, 0.001, 0.46299999999999997, 0.14]
0.9690423333333332
0.7910713333333333
Reward 22.919910480010756
Current State [[0.18  0.15  0.25  0.238 0.143 0.97  0.033 0.001 0.463 0.14 ]]
Logits tf.Tensor([[-0.18043432 -0.3437654   0.7861359 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22330289 0.18965338 0.58704376]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.15, 0.25, 0.227, 0.138, 0.83, 0.042, 0.002, 0.517, 0.15]
0.8291213333333333
1.8345236666666667
Reward 17.712501377303827
Current State [[0.08  0.15  0.25  0.227 0.138 0.83  0.042 0.002 0.517 0.15 ]]
Logits tf.Tensor([[-0.16607197 -0.30994898  0.7688466 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22660321 0.19623707 0.5771597 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.15, 0.15, 0.25, 0.224, 0.146, 0.83, 0.042, 0.002, 0.517, 0.15]
0.8291213333333333
1.8345236666666667
Reward 17.712501377303827
Current State [[0.15  0.15  0.25  0.224 0.146 0.83  0.042 0.002 0.517 0.15 ]]
Logits tf.Tensor([[-0.17328885 -0.32665157  0.77216166]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2256424  0.19356021 0.5807974 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.11, 0.04, 0.26, 0.21, 0.143, 0.83, 0.042, 0.002, 0.517, 0.15]
0.8291213333333333
1.8345236666666667
Reward 5.712501377303828
Current State [[0.11  0.04  0.26  0.21  0.143 0.83  0.042 0.002 0.517 0.15 ]]
Logits tf.Tensor([[-0.16423608 -0.29312664  0.7287384 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2314036  0.20342    0.56517637]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.15, 0.26, 0.234, 0.14, 0.79, 0.033, 0.007, 0.496, 0.13]
0.7910253333333334
7.210714166666665
Reward 16.195773672043416
Current State [[0.06  0.15  0.26  0.234 0.14  0.79  0.033 0.007 0.496 0.13 ]]
Logits tf.Tensor([[-0.15559503 -0.2913099   0.74697757]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23046625 0.20121813 0.5683156 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.2, 0.15, 0.28, 0.21, 0.142, 0.79, 0.033, 0.007, 0.496, 0.13]
0.7910253333333334
7.210714166666665
Reward 16.195773672043416
Current State [[0.2   0.15  0.28  0.21  0.142 0.79  0.033 0.007 0.496 0.13 ]]
Logits tf.Tensor([[-0.17285371 -0.32581136  0.75266623]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22824037 0.19586812 0.5758915 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.15, 0.24, 0.189, 0.141, 0.83, 0.03, 0.002, 0.554, 0.13]
0.8328546666666665
2.0124998333333335
Reward 17.52246880272027
Current State [[0.07  0.15  0.24  0.189 0.141 0.83  0.03  0.002 0.554 0.13 ]]
Logits tf.Tensor([[-0.16592377 -0.31230974  0.7804882 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2252114  0.19454305 0.58024555]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.15, 0.26, 0.212, 0.143, 0.83, 0.03, 0.002, 0.554, 0.13]
0.8328546666666665
2.0124998333333335
Reward 17.52246880272027
Current State [[0.07  0.15  0.26  0.212 0.143 0.83  0.03  0.002 0.554 0.13 ]]
Logits tf.Tensor([[-0.16569805 -0.30896544  0.7867853 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22428258 0.19434585 0.58137155]], shape=(1, 3), dtype=float32)
Selected action 0
[0.21, 0.04, 0.28, 0.229, 0.149, 0.83, 0.03, 0.002, 0.554, 0.13]
0.8328546666666665
2.0124998333333335
Reward 5.522468802720267
Current State [[0.21  0.04  0.28  0.229 0.149 0.83  0.03  0.002 0.554 0.13 ]]
Logits tf.Tensor([[-0.1755307  -0.31292975  0.75282866]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22717068 0.19800702 0.5748223 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.2, 0.15, 0.26, 0.228, 0.149, 0.88, 0.032, 0.002, 0.7070000000000001, 0.15]
0.8777945
1.6970241666666666
Reward 18.051326996814055
Current State [[0.2   0.15  0.26  0.228 0.149 0.88  0.032 0.002 0.707 0.15 ]]
Logits tf.Tensor([[-0.19565901 -0.37310857  0.87523186]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.21028806 0.17609593 0.613616  ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.02, 0.04, 0.31, 0.191, 0.144, 0.88, 0.032, 0.002, 0.7070000000000001, 0.15]
0.8777945
1.6970241666666666
Reward 6.051326996814053
Current State [[0.02  0.04  0.31  0.191 0.144 0.88  0.032 0.002 0.707 0.15 ]]
Logits tf.Tensor([[-0.17361656 -0.30632836  0.839098  ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.21603958 0.18918963 0.5947708 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.02, 0.04, 0.31, 0.191, 0.144, 0.88, 0.032, 0.002, 0.7070000000000001, 0.15]
0.8777945
1.6970241666666666
Reward 18.051326996814055
Episode: 138 | Average Reward: 289 | Episode Reward: 345 | Loss: 836.814 | Steps: 19 | Worker: 0
Current State [[-0.00974949 -0.0085697   0.00492906  0.00990783 -0.00692503 -0.00149898
  -0.00112595  0.00029363 -0.00843271 -0.0052204 ]]
Logits tf.Tensor([[-0.04102371 -0.03080753  0.06599717]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.32018176 0.32346958 0.3563487 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.13, 0.15, 0.25, 0.233, 0.138, 0.8, 0.023, 0.006, 0.686, 0.06]
0.7988738333333333
5.657143833333333
Reward 16.31850129956939
Current State [[0.13  0.15  0.25  0.233 0.138 0.8   0.023 0.006 0.686 0.06 ]]
Logits tf.Tensor([[-0.17153734 -0.3339534   0.83147264]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.21850455 0.18574798 0.5957475 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.08, 0.08, 0.3, 0.214, 0.142, 0.8, 0.023, 0.006, 0.686, 0.06]
0.7988738333333333
5.657143833333333
Reward 10.318501299569391
Current State [[0.08  0.08  0.3   0.214 0.142 0.8   0.023 0.006 0.686 0.06 ]]
Logits tf.Tensor([[-0.16602334 -0.30379817  0.81456625]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22039428 0.1920284  0.5875773 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.18, 0.04, 0.29, 0.204, 0.139, 0.8, 0.023, 0.006, 0.686, 0.06]
0.7988738333333333
5.657143833333333
Reward 4.31850129956939
Current State [[0.18  0.04  0.29  0.204 0.139 0.8   0.023 0.006 0.686 0.06 ]]
Logits tf.Tensor([[-0.17518105 -0.31947145  0.798066  ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22162333 0.1918452  0.58653146]], shape=(1, 3), dtype=float32)
Selected action 2
[0.34, 0.15, 0.3, 0.18, 0.143, 0.77, 0.062, 0.004, 0.395, 0.12]
0.7683183333333333
3.734524999999999
Reward 16.57994767235542
Current State [[0.34  0.15  0.3   0.18  0.143 0.77  0.062 0.004 0.395 0.12 ]]
Logits tf.Tensor([[-0.18899281 -0.3560193   0.7098915 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23239398 0.19664647 0.57095957]], shape=(1, 3), dtype=float32)
Selected action 0
[0.21, 0.04, 0.29, 0.247, 0.144, 0.77, 0.062, 0.004, 0.395, 0.12]
0.7683183333333333
3.734524999999999
Reward 4.57994767235542
Current State [[0.21  0.04  0.29  0.247 0.144 0.77  0.062 0.004 0.395 0.12 ]]
Logits tf.Tensor([[-0.16111286 -0.28882506  0.66711485]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23984471 0.21108893 0.54906636]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.41, 0.195, 0.144, 0.77, 0.062, 0.004, 0.395, 0.12]
0.7683183333333333
3.734524999999999
Reward 4.57994767235542
Current State [[0.04  0.04  0.41  0.195 0.144 0.77  0.062 0.004 0.395 0.12 ]]
Logits tf.Tensor([[-0.13775319 -0.25647214  0.69090885]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23933125 0.21253984 0.5481289 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.02, 0.04, 0.3, 0.224, 0.138, 0.8, 0.05, 0.001, 0.43200000000000005, 0.11]
0.8047356666666668
0.8589281666666666
Reward 8.660162267799333
Current State [[0.02  0.04  0.3   0.224 0.138 0.8   0.05  0.001 0.432 0.11 ]]
Logits tf.Tensor([[-0.13657041 -0.25663114  0.6900197 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23967144 0.21255659 0.547772  ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.1, 0.08, 0.33, 0.2, 0.144, 0.8, 0.05, 0.001, 0.43200000000000005, 0.11]
0.8047356666666668
0.8589281666666666
Reward 14.660162267799333
Current State [[0.1   0.08  0.33  0.2   0.144 0.8   0.05  0.001 0.432 0.11 ]]
Logits tf.Tensor([[-0.15055668 -0.28439516  0.7146903 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23527618 0.20580345 0.5589204 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.1, 0.08, 0.33, 0.2, 0.144, 0.8, 0.05, 0.001, 0.43200000000000005, 0.11]
0.8047356666666668
0.8589281666666666
Reward 20.660162267799333
Current State [[0.1   0.08  0.33  0.2   0.144 0.8   0.05  0.001 0.432 0.11 ]]
Logits tf.Tensor([[-0.15055668 -0.28439516  0.7146903 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23527618 0.20580345 0.5589204 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.18, 0.15, 0.27, 0.231, 0.138, 0.91, 0.05, 0.001, 0.438, 0.19]
0.9130563333333334
0.7398806666666666
Reward 22.997643162108176
Current State [[0.18  0.15  0.27  0.231 0.138 0.91  0.05  0.001 0.438 0.19 ]]
Logits tf.Tensor([[-0.17526491 -0.34797964  0.7620426 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22755843 0.19146259 0.580979  ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.09, 0.15, 0.25, 0.193, 0.14, 0.91, 0.05, 0.001, 0.438, 0.19]
0.9130563333333334
0.7398806666666666
Reward 22.997643162108176
Current State [[0.09  0.15  0.25  0.193 0.14  0.91  0.05  0.001 0.438 0.19 ]]
Logits tf.Tensor([[-0.16066088 -0.33623898  0.7579861 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23015653 0.19309482 0.57674867]], shape=(1, 3), dtype=float32)
Selected action 2
[0.1, 0.15, 0.24, 0.223, 0.138, 0.91, 0.05, 0.001, 0.438, 0.19]
0.9130563333333334
0.7398806666666666
Reward 22.997643162108176
Current State [[0.1   0.15  0.24  0.223 0.138 0.91  0.05  0.001 0.438 0.19 ]]
Logits tf.Tensor([[-0.1620822  -0.33389387  0.75654256]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22999187 0.19368485 0.5763233 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.2, 0.08, 0.28, 0.229, 0.138, 0.9, 0.038, 0.003, 0.383, 0.16]
0.8962433333333332
3.232142333333334
Reward 10.886482521810294
Current State [[0.2   0.08  0.28  0.229 0.138 0.9   0.038 0.003 0.383 0.16 ]]
Logits tf.Tensor([[-0.16282229 -0.32249582  0.70635176]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23599587 0.2011681  0.56283605]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.15, 0.26, 0.237, 0.145, 0.9, 0.038, 0.003, 0.383, 0.16]
0.8962433333333332
3.232142333333334
Reward 16.886482521810294
Current State [[0.08  0.15  0.26  0.237 0.145 0.9   0.038 0.003 0.383 0.16 ]]
Logits tf.Tensor([[-0.14646532 -0.31149468  0.73307455]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23487085 0.19913964 0.56598955]], shape=(1, 3), dtype=float32)
Selected action 2
[0.17, 0.15, 0.28, 0.1, 0.145, 0.96, 0.046, 0.001, 0.42000000000000004, 0.16]
0.9587838333333334
0.7327381666666667
Reward 23.649488983803096
Current State [[0.17  0.15  0.28  0.1   0.145 0.96  0.046 0.001 0.42  0.16 ]]
Logits tf.Tensor([[-0.17681062 -0.36874142  0.7664016 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22760473 0.18785673 0.5845385 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.1, 0.15, 0.26, 0.2, 0.138, 0.96, 0.046, 0.001, 0.42000000000000004, 0.16]
0.9587838333333334
0.7327381666666667
Reward 23.649488983803096
Current State [[0.1   0.15  0.26  0.2   0.138 0.96  0.046 0.001 0.42  0.16 ]]
Logits tf.Tensor([[-0.1620263  -0.33832538  0.7651402 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22905807 0.19203478 0.57890713]], shape=(1, 3), dtype=float32)
Selected action 2
[0.12, 0.15, 0.25, 0.209, 0.144, 0.96, 0.046, 0.001, 0.42000000000000004, 0.16]
0.9587838333333334
0.7327381666666667
Reward 23.649488983803096
Current State [[0.12  0.15  0.25  0.209 0.144 0.96  0.046 0.001 0.42  0.16 ]]
Logits tf.Tensor([[-0.16516973 -0.34152168  0.76510704]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22864807 0.19168091 0.579671  ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.16, 0.04, 0.27, 0.225, 0.142, 0.95, 0.076, 0.005, 0.378, 0.17]
0.9546821666666666
5.251786499999999
Reward 4.481269043280476
Current State [[0.16  0.04  0.27  0.225 0.142 0.95  0.076 0.005 0.378 0.17 ]]
Logits tf.Tensor([[-0.16824926 -0.3232181   0.70599395]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23510037 0.20134981 0.5635498 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.09, 0.15, 0.26, 0.213, 0.143, 0.95, 0.076, 0.005, 0.378, 0.17]
0.9546821666666666
5.251786499999999
Reward 16.481269043280477
Current State [[0.09  0.15  0.26  0.213 0.143 0.95  0.076 0.005 0.378 0.17 ]]
Logits tf.Tensor([[-0.16696757 -0.3354676   0.7496449 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23011065 0.19442767 0.5754617 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.21, 0.15, 0.27, 0.223, 0.139, 0.92, 0.052, 0.001, 0.40499999999999997, 0.17]
0.9236096666666668
1.1833333333333333
Reward 19.59687690120225
Episode: 139 | Average Reward: 289 | Episode Reward: 308 | Loss: 870.088 | Steps: 19 | Worker: 0
Current State [[ 0.0019678  -0.00980886 -0.00332777  0.00638275  0.00011742 -0.00052992
  -0.0078446   0.00902308 -0.00946956 -0.00760074]]
Logits tf.Tensor([[-0.03652781 -0.03359898  0.06495474]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3215699  0.32251313 0.35591698]], shape=(1, 3), dtype=float32)
Selected action 1
[0.13, 0.08, 0.35, 0.236, 0.146, 0.92, 0.052, 0.001, 0.40499999999999997, 0.17]
0.9236096666666668
1.1833333333333333
Reward 13.59687690120225
Current State [[0.13  0.08  0.35  0.236 0.146 0.92  0.052 0.001 0.405 0.17 ]]
Logits tf.Tensor([[-0.15013193 -0.32130414  0.74479234]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23310964 0.196436   0.57045436]], shape=(1, 3), dtype=float32)
Selected action 1
[0.2, 0.08, 0.29, 0.238, 0.143, 0.92, 0.052, 0.001, 0.40499999999999997, 0.17]
0.9236096666666668
1.1833333333333333
Reward 13.59687690120225
Current State [[0.2   0.08  0.29  0.238 0.143 0.92  0.052 0.001 0.405 0.17 ]]
Logits tf.Tensor([[-0.16400553 -0.33777168  0.7291107 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23346904 0.19622919 0.57030183]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.22, 0.15, 0.123, 0.88, 0.042, 0.001, 0.465, 0.16]
0.883727
1.2839285000000003
Reward 19.021634904972174
Current State [[0.04  0.15  0.22  0.15  0.123 0.88  0.042 0.001 0.465 0.16 ]]
Logits tf.Tensor([[-0.14689718 -0.33016163  0.7456208 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23398288 0.19480196 0.57121515]], shape=(1, 3), dtype=float32)
Selected action 1
[0.02, 0.08, 0.3, 0.05, 0.138, 0.88, 0.042, 0.001, 0.465, 0.16]
0.883727
1.2839285000000003
Reward 13.021634904972174
Current State [[0.02  0.08  0.3   0.05  0.138 0.88  0.042 0.001 0.465 0.16 ]]
Logits tf.Tensor([[-0.1391021  -0.31993818  0.735386  ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23628262 0.19719489 0.5665225 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.27, 0.15, 0.26, 0.2, 0.139, 0.88, 0.042, 0.001, 0.465, 0.16]
0.883727
1.2839285000000003
Reward 19.021634904972174
Current State [[0.27  0.15  0.26  0.2   0.139 0.88  0.042 0.001 0.465 0.16 ]]
Logits tf.Tensor([[-0.17964509 -0.3739943   0.7614722 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22798707 0.18771777 0.58429515]], shape=(1, 3), dtype=float32)
Selected action 2
[0.13, 0.15, 0.26, 0.221, 0.139, 0.88, 0.042, 0.001, 0.465, 0.16]
0.883727
1.2839285000000003
Reward 19.021634904972174
Current State [[0.13  0.15  0.26  0.221 0.139 0.88  0.042 0.001 0.465 0.16 ]]
Logits tf.Tensor([[-0.15671004 -0.33726156  0.7617417 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23040318 0.19234277 0.577254  ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.14, 0.15, 0.27, 0.1, 0.145, 0.89, 0.042, 0.001, 0.43200000000000005, 0.13]
0.8922095000000001
0.6392855
Reward 24.446150043494825
Current State [[0.14  0.15  0.27  0.1   0.145 0.89  0.042 0.001 0.432 0.13 ]]
Logits tf.Tensor([[-0.16019289 -0.35140324  0.7484329 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2321872  0.19177705 0.57603574]], shape=(1, 3), dtype=float32)
Selected action 2
[0.16, 0.15, 0.28, 0.229, 0.139, 0.89, 0.042, 0.001, 0.43200000000000005, 0.13]
0.8922095000000001
0.6392855
Reward 24.446150043494825
Current State [[0.16  0.15  0.28  0.229 0.139 0.89  0.042 0.001 0.432 0.13 ]]
Logits tf.Tensor([[-0.15984315 -0.3349656   0.75472593]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23067765 0.19362025 0.5757021 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.21, 0.233, 0.141, 0.89, 0.042, 0.001, 0.43200000000000005, 0.13]
0.8922095000000001
0.6392855
Reward 24.446150043494825
Current State [[0.04  0.15  0.21  0.233 0.141 0.89  0.042 0.001 0.432 0.13 ]]
Logits tf.Tensor([[-0.14156738 -0.31332257  0.7407656 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23481257 0.19775566 0.56743175]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.15, 0.23, 0.243, 0.145, 0.77, 0.027, 0.003, 0.6769999999999999, 0.05]
0.7680315
3.4202393333333343
Reward 16.658855372527366
Current State [[0.08  0.15  0.23  0.243 0.145 0.77  0.027 0.003 0.677 0.05 ]]
Logits tf.Tensor([[-0.15764818 -0.32004148  0.817176  ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22218233 0.1888787  0.58893895]], shape=(1, 3), dtype=float32)
Selected action 2
[0.2, 0.15, 0.26, 0.21, 0.147, 0.77, 0.027, 0.003, 0.6769999999999999, 0.05]
0.7680315
3.4202393333333343
Reward 16.658855372527366
Current State [[0.2   0.15  0.26  0.21  0.147 0.77  0.027 0.003 0.677 0.05 ]]
Logits tf.Tensor([[-0.17052236 -0.35265467  0.8244285 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22035737 0.18366592 0.5959767 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.16, 0.08, 0.27, 0.228, 0.138, 0.77, 0.027, 0.003, 0.6769999999999999, 0.05]
0.7680315
3.4202393333333343
Reward 10.658855372527366
Current State [[0.16  0.08  0.27  0.228 0.138 0.77  0.027 0.003 0.677 0.05 ]]
Logits tf.Tensor([[-0.16563751 -0.32318723  0.79752785]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22350311 0.190924   0.5855729 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.08, 0.04, 0.26, 0.245, 0.143, 0.79, 0.042, 0.01, 0.393, 0.15]
0.7942176666666668
9.572618833333333
Reward 4.094154067315374
Current State [[0.08  0.04  0.26  0.245 0.143 0.79  0.042 0.01  0.393 0.15 ]]
Logits tf.Tensor([[-0.12732784 -0.27380526  0.6585806 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24641801 0.2128424  0.5407396 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.15, 0.08, 0.3, 0.212, 0.144, 0.79, 0.042, 0.01, 0.393, 0.15]
0.7942176666666668
9.572618833333333
Reward 10.094154067315374
Current State [[0.15  0.08  0.3   0.212 0.144 0.79  0.042 0.01  0.393 0.15 ]]
Logits tf.Tensor([[-0.14086863 -0.30104774  0.68351936]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24198568 0.20616966 0.55184466]], shape=(1, 3), dtype=float32)
Selected action 2
[0.16, 0.15, 0.18, 0.212, 0.144, 0.83, 0.018, 0.001, 0.46900000000000003, 0.07]
0.8301800000000001
0.9714283333333333
Reward 20.086562597448733
Current State [[0.16  0.15  0.18  0.212 0.144 0.83  0.018 0.001 0.469 0.07 ]]
Logits tf.Tensor([[-0.14777489 -0.3239897   0.72739875]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23597541 0.19785069 0.5661739 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.12, 0.15, 0.26, 0.238, 0.139, 0.83, 0.018, 0.001, 0.46900000000000003, 0.07]
0.8301800000000001
0.9714283333333333
Reward 20.086562597448733
Current State [[0.12  0.15  0.26  0.238 0.139 0.83  0.018 0.001 0.469 0.07 ]]
Logits tf.Tensor([[-0.14530173 -0.30791005  0.7462949 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23315759 0.19816622 0.5686762 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.12, 0.15, 0.26, 0.238, 0.139, 0.83, 0.018, 0.001, 0.46900000000000003, 0.07]
0.8301800000000001
0.9714283333333333
Reward 20.086562597448733
Current State [[0.12  0.15  0.26  0.238 0.139 0.83  0.018 0.001 0.469 0.07 ]]
Logits tf.Tensor([[-0.14530173 -0.30791005  0.7462949 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23315759 0.19816622 0.5686762 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.21, 0.15, 0.27, 0.2, 0.138, 0.75, 0.025, 0.001, 0.37, 0.02]
0.7489436666666668
0.8130941666666668
Reward 20.54758918231201
Current State [[0.21  0.15  0.27  0.2   0.138 0.75  0.025 0.001 0.37  0.02 ]]
Logits tf.Tensor([[-0.14949284 -0.29710448  0.6793756 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24076131 0.2077207  0.55151796]], shape=(1, 3), dtype=float32)
Selected action 0
[0.07, 0.04, 0.34, 0.2, 0.138, 0.75, 0.025, 0.001, 0.37, 0.02]
0.7489436666666668
0.8130941666666668
Reward 8.547589182312008
Current State [[0.07  0.04  0.34  0.2   0.138 0.75  0.025 0.001 0.37  0.02 ]]
Logits tf.Tensor([[-0.12019883 -0.24116585  0.65264684]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24679266 0.21867391 0.53453344]], shape=(1, 3), dtype=float32)
Selected action 0
[0.21, 0.04, 0.27, 0.2, 0.139, 0.75, 0.025, 0.001, 0.37, 0.02]
0.7489436666666668
0.8130941666666668
Reward 8.547589182312008
Episode: 140 | Average Reward: 290 | Episode Reward: 326 | Loss: 794.998 | Steps: 19 | Worker: 0
Current State [[-0.00294749 -0.00442222  0.00556077  0.00874865  0.00988338 -0.00861675
   0.00638263 -0.00197581 -0.00911785  0.00544832]]
Logits tf.Tensor([[-0.04158041 -0.03696628  0.07305445]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.31988856 0.32136798 0.35874346]], shape=(1, 3), dtype=float32)
Selected action 1
[0.13, 0.08, 0.26, 0.229, 0.138, 0.77, 0.046, 0.001, 0.45599999999999996, 0.03]
0.7736353333333332
0.5904743333333333
Reward 17.66467269833992
Current State [[0.13  0.08  0.26  0.229 0.138 0.77  0.046 0.001 0.456 0.03 ]]
Logits tf.Tensor([[-0.1455319  -0.2870008   0.70003283]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23824415 0.2068155  0.5549404 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.07, 0.04, 0.34, 0.192, 0.139, 0.77, 0.046, 0.001, 0.45599999999999996, 0.03]
0.7736353333333332
0.5904743333333333
Reward 11.664672698339922
Current State [[0.07  0.04  0.34  0.192 0.139 0.77  0.046 0.001 0.456 0.03 ]]
Logits tf.Tensor([[-0.13573763 -0.2667362   0.7022381 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23872605 0.20941505 0.5518589 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.1, 0.15, 0.24, 0.224, 0.144, 0.89, 0.02, 0.002, 0.437, 0.08]
0.8946805
1.861905
Reward 17.858632727103128
Current State [[0.1   0.15  0.24  0.224 0.144 0.89  0.02  0.002 0.437 0.08 ]]
Logits tf.Tensor([[-0.13776866 -0.3196496   0.7466201 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23500633 0.19592491 0.56906873]], shape=(1, 3), dtype=float32)
Selected action 2
[0.09, 0.15, 0.24, 0.2, 0.146, 0.89, 0.02, 0.002, 0.437, 0.08]
0.8946805
1.861905
Reward 17.858632727103128
Current State [[0.09  0.15  0.24  0.2   0.146 0.89  0.02  0.002 0.437 0.08 ]]
Logits tf.Tensor([[-0.13610429 -0.3209409   0.7462148 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23541945 0.19569007 0.56889045]], shape=(1, 3), dtype=float32)
Selected action 1
[0.09, 0.15, 0.24, 0.2, 0.146, 0.89, 0.02, 0.002, 0.437, 0.08]
0.8946805
1.861905
Reward 11.858632727103128
Current State [[0.09  0.15  0.24  0.2   0.146 0.89  0.02  0.002 0.437 0.08 ]]
Logits tf.Tensor([[-0.13610429 -0.3209409   0.7462148 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23541945 0.19569007 0.56889045]], shape=(1, 3), dtype=float32)
Selected action 2
[0.13, 0.15, 0.25, 0.211, 0.138, 0.97, 0.039, 0.001, 0.445, 0.13]
0.9735975
0.5720235
Reward 27.522927703666518
Current State [[0.13  0.15  0.25  0.211 0.138 0.97  0.039 0.001 0.445 0.13 ]]
Logits tf.Tensor([[-0.15521853 -0.35428536  0.777018  ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22937469 0.18797144 0.5826539 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.27, 0.15, 0.27, 0.187, 0.144, 0.97, 0.039, 0.001, 0.445, 0.13]
0.9735975
0.5720235
Reward 27.522927703666518
Current State [[0.27  0.15  0.27  0.187 0.144 0.97  0.039 0.001 0.445 0.13 ]]
Logits tf.Tensor([[-0.18091722 -0.38868368  0.7825044 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2255786  0.18325932 0.5911621 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.23, 0.15, 0.27, 0.203, 0.139, 0.97, 0.039, 0.001, 0.445, 0.13]
0.9735975
0.5720235
Reward 27.522927703666518
Current State [[0.23  0.15  0.27  0.203 0.139 0.97  0.039 0.001 0.445 0.13 ]]
Logits tf.Tensor([[-0.17383678 -0.37688312  0.7815169 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.226458   0.18484415 0.58869785]], shape=(1, 3), dtype=float32)
Selected action 2
[0.09, 0.15, 0.26, 0.234, 0.138, 0.66, 0.039, 0.007, 0.46799999999999997, 0.06]
0.6627363333333333
6.852382166666664
Reward 16.14613162463639
Current State [[0.09  0.15  0.26  0.234 0.138 0.66  0.039 0.007 0.468 0.06 ]]
Logits tf.Tensor([[-0.13562031 -0.28308123  0.6954051 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24046743 0.2074984  0.5520342 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.16, 0.15, 0.27, 0.212, 0.145, 0.66, 0.039, 0.007, 0.46799999999999997, 0.06]
0.6627363333333333
6.852382166666664
Reward 16.14613162463639
Current State [[0.16  0.15  0.27  0.212 0.145 0.66  0.039 0.007 0.468 0.06 ]]
Logits tf.Tensor([[-0.143549   -0.30244026  0.6990797 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23948923 0.20430565 0.5562051 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.15, 0.25, 0.179, 0.145, 0.66, 0.039, 0.007, 0.46799999999999997, 0.06]
0.6627363333333333
6.852382166666664
Reward 16.14613162463639
Current State [[0.06  0.15  0.25  0.179 0.145 0.66  0.039 0.007 0.468 0.06 ]]
Logits tf.Tensor([[-0.13354148 -0.27945632  0.69137824]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24120048 0.208453   0.55034655]], shape=(1, 3), dtype=float32)
Selected action 0
[0.01, 0.04, 0.3, 0.227, 0.138, 0.86, 0.03, 0.001, 0.483, 0.05]
0.8603450000000001
0.7404753333333333
Reward 10.390986587811248
Current State [[0.01  0.04  0.3   0.227 0.138 0.86  0.03  0.001 0.483 0.05 ]]
Logits tf.Tensor([[-0.12693682 -0.2715304   0.7296309 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23694226 0.20504366 0.5580141 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.15, 0.21, 0.125, 0.141, 0.86, 0.03, 0.001, 0.483, 0.05]
0.8603450000000001
0.7404753333333333
Reward 22.39098658781125
Current State [[0.07  0.15  0.21  0.125 0.141 0.86  0.03  0.001 0.483 0.05 ]]
Logits tf.Tensor([[-0.14393556 -0.3243026   0.74771774]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23396616 0.19535324 0.5706806 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.07, 0.15, 0.21, 0.125, 0.141, 0.86, 0.03, 0.001, 0.483, 0.05]
0.8603450000000001
0.7404753333333333
Reward 16.39098658781125
Current State [[0.07  0.15  0.21  0.125 0.141 0.86  0.03  0.001 0.483 0.05 ]]
Logits tf.Tensor([[-0.14393556 -0.3243026   0.74771774]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23396616 0.19535324 0.5706806 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.15, 0.24, 0.212, 0.139, 0.81, 0.03, 0.002, 0.5650000000000001, 0.11]
0.8077606666666668
2.4577375
Reward 17.117693829529436
Current State [[0.06  0.15  0.24  0.212 0.139 0.81  0.03  0.002 0.565 0.11 ]]
Logits tf.Tensor([[-0.14700258 -0.3220029   0.78132933]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22884649 0.1921067  0.5790468 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.15, 0.27, 0.178, 0.143, 0.81, 0.03, 0.002, 0.5650000000000001, 0.11]
0.8077606666666668
2.4577375
Reward 17.117693829529436
Current State [[0.06  0.15  0.27  0.178 0.143 0.81  0.03  0.002 0.565 0.11 ]]
Logits tf.Tensor([[-0.149039   -0.32481128  0.78748494]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22779524 0.19107671 0.58112806]], shape=(1, 3), dtype=float32)
Selected action 2
[0.09, 0.15, 0.24, 0.216, 0.143, 0.81, 0.03, 0.002, 0.5650000000000001, 0.11]
0.8077606666666668
2.4577375
Reward 17.117693829529436
Current State [[0.09  0.15  0.24  0.216 0.143 0.81  0.03  0.002 0.565 0.11 ]]
Logits tf.Tensor([[-0.14959973 -0.3286822   0.78303236]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2284552  0.19099697 0.5805478 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.13, 0.15, 0.26, 0.233, 0.136, 0.81, 0.03, 0.002, 0.5650000000000001, 0.11]
0.8077606666666668
2.4577375
Reward 17.117693829529436
Current State [[0.13  0.15  0.26  0.233 0.136 0.81  0.03  0.002 0.565 0.11 ]]
Logits tf.Tensor([[-0.15442206 -0.33605367  0.7858332 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22755493 0.18975998 0.5826851 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.07, 0.08, 0.23, 0.24, 0.141, 0.76, 0.029, 0.001, 0.6910000000000001, 0.06]
0.7627295000000002
1.2666681666666666
Reward 12.51762382754061
Current State [[0.07  0.08  0.23  0.24  0.141 0.76  0.029 0.001 0.691 0.06 ]]
Logits tf.Tensor([[-0.15263277 -0.3088731   0.795965  ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22535516 0.19275834 0.58188653]], shape=(1, 3), dtype=float32)
Selected action 2
[0.23, 0.15, 0.29, 0.236, 0.144, 0.76, 0.029, 0.001, 0.6910000000000001, 0.06]
0.7627295000000002
1.2666681666666666
Reward 18.51762382754061
Episode: 141 | Average Reward: 290 | Episode Reward: 356 | Loss: 972.645 | Steps: 19 | Worker: 0
Current State [[-0.00390017 -0.00602432 -0.00207966  0.00561112 -0.00766654 -0.00749077
   0.0029962  -0.00733251  0.00863794 -0.00412066]]
Logits tf.Tensor([[-0.04284985 -0.03582002  0.07546789]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.31921792 0.32146987 0.3593122 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.23, 0.08, 0.28, 0.222, 0.138, 0.76, 0.029, 0.001, 0.6910000000000001, 0.06]
0.7627295000000002
1.2666681666666666
Reward 12.51762382754061
Current State [[0.23  0.08  0.28  0.222 0.138 0.76  0.029 0.001 0.691 0.06 ]]
Logits tf.Tensor([[-0.16843298 -0.35256138  0.81527257]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22191761 0.18459749 0.5934849 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.16, 0.04, 0.27, 0.243, 0.148, 0.86, 0.047, 0.009, 0.44800000000000006, 0.13]
0.8599025
8.877380166666665
Reward 4.146695350770081
Current State [[0.16  0.04  0.27  0.243 0.148 0.86  0.047 0.009 0.448 0.13 ]]
Logits tf.Tensor([[-0.14544354 -0.31928936  0.71682215]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23758909 0.19967617 0.5627347 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.17, 0.15, 0.27, 0.258, 0.146, 0.86, 0.047, 0.009, 0.44800000000000006, 0.13]
0.8599025
8.877380166666665
Reward 16.14669535077008
Current State [[0.17  0.15  0.27  0.258 0.146 0.86  0.047 0.009 0.448 0.13 ]]
Logits tf.Tensor([[-0.15277281 -0.3445789   0.7609666 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23152989 0.19112027 0.57734984]], shape=(1, 3), dtype=float32)
Selected action 2
[0.13, 0.15, 0.3, 0.2, 0.147, 0.86, 0.047, 0.009, 0.44800000000000006, 0.13]
0.8599025
8.877380166666665
Reward 16.14669535077008
Current State [[0.13  0.15  0.3   0.2   0.147 0.86  0.047 0.009 0.448 0.13 ]]
Logits tf.Tensor([[-0.14912051 -0.34236142  0.76585555]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23142798 0.19076222 0.5778098 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.04, 0.33, 0.213, 0.144, 0.8, 0.056, 0.001, 0.40099999999999997, 0.06]
0.8030311666666669
0.9035698333333334
Reward 8.320630159623537
Current State [[0.05  0.04  0.33  0.213 0.144 0.8   0.056 0.001 0.401 0.06 ]]
Logits tf.Tensor([[-0.12928073 -0.26994878  0.6929723 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24128951 0.20962694 0.54908353]], shape=(1, 3), dtype=float32)
Selected action 2
[0.13, 0.15, 0.2, 0.204, 0.143, 0.8, 0.056, 0.001, 0.40099999999999997, 0.06]
0.8030311666666669
0.9035698333333334
Reward 20.320630159623537
Current State [[0.13  0.15  0.2   0.204 0.143 0.8   0.056 0.001 0.401 0.06 ]]
Logits tf.Tensor([[-0.14681736 -0.3173744   0.70440453]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23890851 0.20144649 0.559645  ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.09, 0.15, 0.26, 0.222, 0.139, 0.8, 0.056, 0.001, 0.40099999999999997, 0.06]
0.8030311666666669
0.9035698333333334
Reward 20.320630159623537
Current State [[0.09  0.15  0.26  0.222 0.139 0.8   0.056 0.001 0.401 0.06 ]]
Logits tf.Tensor([[-0.14277373 -0.30409285  0.7185623 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23711626 0.20179081 0.561093  ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.25, 0.15, 0.28, 0.228, 0.141, 0.8, 0.056, 0.001, 0.40099999999999997, 0.06]
0.8030311666666669
0.9035698333333334
Reward 20.320630159623537
Current State [[0.25  0.15  0.28  0.228 0.141 0.8   0.056 0.001 0.401 0.06 ]]
Logits tf.Tensor([[-0.16540872 -0.33929247  0.72509575]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23382227 0.19650294 0.5696748 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.15, 0.25, 0.221, 0.142, 0.85, 0.051, 0.001, 0.43499999999999994, 0.03]
0.848234
0.748215
Reward 22.16072705943806
Current State [[0.08  0.15  0.25  0.221 0.142 0.85  0.051 0.001 0.435 0.03 ]]
Logits tf.Tensor([[-0.14557138 -0.31101575  0.7464599 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23323081 0.19766708 0.5691021 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.05, 0.08, 0.29, 0.05, 0.139, 0.85, 0.051, 0.001, 0.43499999999999994, 0.03]
0.848234
0.748215
Reward 16.16072705943806
Current State [[0.05  0.08  0.29  0.05  0.139 0.85  0.051 0.001 0.435 0.03 ]]
Logits tf.Tensor([[-0.13886663 -0.30867064  0.71896034]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23798978 0.20082293 0.56118727]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.22, 0.2, 0.126, 0.85, 0.051, 0.001, 0.43499999999999994, 0.03]
0.848234
0.748215
Reward 22.16072705943806
Current State [[0.05  0.15  0.22  0.2   0.126 0.85  0.051 0.001 0.435 0.03 ]]
Logits tf.Tensor([[-0.14293909 -0.3081326   0.73276603]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23538844 0.19954577 0.5650658 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.12, 0.08, 0.34, 0.21, 0.139, 0.97, 0.039, 0.0, 0.379, 0.01]
0.9686358333333334
0.35535733333333325
Reward 33.81066632040131
Current State [[0.12  0.08  0.34  0.21  0.139 0.97  0.039 0.    0.379 0.01 ]]
Logits tf.Tensor([[-0.14031872 -0.3129851   0.7475045 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23412333 0.19699568 0.568881  ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.34, 0.15, 0.3, 0.204, 0.139, 0.97, 0.039, 0.0, 0.379, 0.01]
0.9686358333333334
0.35535733333333325
Reward 39.81066632040131
Current State [[0.34  0.15  0.3   0.204 0.139 0.97  0.039 0.    0.379 0.01 ]]
Logits tf.Tensor([[-0.18747501 -0.37925994  0.76532996]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22632334 0.18682641 0.5868503 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.15, 0.25, 0.198, 0.145, 0.97, 0.039, 0.0, 0.379, 0.01]
0.9686358333333334
0.35535733333333325
Reward 39.81066632040131
Current State [[0.08  0.15  0.25  0.198 0.145 0.97  0.039 0.    0.379 0.01 ]]
Logits tf.Tensor([[-0.14002194 -0.32310367  0.7542249 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23374352 0.19463824 0.5716182 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.13, 0.04, 0.25, 0.3, 0.124, 0.96, 0.048, 0.001, 0.441, 0.14]
0.9622421666666665
0.7952383333333333
Reward 10.792680803853086
Current State [[0.13  0.04  0.25  0.3   0.124 0.96  0.048 0.001 0.441 0.14 ]]
Logits tf.Tensor([[-0.14772592 -0.3240195   0.7352774 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23493353 0.19696166 0.5681048 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.04, 0.36, 0.229, 0.138, 0.96, 0.048, 0.001, 0.441, 0.14]
0.9622421666666665
0.7952383333333333
Reward 10.792680803853086
Current State [[0.05  0.04  0.36  0.229 0.138 0.96  0.048 0.001 0.441 0.14 ]]
Logits tf.Tensor([[-0.13505417 -0.31325096  0.76361275]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23293169 0.19491203 0.57215625]], shape=(1, 3), dtype=float32)
Selected action 2
[0.15, 0.15, 0.28, 0.1, 0.134, 0.96, 0.048, 0.001, 0.441, 0.14]
0.9622421666666665
0.7952383333333333
Reward 22.792680803853088
Current State [[0.15  0.15  0.28  0.1   0.134 0.96  0.048 0.001 0.441 0.14 ]]
Logits tf.Tensor([[-0.16483285 -0.38248405  0.78078836]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22837214 0.1837039  0.58792394]], shape=(1, 3), dtype=float32)
Selected action 0
[0.26, 0.04, 0.27, 0.212, 0.144, 0.73, 0.075, 0.005, 0.383, 0.0]
0.7276168333333334
4.773213999999999
Reward 4.362985671560026
Current State [[0.26  0.04  0.27  0.212 0.144 0.73  0.075 0.005 0.383 0.   ]]
Logits tf.Tensor([[-0.15843458 -0.29845726  0.65198565]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24282505 0.21109717 0.5460778 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.18, 0.04, 0.27, 0.1, 0.143, 0.73, 0.075, 0.005, 0.383, 0.0]
0.7276168333333334
4.773213999999999
Reward 4.362985671560026
Current State [[0.18  0.04  0.27  0.1   0.143 0.73  0.075 0.005 0.383 0.   ]]
Logits tf.Tensor([[-0.15352033 -0.29464826  0.6451529 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24444091 0.21226715 0.5432919 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.12, 0.04, 0.23, 0.23, 0.138, 0.73, 0.075, 0.005, 0.383, 0.0]
0.7276168333333334
4.773213999999999
Reward 4.362985671560026
Episode: 142 | Average Reward: 291 | Episode Reward: 349 | Loss: 1051.181 | Steps: 19 | Worker: 0
Current State [[ 0.00158895 -0.0098695  -0.00626599  0.00356356 -0.0038744  -0.00213111
   0.00410075 -0.00891695  0.00120134  0.00548838]]
Logits tf.Tensor([[-0.04159382 -0.03996121  0.07769662]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.31965926 0.32018158 0.36015916]], shape=(1, 3), dtype=float32)
Selected action 0
[0.08, 0.04, 0.27, 0.239, 0.138, 0.88, 0.053, 0.002, 0.409, 0.11]
0.8838276666666667
2.2428565000000003
Reward 5.426057654405203
Current State [[0.08  0.04  0.27  0.239 0.138 0.88  0.053 0.002 0.409 0.11 ]]
Logits tf.Tensor([[-0.13190748 -0.30530313  0.7082748 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24052374 0.20223352 0.55724275]], shape=(1, 3), dtype=float32)
Selected action 2
[0.12, 0.15, 0.31, 0.242, 0.14, 0.88, 0.053, 0.002, 0.409, 0.11]
0.8838276666666667
2.2428565000000003
Reward 17.426057654405202
Current State [[0.12  0.15  0.31  0.242 0.14  0.88  0.053 0.002 0.409 0.11 ]]
Logits tf.Tensor([[-0.14488186 -0.33667377  0.7632884 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23227403 0.19173726 0.5759887 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.06, 0.04, 0.38, 0.218, 0.139, 0.91, 0.042, 0.001, 0.46399999999999997, 0.15]
0.9108528333333334
0.5005945
Reward 16.807957047340594
Current State [[0.06  0.04  0.38  0.218 0.139 0.91  0.042 0.001 0.464 0.15 ]]
Logits tf.Tensor([[-0.1317692  -0.31787428  0.767854  ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23316206 0.19356793 0.57327   ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.14, 0.15, 0.26, 0.249, 0.138, 0.91, 0.042, 0.001, 0.46399999999999997, 0.15]
0.9108528333333334
0.5005945
Reward 28.807957047340594
Current State [[0.14  0.15  0.26  0.249 0.138 0.91  0.042 0.001 0.464 0.15 ]]
Logits tf.Tensor([[-0.15051845 -0.35901618  0.78369164]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22951546 0.1863213  0.58416325]], shape=(1, 3), dtype=float32)
Selected action 2
[0.2, 0.15, 0.26, 0.216, 0.139, 0.91, 0.042, 0.001, 0.46399999999999997, 0.15]
0.9108528333333334
0.5005945
Reward 28.807957047340594
Current State [[0.2   0.15  0.26  0.216 0.139 0.91  0.042 0.001 0.464 0.15 ]]
Logits tf.Tensor([[-0.16130427 -0.3779396   0.7826468 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2285537  0.18403682 0.5874095 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.17, 0.15, 0.21, 0.207, 0.14, 0.98, 0.039, 0.001, 0.457, 0.13]
0.9823149999999999
0.9464283333333333
Reward 21.407454740033877
Current State [[0.17  0.15  0.21  0.207 0.14  0.98  0.039 0.001 0.457 0.13 ]]
Logits tf.Tensor([[-0.16002037 -0.38259575  0.7878438 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22827676 0.18272519 0.5889981 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.17, 0.15, 0.27, 0.246, 0.138, 0.98, 0.039, 0.001, 0.457, 0.13]
0.9823149999999999
0.9464283333333333
Reward 21.407454740033877
Current State [[0.17  0.15  0.27  0.246 0.138 0.98  0.039 0.001 0.457 0.13 ]]
Logits tf.Tensor([[-0.15825239 -0.37427685  0.80289596]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22622322 0.18227157 0.5915052 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.2, 0.15, 0.28, 0.229, 0.143, 0.98, 0.039, 0.001, 0.457, 0.13]
0.9823149999999999
0.9464283333333333
Reward 21.407454740033877
Current State [[0.2   0.15  0.28  0.229 0.143 0.98  0.039 0.001 0.457 0.13 ]]
Logits tf.Tensor([[-0.16380091 -0.38359386  0.80627006]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2251838  0.18075165 0.59406453]], shape=(1, 3), dtype=float32)
Selected action 2
[0.25, 0.15, 0.27, 0.2, 0.146, 0.89, 0.032, 0.001, 0.44400000000000006, 0.11]
0.8857845
1.4511898333333333
Reward 18.564418630981173
Current State [[0.25  0.15  0.27  0.2   0.146 0.89  0.032 0.001 0.444 0.11 ]]
Logits tf.Tensor([[-0.1635186  -0.37695527  0.7700857 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2298077  0.18563943 0.5845528 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.01, 0.15, 0.12, 0.2, 0.143, 0.89, 0.032, 0.001, 0.44400000000000006, 0.11]
0.8857845
1.4511898333333333
Reward 18.564418630981173
Current State [[0.01  0.15  0.12  0.2   0.143 0.89  0.032 0.001 0.444 0.11 ]]
Logits tf.Tensor([[-0.13007851 -0.33059904  0.7367978 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23822165 0.19493788 0.5668404 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.15, 0.2, 0.215, 0.137, 0.89, 0.032, 0.001, 0.44400000000000006, 0.11]
0.8857845
1.4511898333333333
Reward 18.564418630981173
Current State [[0.07  0.15  0.2   0.215 0.137 0.89  0.032 0.001 0.444 0.11 ]]
Logits tf.Tensor([[-0.13621514 -0.33687222  0.7514393 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2354261  0.19262399 0.57194996]], shape=(1, 3), dtype=float32)
Selected action 2
[0.11, 0.15, 0.22, 0.249, 0.138, 0.91, 0.024, 0.01, 0.321, 0.01]
0.9067008333333334
10.12261883333333
Reward 16.119047009454754
Current State [[0.11  0.15  0.22  0.249 0.138 0.91  0.024 0.01  0.321 0.01 ]]
Logits tf.Tensor([[-0.12550926 -0.30926687  0.7016106 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24278559 0.20203097 0.5551834 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.08, 0.08, 0.25, 0.2, 0.139, 0.91, 0.024, 0.01, 0.321, 0.01]
0.9067008333333334
10.12261883333333
Reward 10.119047009454754
Current State [[0.08  0.08  0.25  0.2   0.139 0.91  0.024 0.01  0.321 0.01 ]]
Logits tf.Tensor([[-0.11462262 -0.29469955  0.6792605 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24708593 0.20636766 0.54654646]], shape=(1, 3), dtype=float32)
Selected action 2
[0.12, 0.15, 0.22, 0.238, 0.138, 0.94, 0.039, 0.0, 0.43, 0.13]
0.9366996666666668
0.4958333333333334
Reward 29.59317717669559
Current State [[0.12  0.15  0.22  0.238 0.138 0.94  0.039 0.    0.43  0.13 ]]
Logits tf.Tensor([[-0.14668864 -0.3547544   0.7674351 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23219408 0.18857725 0.57922864]], shape=(1, 3), dtype=float32)
Selected action 1
[0.08, 0.08, 0.23, 0.238, 0.142, 0.94, 0.039, 0.0, 0.43, 0.13]
0.9366996666666668
0.4958333333333334
Reward 23.59317717669559
Current State [[0.08  0.08  0.23  0.238 0.142 0.94  0.039 0.    0.43  0.13 ]]
Logits tf.Tensor([[-0.13384624 -0.33031344  0.74172044]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23686223 0.19461271 0.568525  ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.24, 0.226, 0.143, 0.94, 0.039, 0.0, 0.43, 0.13]
0.9366996666666668
0.4958333333333334
Reward 29.59317717669559
Current State [[0.05  0.15  0.24  0.226 0.143 0.94  0.039 0.    0.43  0.13 ]]
Logits tf.Tensor([[-0.13507527 -0.3420034   0.77377605]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23285335 0.18932796 0.5778187 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.16, 0.15, 0.16, 0.224, 0.139, 0.96, 0.035, 0.0, 0.42400000000000004, 0.06]
0.9611981666666668
0.3964283333333334
Reward 36.058513964820435
Current State [[0.16  0.15  0.16  0.224 0.139 0.96  0.035 0.    0.424 0.06 ]]
Logits tf.Tensor([[-0.15129127 -0.35964474  0.75480354]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23328732 0.18941063 0.57730204]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.15, 0.23, 0.213, 0.147, 0.96, 0.035, 0.0, 0.42400000000000004, 0.06]
0.9611981666666668
0.3964283333333334
Reward 36.058513964820435
Current State [[0.07  0.15  0.23  0.213 0.147 0.96  0.035 0.    0.424 0.06 ]]
Logits tf.Tensor([[-0.13684496 -0.33867982  0.77268976]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23253669 0.19003592 0.5774274 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.04, 0.08, 0.26, 0.227, 0.141, 0.83, 0.023, 0.001, 0.353, 0.06]
0.8291298333333333
1.0910715000000004
Reward 13.465154841939306
Current State [[0.04  0.08  0.26  0.227 0.141 0.83  0.023 0.001 0.353 0.06 ]]
Logits tf.Tensor([[-0.11043563 -0.27794996  0.6774533 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24724849 0.20911399 0.5436375 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.06, 0.04, 0.24, 0.244, 0.14, 0.83, 0.023, 0.001, 0.353, 0.06]
0.8291298333333333
1.0910715000000004
Reward 7.465154841939306
Episode: 143 | Average Reward: 292 | Episode Reward: 419 | Loss: 1484.847 | Steps: 19 | Worker: 0
Current State [[-0.0030637  -0.00915043 -0.00978821  0.00744822  0.00907819  0.00616093
   0.00130676  0.00849002  0.00687215 -0.00019364]]
Logits tf.Tensor([[-0.03880932 -0.04397306  0.08491603]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.31984088 0.31819358 0.36196554]], shape=(1, 3), dtype=float32)
Selected action 1
[0.1, 0.08, 0.24, 0.209, 0.144, 0.83, 0.023, 0.001, 0.353, 0.06]
0.8291298333333333
1.0910715000000004
Reward 13.465154841939306
Current State [[0.1   0.08  0.24  0.209 0.144 0.83  0.023 0.001 0.353 0.06 ]]
Logits tf.Tensor([[-0.11935574 -0.30065954  0.68182576]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24616271 0.20534445 0.5484928 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.15, 0.23, 0.233, 0.137, 0.83, 0.023, 0.001, 0.353, 0.06]
0.8291298333333333
1.0910715000000004
Reward 19.465154841939306
Current State [[0.08  0.15  0.23  0.233 0.137 0.83  0.023 0.001 0.353 0.06 ]]
Logits tf.Tensor([[-0.12273951 -0.30828854  0.7062524 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24262094 0.20153262 0.55584645]], shape=(1, 3), dtype=float32)
Selected action 0
[0.15, 0.04, 0.27, 0.24, 0.137, 0.89, 0.019, 0.001, 0.377, 0.06]
0.8853916666666667
1.4166663333333331
Reward 6.648111136358506
Current State [[0.15  0.04  0.27  0.24  0.137 0.89  0.019 0.001 0.377 0.06 ]]
Logits tf.Tensor([[-0.1272158  -0.31183535  0.701218  ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24265072 0.20174477 0.5556045 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.03, 0.04, 0.29, 0.215, 0.138, 0.89, 0.019, 0.001, 0.377, 0.06]
0.8853916666666667
1.4166663333333331
Reward 6.648111136358506
Current State [[0.03  0.04  0.29  0.215 0.138 0.89  0.019 0.001 0.377 0.06 ]]
Logits tf.Tensor([[-0.1103275  -0.28875655  0.70466316]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24415626 0.20425707 0.5515867 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.15, 0.15, 0.27, 0.235, 0.137, 0.89, 0.019, 0.001, 0.377, 0.06]
0.8853916666666667
1.4166663333333331
Reward 18.648111136358505
Current State [[0.15  0.15  0.27  0.235 0.137 0.89  0.019 0.001 0.377 0.06 ]]
Logits tf.Tensor([[-0.13712205 -0.33637336  0.74520916]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23607899 0.19342987 0.57049114]], shape=(1, 3), dtype=float32)
Selected action 0
[0.07, 0.04, 0.24, 0.236, 0.137, 0.84, 0.031, 0.002, 0.501, 0.12]
0.8357088333333333
2.301190333333333
Reward 5.27838725840388
Current State [[0.07  0.04  0.24  0.236 0.137 0.84  0.031 0.002 0.501 0.12 ]]
Logits tf.Tensor([[-0.13295133 -0.31443605  0.7371666 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23689815 0.1975804  0.5655214 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.19, 0.15, 0.28, 0.224, 0.141, 0.84, 0.031, 0.002, 0.501, 0.12]
0.8357088333333333
2.301190333333333
Reward 17.278387258403882
Current State [[0.19  0.15  0.28  0.224 0.141 0.84  0.031 0.002 0.501 0.12 ]]
Logits tf.Tensor([[-0.15372488 -0.36853305  0.79256153]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22816353 0.18405864 0.5877778 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.16, 0.15, 0.27, 0.228, 0.138, 0.84, 0.031, 0.002, 0.501, 0.12]
0.8357088333333333
2.301190333333333
Reward 17.278387258403882
Current State [[0.16  0.15  0.27  0.228 0.138 0.84  0.031 0.002 0.501 0.12 ]]
Logits tf.Tensor([[-0.15021558 -0.36125934  0.7893433 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22890675 0.18535465 0.58573854]], shape=(1, 3), dtype=float32)
Selected action 1
[0.1, 0.08, 0.26, 0.24, 0.142, 0.85, 0.023, 0.003, 0.40499999999999997, 0.08]
0.8513411666666667
2.5095234999999994
Reward 11.166519925822532
Current State [[0.1   0.08  0.26  0.24  0.142 0.85  0.023 0.003 0.405 0.08 ]]
Logits tf.Tensor([[-0.12510484 -0.31077865  0.7172995 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2408195  0.20001131 0.5591692 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.1, 0.04, 0.24, 0.25, 0.123, 0.85, 0.023, 0.003, 0.40499999999999997, 0.08]
0.8513411666666667
2.5095234999999994
Reward 5.1665199258225325
Current State [[0.1   0.04  0.24  0.25  0.123 0.85  0.023 0.003 0.405 0.08 ]]
Logits tf.Tensor([[-0.1239057  -0.30093896  0.6904011 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24417865 0.20456113 0.5512602 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.23, 0.2, 0.14, 0.85, 0.023, 0.003, 0.40499999999999997, 0.08]
0.8513411666666667
2.5095234999999994
Reward 17.166519925822534
Current State [[0.05  0.15  0.23  0.2   0.14  0.85  0.023 0.003 0.405 0.08 ]]
Logits tf.Tensor([[-0.12367471 -0.32147825  0.7351852 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2391773  0.19625236 0.56457037]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.3, 0.248, 0.138, 0.85, 0.023, 0.003, 0.40499999999999997, 0.08]
0.8513411666666667
2.5095234999999994
Reward 5.1665199258225325
Current State [[0.04  0.04  0.3   0.248 0.138 0.85  0.023 0.003 0.405 0.08 ]]
Logits tf.Tensor([[-0.1140749  -0.28667936  0.7098697 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24266285 0.20419359 0.55314356]], shape=(1, 3), dtype=float32)
Selected action 2
[0.2, 0.15, 0.29, 0.24, 0.142, 0.74, 0.024, 0.005, 0.591, 0.05]
0.7355371666666667
4.8541663333333345
Reward 16.35936107619388
Current State [[0.2   0.15  0.29  0.24  0.142 0.74  0.024 0.005 0.591 0.05 ]]
Logits tf.Tensor([[-0.15438403 -0.35821614  0.8013871 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2264352  0.18468039 0.5888844 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.18, 0.08, 0.27, 0.25, 0.143, 0.74, 0.024, 0.005, 0.591, 0.05]
0.7355371666666667
4.8541663333333345
Reward 10.359361076193881
Current State [[0.18  0.08  0.27  0.25  0.143 0.74  0.024 0.005 0.591 0.05 ]]
Logits tf.Tensor([[-0.14816195 -0.33325705  0.77222943]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23034586 0.19142322 0.578231  ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.1, 0.15, 0.23, 0.225, 0.146, 0.74, 0.024, 0.005, 0.591, 0.05]
0.7355371666666667
4.8541663333333345
Reward 16.35936107619388
Current State [[0.1   0.15  0.23  0.225 0.146 0.74  0.024 0.005 0.591 0.05 ]]
Logits tf.Tensor([[-0.14236797 -0.33449584  0.7893093 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2291494  0.1890944  0.58175623]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.15, 0.26, 0.16, 0.149, 0.79, 0.032, 0.001, 0.7110000000000001, 0.07]
0.7947966666666666
1.3357163333333337
Reward 18.477372787342844
Current State [[0.06  0.15  0.26  0.16  0.149 0.79  0.032 0.001 0.711 0.07 ]]
Logits tf.Tensor([[-0.1573879  -0.35933572  0.86039835]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.21814059 0.17825085 0.6036086 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.09, 0.15, 0.21, 0.2, 0.141, 0.79, 0.032, 0.001, 0.7110000000000001, 0.07]
0.7947966666666666
1.3357163333333337
Reward 18.477372787342844
Current State [[0.09  0.15  0.21  0.2   0.141 0.79  0.032 0.001 0.711 0.07 ]]
Logits tf.Tensor([[-0.1581105  -0.36654648  0.8534154 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.21921909 0.17797367 0.6028073 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.09, 0.15, 0.21, 0.2, 0.141, 0.79, 0.032, 0.001, 0.7110000000000001, 0.07]
0.7947966666666666
1.3357163333333337
Reward 18.477372787342844
Current State [[0.09  0.15  0.21  0.2   0.141 0.79  0.032 0.001 0.711 0.07 ]]
Logits tf.Tensor([[-0.1581105  -0.36654648  0.8534154 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.21921909 0.17797367 0.6028073 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.02, 0.04, 0.3, 0.239, 0.139, 0.9, 0.037, 0.002, 0.541, 0.14]
0.8986283333333334
2.3434521666666663
Reward 5.374995924679986
Current State [[0.02  0.04  0.3   0.239 0.139 0.9   0.037 0.002 0.541 0.14 ]]
Logits tf.Tensor([[-0.13408904 -0.32291463  0.7902196 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22998783 0.19041403 0.5795981 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.16, 0.15, 0.23, 0.238, 0.145, 0.9, 0.037, 0.002, 0.541, 0.14]
0.8986283333333334
2.3434521666666663
Reward 17.374995924679986
Episode: 144 | Average Reward: 292 | Episode Reward: 264 | Loss: 550.166 | Steps: 19 | Worker: 0
Current State [[-0.00409653  0.00496715  0.00161899  0.00556606 -0.00229727  0.00563141
   0.00624773 -0.00054698  0.00104488 -0.00496804]]
Logits tf.Tensor([[-0.04293644 -0.04523684  0.08884498]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.31861734 0.31788525 0.36349744]], shape=(1, 3), dtype=float32)
Selected action 2
[0.24, 0.15, 0.23, 0.1, 0.139, 0.9, 0.037, 0.002, 0.541, 0.14]
0.8986283333333334
2.3434521666666663
Reward 17.374995924679986
Current State [[0.24  0.15  0.23  0.1   0.139 0.9   0.037 0.002 0.541 0.14 ]]
Logits tf.Tensor([[-0.17543592 -0.4280733   0.8209555 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22295353 0.17317903 0.6038675 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.13, 0.08, 0.26, 0.214, 0.138, 0.87, 0.053, 0.001, 0.40499999999999997, 0.05]
0.8679563333333332
0.8702375000000001
Reward 15.101744468866322
Current State [[0.13  0.08  0.26  0.214 0.138 0.87  0.053 0.001 0.405 0.05 ]]
Logits tf.Tensor([[-0.14176057 -0.33263993  0.73424125]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23654576 0.19544174 0.56801254]], shape=(1, 3), dtype=float32)
Selected action 2
[0.29, 0.15, 0.29, 0.1, 0.133, 0.87, 0.053, 0.001, 0.40499999999999997, 0.05]
0.8679563333333332
0.8702375000000001
Reward 21.101744468866322
Current State [[0.29  0.15  0.29  0.1   0.133 0.87  0.053 0.001 0.405 0.05 ]]
Logits tf.Tensor([[-0.18048976 -0.40177196  0.7633858 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22875902 0.18334815 0.58789283]], shape=(1, 3), dtype=float32)
Selected action 2
[0.11, 0.15, 0.27, 0.24, 0.144, 0.87, 0.053, 0.001, 0.40499999999999997, 0.05]
0.8679563333333332
0.8702375000000001
Reward 21.101744468866322
Current State [[0.11  0.15  0.27  0.24  0.144 0.87  0.053 0.001 0.405 0.05 ]]
Logits tf.Tensor([[-0.1434326  -0.34034562  0.76833737]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23201934 0.19054867 0.577432  ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.08, 0.04, 0.25, 0.2, 0.125, 0.87, 0.053, 0.001, 0.40499999999999997, 0.05]
0.8679563333333332
0.8702375000000001
Reward 9.101744468866322
Current State [[0.08  0.04  0.25  0.2   0.125 0.87  0.053 0.001 0.405 0.05 ]]
Logits tf.Tensor([[-0.13344577 -0.31439734  0.7100697 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2404424  0.20064338 0.55891424]], shape=(1, 3), dtype=float32)
Selected action 0
[0.03, 0.04, 0.32, 0.224, 0.139, 0.81, 0.052, 0.002, 0.41100000000000003, 0.1]
0.8085971666666667
1.570238
Reward 6.039087192733545
Current State [[0.03  0.04  0.32  0.224 0.139 0.81  0.052 0.002 0.411 0.1  ]]
Logits tf.Tensor([[-0.12212265 -0.29549634  0.7175695 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24058835 0.20229231 0.55711937]], shape=(1, 3), dtype=float32)
Selected action 0
[0.07, 0.04, 0.36, 0.226, 0.138, 0.81, 0.052, 0.002, 0.41100000000000003, 0.1]
0.8085971666666667
1.570238
Reward 6.039087192733545
Current State [[0.07  0.04  0.36  0.226 0.138 0.81  0.052 0.002 0.411 0.1  ]]
Logits tf.Tensor([[-0.1276508  -0.30358016  0.72701687]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23870505 0.2001965  0.56109846]], shape=(1, 3), dtype=float32)
Selected action 2
[0.24, 0.15, 0.28, 0.24, 0.144, 0.81, 0.052, 0.002, 0.41100000000000003, 0.1]
0.8085971666666667
1.570238
Reward 18.039087192733547
Current State [[0.24  0.15  0.28  0.24  0.144 0.81  0.052 0.002 0.411 0.1  ]]
Logits tf.Tensor([[-0.1582096  -0.36839306  0.7562788 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23223767 0.18821365 0.5795487 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.12, 0.08, 0.25, 0.206, 0.144, 0.81, 0.052, 0.002, 0.41100000000000003, 0.1]
0.8085971666666667
1.570238
Reward 12.039087192733545
Current State [[0.12  0.08  0.25  0.206 0.144 0.81  0.052 0.002 0.411 0.1  ]]
Logits tf.Tensor([[-0.13754009 -0.32814652  0.71756583]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23934431 0.19780798 0.56284773]], shape=(1, 3), dtype=float32)
Selected action 2
[0.14, 0.15, 0.27, 0.247, 0.147, 0.86, 0.044, 0.001, 0.465, 0.18]
0.8558328333333332
1.0791661666666665
Reward 19.67798730102868
Current State [[0.14  0.15  0.27  0.247 0.147 0.86  0.044 0.001 0.465 0.18 ]]
Logits tf.Tensor([[-0.14753817 -0.37273324  0.7936343 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22928706 0.18305372 0.58765924]], shape=(1, 3), dtype=float32)
Selected action 1
[0.12, 0.08, 0.24, 0.25, 0.143, 0.86, 0.044, 0.001, 0.465, 0.18]
0.8558328333333332
1.0791661666666665
Reward 13.67798730102868
Current State [[0.12  0.08  0.24  0.25  0.143 0.86  0.044 0.001 0.465 0.18 ]]
Logits tf.Tensor([[-0.14118738 -0.35142052  0.75705415]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23442939 0.18998045 0.5755902 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.12, 0.15, 0.27, 0.226, 0.144, 0.95, 0.029, 0.002, 0.38, 0.1]
0.9506158333333333
1.7928564999999999
Reward 18.120648297478123
Current State [[0.12  0.15  0.27  0.226 0.144 0.95  0.029 0.002 0.38  0.1  ]]
Logits tf.Tensor([[-0.13733412 -0.36105156  0.77671874]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23288569 0.18620163 0.5809127 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.09, 0.04, 0.4, 0.21, 0.144, 0.95, 0.029, 0.002, 0.38, 0.1]
0.9506158333333333
1.7928564999999999
Reward 6.120648297478123
Current State [[0.09  0.04  0.4   0.21  0.144 0.95  0.029 0.002 0.38  0.1  ]]
Logits tf.Tensor([[-0.12201013 -0.32880062  0.7639825 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23592803 0.19185433 0.57221764]], shape=(1, 3), dtype=float32)
Selected action 1
[0.13, 0.08, 0.3, 0.218, 0.143, 0.95, 0.029, 0.002, 0.38, 0.1]
0.9506158333333333
1.7928564999999999
Reward 12.120648297478123
Current State [[0.13  0.08  0.3   0.218 0.143 0.95  0.029 0.002 0.38  0.1  ]]
Logits tf.Tensor([[-0.13258058 -0.34866172  0.7553303 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23608752 0.19020861 0.57370394]], shape=(1, 3), dtype=float32)
Selected action 2
[0.14, 0.15, 0.27, 0.24, 0.138, 0.95, 0.029, 0.002, 0.38, 0.1]
0.9506158333333333
1.7928564999999999
Reward 18.120648297478123
Current State [[0.14  0.15  0.27  0.24  0.138 0.95  0.029 0.002 0.38  0.1  ]]
Logits tf.Tensor([[-0.14113496 -0.36326236  0.7755288 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23246375 0.18616007 0.58137614]], shape=(1, 3), dtype=float32)
Selected action 1
[0.21, 0.08, 0.3, 0.235, 0.145, 0.81, 0.033, 0.001, 0.434, 0.07]
0.8096691666666666
1.3327390000000001
Reward 12.54811323725898
Current State [[0.21  0.08  0.3   0.235 0.145 0.81  0.033 0.001 0.434 0.07 ]]
Logits tf.Tensor([[-0.14509138 -0.33886886  0.7408195 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23534764 0.19388908 0.5707633 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.07, 0.04, 0.33, 0.205, 0.146, 0.81, 0.033, 0.001, 0.434, 0.07]
0.8096691666666666
1.3327390000000001
Reward 6.548113237258979
Current State [[0.07  0.04  0.33  0.205 0.146 0.81  0.033 0.001 0.434 0.07 ]]
Logits tf.Tensor([[-0.12371072 -0.30165064  0.7297732 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23895977 0.20000759 0.56103265]], shape=(1, 3), dtype=float32)
Selected action 0
[0.02, 0.04, 0.3, 0.216, 0.138, 0.81, 0.033, 0.001, 0.434, 0.07]
0.8096691666666666
1.3327390000000001
Reward 6.548113237258979
Current State [[0.02  0.04  0.3   0.216 0.138 0.81  0.033 0.001 0.434 0.07 ]]
Logits tf.Tensor([[-0.11755089 -0.29007304  0.7197804 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24086325 0.202696   0.5564408 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.04, 0.26, 0.214, 0.139, 0.8, 0.05, 0.001, 0.42699999999999994, 0.03]
0.7980468333333331
0.619642
Reward 11.46662576300609
Current State [[0.05  0.04  0.26  0.214 0.139 0.8   0.05  0.001 0.427 0.03 ]]
Logits tf.Tensor([[-0.12777129 -0.29151452  0.7060416 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24090353 0.20451744 0.554579  ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.18, 0.04, 0.28, 0.24, 0.14, 0.8, 0.05, 0.001, 0.42699999999999994, 0.03]
0.7980468333333331
0.619642
Reward 11.46662576300609
Episode: 145 | Average Reward: 292 | Episode Reward: 262 | Loss: 461.783 | Steps: 19 | Worker: 0
Current State [[-0.00644701 -0.00047282 -0.00430068  0.00670261 -0.00804819  0.00465151
  -0.00542234 -0.00883995  0.00961158 -0.00923232]]
Logits tf.Tensor([[-0.04144318 -0.04137944  0.08672015]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.31879598 0.3188163  0.36238772]], shape=(1, 3), dtype=float32)
Selected action 0
[0.06, 0.04, 0.39, 0.178, 0.142, 0.8, 0.05, 0.001, 0.42699999999999994, 0.03]
0.7980468333333331
0.619642
Reward 11.46662576300609
Current State [[0.06  0.04  0.39  0.178 0.142 0.8   0.05  0.001 0.427 0.03 ]]
Logits tf.Tensor([[-0.12492034 -0.30153653  0.74040294]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23731123 0.19889088 0.5637979 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.06, 0.04, 0.31, 0.221, 0.146, 0.91, 0.042, 0.001, 0.44699999999999995, 0.17]
0.9076471666666667
1.0482141666666667
Reward 8.163464163097546
Current State [[0.06  0.04  0.31  0.221 0.146 0.91  0.042 0.001 0.447 0.17 ]]
Logits tf.Tensor([[-0.12516448 -0.34312803  0.76726717]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23555945 0.18942624 0.57501435]], shape=(1, 3), dtype=float32)
Selected action 1
[0.09, 0.08, 0.26, 0.229, 0.139, 0.91, 0.042, 0.001, 0.44699999999999995, 0.17]
0.9076471666666667
1.0482141666666667
Reward 14.163464163097546
Current State [[0.09  0.08  0.26  0.229 0.139 0.91  0.042 0.001 0.447 0.17 ]]
Logits tf.Tensor([[-0.13281974 -0.35903177  0.76931417]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23460928 0.18711238 0.57827836]], shape=(1, 3), dtype=float32)
Selected action 2
[0.16, 0.15, 0.28, 0.233, 0.143, 0.91, 0.042, 0.001, 0.44699999999999995, 0.17]
0.9076471666666667
1.0482141666666667
Reward 20.163464163097544
Current State [[0.16  0.15  0.28  0.233 0.143 0.91  0.042 0.001 0.447 0.17 ]]
Logits tf.Tensor([[-0.14886831 -0.39031312  0.8048483 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22826725 0.17930214 0.59243065]], shape=(1, 3), dtype=float32)
Selected action 2
[0.14, 0.15, 0.24, 0.241, 0.145, 0.89, 0.046, 0.001, 0.399, 0.16]
0.8917481666666666
1.4499998333333333
Reward 18.590774075419965
Current State [[0.14  0.15  0.24  0.241 0.145 0.89  0.046 0.001 0.399 0.16 ]]
Logits tf.Tensor([[-0.14265783 -0.37376007  0.76797485]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23366925 0.18545353 0.5808772 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.15, 0.08, 0.28, 0.226, 0.142, 0.89, 0.046, 0.001, 0.399, 0.16]
0.8917481666666666
1.4499998333333333
Reward 12.590774075419965
Current State [[0.15  0.08  0.28  0.226 0.142 0.89  0.046 0.001 0.399 0.16 ]]
Logits tf.Tensor([[-0.13793714 -0.3619955   0.7475641 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23677225 0.18924461 0.5739831 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.18, 0.15, 0.28, 0.239, 0.148, 0.89, 0.046, 0.001, 0.399, 0.16]
0.8917481666666666
1.4499998333333333
Reward 18.590774075419965
Current State [[0.18  0.15  0.28  0.239 0.148 0.89  0.046 0.001 0.399 0.16 ]]
Logits tf.Tensor([[-0.14890793 -0.38245234  0.778707  ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2314711  0.18326086 0.585268  ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.03, 0.08, 0.28, 0.181, 0.149, 0.83, 0.049, 0.001, 0.42400000000000004, 0.02]
0.8303518333333334
0.7404751666666668
Reward 16.061512286047968
Current State [[0.03  0.08  0.28  0.181 0.149 0.83  0.049 0.001 0.424 0.02 ]]
Logits tf.Tensor([[-0.12424323 -0.30979413  0.73937505]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23796077 0.19766131 0.56437796]], shape=(1, 3), dtype=float32)
Selected action 2
[0.11, 0.15, 0.25, 0.194, 0.148, 0.83, 0.049, 0.001, 0.42400000000000004, 0.02]
0.8303518333333334
0.7404751666666668
Reward 22.061512286047968
Current State [[0.11  0.15  0.25  0.194 0.148 0.83  0.049 0.001 0.424 0.02 ]]
Logits tf.Tensor([[-0.140016   -0.3425868   0.76132655]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23367019 0.19082177 0.57550806]], shape=(1, 3), dtype=float32)
Selected action 1
[0.09, 0.08, 0.26, 0.2, 0.139, 0.83, 0.049, 0.001, 0.42400000000000004, 0.02]
0.8303518333333334
0.7404751666666668
Reward 16.061512286047968
Current State [[0.09  0.08  0.26  0.2   0.139 0.83  0.049 0.001 0.424 0.02 ]]
Logits tf.Tensor([[-0.1331286  -0.32113218  0.7324896 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23780724 0.19704986 0.56514287]], shape=(1, 3), dtype=float32)
Selected action 2
[0.09, 0.08, 0.26, 0.2, 0.139, 0.83, 0.049, 0.001, 0.42400000000000004, 0.02]
0.8303518333333334
0.7404751666666668
Reward 22.061512286047968
Current State [[0.09  0.08  0.26  0.2   0.139 0.83  0.049 0.001 0.424 0.02 ]]
Logits tf.Tensor([[-0.1331286  -0.32113218  0.7324896 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23780724 0.19704986 0.56514287]], shape=(1, 3), dtype=float32)
Selected action 2
[0.16, 0.15, 0.27, 0.239, 0.138, 0.74, 0.037, 0.023, 0.409, 0.05]
0.7428218333333335
22.719047000000007
Reward 15.909115709299199
Current State [[0.16  0.15  0.27  0.239 0.138 0.74  0.037 0.023 0.409 0.05 ]]
Logits tf.Tensor([[-0.12982406 -0.33493873  0.7227541 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24037074 0.1957949  0.56383437]], shape=(1, 3), dtype=float32)
Selected action 2
[0.09, 0.15, 0.21, 0.208, 0.148, 0.74, 0.037, 0.023, 0.409, 0.05]
0.7428218333333335
22.719047000000007
Reward 15.909115709299199
Current State [[0.09  0.15  0.21  0.208 0.148 0.74  0.037 0.023 0.409 0.05 ]]
Logits tf.Tensor([[-0.12115911 -0.32406142  0.7090128 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2433048  0.1986238  0.55807143]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.15, 0.22, 0.242, 0.138, 0.74, 0.037, 0.023, 0.409, 0.05]
0.7428218333333335
22.719047000000007
Reward 15.909115709299199
Current State [[0.07  0.15  0.22  0.242 0.138 0.74  0.037 0.023 0.409 0.05 ]]
Logits tf.Tensor([[-0.11834181 -0.31560737  0.7099319 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24328913 0.1997337  0.55697715]], shape=(1, 3), dtype=float32)
Selected action 1
[0.05, 0.08, 0.21, 0.2, 0.138, 0.74, 0.037, 0.023, 0.409, 0.05]
0.7428218333333335
22.719047000000007
Reward 9.909115709299199
Current State [[0.05  0.08  0.21  0.2   0.138 0.74  0.037 0.023 0.409 0.05 ]]
Logits tf.Tensor([[-0.1126234  -0.29960552  0.67636067]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24810092 0.20578943 0.5461096 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.12, 0.15, 0.26, 0.239, 0.139, 0.82, 0.027, 0.001, 0.40099999999999997, 0.04]
0.8245793333333331
0.6875008333333332
Reward 22.703090609158686
Current State [[0.12  0.15  0.26  0.239 0.139 0.82  0.027 0.001 0.401 0.04 ]]
Logits tf.Tensor([[-0.13038684 -0.33273548  0.7463736 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23697177 0.19356091 0.5694673 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.04, 0.25, 0.212, 0.145, 0.82, 0.027, 0.001, 0.40099999999999997, 0.04]
0.8245793333333331
0.6875008333333332
Reward 10.703090609158684
Current State [[0.05  0.04  0.25  0.212 0.145 0.82  0.027 0.001 0.401 0.04 ]]
Logits tf.Tensor([[-0.11287718 -0.29613647  0.69906884]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2448077  0.20381519 0.5513771 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.08, 0.08, 0.25, 0.234, 0.135, 0.82, 0.027, 0.001, 0.40099999999999997, 0.04]
0.8245793333333331
0.6875008333333332
Reward 16.703090609158686
Current State [[0.08  0.08  0.25  0.234 0.135 0.82  0.027 0.001 0.401 0.04 ]]
Logits tf.Tensor([[-0.12013041 -0.30928466  0.7134986 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2421709 0.2004349 0.5573942]], shape=(1, 3), dtype=float32)
Selected action 0
[0.09, 0.04, 0.25, 0.236, 0.141, 0.81, 0.028, 0.001, 0.49000000000000005, 0.12]
0.8138443333333333
1.1946428333333332
Reward 6.979165886361676
Current State [[0.09  0.04  0.25  0.236 0.141 0.81  0.028 0.001 0.49  0.12 ]]
Logits tf.Tensor([[-0.12786862 -0.3250753   0.73852843]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23813227 0.19551155 0.5663562 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.21, 0.15, 0.26, 0.241, 0.143, 0.81, 0.028, 0.001, 0.49000000000000005, 0.12]
0.8138443333333333
1.1946428333333332
Reward 18.979165886361677
Episode: 146 | Average Reward: 292 | Episode Reward: 313 | Loss: 778.664 | Steps: 19 | Worker: 0
Current State [[ 0.00795039 -0.00383818  0.00978042 -0.00040495  0.0062676  -0.00577653
  -0.00959376  0.00054856 -0.00460508 -0.00948012]]
Logits tf.Tensor([[-0.03648346 -0.04215058  0.07812876]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.32094616 0.31913245 0.35992137]], shape=(1, 3), dtype=float32)
Selected action 1
[0.04, 0.08, 0.25, 0.21, 0.139, 0.81, 0.028, 0.001, 0.49000000000000005, 0.12]
0.8138443333333333
1.1946428333333332
Reward 12.979165886361676
Current State [[0.04  0.08  0.25  0.21  0.139 0.81  0.028 0.001 0.49  0.12 ]]
Logits tf.Tensor([[-0.1227741  -0.32921636  0.7542123 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23712875 0.1928979  0.56997335]], shape=(1, 3), dtype=float32)
Selected action 2
[0.22, 0.15, 0.25, 0.232, 0.139, 0.8, 0.031, 0.001, 0.44699999999999995, 0.05]
0.7976358333333333
0.6178581666666667
Reward 23.493628805569113
Current State [[0.22  0.15  0.25  0.232 0.139 0.8   0.031 0.001 0.447 0.05 ]]
Logits tf.Tensor([[-0.14415593 -0.36613747  0.76235974]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23382999 0.18728149 0.57888854]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.15, 0.24, 0.215, 0.139, 0.8, 0.031, 0.001, 0.44699999999999995, 0.05]
0.7976358333333333
0.6178581666666667
Reward 23.493628805569113
Current State [[0.07  0.15  0.24  0.215 0.139 0.8   0.031 0.001 0.447 0.05 ]]
Logits tf.Tensor([[-0.12836896 -0.333114    0.7574963 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23585255 0.19218566 0.57196176]], shape=(1, 3), dtype=float32)
Selected action 0
[0.02, 0.04, 0.3, 0.2, 0.139, 0.97, 0.042, 0.001, 0.397, 0.08]
0.9692825
0.7517855
Reward 11.478925040580753
Current State [[0.02  0.04  0.3   0.2   0.139 0.97  0.042 0.001 0.397 0.08 ]]
Logits tf.Tensor([[-0.11625816 -0.331336    0.7572607 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23799306 0.19193631 0.5700707 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.15, 0.15, 0.27, 0.223, 0.139, 0.97, 0.042, 0.001, 0.397, 0.08]
0.9692825
0.7517855
Reward 23.478925040580755
Current State [[0.15  0.15  0.27  0.223 0.139 0.97  0.042 0.001 0.397 0.08 ]]
Logits tf.Tensor([[-0.14574721 -0.3831524   0.7964389 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22966039 0.18112662 0.58921295]], shape=(1, 3), dtype=float32)
Selected action 0
[0.02, 0.04, 0.31, 0.2, 0.14, 0.97, 0.042, 0.001, 0.397, 0.08]
0.9692825
0.7517855
Reward 11.478925040580753
Current State [[0.02  0.04  0.31  0.2   0.14  0.97  0.042 0.001 0.397 0.08 ]]
Logits tf.Tensor([[-0.11608077 -0.3311312   0.76011395]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23762882 0.19164781 0.57072335]], shape=(1, 3), dtype=float32)
Selected action 2
[0.11, 0.15, 0.24, 0.1, 0.139, 0.91, 0.026, 0.004, 0.40700000000000003, 0.1]
0.9080108333333333
3.9982145000000004
Reward 16.66963622235798
Current State [[0.11  0.15  0.24  0.1   0.139 0.91  0.026 0.004 0.407 0.1  ]]
Logits tf.Tensor([[-0.13424821 -0.38270575  0.7654906 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23590672 0.18400794 0.58008534]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.04, 0.33, 0.209, 0.138, 0.91, 0.026, 0.004, 0.40700000000000003, 0.1]
0.9080108333333333
3.9982145000000004
Reward 4.66963622235798
Current State [[0.05  0.04  0.33  0.209 0.138 0.91  0.026 0.004 0.407 0.1  ]]
Logits tf.Tensor([[-0.11235235 -0.32637113  0.7483231 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23968798 0.19350809 0.56680393]], shape=(1, 3), dtype=float32)
Selected action 2
[0.12, 0.15, 0.26, 0.236, 0.139, 0.91, 0.026, 0.004, 0.40700000000000003, 0.1]
0.9080108333333333
3.9982145000000004
Reward 16.66963622235798
Current State [[0.12  0.15  0.26  0.236 0.139 0.91  0.026 0.004 0.407 0.1  ]]
Logits tf.Tensor([[-0.13057828 -0.3642268   0.77769667]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2340999  0.18532284 0.58057725]], shape=(1, 3), dtype=float32)
Selected action 0
[0.08, 0.04, 0.25, 0.241, 0.145, 0.91, 0.026, 0.004, 0.40700000000000003, 0.1]
0.9080108333333333
3.9982145000000004
Reward 4.66963622235798
Current State [[0.08  0.04  0.25  0.241 0.145 0.91  0.026 0.004 0.407 0.1  ]]
Logits tf.Tensor([[-0.11626916 -0.33094183  0.7323341 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24136011 0.19473067 0.56390923]], shape=(1, 3), dtype=float32)
Selected action 2
[0.11, 0.15, 0.26, 0.225, 0.146, 0.85, 0.028, 0.003, 0.562, 0.13]
0.8502186666666667
3.3095233333333334
Reward 16.79731822069781
Current State [[0.11  0.15  0.26  0.225 0.146 0.85  0.028 0.003 0.562 0.13 ]]
Logits tf.Tensor([[-0.1435553  -0.38117442  0.8336058 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22495133 0.1773748  0.59767383]], shape=(1, 3), dtype=float32)
Selected action 2
[0.21, 0.15, 0.23, 0.246, 0.141, 0.85, 0.028, 0.003, 0.562, 0.13]
0.8502186666666667
3.3095233333333334
Reward 16.79731822069781
Current State [[0.21  0.15  0.23  0.246 0.141 0.85  0.028 0.003 0.562 0.13 ]]
Logits tf.Tensor([[-0.15093434 -0.40475067  0.82769316]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22539599 0.17486994 0.59973407]], shape=(1, 3), dtype=float32)
Selected action 0
[0.11, 0.04, 0.35, 0.238, 0.138, 0.85, 0.028, 0.003, 0.562, 0.13]
0.8502186666666667
3.3095233333333334
Reward 4.797318220697809
Current State [[0.11  0.04  0.35  0.238 0.138 0.85  0.028 0.003 0.562 0.13 ]]
Logits tf.Tensor([[-0.13835698 -0.3520406   0.807845  ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2281276  0.18423672 0.58763564]], shape=(1, 3), dtype=float32)
Selected action 1
[0.07, 0.08, 0.26, 0.245, 0.141, 0.77, 0.035, 0.008, 0.538, 0.15]
0.7697119999999998
7.879166333333333
Reward 10.149834032958386
Current State [[0.07  0.08  0.26  0.245 0.141 0.77  0.035 0.008 0.538 0.15 ]]
Logits tf.Tensor([[-0.13082543 -0.3389698   0.76703185]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23438808 0.19034418 0.57526773]], shape=(1, 3), dtype=float32)
Selected action 2
[0.09, 0.15, 0.24, 0.2, 0.142, 0.77, 0.035, 0.008, 0.538, 0.15]
0.7697119999999998
7.879166333333333
Reward 16.14983403295839
Current State [[0.09  0.15  0.24  0.2   0.142 0.77  0.035 0.008 0.538 0.15 ]]
Logits tf.Tensor([[-0.1375911  -0.36624995  0.7886249 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23145273 0.18414377 0.58440346]], shape=(1, 3), dtype=float32)
Selected action 1
[0.07, 0.08, 0.29, 0.216, 0.143, 0.9, 0.038, 0.002, 0.746, 0.17]
0.9010239999999999
2.0279758333333335
Reward 11.673870645023358
Current State [[0.07  0.08  0.29  0.216 0.143 0.9   0.038 0.002 0.746 0.17 ]]
Logits tf.Tensor([[-0.16009134 -0.4023027   0.91296655]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.21235037 0.16667174 0.62097794]], shape=(1, 3), dtype=float32)
Selected action 2
[0.14, 0.15, 0.25, 0.167, 0.138, 0.9, 0.038, 0.002, 0.746, 0.17]
0.9010239999999999
2.0279758333333335
Reward 17.673870645023356
Current State [[0.14  0.15  0.25  0.167 0.138 0.9   0.038 0.002 0.746 0.17 ]]
Logits tf.Tensor([[-0.17064737 -0.44400188  0.92778975]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.21007091 0.15982677 0.6301023 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.16, 0.15, 0.26, 0.24, 0.145, 0.9, 0.038, 0.002, 0.746, 0.17]
0.9010239999999999
2.0279758333333335
Reward 17.673870645023356
Current State [[0.16  0.15  0.26  0.24  0.145 0.9   0.038 0.002 0.746 0.17 ]]
Logits tf.Tensor([[-0.16921447 -0.44182792  0.936414  ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.20909522 0.15920241 0.63170236]], shape=(1, 3), dtype=float32)
Selected action 2
[0.15, 0.15, 0.24, 0.3, 0.124, 0.65, 0.019, 0.002, 0.622, 0.03]
0.6462561666666667
1.5297638333333334
Reward 17.564927412972647
Current State [[0.15  0.15  0.24  0.3   0.124 0.65  0.019 0.002 0.622 0.03 ]]
Logits tf.Tensor([[-0.1374933  -0.33691275  0.785459  ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2306318  0.18893501 0.5804332 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.12, 0.15, 0.25, 0.219, 0.139, 0.65, 0.019, 0.002, 0.622, 0.03]
0.6462561666666667
1.5297638333333334
Reward 17.564927412972647
Episode: 147 | Average Reward: 292 | Episode Reward: 295 | Loss: 614.307 | Steps: 19 | Worker: 0
Current State [[-0.00998871 -0.00010926  0.00168383  0.00582895 -0.00787901  0.00484996
  -0.00757239  0.00212213 -0.00234123 -0.00695549]]
Logits tf.Tensor([[-0.03584197 -0.04158479  0.07947417]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.32087258 0.31903514 0.36009225]], shape=(1, 3), dtype=float32)
Selected action 1
[0.09, 0.08, 0.27, 0.18, 0.133, 0.74, 0.086, 0.001, 0.351, 0.04]
0.7449155
1.2464315
Reward 12.492071845767486
Current State [[0.09  0.08  0.27  0.18  0.133 0.74  0.086 0.001 0.351 0.04 ]]
Logits tf.Tensor([[-0.13244818 -0.31032816  0.6795529 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24453144 0.2046833  0.55078524]], shape=(1, 3), dtype=float32)
Selected action 1
[0.05, 0.08, 0.3, 0.218, 0.14, 0.74, 0.086, 0.001, 0.351, 0.04]
0.7449155
1.2464315
Reward 12.492071845767486
Current State [[0.05  0.08  0.3   0.218 0.14  0.74  0.086 0.001 0.351 0.04 ]]
Logits tf.Tensor([[-0.12566403 -0.29652354  0.6911887 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24352795 0.20527942 0.55119264]], shape=(1, 3), dtype=float32)
Selected action 0
[0.15, 0.04, 0.27, 0.243, 0.138, 0.74, 0.086, 0.001, 0.351, 0.04]
0.7449155
1.2464315
Reward 6.4920718457674855
Current State [[0.15  0.04  0.27  0.243 0.138 0.74  0.086 0.001 0.351 0.04 ]]
Logits tf.Tensor([[-0.13661279 -0.30706525  0.6686208 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24506788 0.20666161 0.5482705 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.2, 0.04, 0.29, 0.242, 0.142, 0.93, 0.071, 0.003, 0.387, 0.14]
0.9264071666666667
3.1375001666666664
Reward 4.966323273647919
Current State [[0.2   0.04  0.29  0.242 0.142 0.93  0.071 0.003 0.387 0.14 ]]
Logits tf.Tensor([[-0.14904135 -0.3774504   0.7487227 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23529918 0.1872508  0.57745004]], shape=(1, 3), dtype=float32)
Selected action 2
[0.12, 0.15, 0.25, 0.231, 0.144, 0.93, 0.071, 0.003, 0.387, 0.14]
0.9264071666666667
3.1375001666666664
Reward 16.96632327364792
Current State [[0.12  0.15  0.25  0.231 0.144 0.93  0.071 0.003 0.387 0.14 ]]
Logits tf.Tensor([[-0.14604597 -0.38627702  0.78385913]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2314432  0.1820176  0.58653927]], shape=(1, 3), dtype=float32)
Selected action 2
[0.14, 0.15, 0.23, 0.0, 0.145, 0.89, 0.059, 0.007, 0.377, 0.18]
0.8888366666666666
6.681547833333334
Reward 16.28631058562339
Current State [[0.14  0.15  0.23  0.    0.145 0.89  0.059 0.007 0.377 0.18 ]]
Logits tf.Tensor([[-0.1508548 -0.4214467  0.7479043]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23699598 0.18081082 0.5821932 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.25, 0.15, 0.28, 0.211, 0.148, 0.89, 0.059, 0.007, 0.377, 0.18]
0.8888366666666666
6.681547833333334
Reward 16.28631058562339
Current State [[0.25  0.15  0.28  0.211 0.148 0.89  0.059 0.007 0.377 0.18 ]]
Logits tf.Tensor([[-0.15966228 -0.4137103   0.77164805]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.231831   0.17982079 0.5883482 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.1, 0.04, 0.25, 0.23, 0.139, 0.89, 0.059, 0.007, 0.377, 0.18]
0.8888366666666666
6.681547833333334
Reward 4.286310585623389
Current State [[0.1   0.04  0.25  0.23  0.139 0.89  0.059 0.007 0.377 0.18 ]]
Logits tf.Tensor([[-0.12457081 -0.35142943  0.71676934]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24292442 0.19361888 0.5634567 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.15, 0.23, 0.15, 0.123, 0.95, 0.06, 0.002, 0.393, 0.19]
0.9521283333333331
2.4238096666666675
Reward 17.420060762994623
Current State [[0.08  0.15  0.23  0.15  0.123 0.95  0.06  0.002 0.393 0.19 ]]
Logits tf.Tensor([[-0.1427911  -0.40256068  0.77843493]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2334486  0.18004239 0.586509  ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.33, 0.2, 0.139, 0.95, 0.06, 0.002, 0.393, 0.19]
0.9521283333333331
2.4238096666666675
Reward 5.420060762994625
Current State [[0.04  0.04  0.33  0.2   0.139 0.95  0.06  0.002 0.393 0.19 ]]
Logits tf.Tensor([[-0.12112239 -0.35549805  0.76276207]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2374537  0.18784119 0.57470506]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.15, 0.26, 0.196, 0.14, 0.95, 0.06, 0.002, 0.393, 0.19]
0.9521283333333331
2.4238096666666675
Reward 17.420060762994623
Current State [[0.06  0.15  0.26  0.196 0.14  0.95  0.06  0.002 0.393 0.19 ]]
Logits tf.Tensor([[-0.13513197 -0.39035523  0.79316646]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2322911  0.17996599 0.5877429 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.09, 0.15, 0.25, 0.2, 0.141, 0.95, 0.06, 0.002, 0.393, 0.19]
0.9521283333333331
2.4238096666666675
Reward 17.420060762994623
Current State [[0.09  0.15  0.25  0.2   0.141 0.95  0.06  0.002 0.393 0.19 ]]
Logits tf.Tensor([[-0.14041416 -0.39671218  0.7911786 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2318862  0.17945933 0.5886545 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.09, 0.08, 0.25, 0.239, 0.144, 0.89, 0.051, 0.0, 0.379, 0.08]
0.8857895
0.26845416666666666
Reward 40.49437108968916
Current State [[0.09  0.08  0.25  0.239 0.144 0.89  0.051 0.    0.379 0.08 ]]
Logits tf.Tensor([[-0.12525219 -0.33904812  0.7362782 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23956151 0.19344907 0.56698936]], shape=(1, 3), dtype=float32)
Selected action 1
[0.08, 0.08, 0.33, 0.15, 0.145, 0.89, 0.051, 0.0, 0.379, 0.08]
0.8857895
0.26845416666666666
Reward 40.49437108968916
Current State [[0.08  0.08  0.33  0.15  0.145 0.89  0.051 0.    0.379 0.08 ]]
Logits tf.Tensor([[-0.12560478 -0.34673348  0.7519642 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23771833 0.19055822 0.57172346]], shape=(1, 3), dtype=float32)
Selected action 2
[0.23, 0.15, 0.24, 0.222, 0.139, 0.91, 0.044, 0.001, 0.434, 0.19]
0.9118568333333332
1.3226185000000001
Reward 19.02848059906044
Current State [[0.23  0.15  0.24  0.222 0.139 0.91  0.044 0.001 0.434 0.19 ]]
Logits tf.Tensor([[-0.15633173 -0.41937602  0.79215235]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2298586  0.17669411 0.59344727]], shape=(1, 3), dtype=float32)
Selected action 2
[0.16, 0.15, 0.28, 0.256, 0.139, 0.91, 0.044, 0.001, 0.434, 0.19]
0.9118568333333332
1.3226185000000001
Reward 19.02848059906044
Current State [[0.16  0.15  0.28  0.256 0.139 0.91  0.044 0.001 0.434 0.19 ]]
Logits tf.Tensor([[-0.14405596 -0.39620885  0.8033141 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22956608 0.17840175 0.5920322 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.13, 0.04, 0.27, 0.253, 0.143, 0.91, 0.044, 0.001, 0.434, 0.19]
0.9118568333333332
1.3226185000000001
Reward 7.028480599060441
Current State [[0.13  0.04  0.27  0.253 0.143 0.91  0.044 0.001 0.434 0.19 ]]
Logits tf.Tensor([[-0.13019013 -0.36459088  0.7572321 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23697214 0.18745555 0.57557225]], shape=(1, 3), dtype=float32)
Selected action 2
[0.09, 0.15, 0.26, 0.225, 0.145, 0.89, 0.051, 0.002, 0.434, 0.15]
0.8879944999999999
2.1142855
Reward 17.552785705100078
Current State [[0.09  0.15  0.26  0.225 0.145 0.89  0.051 0.002 0.434 0.15 ]]
Logits tf.Tensor([[-0.13491644 -0.37562725  0.79279   ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23176198 0.1821809  0.5860571 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.15, 0.25, 0.245, 0.14, 0.89, 0.051, 0.002, 0.434, 0.15]
0.8879944999999999
2.1142855
Reward 17.552785705100078
Current State [[0.06  0.15  0.25  0.245 0.14  0.89  0.051 0.002 0.434 0.15 ]]
Logits tf.Tensor([[-0.13136989 -0.3672348   0.7901038 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23240256 0.18357183 0.58402556]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.15, 0.26, 0.205, 0.144, 0.89, 0.051, 0.002, 0.434, 0.15]
0.8879944999999999
2.1142855
Reward 17.552785705100078
Episode: 148 | Average Reward: 292 | Episode Reward: 326 | Loss: 988.18 | Steps: 19 | Worker: 0
Current State [[-0.00687487 -0.00441751  0.00659123  0.00710419 -0.00739499  0.00931844
  -0.00965081 -0.00465131 -0.00652117  0.00602949]]
Logits tf.Tensor([[-0.03484681 -0.04535773  0.0829827 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.32106888 0.31771183 0.36121926]], shape=(1, 3), dtype=float32)
Selected action 1
[0.08, 0.08, 0.25, 0.167, 0.146, 0.84, 0.045, 0.001, 0.45199999999999996, 0.11]
0.8360838333333331
0.971429
Reward 14.127840789234677
Current State [[0.08  0.08  0.25  0.167 0.146 0.84  0.045 0.001 0.452 0.11 ]]
Logits tf.Tensor([[-0.12686494 -0.35369605  0.7533209 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23761982 0.18939617 0.57298404]], shape=(1, 3), dtype=float32)
Selected action 2
[0.2, 0.15, 0.28, 0.244, 0.138, 0.84, 0.045, 0.001, 0.45199999999999996, 0.11]
0.8360838333333331
0.971429
Reward 20.127840789234675
Current State [[0.2   0.15  0.28  0.244 0.138 0.84  0.045 0.001 0.452 0.11 ]]
Logits tf.Tensor([[-0.144826   -0.38844082  0.79150784]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23071231 0.18082987 0.5884579 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.17, 0.15, 0.29, 0.2, 0.139, 0.84, 0.045, 0.001, 0.45199999999999996, 0.11]
0.8360838333333331
0.971429
Reward 20.127840789234675
Current State [[0.17  0.15  0.29  0.2   0.139 0.84  0.045 0.001 0.452 0.11 ]]
Logits tf.Tensor([[-0.14392465 -0.3858876   0.7917473 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23073314 0.1811452  0.5881216 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.12, 0.15, 0.25, 0.229, 0.138, 0.71, 0.048, 0.001, 0.44800000000000006, 0.07]
0.713535
1.4714264999999997
Reward 17.88147273304645
Current State [[0.12  0.15  0.25  0.229 0.138 0.71  0.048 0.001 0.448 0.07 ]]
Logits tf.Tensor([[-0.13124004 -0.34194982  0.73924637]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23820406 0.19294746 0.56884843]], shape=(1, 3), dtype=float32)
Selected action 1
[0.15, 0.08, 0.23, 0.242, 0.144, 0.71, 0.048, 0.001, 0.44800000000000006, 0.07]
0.713535
1.4714264999999997
Reward 11.881472733046452
Current State [[0.15  0.08  0.23  0.242 0.144 0.71  0.048 0.001 0.448 0.07 ]]
Logits tf.Tensor([[-0.12862265 -0.33053702  0.71039385]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24205722 0.19780065 0.56014216]], shape=(1, 3), dtype=float32)
Selected action 2
[0.33, 0.15, 0.27, 0.193, 0.144, 0.71, 0.048, 0.001, 0.44800000000000006, 0.07]
0.713535
1.4714264999999997
Reward 17.88147273304645
Current State [[0.33  0.15  0.27  0.193 0.144 0.71  0.048 0.001 0.448 0.07 ]]
Logits tf.Tensor([[-0.15344444 -0.39988825  0.74573016]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23589642 0.18437079 0.57973284]], shape=(1, 3), dtype=float32)
Selected action 2
[0.15, 0.15, 0.27, 0.248, 0.142, 0.71, 0.048, 0.001, 0.44800000000000006, 0.07]
0.713535
1.4714264999999997
Reward 17.88147273304645
Current State [[0.15  0.15  0.27  0.248 0.142 0.71  0.048 0.001 0.448 0.07 ]]
Logits tf.Tensor([[-0.1336226  -0.34770888  0.7457817 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23714988 0.19144605 0.5714041 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.12, 0.15, 0.26, 0.238, 0.145, 0.87, 0.046, 0.002, 0.42699999999999994, 0.02]
0.8734131666666668
1.5202365
Reward 18.36261119437583
Current State [[0.12  0.15  0.26  0.238 0.145 0.87  0.046 0.002 0.427 0.02 ]]
Logits tf.Tensor([[-0.13538572 -0.35916317  0.78475714]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23206477 0.18553416 0.5824011 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.21, 0.15, 0.27, 0.204, 0.145, 0.87, 0.046, 0.002, 0.42699999999999994, 0.02]
0.8734131666666668
1.5202365
Reward 18.36261119437583
Current State [[0.21  0.15  0.27  0.204 0.145 0.87  0.046 0.002 0.427 0.02 ]]
Logits tf.Tensor([[-0.14885265 -0.38348085  0.78597385]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2305403  0.18232623 0.58713347]], shape=(1, 3), dtype=float32)
Selected action 2
[0.09, 0.15, 0.23, 0.225, 0.13, 0.87, 0.046, 0.002, 0.42699999999999994, 0.02]
0.8734131666666668
1.5202365
Reward 18.36261119437583
Current State [[0.09  0.15  0.23  0.225 0.13  0.87  0.046 0.002 0.427 0.02 ]]
Logits tf.Tensor([[-0.13294168 -0.35463023  0.77135277]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23411785 0.18756698 0.5783152 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.14, 0.08, 0.27, 0.241, 0.138, 0.87, 0.046, 0.002, 0.42699999999999994, 0.02]
0.8734131666666668
1.5202365
Reward 12.36261119437583
Current State [[0.14  0.08  0.27  0.241 0.138 0.87  0.046 0.002 0.427 0.02 ]]
Logits tf.Tensor([[-0.13354717 -0.34709418  0.7566606 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23566288 0.19034822 0.57398885]], shape=(1, 3), dtype=float32)
Selected action 0
[0.15, 0.04, 0.27, 0.25, 0.144, 0.79, 0.041, 0.001, 0.414, 0.01]
0.7927841666666666
1.3053566666666663
Reward 6.5470251603429634
Current State [[0.15  0.04  0.27  0.25  0.144 0.79  0.041 0.001 0.414 0.01 ]]
Logits tf.Tensor([[-0.1264472 -0.317957   0.7113455]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24172273 0.19959326 0.558684  ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.16, 0.15, 0.28, 0.238, 0.141, 0.79, 0.041, 0.001, 0.414, 0.01]
0.7927841666666666
1.3053566666666663
Reward 18.54702516034296
Current State [[0.16  0.15  0.28  0.238 0.141 0.79  0.041 0.001 0.414 0.01 ]]
Logits tf.Tensor([[-0.13443169 -0.3471708   0.7573916 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2354082  0.1902962  0.57429564]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.15, 0.23, 0.2, 0.144, 0.79, 0.041, 0.001, 0.414, 0.01]
0.7927841666666666
1.3053566666666663
Reward 18.54702516034296
Current State [[0.08  0.15  0.23  0.2   0.144 0.79  0.041 0.001 0.414 0.01 ]]
Logits tf.Tensor([[-0.12564364 -0.33433476  0.74309176]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23834832 0.19345443 0.5681972 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.03, 0.04, 0.29, 0.192, 0.142, 0.79, 0.041, 0.001, 0.414, 0.01]
0.7927841666666666
1.3053566666666663
Reward 6.5470251603429634
Current State [[0.03  0.04  0.29  0.192 0.142 0.79  0.041 0.001 0.414 0.01 ]]
Logits tf.Tensor([[-0.11113682 -0.29765666  0.71182024]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24348284 0.2020523  0.5544649 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.09, 0.15, 0.21, 0.217, 0.139, 0.73, 0.023, 0.002, 0.42300000000000004, 0.03]
0.7263053333333335
2.045835
Reward 17.240046718381308
Current State [[0.09  0.15  0.21  0.217 0.139 0.73  0.023 0.002 0.423 0.03 ]]
Logits tf.Tensor([[-0.11771823 -0.3251509   0.7204114 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24244149 0.19702443 0.56053406]], shape=(1, 3), dtype=float32)
Selected action 1
[0.13, 0.08, 0.26, 0.242, 0.142, 0.73, 0.023, 0.002, 0.42300000000000004, 0.03]
0.7263053333333335
2.045835
Reward 11.240046718381306
Current State [[0.13  0.08  0.26  0.242 0.142 0.73  0.023 0.002 0.423 0.03 ]]
Logits tf.Tensor([[-0.11862021 -0.31315035  0.7068594 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24353437 0.2004827  0.55598295]], shape=(1, 3), dtype=float32)
Selected action 0
[0.14, 0.04, 0.27, 0.246, 0.144, 0.73, 0.023, 0.002, 0.42300000000000004, 0.03]
0.7263053333333335
2.045835
Reward 5.240046718381306
Current State [[0.14  0.04  0.27  0.246 0.144 0.73  0.023 0.002 0.423 0.03 ]]
Logits tf.Tensor([[-0.11734628 -0.3052491   0.6939182 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24513122 0.20313908 0.5517297 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.08, 0.08, 0.27, 0.1, 0.146, 0.79, 0.036, 0.0, 0.442, 0.03]
0.7870864999999999
0.4369035
Reward 22.607367039144904
Current State [[0.08  0.08  0.27  0.1   0.146 0.79  0.036 0.    0.442 0.03 ]]
Logits tf.Tensor([[-0.1231316 -0.3348617  0.732541 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24026105 0.19441517 0.56532377]], shape=(1, 3), dtype=float32)
Selected action 2
[0.2, 0.15, 0.22, 0.231, 0.145, 0.79, 0.036, 0.0, 0.442, 0.03]
0.7870864999999999
0.4369035
Reward 28.607367039144904
Episode: 149 | Average Reward: 293 | Episode Reward: 322 | Loss: 760.275 | Steps: 19 | Worker: 0
Current State [[-0.00366457  0.00631212 -0.0002245  -0.00658465  0.00921826  0.00757953
  -0.0014099   0.0010952  -0.00549291 -0.00053174]]
Logits tf.Tensor([[-0.037326   -0.04826222  0.0884599 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.32018822 0.3167057  0.36310607]], shape=(1, 3), dtype=float32)
Selected action 0
[0.07, 0.04, 0.24, 0.215, 0.138, 0.79, 0.036, 0.0, 0.442, 0.03]
0.7870864999999999
0.4369035
Reward 16.607367039144904
Current State [[0.07  0.04  0.24  0.215 0.138 0.79  0.036 0.    0.442 0.03 ]]
Logits tf.Tensor([[-0.11809269 -0.31437194  0.71562606]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24250388 0.19928548 0.5582107 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.12, 0.08, 0.25, 0.224, 0.139, 0.94, 0.02, 0.002, 0.346, 0.06]
0.9395158333333333
2.159524333333333
Reward 11.627557207109792
Current State [[0.12  0.08  0.25  0.224 0.139 0.94  0.02  0.002 0.346 0.06 ]]
Logits tf.Tensor([[-0.11491766 -0.35295174  0.7344784 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2423414  0.19100764 0.566651  ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.14, 0.15, 0.27, 0.222, 0.137, 0.94, 0.02, 0.002, 0.346, 0.06]
0.9395158333333333
2.159524333333333
Reward 17.627557207109792
Current State [[0.14  0.15  0.27  0.222 0.137 0.94  0.02  0.002 0.346 0.06 ]]
Logits tf.Tensor([[-0.12501076 -0.3732648   0.7673505 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23690797 0.18482654 0.5782655 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.03, 0.04, 0.28, 0.215, 0.138, 0.94, 0.02, 0.002, 0.346, 0.06]
0.9395158333333333
2.159524333333333
Reward 5.627557207109792
Current State [[0.03  0.04  0.28  0.215 0.138 0.94  0.02  0.002 0.346 0.06 ]]
Logits tf.Tensor([[-0.09796958 -0.32445198  0.72441286]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24550426 0.19574873 0.558747  ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.07, 0.08, 0.29, 0.188, 0.137, 0.94, 0.02, 0.002, 0.346, 0.06]
0.9395158333333333
2.159524333333333
Reward 11.627557207109792
Current State [[0.07  0.08  0.29  0.188 0.137 0.94  0.02  0.002 0.346 0.06 ]]
Logits tf.Tensor([[-0.10708424 -0.34609532  0.74181163]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24245532 0.19091082 0.5666338 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.03, 0.04, 0.28, 0.205, 0.145, 0.74, 0.036, 0.001, 0.442, 0.02]
0.7409833333333335
0.8619021666666669
Reward 8.121259956129633
Current State [[0.03  0.04  0.28  0.205 0.145 0.74  0.036 0.001 0.442 0.02 ]]
Logits tf.Tensor([[-0.11037054 -0.29406077  0.7111998 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24353053 0.20266452 0.553805  ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.07, 0.04, 0.25, 0.203, 0.149, 0.74, 0.036, 0.001, 0.442, 0.02]
0.7409833333333335
0.8619021666666669
Reward 8.121259956129633
Current State [[0.07  0.04  0.25  0.203 0.149 0.74  0.036 0.001 0.442 0.02 ]]
Logits tf.Tensor([[-0.11578849 -0.30377135  0.7051066 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24383335 0.20204735 0.55411935]], shape=(1, 3), dtype=float32)
Selected action 2
[0.18, 0.15, 0.26, 0.232, 0.14, 0.74, 0.036, 0.001, 0.442, 0.02]
0.7409833333333335
0.8619021666666669
Reward 20.121259956129634
Current State [[0.18  0.15  0.26  0.232 0.14  0.74  0.036 0.001 0.442 0.02 ]]
Logits tf.Tensor([[-0.13369769 -0.35349023  0.7519246 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23656444 0.18988678 0.57354873]], shape=(1, 3), dtype=float32)
Selected action 0
[0.12, 0.04, 0.27, 0.236, 0.142, 0.78, 0.024, 0.005, 0.48200000000000004, 0.03]
0.7849393333333334
4.5964285
Reward 4.436551566385222
Current State [[0.12  0.04  0.27  0.236 0.142 0.78  0.024 0.005 0.482 0.03 ]]
Logits tf.Tensor([[-0.12244536 -0.3252542   0.7385265 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23912618 0.1952308  0.5656431 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.12, 0.15, 0.25, 0.2, 0.123, 0.78, 0.024, 0.005, 0.48200000000000004, 0.03]
0.7849393333333334
4.5964285
Reward 16.436551566385223
Current State [[0.12  0.15  0.25  0.2   0.123 0.78  0.024 0.005 0.482 0.03 ]]
Logits tf.Tensor([[-0.13088226 -0.35574606  0.77040005]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23466554 0.18740976 0.57792467]], shape=(1, 3), dtype=float32)
Selected action 2
[0.09, 0.15, 0.24, 0.221, 0.138, 0.78, 0.024, 0.005, 0.48200000000000004, 0.03]
0.7849393333333334
4.5964285
Reward 16.436551566385223
Current State [[0.09  0.15  0.24  0.221 0.138 0.78  0.024 0.005 0.482 0.03 ]]
Logits tf.Tensor([[-0.12549332 -0.3469885   0.7737567 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23479255 0.18814392 0.5770635 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.22, 0.15, 0.21, 0.218, 0.141, 0.78, 0.024, 0.005, 0.48200000000000004, 0.03]
0.7849393333333334
4.5964285
Reward 16.436551566385223
Current State [[0.22  0.15  0.21  0.218 0.141 0.78  0.024 0.005 0.482 0.03 ]]
Logits tf.Tensor([[-0.1369823  -0.38056546  0.76853627]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23490565 0.1841224  0.58097196]], shape=(1, 3), dtype=float32)
Selected action 2
[0.09, 0.15, 0.26, 0.229, 0.142, 0.7, 0.04, 0.003, 0.54, 0.0]
0.7004368333333334
2.7988078333333335
Reward 16.768605790417308
Current State [[0.09  0.15  0.26  0.229 0.142 0.7   0.04  0.003 0.54  0.   ]]
Logits tf.Tensor([[-0.13130932 -0.33747193  0.77922505]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23259324 0.18926129 0.57814544]], shape=(1, 3), dtype=float32)
Selected action 2
[0.15, 0.15, 0.27, 0.23, 0.138, 0.7, 0.04, 0.003, 0.54, 0.0]
0.7004368333333334
2.7988078333333335
Reward 16.768605790417308
Current State [[0.15  0.15  0.27  0.23  0.138 0.7   0.04  0.003 0.54  0.   ]]
Logits tf.Tensor([[-0.13766892 -0.3536667   0.7811162 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23191197 0.18686007 0.5812279 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.14, 0.15, 0.27, 0.242, 0.142, 0.7, 0.04, 0.003, 0.54, 0.0]
0.7004368333333334
2.7988078333333335
Reward 16.768605790417308
Current State [[0.14  0.15  0.27  0.242 0.142 0.7   0.04  0.003 0.54  0.   ]]
Logits tf.Tensor([[-0.1359495 -0.350131   0.7832414]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23177858 0.1870921  0.5811294 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.26, 0.15, 0.27, 0.196, 0.144, 0.7, 0.04, 0.003, 0.54, 0.0]
0.7004368333333334
2.7988078333333335
Reward 16.768605790417308
Current State [[0.26  0.15  0.27  0.196 0.144 0.7   0.04  0.003 0.54  0.   ]]
Logits tf.Tensor([[-0.14772022 -0.38377303  0.7872488 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23058085 0.18209869 0.58732045]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.04, 0.31, 0.238, 0.139, 0.67, 0.036, 0.005, 0.818, 0.04]
0.6667828333333333
5.295238666666666
Reward 4.258539743004905
Current State [[0.05  0.04  0.31  0.238 0.139 0.67  0.036 0.005 0.818 0.04 ]]
Logits tf.Tensor([[-0.1478061 -0.339474   0.8660702]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.21825267 0.18018524 0.6015621 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.13, 0.15, 0.27, 0.229, 0.147, 0.67, 0.036, 0.005, 0.818, 0.04]
0.6667828333333333
5.295238666666666
Reward 16.258539743004903
Current State [[0.13  0.15  0.27  0.229 0.147 0.67  0.036 0.005 0.818 0.04 ]]
Logits tf.Tensor([[-0.15365484 -0.38312268  0.90055054]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.21437831 0.17042145 0.6152002 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.15, 0.04, 0.29, 0.211, 0.143, 0.79, 0.021, 0.001, 0.7190000000000001, 0.08]
0.7852936666666668
1.4321431666666664
Reward 6.218593901167964
Current State [[0.15  0.04  0.29  0.211 0.143 0.79  0.021 0.001 0.719 0.08 ]]
Logits tf.Tensor([[-0.14872368 -0.38560578  0.8554838 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22129636 0.17462148 0.60408217]], shape=(1, 3), dtype=float32)
Selected action 2
[0.15, 0.15, 0.31, 0.171, 0.143, 0.9, 0.048, 0.004, 0.40599999999999997, 0.23]
0.9029073333333335
3.5994045
Reward 16.771136529259635
Episode: 150 | Average Reward: 292 | Episode Reward: 263 | Loss: 537.513 | Steps: 19 | Worker: 0
Current State [[ 0.0033886   0.00255163 -0.00170187 -0.00284174  0.00069703  0.0069777
  -0.00486    -0.00394724  0.00504185  0.0032573 ]]
Logits tf.Tensor([[-0.03691148 -0.05047632  0.09164599]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.32013178 0.3158186  0.36404964]], shape=(1, 3), dtype=float32)
Selected action 1
[0.09, 0.08, 0.33, 0.141, 0.143, 0.92, 0.056, 0.0, 0.42000000000000004, 0.21]
0.9226588333333332
0.3994048333333333
Reward 28.633163347506475
Current State [[0.09  0.08  0.33  0.141 0.143 0.92  0.056 0.    0.42  0.21 ]]
Logits tf.Tensor([[-0.13037735 -0.39825395  0.7912044 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23373961 0.17881131 0.5874491 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.05, 0.08, 0.33, 0.183, 0.144, 0.92, 0.056, 0.0, 0.42000000000000004, 0.21]
0.9226588333333332
0.3994048333333333
Reward 28.633163347506475
Current State [[0.05  0.08  0.33  0.183 0.144 0.92  0.056 0.    0.42  0.21 ]]
Logits tf.Tensor([[-0.12174608 -0.382449    0.79357684]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23429675 0.18052794 0.5851753 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.04, 0.38, 0.161, 0.145, 0.9, 0.064, 0.001, 0.398, 0.21]
0.8982083333333334
1.3720236666666668
Reward 6.821045247540898
Current State [[0.05  0.04  0.38  0.161 0.145 0.9   0.064 0.001 0.398 0.21 ]]
Logits tf.Tensor([[-0.11964029 -0.36812124  0.7735146 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23680921 0.18470755 0.5784833 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.04, 0.38, 0.133, 0.145, 0.83, 0.039, 0.002, 0.508, 0.14]
0.8324330000000001
2.035119
Reward 5.498899520592542
Current State [[0.05  0.04  0.38  0.133 0.145 0.83  0.039 0.002 0.508 0.14 ]]
Logits tf.Tensor([[-0.12082442 -0.35996187  0.7938094 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23347208 0.18381411 0.58271384]], shape=(1, 3), dtype=float32)
Selected action 2
[0.17, 0.15, 0.27, 0.215, 0.145, 0.83, 0.039, 0.002, 0.508, 0.14]
0.8324330000000001
2.035119
Reward 17.49889952059254
Current State [[0.17  0.15  0.27  0.215 0.145 0.83  0.039 0.002 0.508 0.14 ]]
Logits tf.Tensor([[-0.14204441 -0.40526104  0.8183712 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22823976 0.17541946 0.5963408 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.11, 0.15, 0.29, 0.194, 0.145, 0.97, 0.052, 0.001, 0.40800000000000003, 0.11]
0.9691468333333334
0.5999994999999999
Reward 26.60968084756457
Current State [[0.11  0.15  0.29  0.194 0.145 0.97  0.052 0.001 0.408 0.11 ]]
Logits tf.Tensor([[-0.13585322 -0.40528998  0.8214051 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2289191  0.17485061 0.5962303 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.18, 0.15, 0.28, 0.198, 0.145, 0.96, 0.052, 0.001, 0.40800000000000003, 0.17]
0.9612261666666667
0.5142853333333334
Reward 29.364783632028594
Current State [[0.18  0.15  0.28  0.198 0.145 0.96  0.052 0.001 0.408 0.17 ]]
Logits tf.Tensor([[-0.14815761 -0.4291558   0.8170146 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22829647 0.17237061 0.5993329 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.1, 0.15, 0.25, 0.145, 0.145, 0.87, 0.028, 0.001, 0.44299999999999995, 0.12]
0.8651171666666667
0.6458333333333334
Reward 23.929151552133177
Current State [[0.1   0.15  0.25  0.145 0.145 0.87  0.028 0.001 0.443 0.12 ]]
Logits tf.Tensor([[-0.1263717  -0.3895302   0.79026216]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23422068 0.1800267  0.5857526 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.02, 0.04, 0.31, 0.145, 0.145, 0.87, 0.028, 0.001, 0.44299999999999995, 0.12]
0.8651171666666667
0.6458333333333334
Reward 11.929151552133176
Current State [[0.02  0.04  0.31  0.145 0.145 0.87  0.028 0.001 0.443 0.12 ]]
Logits tf.Tensor([[-0.10691085 -0.3445306   0.75973165]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23995705 0.1892067  0.57083625]], shape=(1, 3), dtype=float32)
Selected action 2
[0.15, 0.15, 0.3, 0.173, 0.145, 0.94, 0.036, 0.0, 0.417, 0.01]
0.9358436666666667
0.4607136666666667
Reward 31.246096222164162
Current State [[0.15  0.15  0.3   0.173 0.145 0.94  0.036 0.    0.417 0.01 ]]
Logits tf.Tensor([[-0.13645923 -0.39219993  0.81467247]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22920114 0.17748022 0.59331864]], shape=(1, 3), dtype=float32)
Selected action 2
[0.14, 0.15, 0.28, 0.184, 0.145, 0.97, 0.062, 0.0, 0.43899999999999995, 0.22]
0.9710131666666668
0.3672618333333333
Reward 38.795977732617274
Current State [[0.14  0.15  0.28  0.184 0.145 0.97  0.062 0.    0.439 0.22 ]]
Logits tf.Tensor([[-0.14880213 -0.43916816  0.8370605 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22582985 0.1689184  0.6052517 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.04, 0.36, 0.119, 0.145, 1.0, 0.045, 0.0, 0.421, 0.15]
0.9985529999999998
0.31607166666666664
Reward 32.95472206131093
Current State [[0.05  0.04  0.36  0.119 0.145 1.    0.045 0.    0.421 0.15 ]]
Logits tf.Tensor([[-0.1201511  -0.38714722  0.8047895 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2332419  0.17858772 0.58817035]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.15, 0.26, 0.165, 0.145, 1.0, 0.045, 0.0, 0.421, 0.15]
0.9985529999999998
0.31607166666666664
Reward 44.95472206131093
Current State [[0.08  0.15  0.26  0.165 0.145 1.    0.045 0.    0.421 0.15 ]]
Logits tf.Tensor([[-0.13309722 -0.4168738   0.8283725 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22891296 0.17235653 0.5987305 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.13, 0.15, 0.27, 0.186, 0.145, 0.97, 0.038, 0.002, 0.40700000000000003, 0.1]
0.9717998333333332
1.7190473333333331
Reward 18.31163544338878
Current State [[0.13  0.15  0.27  0.186 0.145 0.97  0.038 0.002 0.407 0.1  ]]
Logits tf.Tensor([[-0.13432053 -0.40700874  0.8129964 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23040885 0.17541717 0.594174  ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.04, 0.42, 0.165, 0.145, 0.95, 0.045, 0.001, 0.44299999999999995, 0.18]
0.951855
1.180357
Reward 7.765233573544
Current State [[0.05  0.04  0.42  0.165 0.145 0.95  0.045 0.001 0.443 0.18 ]]
Logits tf.Tensor([[-0.11753663 -0.37640664  0.81677115]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23162226 0.17879462 0.5895831 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.17, 0.15, 0.29, 0.158, 0.145, 0.75, 0.03, 0.003, 0.5549999999999999, 0.11]
0.7460811666666668
3.3821434999999997
Reward 16.64214922992546
Current State [[0.17  0.15  0.29  0.158 0.145 0.75  0.03  0.003 0.555 0.11 ]]
Logits tf.Tensor([[-0.14242563 -0.39839712  0.80942774]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22911237 0.17737055 0.59351707]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.4, 0.147, 0.145, 0.75, 0.03, 0.003, 0.5549999999999999, 0.11]
0.7460811666666668
3.3821434999999997
Reward 4.6421492299254625
Current State [[0.04  0.04  0.4   0.147 0.145 0.75  0.03  0.003 0.555 0.11 ]]
Logits tf.Tensor([[-0.11828005 -0.33968315  0.7865665 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23403057 0.18755057 0.57841885]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.4, 0.153, 0.145, 0.81, 0.037, 0.001, 0.5599999999999999, 0.17]
0.8122578333333332
1.3994050000000002
Reward 6.3954809684139535
Current State [[0.04  0.04  0.4   0.153 0.145 0.81  0.037 0.001 0.56  0.17 ]]
Logits tf.Tensor([[-0.12386484 -0.36483958  0.8138547 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23041412 0.18107359 0.58851224]], shape=(1, 3), dtype=float32)
Selected action 2
[0.09, 0.15, 0.22, 0.109, 0.145, 0.88, 0.043, 0.003, 0.479, 0.15]
0.8785988333333333
3.1244050000000003
Reward 16.903767886254002
Current State [[0.09  0.15  0.22  0.109 0.145 0.88  0.043 0.003 0.479 0.15 ]]
Logits tf.Tensor([[-0.13562013 -0.40738034  0.8027335 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23159905 0.17648703 0.5919139 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.11, 0.08, 0.35, 0.161, 0.145, 0.95, 0.035, 0.001, 0.399, 0.03]
0.9543276666666667
0.789881
Reward 16.777344711564922
Episode: 151 | Average Reward: 294 | Episode Reward: 414 | Loss: 1289.939 | Steps: 19 | Worker: 0
Current State [[-0.00675362  0.00746545  0.00542519  0.00139174  0.00650066  0.00664033
  -0.00165928 -0.00847025 -0.00601294 -0.00805879]]
Logits tf.Tensor([[-0.03796236 -0.04575204  0.08927492]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.31970054 0.31721985 0.36307958]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.04, 0.36, 0.165, 0.145, 0.95, 0.035, 0.001, 0.399, 0.03]
0.9543276666666667
0.789881
Reward 10.77734471156492
Current State [[0.05  0.04  0.36  0.165 0.145 0.95  0.035 0.001 0.399 0.03 ]]
Logits tf.Tensor([[-0.1055297 -0.352193   0.7791239]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23789422 0.18589143 0.5762144 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.13, 0.15, 0.26, 0.172, 0.145, 0.67, 0.027, 0.009, 0.673, 0.19]
0.670834
8.817261666666667
Reward 16.0683455442249
Current State [[0.13  0.15  0.26  0.172 0.145 0.67  0.027 0.009 0.673 0.19 ]]
Logits tf.Tensor([[-0.13083263 -0.41767615  0.82365626]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2299923  0.17263892 0.5973688 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.08, 0.08, 0.3, 0.129, 0.145, 0.86, 0.049, 0.003, 0.374, 0.16]
0.8608226666666667
3.373809833333333
Reward 10.789724694670179
Current State [[0.08  0.08  0.3   0.129 0.145 0.86  0.049 0.003 0.374 0.16 ]]
Logits tf.Tensor([[-0.11410016 -0.3754975   0.74136424]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2425747  0.18677643 0.57064885]], shape=(1, 3), dtype=float32)
Selected action 2
[0.09, 0.15, 0.26, 0.159, 0.146, 0.86, 0.049, 0.003, 0.374, 0.16]
0.8608226666666667
3.373809833333333
Reward 16.789724694670177
Current State [[0.09  0.15  0.26  0.159 0.146 0.86  0.049 0.003 0.374 0.16 ]]
Logits tf.Tensor([[-0.1201366  -0.3913939   0.76207286]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23931159 0.182456   0.5782324 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.07, 0.08, 0.29, 0.149, 0.146, 0.9, 0.032, 0.001, 0.445, 0.08]
0.8997461666666666
0.6440471666666667
Reward 18.459088630446622
Current State [[0.07  0.08  0.29  0.149 0.146 0.9   0.032 0.001 0.445 0.08 ]]
Logits tf.Tensor([[-0.11429369 -0.3723904   0.7836172 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23657492 0.182759   0.58066607]], shape=(1, 3), dtype=float32)
Selected action 2
[0.17, 0.15, 0.27, 0.176, 0.146, 0.97, 0.034, 0.0, 0.403, 0.05]
0.9663895
0.47559483333333336
Reward 31.254008285800374
Current State [[0.17  0.15  0.27  0.176 0.146 0.97  0.034 0.    0.403 0.05 ]]
Logits tf.Tensor([[-0.1346595 -0.4143116  0.8116469]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23082834 0.17451702 0.5946546 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.2, 0.15, 0.28, 0.149, 0.146, 0.81, 0.028, 0.003, 0.554, 0.14]
0.8065425000000002
3.1761903333333326
Reward 16.78446691894667
Current State [[0.2   0.15  0.28  0.149 0.146 0.81  0.028 0.003 0.554 0.14 ]]
Logits tf.Tensor([[-0.1425139  -0.42849475  0.830595  ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22740526 0.17084436 0.6017503 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.15, 0.15, 0.26, 0.176, 0.146, 0.81, 0.025, 0.003, 0.743, 0.18]
0.8093758333333333
2.8023803333333333
Reward 16.93753806198423
Current State [[0.15  0.15  0.26  0.176 0.146 0.81  0.025 0.003 0.743 0.18 ]]
Logits tf.Tensor([[-0.14921153 -0.45549986  0.9109025 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.21631561 0.15924601 0.62443835]], shape=(1, 3), dtype=float32)
Selected action 2
[0.16, 0.15, 0.26, 0.165, 0.146, 0.81, 0.025, 0.003, 0.743, 0.18]
0.8093758333333333
2.8023803333333333
Reward 16.93753806198423
Current State [[0.16  0.15  0.26  0.165 0.146 0.81  0.025 0.003 0.743 0.18 ]]
Logits tf.Tensor([[-0.14993796 -0.45929652  0.9101147 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.21642958 0.15884146 0.624729  ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.35, 0.144, 0.146, 0.73, 0.014, 0.003, 0.819, 0.08]
0.7283518333333332
2.595833499999999
Reward 4.901025486141836
Current State [[0.04  0.04  0.35  0.144 0.146 0.73  0.014 0.003 0.819 0.08 ]]
Logits tf.Tensor([[-0.13675565 -0.36926752  0.8869906 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.21852462 0.17318957 0.6082858 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.1, 0.15, 0.22, 0.135, 0.146, 0.86, 0.034, 0.001, 0.5549999999999999, 0.01]
0.8631101666666666
0.8464281666666668
Reward 21.26917121967721
Current State [[0.1   0.15  0.22  0.135 0.146 0.86  0.034 0.001 0.555 0.01 ]]
Logits tf.Tensor([[-0.1375328  -0.39429605  0.8320273 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2267401  0.17539512 0.5978648 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.1, 0.15, 0.22, 0.115, 0.146, 0.98, 0.039, 0.0, 0.426, 0.06]
0.9827873333333333
0.32976149999999993
Reward 42.89090467245552
Current State [[0.1   0.15  0.22  0.115 0.146 0.98  0.039 0.    0.426 0.06 ]]
Logits tf.Tensor([[-0.1301238  -0.41480204  0.81009513]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23186801 0.17442417 0.5937078 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.08, 0.08, 0.2, 0.124, 0.146, 0.98, 0.039, 0.0, 0.426, 0.06]
0.9827873333333333
0.32976149999999993
Reward 36.89090467245552
Current State [[0.08  0.08  0.2   0.124 0.146 0.98  0.039 0.    0.426 0.06 ]]
Logits tf.Tensor([[-0.12130185 -0.3918839   0.77667856]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23710303 0.18089427 0.58200276]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.24, 0.154, 0.146, 0.92, 0.032, 0.001, 0.508, 0.08]
0.9190958333333333
0.711309
Reward 23.503809412425486
Current State [[0.05  0.15  0.24  0.154 0.146 0.92  0.032 0.001 0.508 0.08 ]]
Logits tf.Tensor([[-0.12481838 -0.3982371   0.83591473]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22860353 0.17391564 0.59748083]], shape=(1, 3), dtype=float32)
Selected action 2
[0.1, 0.15, 0.24, 0.133, 0.146, 0.95, 0.033, 0.001, 0.466, 0.09]
0.9509921666666667
0.6333333333333333
Reward 25.46247704764535
Current State [[0.1   0.15  0.24  0.133 0.146 0.95  0.033 0.001 0.466 0.09 ]]
Logits tf.Tensor([[-0.12865359 -0.41445476  0.8249386 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23007405 0.1728804  0.59704554]], shape=(1, 3), dtype=float32)
Selected action 2
[0.13, 0.15, 0.25, 0.162, 0.146, 0.94, 0.033, 0.001, 0.47000000000000003, 0.12]
0.9407423333333335
1.0339281666666666
Reward 20.46829475220801
Current State [[0.13  0.15  0.25  0.162 0.146 0.94  0.033 0.001 0.47  0.12 ]]
Logits tf.Tensor([[-0.13203278 -0.42122978  0.8284659 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2292598  0.17168456 0.59905565]], shape=(1, 3), dtype=float32)
Selected action 2
[0.15, 0.15, 0.27, 0.171, 0.146, 0.94, 0.033, 0.001, 0.47000000000000003, 0.12]
0.9407423333333335
1.0339281666666666
Reward 20.46829475220801
Current State [[0.15  0.15  0.27  0.171 0.146 0.94  0.033 0.001 0.47  0.12 ]]
Logits tf.Tensor([[-0.13458022 -0.424747    0.8342106 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22815968 0.1706951  0.6011452 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.16, 0.15, 0.27, 0.176, 0.146, 0.88, 0.025, 0.001, 0.374, 0.08]
0.8750208333333334
1.3821428333333332
Reward 18.69498342871388
Current State [[0.16  0.15  0.27  0.176 0.146 0.88  0.025 0.001 0.374 0.08 ]]
Logits tf.Tensor([[-0.12312294 -0.39161336  0.7682607 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23792335 0.1819002  0.5801764 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.12, 0.15, 0.27, 0.187, 0.146, 0.88, 0.043, 0.002, 0.49000000000000005, 0.18]
0.8815186666666667
1.6630953333333334
Reward 18.119696676487695
Current State [[0.12  0.15  0.27  0.187 0.146 0.88  0.043 0.002 0.49  0.18 ]]
Logits tf.Tensor([[-0.13224413 -0.416454    0.82713336]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22921692 0.17251062 0.59827244]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.04, 0.34, 0.126, 0.146, 0.89, 0.019, 0.003, 0.374, 0.06]
0.8872631666666667
2.845833166666667
Reward 5.040649759645877
Episode: 152 | Average Reward: 295 | Episode Reward: 392 | Loss: 1317.774 | Steps: 19 | Worker: 0
Current State [[ 0.00596201 -0.00995165 -0.00596329 -0.00080209 -0.00163026 -0.00465376
   0.00010981  0.00512831  0.00759873 -0.00837146]]
Logits tf.Tensor([[-0.03379747 -0.04574035  0.0789072 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3218094 0.3179889 0.3602017]], shape=(1, 3), dtype=float32)
Selected action 2
[0.12, 0.15, 0.27, 0.14, 0.146, 0.89, 0.019, 0.003, 0.374, 0.06]
0.8872631666666667
2.845833166666667
Reward 17.040649759645877
Current State [[0.12  0.15  0.27  0.14  0.146 0.89  0.019 0.003 0.374 0.06 ]]
Logits tf.Tensor([[-0.11337738 -0.3917312   0.77283776]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2390652  0.18097928 0.5799555 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.15, 0.08, 0.3, 0.149, 0.146, 0.89, 0.023, 0.002, 0.502, 0.1]
0.8925948333333333
2.270833
Reward 11.421251034452869
Current State [[0.15  0.08  0.3   0.149 0.146 0.89  0.023 0.002 0.502 0.1  ]]
Logits tf.Tensor([[-0.12537023 -0.4052753   0.8150746 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23164365 0.17508912 0.59326726]], shape=(1, 3), dtype=float32)
Selected action 2
[0.1, 0.15, 0.23, 0.144, 0.146, 0.84, 0.017, 0.001, 0.404, 0.07]
0.8432333333333333
1.1797618333333333
Reward 19.182796271022404
Current State [[0.1   0.15  0.23  0.144 0.146 0.84  0.017 0.001 0.404 0.07 ]]
Logits tf.Tensor([[-0.11085529 -0.37990117  0.76155543]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24057081 0.18382214 0.57560706]], shape=(1, 3), dtype=float32)
Selected action 2
[0.11, 0.15, 0.24, 0.137, 0.146, 0.84, 0.022, 0.001, 0.398, 0.05]
0.8385626666666667
1.2053575
Reward 19.066398835907293
Current State [[0.11  0.15  0.24  0.137 0.146 0.84  0.022 0.001 0.398 0.05 ]]
Logits tf.Tensor([[-0.11402625 -0.37998843  0.7614232 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24001409 0.18396318 0.57602274]], shape=(1, 3), dtype=float32)
Selected action 0
[0.03, 0.04, 0.31, 0.148, 0.146, 0.84, 0.022, 0.001, 0.398, 0.05]
0.8385626666666667
1.2053575
Reward 7.066398835907295
Current State [[0.03  0.04  0.31  0.148 0.146 0.84  0.022 0.001 0.398 0.05 ]]
Logits tf.Tensor([[-0.094405   -0.33331788  0.7339908 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24527082 0.19314669 0.5615825 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.07, 0.08, 0.27, 0.152, 0.146, 0.77, 0.027, 0.004, 0.508, 0.09]
0.7680611666666667
4.486309333333334
Reward 10.438288463708867
Current State [[0.07  0.08  0.27  0.152 0.146 0.77  0.027 0.004 0.508 0.09 ]]
Logits tf.Tensor([[-0.11439537 -0.36141557  0.7711802 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2377836 0.1857387 0.5764777]], shape=(1, 3), dtype=float32)
Selected action 2
[0.1, 0.15, 0.26, 0.144, 0.146, 0.98, 0.034, 0.001, 0.442, 0.02]
0.9795681666666667
1.2779763333333336
Reward 19.50701847466554
Current State [[0.1   0.15  0.26  0.144 0.146 0.98  0.034 0.001 0.442 0.02 ]]
Logits tf.Tensor([[-0.12547705 -0.41129276  0.83369297]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22930884 0.17230292 0.5983882 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.11, 0.15, 0.25, 0.173, 0.146, 0.98, 0.034, 0.001, 0.442, 0.02]
0.9795681666666667
1.2779763333333336
Reward 19.50701847466554
Current State [[0.11  0.15  0.25  0.173 0.146 0.98  0.034 0.001 0.442 0.02 ]]
Logits tf.Tensor([[-0.12587623 -0.41004354  0.8328949 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22929838 0.17257929 0.5981223 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.09, 0.15, 0.25, 0.175, 0.146, 0.84, 0.027, 0.002, 0.461, 0.07]
0.8380903333333334
2.2077384999999996
Reward 17.35656121620513
Current State [[0.09  0.15  0.25  0.175 0.146 0.84  0.027 0.002 0.461 0.07 ]]
Logits tf.Tensor([[-0.11847167 -0.38442162  0.7967023 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23453878 0.17976868 0.5856925 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.09, 0.08, 0.26, 0.153, 0.146, 0.95, 0.048, 0.002, 0.429, 0.14]
0.9456379999999999
1.8130958333333331
Reward 12.074260879202871
Current State [[0.09  0.08  0.26  0.153 0.146 0.95  0.048 0.002 0.429 0.14 ]]
Logits tf.Tensor([[-0.12129476 -0.40539253  0.79294765]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23542832 0.17720525 0.5873664 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.31, 0.131, 0.146, 0.88, 0.042, 0.002, 0.613, 0.14]
0.8825406666666668
2.329761666666667
Reward 5.352720529830354
Current State [[0.04  0.04  0.31  0.131 0.146 0.88  0.042 0.002 0.613 0.14 ]]
Logits tf.Tensor([[-0.12761325 -0.39741108  0.8521036 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22587459 0.17246288 0.6016625 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.16, 0.15, 0.27, 0.185, 0.146, 0.88, 0.042, 0.002, 0.613, 0.14]
0.8825406666666668
2.329761666666667
Reward 17.352720529830354
Current State [[0.16  0.15  0.27  0.185 0.146 0.88  0.042 0.002 0.613 0.14 ]]
Logits tf.Tensor([[-0.14750081 -0.44783348  0.89041275]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.21911123 0.1622676  0.6186212 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.07, 0.08, 0.33, 0.167, 0.146, 0.74, 0.017, 0.002, 0.5599999999999999, 0.05]
0.7446146666666666
1.7982143333333334
Reward 11.523671209553207
Current State [[0.07  0.08  0.33  0.167 0.146 0.74  0.017 0.002 0.56  0.05 ]]
Logits tf.Tensor([[-0.11534592 -0.35225627  0.7928811 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2342478  0.18483603 0.58091617]], shape=(1, 3), dtype=float32)
Selected action 2
[0.14, 0.15, 0.3, 0.186, 0.146, 0.83, 0.032, 0.002, 0.7929999999999999, 0.16]
0.8307571666666667
2.2880955
Reward 17.27798265105418
Current State [[0.14  0.15  0.3   0.186 0.146 0.83  0.032 0.002 0.793 0.16 ]]
Logits tf.Tensor([[-0.15469536 -0.4687712   0.95430356]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.21000524 0.1534012  0.6365935 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.13, 0.15, 0.3, 0.15, 0.146, 0.89, 0.041, 0.001, 0.6900000000000001, 0.15]
0.8858858333333334
1.0113093333333334
Reward 20.232554216155144
Current State [[0.13  0.15  0.3   0.15  0.146 0.89  0.041 0.001 0.69  0.15 ]]
Logits tf.Tensor([[-0.15354645 -0.45991355  0.9308958 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.21304218 0.15682384 0.630134  ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.02, 0.04, 0.31, 0.161, 0.146, 0.63, 0.025, 0.006, 0.842, 0.17]
0.6329441666666666
5.5994055000000005
Reward 4.2086153941437034
Current State [[0.02  0.04  0.31  0.161 0.146 0.63  0.025 0.006 0.842 0.17 ]]
Logits tf.Tensor([[-0.12594703 -0.38548192  0.8616554 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22440642 0.17310944 0.6024841 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.14, 0.15, 0.26, 0.174, 0.146, 0.63, 0.025, 0.006, 0.842, 0.17]
0.6329441666666666
5.5994055000000005
Reward 16.208615394143703
Current State [[0.14  0.15  0.26  0.174 0.146 0.63  0.025 0.006 0.842 0.17 ]]
Logits tf.Tensor([[-0.13785139 -0.43585783  0.8948776 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2197311  0.16310564 0.61716324]], shape=(1, 3), dtype=float32)
Selected action 2
[0.11, 0.15, 0.26, 0.182, 0.146, 0.96, 0.041, 0.004, 0.708, 0.21]
0.9598753333333332
3.591666833333333
Reward 16.842394700947636
Current State [[0.11  0.15  0.26  0.182 0.146 0.96  0.041 0.004 0.708 0.21 ]]
Logits tf.Tensor([[-0.15332136 -0.47889203  0.9586367 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.20997725 0.15162775 0.638395  ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.22, 0.15, 0.32, 0.15, 0.146, 0.94, 0.046, 0.001, 0.43, 0.02]
0.937144
0.6791671666666665
Reward 24.299107311639162
Current State [[0.22  0.15  0.32  0.15  0.146 0.94  0.046 0.001 0.43  0.02 ]]
Logits tf.Tensor([[-0.14617625 -0.43113178  0.8337413 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22643471 0.1702897  0.6032756 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.16, 0.15, 0.31, 0.157, 0.146, 0.94, 0.057, 0.002, 0.434, 0.21]
0.9408885
2.4113093333333335
Reward 17.407388978575725
Episode: 153 | Average Reward: 295 | Episode Reward: 303 | Loss: 700.024 | Steps: 19 | Worker: 0
Current State [[ 2.80989543e-04  8.97350269e-03 -9.45377139e-05 -2.41942836e-03
   7.34167677e-03  8.15226864e-03 -2.39839267e-03  4.50926898e-03
   2.58366782e-03 -1.35266367e-03]]
Logits tf.Tensor([[-0.03477313 -0.05283099  0.09388614]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.32057378 0.31483686 0.36458936]], shape=(1, 3), dtype=float32)
Selected action 0
[0.02, 0.04, 0.34, 0.136, 0.146, 0.8, 0.045, 0.002, 0.508, 0.17]
0.7999161666666667
1.8357148333333335
Reward 5.631029224209837
Current State [[0.02  0.04  0.34  0.136 0.146 0.8   0.045 0.002 0.508 0.17 ]]
Logits tf.Tensor([[-0.11178938 -0.3701697   0.7886399 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23624128 0.18244947 0.58130926]], shape=(1, 3), dtype=float32)
Selected action 2
[0.09, 0.15, 0.27, 0.186, 0.146, 0.8, 0.045, 0.002, 0.508, 0.17]
0.7999161666666667
1.8357148333333335
Reward 17.631029224209836
Current State [[0.09  0.15  0.27  0.186 0.146 0.8   0.045 0.002 0.508 0.17 ]]
Logits tf.Tensor([[-0.12851472 -0.40733978  0.81944764]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23056783 0.17446427 0.5949679 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.21, 0.15, 0.29, 0.171, 0.146, 0.86, 0.058, 0.003, 0.388, 0.19]
0.8643605000000001
2.810713999999999
Reward 17.021406792960136
Current State [[0.21  0.15  0.29  0.171 0.146 0.86  0.058 0.003 0.388 0.19 ]]
Logits tf.Tensor([[-0.14058475 -0.43916002  0.7904715 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23369607 0.17337313 0.5929308 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.14, 0.15, 0.25, 0.151, 0.146, 0.97, 0.057, 0.0, 0.403, 0.12]
0.9682485
0.3898811666666667
Reward 36.79306934352365
Current State [[0.14  0.15  0.25  0.151 0.146 0.97  0.057 0.    0.403 0.12 ]]
Logits tf.Tensor([[-0.137702   -0.43960366  0.8211486 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22998515 0.17005348 0.59996134]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.38, 0.145, 0.146, 0.97, 0.055, 0.001, 0.398, 0.13]
0.9684461666666666
0.5559525
Reward 15.953581116566609
Current State [[0.04  0.04  0.38  0.145 0.146 0.97  0.055 0.001 0.398 0.13 ]]
Logits tf.Tensor([[-0.10994901 -0.38807163  0.805083  ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23506962 0.17799565 0.58693475]], shape=(1, 3), dtype=float32)
Selected action 2
[0.09, 0.15, 0.29, 0.167, 0.146, 0.97, 0.055, 0.001, 0.398, 0.13]
0.9684461666666666
0.5559525
Reward 27.95358111656661
Current State [[0.09  0.15  0.29  0.167 0.146 0.97  0.055 0.001 0.398 0.13 ]]
Logits tf.Tensor([[-0.12661971 -0.42546293  0.82900685]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23030996 0.17081529 0.5988748 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.12, 0.15, 0.25, 0.172, 0.146, 0.93, 0.047, 0.0, 0.45999999999999996, 0.15]
0.9320683333333333
0.4857148333333334
Reward 29.934689843244133
Current State [[0.12  0.15  0.25  0.172 0.146 0.93  0.047 0.    0.46  0.15 ]]
Logits tf.Tensor([[-0.13261357 -0.43338087  0.8356947 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22863752 0.16924892 0.60211354]], shape=(1, 3), dtype=float32)
Selected action 2
[0.11, 0.15, 0.26, 0.178, 0.146, 0.92, 0.039, 0.001, 0.433, 0.16]
0.9174406666666667
0.5684526666666667
Reward 26.596036327962274
Current State [[0.11  0.15  0.26  0.178 0.146 0.92  0.039 0.001 0.433 0.16 ]]
Logits tf.Tensor([[-0.12460629 -0.4244694   0.82097447]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23173748 0.17169885 0.59656364]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.04, 0.34, 0.124, 0.146, 0.98, 0.054, 0.0, 0.421, 0.04]
0.9803346666666666
0.3226191666666666
Reward 31.575202084273847
Current State [[0.05  0.04  0.34  0.124 0.146 0.98  0.054 0.    0.421 0.04 ]]
Logits tf.Tensor([[-0.11510931 -0.38330975  0.8069004 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23369439 0.17871884 0.58758676]], shape=(1, 3), dtype=float32)
Selected action 2
[0.14, 0.15, 0.26, 0.155, 0.146, 0.98, 0.054, 0.0, 0.421, 0.04]
0.9803346666666666
0.3226191666666666
Reward 43.57520208427385
Current State [[0.14  0.15  0.26  0.155 0.146 0.98  0.054 0.    0.421 0.04 ]]
Logits tf.Tensor([[-0.13765697 -0.42947754  0.834338  ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22778447 0.1701328  0.6020827 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.11, 0.15, 0.26, 0.166, 0.146, 0.85, 0.025, 0.006, 0.491, 0.08]
0.8481251666666665
5.5000003333333325
Reward 16.370027726058275
Current State [[0.11  0.15  0.26  0.166 0.146 0.85  0.025 0.006 0.491 0.08 ]]
Logits tf.Tensor([[-0.1227527  -0.40377617  0.82103014]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23123023 0.17458126 0.5941885 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.15, 0.15, 0.28, 0.171, 0.146, 0.9, 0.057, 0.003, 0.399, 0.21]
0.8983578333333332
2.770832833333333
Reward 17.09732914011466
Current State [[0.15  0.15  0.28  0.171 0.146 0.9   0.057 0.003 0.399 0.21 ]]
Logits tf.Tensor([[-0.13294931 -0.438543    0.8060406 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23287861 0.17155838 0.595563  ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.2, 0.15, 0.28, 0.178, 0.146, 0.92, 0.05, 0.008, 0.38, 0.15]
0.9200804999999999
8.342856999999999
Reward 16.19801215327198
Current State [[0.2   0.15  0.28  0.178 0.146 0.92  0.05  0.008 0.38  0.15 ]]
Logits tf.Tensor([[-0.13782139 -0.44026524  0.8007569 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23280965 0.17204867 0.59514165]], shape=(1, 3), dtype=float32)
Selected action 2
[0.19, 0.15, 0.28, 0.148, 0.146, 0.88, 0.048, 0.002, 0.39, 0.21]
0.8845613333333335
2.4809526666666666
Reward 17.247201911521337
Current State [[0.19  0.15  0.28  0.148 0.146 0.88  0.048 0.002 0.39  0.21 ]]
Logits tf.Tensor([[-0.13543665 -0.44377375  0.79320616]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23442595 0.17222515 0.59334886]], shape=(1, 3), dtype=float32)
Selected action 1
[0.05, 0.08, 0.3, 0.157, 0.146, 0.88, 0.048, 0.002, 0.39, 0.21]
0.8845613333333335
2.4809526666666666
Reward 11.247201911521337
Current State [[0.05  0.08  0.3   0.157 0.146 0.88  0.048 0.002 0.39  0.21 ]]
Logits tf.Tensor([[-0.10821763 -0.39016882  0.7688356 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2404935  0.18140677 0.57809967]], shape=(1, 3), dtype=float32)
Selected action 2
[0.17, 0.15, 0.28, 0.182, 0.146, 0.94, 0.057, 0.002, 0.48600000000000004, 0.26]
0.9398648333333334
2.1464288333333332
Reward 17.64164067051276
Current State [[0.17  0.15  0.28  0.182 0.146 0.94  0.057 0.002 0.486 0.26 ]]
Logits tf.Tensor([[-0.14476421 -0.47161347  0.8619353 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22432858 0.16178408 0.6138873 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.17, 0.15, 0.27, 0.151, 0.146, 1.0, 0.052, 0.0, 0.434, 0.17]
1.003287
0.3220235
Reward 44.46052587949347
Current State [[0.17  0.15  0.27  0.151 0.146 1.    0.052 0.    0.434 0.17 ]]
Logits tf.Tensor([[-0.1441929  -0.46585733  0.8510264 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22572044 0.16363409 0.6106455 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.15, 0.25, 0.145, 0.146, 0.93, 0.051, 0.001, 0.42400000000000004, 0.21]
0.92695
0.8250001666666668
Reward 22.07919297864319
Current State [[0.08  0.15  0.25  0.145 0.146 0.93  0.051 0.001 0.424 0.21 ]]
Logits tf.Tensor([[-0.12674248 -0.4345728   0.81929123]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23199087 0.17052257 0.5974865 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.19, 0.15, 0.28, 0.174, 0.146, 0.93, 0.051, 0.001, 0.42400000000000004, 0.21]
0.92695
0.8250001666666668
Reward 22.07919297864319
Current State [[0.19  0.15  0.28  0.174 0.146 0.93  0.051 0.001 0.424 0.21 ]]
Logits tf.Tensor([[-0.14108214 -0.45674247  0.82790166]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22911753 0.16709703 0.6037854 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.02, 0.04, 0.38, 0.15, 0.146, 0.94, 0.041, 0.001, 0.41900000000000004, 0.13]
0.9354038333333334
0.9672616666666667
Reward 8.87822522162507
Episode: 154 | Average Reward: 296 | Episode Reward: 445 | Loss: 1596.09 | Steps: 19 | Worker: 0
Current State [[-7.78606163e-03 -7.30332156e-03  2.39257434e-03 -3.62467435e-03
   3.95750005e-04  3.90201732e-05 -2.74849571e-03  8.53647511e-03
   6.04198158e-04  2.05466369e-03]]
Logits tf.Tensor([[-0.03124938 -0.04778007  0.08145494]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.32227853 0.31699485 0.36072665]], shape=(1, 3), dtype=float32)
Selected action 2
[0.1, 0.15, 0.26, 0.156, 0.146, 0.76, 0.036, 0.002, 0.593, 0.21]
0.7647121666666669
2.280952333333333
Reward 17.14809203291868
Current State [[0.1   0.15  0.26  0.156 0.146 0.76  0.036 0.002 0.593 0.21 ]]
Logits tf.Tensor([[-0.13491116 -0.43532416  0.84910023]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22646578 0.16770068 0.60583353]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.32, 0.126, 0.146, 0.96, 0.055, 0.001, 0.441, 0.17]
0.9626936666666667
0.631548
Reward 13.68768580850596
Current State [[0.04  0.04  0.32  0.126 0.146 0.96  0.055 0.001 0.441 0.17 ]]
Logits tf.Tensor([[-0.11680482 -0.41050234  0.81886816]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23285976 0.17359741 0.5935428 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.13, 0.15, 0.26, 0.176, 0.146, 0.96, 0.055, 0.001, 0.441, 0.17]
0.9626936666666667
0.631548
Reward 25.68768580850596
Current State [[0.13  0.15  0.26  0.176 0.146 0.96  0.055 0.001 0.441 0.17 ]]
Logits tf.Tensor([[-0.13811815 -0.45432884  0.8530003 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22608311 0.16479331 0.6091236 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.1, 0.15, 0.26, 0.158, 0.146, 0.94, 0.034, 0.002, 0.40599999999999997, 0.14]
0.9424906666666667
1.6220239999999997
Reward 18.39898189572623
Current State [[0.1   0.15  0.26  0.158 0.146 0.94  0.034 0.002 0.406 0.14 ]]
Logits tf.Tensor([[-0.12198659 -0.43056086  0.82405776]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23201883 0.1704163  0.5975649 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.15, 0.15, 0.28, 0.139, 0.146, 0.98, 0.048, 0.001, 0.438, 0.07]
0.9843733333333334
0.9214286666666668
Reward 21.64179079311507
Current State [[0.15  0.15  0.28  0.139 0.146 0.98  0.048 0.001 0.438 0.07 ]]
Logits tf.Tensor([[-0.14040712 -0.44984093  0.8586588 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.224739   0.16492747 0.6103335 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.06, 0.04, 0.4, 0.172, 0.146, 0.98, 0.048, 0.001, 0.438, 0.07]
0.9843733333333334
0.9214286666666668
Reward 9.641790793115069
Current State [[0.06  0.04  0.4   0.172 0.146 0.98  0.048 0.001 0.438 0.07 ]]
Logits tf.Tensor([[-0.11533964 -0.3954213   0.84519595]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22889489 0.1729809  0.5981242 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.25, 0.15, 0.28, 0.178, 0.146, 0.84, 0.044, 0.002, 0.499, 0.23]
0.8402601666666668
2.3303571666666665
Reward 17.266161068619965
Current State [[0.25  0.15  0.28  0.178 0.146 0.84  0.044 0.002 0.499 0.23 ]]
Logits tf.Tensor([[-0.14754462 -0.47724268  0.84332055]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22661838 0.16297053 0.6104111 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.15, 0.15, 0.26, 0.171, 0.146, 0.77, 0.017, 0.003, 0.5660000000000001, 0.07]
0.7675563333333334
2.8660715000000008
Reward 16.844831899184925
Current State [[0.15  0.15  0.26  0.171 0.146 0.77  0.017 0.003 0.566 0.07 ]]
Logits tf.Tensor([[-0.13175145 -0.41462794  0.83905435]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22759946 0.17152187 0.6008787 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.16, 0.15, 0.27, 0.149, 0.146, 0.81, 0.018, 0.002, 0.661, 0.1]
0.807039
2.225
Reward 17.276265194923678
Current State [[0.16  0.15  0.27  0.149 0.146 0.81  0.018 0.002 0.661 0.1  ]]
Logits tf.Tensor([[-0.1437688  -0.44962886  0.89770335]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.21882436 0.1611619  0.6200137 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.11, 0.15, 0.25, 0.163, 0.146, 0.81, 0.018, 0.002, 0.661, 0.1]
0.807039
2.225
Reward 17.276265194923678
Current State [[0.11  0.15  0.25  0.163 0.146 0.81  0.018 0.002 0.661 0.1  ]]
Logits tf.Tensor([[-0.13801408 -0.43505743  0.89389956]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.21980713 0.16331929 0.6168736 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.1, 0.15, 0.25, 0.165, 0.146, 0.91, 0.03, 0.001, 0.524, 0.08]
0.9084001666666667
1.0666668333333331
Reward 20.066434853434256
Current State [[0.1   0.15  0.25  0.165 0.146 0.91  0.03  0.001 0.524 0.08 ]]
Logits tf.Tensor([[-0.13181989 -0.4292446   0.8680761 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22417869 0.16650389 0.6093174 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.14, 0.15, 0.27, 0.16, 0.146, 0.92, 0.04, 0.002, 0.43200000000000005, 0.14]
0.9196733333333333
2.0244043333333335
Reward 17.72434575579385
Current State [[0.14  0.15  0.27  0.16  0.146 0.92  0.04  0.002 0.432 0.14 ]]
Logits tf.Tensor([[-0.13184793 -0.44037238  0.83432996]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22923103 0.16837706 0.6023919 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.13, 0.15, 0.27, 0.141, 0.146, 0.9, 0.026, 0.002, 0.462, 0.09]
0.9006598333333332
1.7494048333333336
Reward 18.038481258213256
Current State [[0.13  0.15  0.27  0.141 0.146 0.9   0.026 0.002 0.462 0.09 ]]
Logits tf.Tensor([[-0.12733714 -0.42825451  0.8381786 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2290279  0.16951245 0.6014597 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.15, 0.24, 0.161, 0.146, 0.9, 0.026, 0.002, 0.462, 0.09]
0.9006598333333332
1.7494048333333336
Reward 18.038481258213256
Current State [[0.07  0.15  0.24  0.161 0.146 0.9   0.026 0.002 0.462 0.09 ]]
Logits tf.Tensor([[-0.11872488 -0.4116684   0.83076715]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23092231 0.17228287 0.5967948 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.13, 0.15, 0.26, 0.174, 0.146, 0.95, 0.038, 0.0, 0.41900000000000004, 0.12]
0.9490341666666666
0.31845216666666665
Reward 42.88912550494871
Current State [[0.13  0.15  0.26  0.174 0.146 0.95  0.038 0.    0.419 0.12 ]]
Logits tf.Tensor([[-0.129552   -0.43718475  0.8359024 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22929649 0.16857538 0.6021281 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.12, 0.15, 0.26, 0.19, 0.146, 0.84, 0.023, 0.001, 0.40099999999999997, 0.03]
0.8448961666666667
1.232143166666667
Reward 19.006037983179496
Current State [[0.12  0.15  0.26  0.19  0.146 0.84  0.023 0.001 0.401 0.03 ]]
Logits tf.Tensor([[-0.11579877 -0.38643777  0.788231  ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23627108 0.18024927 0.58347964]], shape=(1, 3), dtype=float32)
Selected action 0
[0.03, 0.04, 0.29, 0.125, 0.146, 0.86, 0.029, 0.001, 0.398, 0.08]
0.8606226666666665
0.7416665000000001
Reward 10.37871313033279
Current State [[0.03  0.04  0.29  0.125 0.146 0.86  0.029 0.001 0.398 0.08 ]]
Logits tf.Tensor([[-0.09913649 -0.35938117  0.7521039 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.24310708 0.18740223 0.5694907 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.09, 0.08, 0.29, 0.17, 0.146, 0.86, 0.029, 0.001, 0.398, 0.08]
0.8606226666666665
0.7416665000000001
Reward 16.37871313033279
Current State [[0.09  0.08  0.29  0.17  0.146 0.86  0.029 0.001 0.398 0.08 ]]
Logits tf.Tensor([[-0.1087566  -0.37788215  0.7722163 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23938945 0.18290487 0.5777057 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.02, 0.04, 0.31, 0.142, 0.146, 0.78, 0.03, 0.002, 0.588, 0.1]
0.7809514999999999
1.628571166666667
Reward 5.853528816547322
Current State [[0.02  0.04  0.31  0.142 0.146 0.78  0.03  0.002 0.588 0.1  ]]
Logits tf.Tensor([[-0.11679576 -0.37060714  0.81929344]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23116964 0.17935021 0.58948016]], shape=(1, 3), dtype=float32)
Selected action 1
[0.09, 0.08, 0.33, 0.164, 0.146, 0.8, 0.028, 0.002, 0.571, 0.14]
0.7958613333333334
1.9779766666666667
Reward 11.466327122395143
Episode: 155 | Average Reward: 297 | Episode Reward: 354 | Loss: 946.652 | Steps: 19 | Worker: 0
Current State [[-0.00238143  0.00041757  0.00294607  0.00630196 -0.00774128 -0.00541111
  -0.00169062  0.00708178  0.00341981  0.00799077]]
Logits tf.Tensor([[-0.03341042 -0.05129337  0.08471178]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.32178575 0.31608245 0.36213177]], shape=(1, 3), dtype=float32)
Selected action 2
[0.16, 0.15, 0.27, 0.141, 0.146, 0.92, 0.024, 0.002, 0.471, 0.11]
0.9175706666666665
1.7880955
Reward 18.029553856562277
Current State [[0.16  0.15  0.27  0.141 0.146 0.92  0.024 0.002 0.471 0.11 ]]
Logits tf.Tensor([[-0.13525456 -0.45554015  0.86374444]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22514898 0.16344504 0.611406  ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.12, 0.15, 0.26, 0.175, 0.146, 0.92, 0.024, 0.002, 0.471, 0.11]
0.9175706666666665
1.7880955
Reward 18.029553856562277
Current State [[0.12  0.15  0.26  0.175 0.146 0.92  0.024 0.002 0.471 0.11 ]]
Logits tf.Tensor([[-0.1272884  -0.4407388   0.86261076]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22614796 0.16529623 0.60855585]], shape=(1, 3), dtype=float32)
Selected action 1
[0.09, 0.08, 0.31, 0.156, 0.146, 0.87, 0.018, 0.002, 0.367, 0.06]
0.8712625
2.2928571666666664
Reward 11.358355067947622
Current State [[0.09  0.08  0.31  0.156 0.146 0.87  0.018 0.002 0.367 0.06 ]]
Logits tf.Tensor([[-0.10386977 -0.38154608  0.7755174 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23998283 0.18179709 0.5782201 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.16, 0.15, 0.27, 0.188, 0.146, 0.91, 0.029, 0.001, 0.44400000000000006, 0.06]
0.908898
1.431547833333333
Reward 18.70551919172642
Current State [[0.16  0.15  0.27  0.188 0.146 0.91  0.029 0.001 0.444 0.06 ]]
Logits tf.Tensor([[-0.13223125 -0.43523353  0.85037345]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22675721 0.16748232 0.60576046]], shape=(1, 3), dtype=float32)
Selected action 1
[0.1, 0.08, 0.32, 0.159, 0.146, 0.92, 0.029, 0.002, 0.409, 0.09]
0.9175058333333334
2.283332833333333
Reward 11.463728379049929
Current State [[0.1   0.08  0.32  0.159 0.146 0.92  0.029 0.002 0.409 0.09 ]]
Logits tf.Tensor([[-0.11520427 -0.40894526  0.81792796]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23321278 0.17385302 0.5929342 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.15, 0.15, 0.27, 0.218, 0.146, 0.92, 0.029, 0.002, 0.409, 0.09]
0.9175058333333334
2.283332833333333
Reward 17.46372837904993
Current State [[0.15  0.15  0.27  0.218 0.146 0.92  0.029 0.002 0.409 0.09 ]]
Logits tf.Tensor([[-0.1269888  -0.431125    0.83843416]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22916551 0.16906925 0.6017653 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.15, 0.24, 0.162, 0.146, 0.91, 0.038, 0.001, 0.483, 0.1]
0.9112421666666667
0.7779763333333333
Reward 22.468707995883868
Current State [[0.08  0.15  0.24  0.162 0.146 0.91  0.038 0.001 0.483 0.1  ]]
Logits tf.Tensor([[-0.12926246 -0.43315804  0.860654  ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2257873  0.16661699 0.60759574]], shape=(1, 3), dtype=float32)
Selected action 2
[0.13, 0.15, 0.27, 0.179, 0.146, 0.93, 0.038, 0.002, 0.519, 0.16]
0.9319336666666668
1.7666665
Reward 18.106082627769098
Current State [[0.13  0.15  0.27  0.179 0.146 0.93  0.038 0.002 0.519 0.16 ]]
Logits tf.Tensor([[-0.13863365 -0.4632678   0.89559215]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2204722  0.15935548 0.6201723 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.15, 0.27, 0.15, 0.146, 0.88, 0.045, 0.002, 0.479, 0.15]
0.8760551666666666
1.8613103333333332
Reward 17.807863076371575
Current State [[0.08  0.15  0.27  0.15  0.146 0.88  0.045 0.002 0.479 0.15 ]]
Logits tf.Tensor([[-0.1292607  -0.43615016  0.8575937 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22632043 0.16651116 0.60716844]], shape=(1, 3), dtype=float32)
Selected action 2
[0.14, 0.15, 0.26, 0.168, 0.146, 0.7, 0.017, 0.002, 0.6940000000000001, 0.08]
0.6979664999999999
2.1958325
Reward 17.068289663996733
Current State [[0.14  0.15  0.26  0.168 0.146 0.7   0.017 0.002 0.694 0.08 ]]
Logits tf.Tensor([[-0.13887788 -0.43375683  0.88241625]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22117007 0.16468804 0.61414194]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.15, 0.24, 0.169, 0.146, 0.7, 0.017, 0.002, 0.6940000000000001, 0.08]
0.6979664999999999
2.1958325
Reward 17.068289663996733
Current State [[0.07  0.15  0.24  0.169 0.146 0.7   0.017 0.002 0.694 0.08 ]]
Logits tf.Tensor([[-0.13299458 -0.41365102  0.87642974]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22225638 0.16786751 0.6098761 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.42, 0.159, 0.146, 0.92, 0.037, 0.002, 0.653, 0.18]
0.9249963333333332
1.5494044999999994
Reward 6.4884722404499815
Current State [[0.04  0.04  0.42  0.159 0.146 0.92  0.037 0.002 0.653 0.18 ]]
Logits tf.Tensor([[-0.13313824 -0.44315705  0.94108397]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.21453941 0.15735033 0.62811023]], shape=(1, 3), dtype=float32)
Selected action 2
[0.09, 0.15, 0.28, 0.158, 0.146, 0.84, 0.03, 0.003, 0.6519999999999999, 0.11]
0.8367973333333334
3.441070666666667
Reward 16.738137568751057
Current State [[0.09  0.15  0.28  0.158 0.146 0.84  0.03  0.003 0.652 0.11 ]]
Logits tf.Tensor([[-0.14352778 -0.4481649   0.92149407]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.21559654 0.15897894 0.62542456]], shape=(1, 3), dtype=float32)
Selected action 2
[0.17, 0.15, 0.29, 0.15, 0.146, 0.79, 0.043, 0.022, 0.645, 0.18]
0.7889073333333333
21.85476166666666
Reward 15.921391446940586
Current State [[0.17  0.15  0.29  0.15  0.146 0.79  0.043 0.022 0.645 0.18 ]]
Logits tf.Tensor([[-0.14708535 -0.4794026   0.89962554]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.21903275 0.15710337 0.6238638 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.17, 0.15, 0.28, 0.187, 0.146, 0.79, 0.043, 0.022, 0.645, 0.18]
0.7889073333333333
21.85476166666666
Reward 15.921391446940586
Current State [[0.17  0.15  0.28  0.187 0.146 0.79  0.043 0.022 0.645 0.18 ]]
Logits tf.Tensor([[-0.14574966 -0.47683606  0.90191054]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.21886072 0.15717334 0.6239659 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.12, 0.15, 0.25, 0.196, 0.146, 0.81, 0.043, 0.012, 0.529, 0.14]
0.8076095
12.332143
Reward 16.028928612455655
Current State [[0.12  0.15  0.25  0.196 0.146 0.81  0.043 0.012 0.529 0.14 ]]
Logits tf.Tensor([[-0.13437827 -0.43437046  0.8524774 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22605973 0.16747047 0.60646975]], shape=(1, 3), dtype=float32)
Selected action 2
[0.1, 0.15, 0.25, 0.163, 0.146, 0.96, 0.037, 0.001, 0.614, 0.13]
0.9556731666666668
0.7898808333333334
Reward 22.791755119993727
Current State [[0.1   0.15  0.25  0.163 0.146 0.96  0.037 0.001 0.614 0.13 ]]
Logits tf.Tensor([[-0.14771076 -0.47530875  0.94483346]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2126527  0.15324873 0.6340986 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.09, 0.08, 0.34, 0.15, 0.146, 0.9, 0.036, 0.003, 0.581, 0.08]
0.8969995
3.4285715
Reward 10.817846410854159
Current State [[0.09  0.08  0.34  0.15  0.146 0.9   0.036 0.003 0.581 0.08 ]]
Logits tf.Tensor([[-0.1344492  -0.42947355  0.8991142 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2195111  0.16342896 0.61705995]], shape=(1, 3), dtype=float32)
Selected action 2
[0.14, 0.15, 0.28, 0.143, 0.146, 0.87, 0.08, 0.001, 0.379, 0.18]
0.8747680000000001
1.4130946666666668
Reward 18.613956114402512
Current State [[0.14  0.15  0.28  0.143 0.146 0.87  0.08  0.001 0.379 0.18 ]]
Logits tf.Tensor([[-0.1439231  -0.44816336  0.8147315 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2301036  0.16974363 0.60015273]], shape=(1, 3), dtype=float32)
Selected action 2
[0.17, 0.15, 0.32, 0.179, 0.146, 0.87, 0.08, 0.001, 0.379, 0.18]
0.8747680000000001
1.4130946666666668
Reward 18.613956114402512
Episode: 156 | Average Reward: 297 | Episode Reward: 329 | Loss: 812.835 | Steps: 19 | Worker: 0
Current State [[ 0.00904761  0.00418301 -0.00105476  0.00690451 -0.00371375 -0.00534995
  -0.00385962 -0.00481533  0.00710259 -0.00546514]]
Logits tf.Tensor([[-0.03825413 -0.05301581  0.09406102]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.31981426 0.31512794 0.36505774]], shape=(1, 3), dtype=float32)
Selected action 2
[0.14, 0.15, 0.28, 0.166, 0.146, 1.0, 0.056, 0.0, 0.373, 0.09]
1.0036925
0.33392866666666665
Reward 43.190004879775245
Current State [[0.14  0.15  0.28  0.166 0.146 1.    0.056 0.    0.373 0.09 ]]
Logits tf.Tensor([[-0.14532606 -0.4639399   0.86899537]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22298294 0.16214344 0.6148736 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.12, 0.15, 0.27, 0.18, 0.146, 0.95, 0.073, 0.001, 0.378, 0.13]
0.9506855
0.9928566666666667
Reward 20.80879160206161
Current State [[0.12  0.15  0.27  0.18  0.146 0.95  0.073 0.001 0.378 0.13 ]]
Logits tf.Tensor([[-0.14562982 -0.45654047  0.8557574 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22447523 0.16449082 0.611034  ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.21, 0.15, 0.34, 0.179, 0.146, 0.93, 0.07, 0.001, 0.383, 0.17]
0.9268635
0.8482153333333333
Reward 21.833186595565408
Current State [[0.21  0.15  0.34  0.179 0.146 0.93  0.07  0.001 0.383 0.17 ]]
Logits tf.Tensor([[-0.15724677 -0.48196658  0.8718392 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22117843 0.15985224 0.6189693 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.1, 0.15, 0.26, 0.131, 0.146, 0.9, 0.047, 0.002, 0.43200000000000005, 0.14]
0.8971986666666668
2.230357666666667
Reward 17.465866491409187
Current State [[0.1   0.15  0.26  0.131 0.146 0.9   0.047 0.002 0.432 0.14 ]]
Logits tf.Tensor([[-0.13688807 -0.45017374  0.8550393 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22586274 0.16511495 0.6090223 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.03, 0.04, 0.34, 0.143, 0.146, 0.9, 0.047, 0.002, 0.43200000000000005, 0.14]
0.8971986666666668
2.230357666666667
Reward 5.465866491409187
Current State [[0.03  0.04  0.34  0.143 0.146 0.9   0.047 0.002 0.432 0.14 ]]
Logits tf.Tensor([[-0.11597933 -0.40312874  0.8295364 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23123847 0.17352125 0.5952403 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.04, 0.4, 0.153, 0.146, 0.91, 0.049, 0.001, 0.462, 0.13]
0.9145083333333334
0.9351189999999999
Reward 8.958060709072935
Current State [[0.05  0.04  0.4   0.153 0.146 0.91  0.049 0.001 0.462 0.13 ]]
Logits tf.Tensor([[-0.12308991 -0.41330215  0.86425215]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22562183 0.16878875 0.60558945]], shape=(1, 3), dtype=float32)
Selected action 1
[0.08, 0.08, 0.31, 0.13, 0.146, 0.86, 0.041, 0.002, 0.511, 0.16]
0.8555065000000002
1.756547833333333
Reward 11.892437751538584
Current State [[0.08  0.08  0.31  0.13  0.146 0.86  0.041 0.002 0.511 0.16 ]]
Logits tf.Tensor([[-0.13210025 -0.4328899   0.8626521 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2250079  0.16655838 0.6084337 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.15, 0.23, 0.149, 0.146, 0.86, 0.041, 0.002, 0.511, 0.16]
0.8555065000000002
1.756547833333333
Reward 17.892437751538584
Current State [[0.08  0.15  0.23  0.149 0.146 0.86  0.041 0.002 0.511 0.16 ]]
Logits tf.Tensor([[-0.1372265  -0.44734752  0.87292725]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22324511 0.16371863 0.6130363 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.15, 0.15, 0.31, 0.208, 0.146, 0.88, 0.068, 0.001, 0.376, 0.15]
0.8777440000000002
1.4029761666666667
Reward 18.651844405033387
Current State [[0.15  0.15  0.31  0.208 0.146 0.88  0.068 0.001 0.376 0.15 ]]
Logits tf.Tensor([[-0.14336096 -0.44609246  0.8434332 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22617178 0.16709514 0.6067331 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.15, 0.15, 0.27, 0.157, 0.146, 0.94, 0.039, 0.0, 0.389, 0.08]
0.9401035000000003
0.38154783333333336
Reward 36.549054240111985
Current State [[0.15  0.15  0.27  0.157 0.146 0.94  0.039 0.    0.389 0.08 ]]
Logits tf.Tensor([[-0.13908564 -0.45080894  0.8507204 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22609618 0.16554402 0.6083598 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.12, 0.15, 0.28, 0.171, 0.146, 0.95, 0.059, 0.0, 0.43200000000000005, 0.16]
0.9486855
0.2761905
Reward 47.90337079481272
Current State [[0.12  0.15  0.28  0.171 0.146 0.95  0.059 0.    0.432 0.16 ]]
Logits tf.Tensor([[-0.14547318 -0.46802062  0.88340753]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22112966 0.16016455 0.6187058 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.03, 0.04, 0.32, 0.121, 0.146, 0.96, 0.05, 0.001, 0.426, 0.13]
0.9600941666666667
1.0779761666666667
Reward 8.333909669311208
Current State [[0.03  0.04  0.32  0.121 0.146 0.96  0.05  0.001 0.426 0.13 ]]
Logits tf.Tensor([[-0.12021714 -0.41805553  0.84060156]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22955489 0.17042643 0.6000187 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.15, 0.15, 0.28, 0.179, 0.146, 0.96, 0.05, 0.001, 0.426, 0.13]
0.9600941666666667
1.0779761666666667
Reward 20.333909669311208
Current State [[0.15  0.15  0.28  0.179 0.146 0.96  0.05  0.001 0.426 0.13 ]]
Logits tf.Tensor([[-0.14596738 -0.46956235  0.882627  ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22120592 0.16005205 0.61874205]], shape=(1, 3), dtype=float32)
Selected action 2
[0.09, 0.15, 0.27, 0.185, 0.146, 0.92, 0.045, 0.001, 0.43499999999999994, 0.17]
0.9178686666666669
1.2047615
Reward 19.477515038182766
Current State [[0.09  0.15  0.27  0.185 0.146 0.92  0.045 0.001 0.435 0.17 ]]
Logits tf.Tensor([[-0.13337162 -0.45065615  0.87005895]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22442928 0.16341224 0.6121585 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.13, 0.15, 0.28, 0.185, 0.146, 0.97, 0.077, 0.005, 0.376, 0.22]
0.9711719999999999
5.0113096666666666
Reward 16.53052269748878
Current State [[0.13  0.15  0.28  0.185 0.146 0.97  0.077 0.005 0.376 0.22 ]]
Logits tf.Tensor([[-0.14824247 -0.48057002  0.8666274 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22340094 0.16023485 0.6163642 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.15, 0.15, 0.27, 0.14, 0.146, 0.9, 0.06, 0.008, 0.40499999999999997, 0.16]
0.8968623333333332
8.2220245
Reward 16.193387703686938
Current State [[0.15  0.15  0.27  0.14  0.146 0.9   0.06  0.008 0.405 0.16 ]]
Logits tf.Tensor([[-0.14547496 -0.46538654  0.8467373 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22607002 0.16417503 0.6097549 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.1, 0.15, 0.24, 0.158, 0.146, 0.95, 0.053, 0.001, 0.414, 0.13]
0.9510608333333332
0.6107148333333332
Reward 26.01767508601261
Current State [[0.1   0.15  0.24  0.158 0.146 0.95  0.053 0.001 0.414 0.13 ]]
Logits tf.Tensor([[-0.1390347  -0.45569032  0.86054474]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22493543 0.1638838  0.6111807 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.21, 0.15, 0.33, 0.181, 0.146, 0.95, 0.053, 0.001, 0.414, 0.13]
0.9510608333333332
0.6107148333333332
Reward 26.01767508601261
Current State [[0.21  0.15  0.33  0.181 0.146 0.95  0.053 0.001 0.414 0.13 ]]
Logits tf.Tensor([[-0.15515861 -0.48072094  0.8884729 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2192198  0.15830328 0.6224769 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.37, 0.136, 0.146, 0.92, 0.044, 0.001, 0.453, 0.17]
0.922443
1.0035715
Reward 8.533829073591154
Current State [[0.04  0.04  0.37  0.136 0.146 0.92  0.044 0.001 0.453 0.17 ]]
Logits tf.Tensor([[-0.11915283 -0.41886583  0.8545543 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22785412 0.16884695 0.6032989 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.02, 0.04, 0.34, 0.125, 0.146, 0.78, 0.036, 0.003, 0.563, 0.14]
0.7804905000000001
2.658333166666667
Reward 4.958868394269452
Episode: 157 | Average Reward: 298 | Episode Reward: 397 | Loss: 1110.539 | Steps: 19 | Worker: 0
Current State [[-6.38784675e-05  6.94442804e-03  9.04173020e-04  7.72617326e-04
  -1.89845035e-03 -4.75969223e-03 -5.64708604e-03  2.15954807e-03
   6.75672857e-03 -5.57360192e-03]]
Logits tf.Tensor([[-0.03703558 -0.05404245  0.09642012]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.31990713 0.31451246 0.36558044]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.41, 0.147, 0.146, 0.78, 0.036, 0.003, 0.563, 0.14]
0.7804905000000001
2.658333166666667
Reward 4.958868394269452
Current State [[0.04  0.04  0.41  0.147 0.146 0.78  0.036 0.003 0.563 0.14 ]]
Logits tf.Tensor([[-0.12818547 -0.4115135   0.87598073]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22306974 0.16803235 0.6088979 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.14, 0.15, 0.26, 0.178, 0.146, 0.83, 0.034, 0.002, 0.517, 0.11]
0.8287966666666667
2.0440471666666666
Reward 17.481473214523657
Current State [[0.14  0.15  0.26  0.178 0.146 0.83  0.034 0.002 0.517 0.11 ]]
Logits tf.Tensor([[-0.14684299 -0.4559886   0.8918087 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2193233 0.1609995 0.6196771]], shape=(1, 3), dtype=float32)
Selected action 2
[0.16, 0.15, 0.27, 0.167, 0.146, 0.99, 0.038, 0.0, 0.34900000000000003, 0.14]
0.9903223333333332
0.302976
Reward 46.161433426501766
Current State [[0.16  0.15  0.27  0.167 0.146 0.99  0.038 0.    0.349 0.14 ]]
Logits tf.Tensor([[-0.1445929  -0.48029318  0.8684832 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22376888 0.15995833 0.6162728 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.1, 0.15, 0.26, 0.124, 0.146, 0.96, 0.031, 0.001, 0.403, 0.11]
0.957313
0.9619051666666667
Reward 21.085728650295657
Current State [[0.1   0.15  0.26  0.124 0.146 0.96  0.031 0.001 0.403 0.11 ]]
Logits tf.Tensor([[-0.13577692 -0.46511686  0.8758781 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22373632 0.16095555 0.61530817]], shape=(1, 3), dtype=float32)
Selected action 1
[0.07, 0.08, 0.33, 0.158, 0.146, 0.96, 0.031, 0.001, 0.403, 0.11]
0.957313
0.9619051666666667
Reward 15.085728650295655
Current State [[0.07  0.08  0.33  0.158 0.146 0.96  0.031 0.001 0.403 0.11 ]]
Logits tf.Tensor([[-0.12290308 -0.4352016   0.86680645]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22613099 0.1654743  0.60839474]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.24, 0.173, 0.146, 0.93, 0.029, 0.001, 0.512, 0.14]
0.9302826666666667
1.3470246666666668
Reward 19.035655957237545
Current State [[0.05  0.15  0.24  0.173 0.146 0.93  0.029 0.001 0.512 0.14 ]]
Logits tf.Tensor([[-0.13536291 -0.46063527  0.91742533]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.21796176 0.15744045 0.6245978 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.15, 0.26, 0.192, 0.146, 0.81, 0.027, 0.003, 0.5900000000000001, 0.14]
0.8081446666666666
3.110714
Reward 16.809881259155876
Current State [[0.07  0.15  0.26  0.192 0.146 0.81  0.027 0.003 0.59  0.14 ]]
Logits tf.Tensor([[-0.1427394  -0.44979802  0.9158564 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.21654733 0.15929383 0.62415886]], shape=(1, 3), dtype=float32)
Selected action 2
[0.11, 0.15, 0.25, 0.2, 0.146, 0.75, 0.024, 0.006, 0.751, 0.17]
0.7543128333333334
5.575000333333334
Reward 16.295231203246843
Current State [[0.11  0.15  0.25  0.2   0.146 0.75  0.024 0.006 0.751 0.17 ]]
Logits tf.Tensor([[-0.15443873 -0.48652375  0.96531063]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.20913884 0.1500417  0.64081943]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.15, 0.22, 0.145, 0.146, 0.57, 0.012, 0.003, 0.623, 0.08]
0.5652945
2.7172621666666665
Reward 16.589543902885268
Current State [[0.07  0.15  0.22  0.145 0.146 0.57  0.012 0.003 0.623 0.08 ]]
Logits tf.Tensor([[-0.12790303 -0.39054203  0.8175845 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23025094 0.17706747 0.5926816 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.15, 0.15, 0.26, 0.181, 0.146, 0.57, 0.012, 0.003, 0.623, 0.08]
0.5652945
2.7172621666666665
Reward 16.589543902885268
Current State [[0.15  0.15  0.26  0.181 0.146 0.57  0.012 0.003 0.623 0.08 ]]
Logits tf.Tensor([[-0.13140875 -0.4082755   0.8344393 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22804134 0.1728908  0.59906787]], shape=(1, 3), dtype=float32)
Selected action 2
[0.11, 0.15, 0.26, 0.152, 0.146, 0.91, 0.036, 0.001, 0.5269999999999999, 0.02]
0.9063341666666666
0.663691
Reward 24.167469151075885
Current State [[0.11  0.15  0.26  0.152 0.146 0.91  0.036 0.001 0.527 0.02 ]]
Logits tf.Tensor([[-0.1484236  -0.45544264  0.9208062 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.21511057 0.15824321 0.62664616]], shape=(1, 3), dtype=float32)
Selected action 2
[0.14, 0.15, 0.27, 0.162, 0.146, 0.99, 0.039, 0.0, 0.421, 0.04]
0.9853388333333333
0.3577375
Reward 40.16250109601771
Current State [[0.14  0.15  0.27  0.162 0.146 0.99  0.039 0.    0.421 0.04 ]]
Logits tf.Tensor([[-0.14630474 -0.46985394  0.90160114]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.21856733 0.15815015 0.62328255]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.04, 0.26, 0.114, 0.146, 0.94, 0.03, 0.001, 0.481, 0.08]
0.9358841666666667
0.6696426666666667
Reward 12.46440612610926
Current State [[0.05  0.04  0.26  0.114 0.146 0.94  0.03  0.001 0.481 0.08 ]]
Logits tf.Tensor([[-0.1261837  -0.42722315  0.8584145 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22640906 0.1675537  0.60603726]], shape=(1, 3), dtype=float32)
Selected action 2
[0.1, 0.15, 0.26, 0.178, 0.146, 0.94, 0.03, 0.001, 0.481, 0.08]
0.9358841666666667
0.6696426666666667
Reward 24.46440612610926
Current State [[0.1   0.15  0.26  0.178 0.146 0.94  0.03  0.001 0.481 0.08 ]]
Logits tf.Tensor([[-0.13923597 -0.45946372  0.9110642 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.21812665 0.15835637 0.623517  ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.12, 0.15, 0.26, 0.165, 0.146, 0.96, 0.035, 0.0, 0.425, 0.05]
0.9645666666666667
0.41845200000000005
Reward 34.5712244981365
Current State [[0.12  0.15  0.26  0.165 0.146 0.96  0.035 0.    0.425 0.05 ]]
Logits tf.Tensor([[-0.1404911 -0.4582323  0.8897857]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22076848 0.16067332 0.6185582 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.15, 0.15, 0.27, 0.17, 0.146, 0.96, 0.035, 0.001, 0.458, 0.11]
0.9561326666666667
0.8279763333333333
Reward 22.33266845298277
Current State [[0.15  0.15  0.27  0.17  0.146 0.96  0.035 0.001 0.458 0.11 ]]
Logits tf.Tensor([[-0.14803605 -0.48136643  0.9115239 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2173141 0.1557128 0.6269731]], shape=(1, 3), dtype=float32)
Selected action 2
[0.09, 0.15, 0.26, 0.136, 0.146, 0.84, 0.022, 0.001, 0.37, 0.07]
0.8421363333333336
1.4178573333333337
Reward 18.471263121324714
Current State [[0.09  0.15  0.26  0.136 0.146 0.84  0.022 0.001 0.37  0.07 ]]
Logits tf.Tensor([[-0.1213048 -0.4170754  0.8158013]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23274532 0.17315274 0.59410197]], shape=(1, 3), dtype=float32)
Selected action 2
[0.09, 0.15, 0.26, 0.169, 0.146, 0.84, 0.022, 0.001, 0.37, 0.07]
0.8421363333333336
1.4178573333333337
Reward 18.471263121324714
Current State [[0.09  0.15  0.26  0.169 0.146 0.84  0.022 0.001 0.37  0.07 ]]
Logits tf.Tensor([[-0.11973412 -0.41289136  0.81816137]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23253085 0.1734459  0.5940232 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.11, 0.15, 0.26, 0.156, 0.146, 0.91, 0.044, 0.001, 0.509, 0.18]
0.9079628333333335
0.6047620000000001
Reward 25.460401890950305
Current State [[0.11  0.15  0.26  0.156 0.146 0.91  0.044 0.001 0.509 0.18 ]]
Logits tf.Tensor([[-0.14845853 -0.48190168  0.9181589 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.21635714 0.15500966 0.62863314]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.04, 0.35, 0.136, 0.146, 0.92, 0.019, 0.001, 0.38, 0.06]
0.9162200000000001
1.3059521666666667
Reward 7.102129015748234
Episode: 158 | Average Reward: 299 | Episode Reward: 417 | Loss: 1385.89 | Steps: 19 | Worker: 0
Current State [[ 0.00266067  0.00495201 -0.00995164  0.00079381 -0.00368118 -0.00064496
   0.00473198 -0.00318272  0.0088457   0.00675066]]
Logits tf.Tensor([[-0.04149204 -0.06236636  0.1073925 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.31848344 0.3119042  0.36961243]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.04, 0.32, 0.124, 0.146, 0.82, 0.025, 0.004, 0.564, 0.11]
0.8225966666666669
3.93631
Reward 4.593456626649431
Current State [[0.05  0.04  0.32  0.124 0.146 0.82  0.025 0.004 0.564 0.11 ]]
Logits tf.Tensor([[-0.13469493 -0.42978144  0.89306676]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22029972 0.16400592 0.61569434]], shape=(1, 3), dtype=float32)
Selected action 2
[0.12, 0.15, 0.26, 0.169, 0.146, 0.82, 0.025, 0.004, 0.564, 0.11]
0.8225966666666669
3.93631
Reward 16.59345662664943
Current State [[0.12  0.15  0.26  0.169 0.146 0.82  0.025 0.004 0.564 0.11 ]]
Logits tf.Tensor([[-0.15217681 -0.47079203  0.9296618 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.21380065 0.15546627 0.630733  ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.32, 0.138, 0.146, 0.78, 0.023, 0.004, 0.429, 0.05]
0.7824261666666666
4.1648811666666665
Reward 4.506136898503745
Current State [[0.04  0.04  0.32  0.138 0.146 0.78  0.023 0.004 0.429 0.05 ]]
Logits tf.Tensor([[-0.11495434 -0.3812266   0.81116813]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.23304965 0.17856973 0.5883806 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.14, 0.15, 0.26, 0.176, 0.146, 0.9, 0.032, 0.002, 0.422, 0.06]
0.8979205000000001
1.6202383333333332
Reward 18.250549796961284
Current State [[0.14  0.15  0.26  0.176 0.146 0.9   0.032 0.002 0.422 0.06 ]]
Logits tf.Tensor([[-0.14503796 -0.46254805  0.8913975 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.21991993 0.16009279 0.6199873 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.12, 0.15, 0.25, 0.144, 0.146, 0.94, 0.025, 0.003, 0.40099999999999997, 0.08]
0.9403103333333332
2.7178571666666667
Reward 17.197784518027344
Current State [[0.12  0.15  0.25  0.144 0.146 0.94  0.025 0.003 0.401 0.08 ]]
Logits tf.Tensor([[-0.14058816 -0.47062016  0.88817453]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22141026 0.15917197 0.6194177 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.1, 0.15, 0.26, 0.162, 0.146, 0.94, 0.025, 0.003, 0.40099999999999997, 0.08]
0.9403103333333332
2.7178571666666667
Reward 17.197784518027344
Current State [[0.1   0.15  0.26  0.162 0.146 0.94  0.025 0.003 0.401 0.08 ]]
Logits tf.Tensor([[-0.1363734  -0.46302605  0.891665  ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22139026 0.15969636 0.6189134 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.12, 0.15, 0.26, 0.181, 0.146, 0.98, 0.035, 0.001, 0.43899999999999995, 0.02]
0.979599
1.0416671666666668
Reward 20.685307291666994
Current State [[0.12  0.15  0.26  0.181 0.146 0.98  0.035 0.001 0.439 0.02 ]]
Logits tf.Tensor([[-0.1482347  -0.47272798  0.9278407 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.21477482 0.15525934 0.62996584]], shape=(1, 3), dtype=float32)
Selected action 2
[0.15, 0.15, 0.27, 0.164, 0.146, 0.95, 0.02, 0.001, 0.375, 0.08]
0.9475883333333334
1.1940475
Reward 19.681519510445884
Current State [[0.15  0.15  0.27  0.164 0.146 0.95  0.02  0.001 0.375 0.08 ]]
Logits tf.Tensor([[-0.14171614 -0.4729635   0.88615805]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22157498 0.15909693 0.61932814]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.04, 0.31, 0.15, 0.146, 0.92, 0.037, 0.003, 0.45899999999999996, 0.1]
0.9205905
3.0154764999999997
Reward 5.011320524335547
Current State [[0.05  0.04  0.31  0.15  0.146 0.92  0.037 0.003 0.459 0.1  ]]
Logits tf.Tensor([[-0.1296519  -0.43378785  0.8806986 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22299907 0.1645199  0.61248106]], shape=(1, 3), dtype=float32)
Selected action 2
[0.15, 0.15, 0.26, 0.17, 0.146, 0.8, 0.025, 0.006, 0.5900000000000001, 0.05]
0.7974911666666668
5.853571166666668
Reward 16.298912964299014
Current State [[0.15  0.15  0.26  0.17  0.146 0.8   0.025 0.006 0.59  0.05 ]]
Logits tf.Tensor([[-0.15497708 -0.4686978   0.932856  ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2128312  0.15552066 0.6316481 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.06, 0.08, 0.31, 0.157, 0.146, 0.8, 0.025, 0.006, 0.5900000000000001, 0.05]
0.7974911666666668
5.853571166666668
Reward 10.298912964299015
Current State [[0.06  0.08  0.31  0.157 0.146 0.8   0.025 0.006 0.59  0.05 ]]
Logits tf.Tensor([[-0.14022115 -0.42761707  0.9110435 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.21685003 0.16268407 0.62046593]], shape=(1, 3), dtype=float32)
Selected action 2
[0.15, 0.15, 0.26, 0.192, 0.146, 0.78, 0.029, 0.002, 0.775, 0.15]
0.7767283333333331
2.1696436666666665
Reward 17.25404925074965
Current State [[0.15  0.15  0.26  0.192 0.146 0.78  0.029 0.002 0.775 0.15 ]]
Logits tf.Tensor([[-0.16978614 -0.5224269   1.0180799 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.20068622 0.14104821 0.65826565]], shape=(1, 3), dtype=float32)
Selected action 2
[0.15, 0.15, 0.27, 0.172, 0.146, 0.8, 0.038, 0.003, 0.6980000000000001, 0.19]
0.7978441666666668
3.1988098333333337
Reward 16.764968332951078
Current State [[0.15  0.15  0.27  0.172 0.146 0.8   0.038 0.003 0.698 0.19 ]]
Logits tf.Tensor([[-0.16830131 -0.52222216  0.99160874]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.20443305 0.1434978  0.65206915]], shape=(1, 3), dtype=float32)
Selected action 2
[0.17, 0.15, 0.28, 0.138, 0.146, 0.91, 0.038, 0.002, 0.78, 0.15]
0.906495
1.9321430000000002
Reward 17.800166410816455
Current State [[0.17  0.15  0.28  0.138 0.146 0.91  0.038 0.002 0.78  0.15 ]]
Logits tf.Tensor([[-0.18693574 -0.56009364  1.0757341 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.19144607 0.13182142 0.6767325 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.11, 0.15, 0.26, 0.165, 0.146, 0.91, 0.038, 0.002, 0.78, 0.15]
0.906495
1.9321430000000002
Reward 17.800166410816455
Current State [[0.11  0.15  0.26  0.165 0.146 0.91  0.038 0.002 0.78  0.15 ]]
Logits tf.Tensor([[-0.17954135 -0.5412348   1.0717001 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.19263461 0.13416922 0.67319614]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.04, 0.34, 0.155, 0.146, 0.78, 0.034, 0.015, 0.5549999999999999, 0.12]
0.7822953333333333
15.499404
Reward 3.97365584603325
Current State [[0.05  0.04  0.34  0.155 0.146 0.78  0.034 0.015 0.555 0.12 ]]
Logits tf.Tensor([[-0.13197306 -0.42190295  0.87828934]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22248735 0.16649084 0.61102176]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.27, 0.128, 0.146, 0.78, 0.017, 0.003, 0.779, 0.07]
0.7784351666666666
2.7184528333333335
Reward 16.926579823875265
Current State [[0.05  0.15  0.27  0.128 0.146 0.78  0.017 0.003 0.779 0.07 ]]
Logits tf.Tensor([[-0.16035146 -0.4766118   1.0059501 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.20247145 0.14757532 0.64995325]], shape=(1, 3), dtype=float32)
Selected action 0
[0.03, 0.04, 0.32, 0.127, 0.146, 0.98, 0.058, 0.001, 0.417, 0.05]
0.9754321666666667
0.8791659999999999
Reward 9.966374549482163
Current State [[0.03  0.04  0.32  0.127 0.146 0.98  0.058 0.001 0.417 0.05 ]]
Logits tf.Tensor([[-0.13350914 -0.43402216  0.88351417]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22195636 0.16434498 0.61369866]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.15, 0.28, 0.178, 0.146, 0.98, 0.058, 0.001, 0.417, 0.05]
0.9754321666666667
0.8791659999999999
Reward 21.96637454948216
Current State [[0.08  0.15  0.28  0.178 0.146 0.98  0.058 0.001 0.417 0.05 ]]
Logits tf.Tensor([[-0.14869414 -0.4691528   0.9253846 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.21491   0.1559851 0.6291049]], shape=(1, 3), dtype=float32)
Selected action 2
[0.15, 0.15, 0.3, 0.158, 0.146, 0.97, 0.05, 0.001, 0.41100000000000003, 0.12]
0.9726738333333335
0.7547619999999999
Reward 23.4736966621627
Episode: 159 | Average Reward: 299 | Episode Reward: 296 | Loss: 710.723 | Steps: 19 | Worker: 0
Current State [[ 0.00405773  0.00752074 -0.00742397 -0.00985018  0.00560118  0.0012901
  -0.00762718 -0.00111952 -0.00359141 -0.00396734]]
Logits tf.Tensor([[-0.03921631 -0.06077249  0.10630189]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.31894737 0.31214565 0.36890692]], shape=(1, 3), dtype=float32)
Selected action 1
[0.07, 0.08, 0.28, 0.154, 0.146, 0.94, 0.06, 0.0, 0.404, 0.18]
0.9387821666666667
0.4285718333333333
Reward 27.16171311061729
Current State [[0.07  0.08  0.28  0.154 0.146 0.94  0.06  0.    0.404 0.18 ]]
Logits tf.Tensor([[-0.14702013 -0.47898698  0.900709  ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.21888159 0.15705    0.62406844]], shape=(1, 3), dtype=float32)
Selected action 2
[0.09, 0.15, 0.29, 0.143, 0.146, 0.87, 0.064, 0.002, 0.385, 0.2]
0.8685786666666666
1.8999994999999998
Reward 17.738825931534578
Current State [[0.09  0.15  0.29  0.143 0.146 0.87  0.064 0.002 0.385 0.2  ]]
Logits tf.Tensor([[-0.15219237 -0.4884332   0.8979147 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.21870314 0.15625268 0.62504417]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.04, 0.41, 0.145, 0.146, 0.87, 0.064, 0.002, 0.385, 0.2]
0.8685786666666666
1.8999994999999998
Reward 5.738825931534577
Current State [[0.05  0.04  0.41  0.145 0.146 0.87  0.064 0.002 0.385 0.2  ]]
Logits tf.Tensor([[-0.1373309  -0.44788575  0.88188106]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22202238 0.16275132 0.61522627]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.32, 0.151, 0.146, 0.82, 0.045, 0.001, 0.46900000000000003, 0.1]
0.8234516666666667
1.2529761666666668
Reward 6.8360037846096455
Current State [[0.04  0.04  0.32  0.151 0.146 0.82  0.045 0.001 0.469 0.1  ]]
Logits tf.Tensor([[-0.13494928 -0.4246311   0.8761066 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2223703  0.16644454 0.61118513]], shape=(1, 3), dtype=float32)
Selected action 2
[0.18, 0.15, 0.28, 0.167, 0.146, 0.92, 0.046, 0.001, 0.462, 0.11]
0.9224048333333332
1.1833328333333335
Reward 19.59032166378686
Current State [[0.18  0.15  0.28  0.167 0.146 0.92  0.046 0.001 0.462 0.11 ]]
Logits tf.Tensor([[-0.16847607 -0.5137595   0.9542437 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2091516  0.14808343 0.642765  ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.25, 0.15, 0.28, 0.138, 0.146, 0.9, 0.054, 0.009, 0.39, 0.18]
0.9003515
9.457142833333332
Reward 16.140382853074275
Current State [[0.25  0.15  0.28  0.138 0.146 0.9   0.054 0.009 0.39  0.18 ]]
Logits tf.Tensor([[-0.17461663 -0.53481424  0.91127527]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.21460982 0.14969863 0.6356916 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.21, 0.15, 0.27, 0.147, 0.146, 0.9, 0.054, 0.009, 0.39, 0.18]
0.9003515
9.457142833333332
Reward 16.140382853074275
Current State [[0.21  0.15  0.27  0.147 0.146 0.9   0.054 0.009 0.39  0.18 ]]
Logits tf.Tensor([[-0.16779317 -0.5232123   0.9077229 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.21587151 0.15129997 0.63282853]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.04, 0.35, 0.162, 0.146, 0.89, 0.034, 0.0, 0.45499999999999996, 0.18]
0.8931190000000001
0.4690478333333334
Reward 17.764236005680115
Current State [[0.05  0.04  0.35  0.162 0.146 0.89  0.034 0.    0.455 0.18 ]]
Logits tf.Tensor([[-0.13256687 -0.45392102  0.9043043 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.21999562 0.15953341 0.62047094]], shape=(1, 3), dtype=float32)
Selected action 1
[0.09, 0.08, 0.35, 0.136, 0.146, 0.84, 0.035, 0.004, 0.509, 0.09]
0.8427601666666666
3.9238098333333324
Reward 10.617727281031836
Current State [[0.09  0.08  0.35  0.136 0.146 0.84  0.035 0.004 0.509 0.09 ]]
Logits tf.Tensor([[-0.14534152 -0.4577188   0.9234298 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.21535453 0.15757611 0.62706935]], shape=(1, 3), dtype=float32)
Selected action 1
[0.09, 0.08, 0.34, 0.169, 0.146, 0.84, 0.035, 0.004, 0.509, 0.09]
0.8427601666666666
3.9238098333333324
Reward 10.617727281031836
Current State [[0.09  0.08  0.34  0.169 0.146 0.84  0.035 0.004 0.509 0.09 ]]
Logits tf.Tensor([[-0.14568445 -0.45512134  0.92485714]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.21501587 0.1577916  0.62719256]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.15, 0.27, 0.179, 0.146, 0.92, 0.058, 0.001, 0.457, 0.22]
0.922112
0.7976191666666668
Reward 22.343312216326353
Current State [[0.06  0.15  0.27  0.179 0.146 0.92  0.058 0.001 0.457 0.22 ]]
Logits tf.Tensor([[-0.15375292 -0.5023252   0.9499994 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.21181257 0.14947507 0.63871235]], shape=(1, 3), dtype=float32)
Selected action 0
[0.03, 0.04, 0.32, 0.155, 0.146, 1.0, 0.039, 0.001, 0.409, 0.12]
0.9997338333333334
0.6119046666666667
Reward 14.8023488115093
Current State [[0.03  0.04  0.32  0.155 0.146 1.    0.039 0.001 0.409 0.12 ]]
Logits tf.Tensor([[-0.13147014 -0.4591286   0.91155404]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.21937546 0.15808395 0.6225406 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.12, 0.15, 0.27, 0.145, 0.146, 0.86, 0.032, 0.003, 0.511, 0.12]
0.8635786666666667
3.3500001666666663
Reward 16.801153625210333
Current State [[0.12  0.15  0.27  0.145 0.146 0.86  0.032 0.003 0.511 0.12 ]]
Logits tf.Tensor([[-0.15568937 -0.49164864  0.94617355]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2116662 0.1512677 0.6370661]], shape=(1, 3), dtype=float32)
Selected action 2
[0.15, 0.15, 0.27, 0.147, 0.146, 0.94, 0.057, 0.002, 0.426, 0.16]
0.9435971666666665
1.888690666666667
Reward 17.95806686034742
Current State [[0.15  0.15  0.27  0.147 0.146 0.94  0.057 0.002 0.426 0.16 ]]
Logits tf.Tensor([[-0.16659336 -0.5192512   0.94063973]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.21147051 0.1486252  0.6399043 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.15, 0.15, 0.28, 0.192, 0.146, 0.94, 0.057, 0.002, 0.426, 0.16]
0.9435971666666665
1.888690666666667
Reward 17.95806686034742
Current State [[0.15  0.15  0.28  0.192 0.146 0.94  0.057 0.002 0.426 0.16 ]]
Logits tf.Tensor([[-0.16446249 -0.51389116  0.9471565 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.21077634 0.14861646 0.64060724]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.38, 0.15, 0.146, 0.9, 0.049, 0.005, 0.422, 0.21]
0.8966518333333333
5.298809833333335
Reward 4.430272990666956
Current State [[0.04  0.04  0.38  0.15  0.146 0.9   0.049 0.005 0.422 0.21 ]]
Logits tf.Tensor([[-0.13378413 -0.458284    0.90068126]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22043471 0.1593498  0.6202155 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.16, 0.15, 0.28, 0.16, 0.146, 0.77, 0.041, 0.002, 0.544, 0.16]
0.7727688333333333
2.126785666666667
Reward 17.279269598643396
Current State [[0.16  0.15  0.28  0.16  0.146 0.77  0.041 0.002 0.544 0.16 ]]
Logits tf.Tensor([[-0.16299927 -0.49714908  0.93219894]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.21250725 0.15214384 0.6353489 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.15, 0.25, 0.139, 0.146, 0.94, 0.051, 0.002, 0.409, 0.16]
0.9369703333333333
1.6333335
Reward 18.357785650376037
Current State [[0.08  0.15  0.25  0.139 0.146 0.94  0.051 0.002 0.409 0.16 ]]
Logits tf.Tensor([[-0.15166338 -0.4970265   0.92169636]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.21583569 0.15280375 0.6313606 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.1, 0.15, 0.28, 0.151, 0.146, 0.98, 0.027, 0.0, 0.37, 0.03]
0.9849025
0.3113093333333333
Reward 45.00502690088308
Current State [[0.1   0.15  0.28  0.151 0.146 0.98  0.027 0.    0.37  0.03 ]]
Logits tf.Tensor([[-0.14291784 -0.47648633  0.91792256]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.21714771 0.15555653 0.6272958 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.17, 0.15, 0.27, 0.165, 0.146, 0.98, 0.027, 0.0, 0.37, 0.03]
0.9849025
0.3113093333333333
Reward 45.00502690088308
Episode: 160 | Average Reward: 300 | Episode Reward: 368 | Loss: 1156.922 | Steps: 19 | Worker: 0
Current State [[ 0.00986617 -0.00451354 -0.00115675 -0.00649106  0.0032824  -0.00024834
  -0.00437403 -0.00983027  0.00345234 -0.00687073]]
Logits tf.Tensor([[-0.04234812 -0.06477713  0.1137172 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3177909 0.3107425 0.3714666]], shape=(1, 3), dtype=float32)
Selected action 2
[0.17, 0.15, 0.27, 0.171, 0.146, 0.89, 0.042, 0.001, 0.471, 0.17]
0.8901005000000001
0.5297618333333333
Reward 27.29019895911347
Current State [[0.17  0.15  0.27  0.171 0.146 0.89  0.042 0.001 0.471 0.17 ]]
Logits tf.Tensor([[-0.16952081 -0.5319994   0.9672028 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.20779264 0.14461313 0.6475942 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.13, 0.15, 0.26, 0.167, 0.146, 0.94, 0.058, 0.002, 0.41900000000000004, 0.21]
0.9409698333333333
1.5404760000000002
Reward 18.56695997594821
Current State [[0.13  0.15  0.26  0.167 0.146 0.94  0.058 0.002 0.419 0.21 ]]
Logits tf.Tensor([[-0.16618212 -0.5360565   0.9594879 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.20950733 0.14473209 0.6457606 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.16, 0.15, 0.27, 0.137, 0.146, 0.95, 0.034, 0.002, 0.397, 0.12]
0.9461426666666667
2.359523666666667
Reward 17.459648435985823
Current State [[0.16  0.15  0.27  0.137 0.146 0.95  0.034 0.002 0.397 0.12 ]]
Logits tf.Tensor([[-0.16107638 -0.52515984  0.9454495 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.21192421 0.14725198 0.64082384]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.04, 0.36, 0.134, 0.146, 0.95, 0.028, 0.001, 0.562, 0.1]
0.9478501666666667
1.266072
Reward 7.393876916173345
Current State [[0.05  0.04  0.36  0.134 0.146 0.95  0.028 0.001 0.562 0.1  ]]
Logits tf.Tensor([[-0.14988472 -0.49028552  1.0014163 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.20517917 0.14598191 0.64883894]], shape=(1, 3), dtype=float32)
Selected action 2
[0.16, 0.15, 0.27, 0.167, 0.146, 0.95, 0.028, 0.001, 0.562, 0.1]
0.9478501666666667
1.266072
Reward 19.393876916173344
Current State [[0.16  0.15  0.27  0.167 0.146 0.95  0.028 0.001 0.562 0.1  ]]
Logits tf.Tensor([[-0.17328438 -0.54314494  1.03334   ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.19868807 0.13725983 0.66405207]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.31, 0.155, 0.146, 0.98, 0.049, 0.001, 0.41500000000000004, 0.14]
0.9838841666666666
1.3946428333333332
Reward 7.1259355280487515
Current State [[0.04  0.04  0.31  0.155 0.146 0.98  0.049 0.001 0.415 0.14 ]]
Logits tf.Tensor([[-0.14054635 -0.47888643  0.9289814 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.21612482 0.1540868  0.6297884 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.18, 0.15, 0.28, 0.153, 0.146, 0.69, 0.015, 0.01, 1.03, 0.09]
0.6894451666666668
9.735119333333333
Reward 16.04872496912788
Current State [[0.18  0.15  0.28  0.153 0.146 0.69  0.015 0.01  1.03  0.09 ]]
Logits tf.Tensor([[-0.19030914 -0.560359    1.1608725 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.180093   0.12439024 0.69551677]], shape=(1, 3), dtype=float32)
Selected action 1
[0.14, 0.08, 0.25, 0.137, 0.146, 0.84, 0.02, 0.002, 0.662, 0.1]
0.839616
2.076785666666667
Reward 11.475706287518422
Current State [[0.14  0.08  0.25  0.137 0.146 0.84  0.02  0.002 0.662 0.1  ]]
Logits tf.Tensor([[-0.17025463 -0.5126383   0.9987508 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.20288646 0.14406475 0.6530488 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.07, 0.08, 0.23, 0.132, 0.146, 0.84, 0.02, 0.002, 0.662, 0.1]
0.839616
2.076785666666667
Reward 11.475706287518422
Current State [[0.07  0.08  0.23  0.132 0.146 0.84  0.02  0.002 0.662 0.1  ]]
Logits tf.Tensor([[-0.16133699 -0.49263313  0.98998594]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.20490263 0.14711858 0.6479788 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.17, 0.15, 0.27, 0.178, 0.146, 0.89, 0.046, 0.001, 0.48200000000000004, 0.18]
0.8913726666666668
0.7315475000000001
Reward 22.864541129286465
Current State [[0.17  0.15  0.27  0.178 0.146 0.89  0.046 0.001 0.482 0.18 ]]
Logits tf.Tensor([[-0.17200398 -0.5358874   0.97443026]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.20652948 0.14353225 0.6499383 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.25, 0.154, 0.146, 0.93, 0.038, 0.003, 0.434, 0.15]
0.9253038333333333
3.184524666666666
Reward 16.94531023772259
Current State [[0.05  0.15  0.25  0.154 0.146 0.93  0.038 0.003 0.434 0.15 ]]
Logits tf.Tensor([[-0.14620504 -0.49962667  0.94980335]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.21301615 0.14959723 0.6373866 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.04, 0.32, 0.14, 0.146, 0.93, 0.038, 0.003, 0.434, 0.15]
0.9253038333333333
3.184524666666666
Reward 4.945310237722592
Current State [[0.05  0.04  0.32  0.14  0.146 0.93  0.038 0.003 0.434 0.15 ]]
Logits tf.Tensor([[-0.13714072 -0.4730655   0.92015564]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.21771054 0.1555927  0.62669677]], shape=(1, 3), dtype=float32)
Selected action 2
[0.11, 0.15, 0.26, 0.156, 0.146, 0.83, 0.018, 0.001, 0.47000000000000003, 0.06]
0.8268609999999998
1.2720238333333331
Reward 18.79385488068375
Current State [[0.11  0.15  0.26  0.156 0.146 0.83  0.018 0.001 0.47  0.06 ]]
Logits tf.Tensor([[-0.14690322 -0.47344622  0.92819774]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.21497507 0.15508588 0.629939  ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.15, 0.25, 0.129, 0.146, 0.94, 0.039, 0.0, 0.372, 0.03]
0.9434414999999999
0.1238095
Reward 61.703005153252086
Current State [[0.08  0.15  0.25  0.129 0.146 0.94  0.039 0.    0.372 0.03 ]]
Logits tf.Tensor([[-0.1471662  -0.48052093  0.9163128 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2167812  0.15532719 0.6278916 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.09, 0.08, 0.28, 0.133, 0.146, 0.8, 0.018, 0.002, 0.42699999999999994, 0.07]
0.803882
1.5095238333333332
Reward 12.13309911430007
Current State [[0.09  0.08  0.28  0.133 0.146 0.8   0.018 0.002 0.427 0.07 ]]
Logits tf.Tensor([[-0.13232364 -0.43998018  0.86787814]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.22451738 0.16505794 0.6104247 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.15, 0.15, 0.27, 0.198, 0.146, 0.8, 0.018, 0.002, 0.42699999999999994, 0.07]
0.803882
1.5095238333333332
Reward 18.13309911430007
Current State [[0.15  0.15  0.27  0.198 0.146 0.8   0.018 0.002 0.427 0.07 ]]
Logits tf.Tensor([[-0.14582059 -0.46864712  0.90238464]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.21850155 0.15821686 0.6232816 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.4, 0.152, 0.146, 0.81, 0.027, 0.002, 0.505, 0.1]
0.8053156666666668
1.5809530000000003
Reward 6.009597112648407
Current State [[0.04  0.04  0.4   0.152 0.146 0.81  0.027 0.002 0.505 0.1  ]]
Logits tf.Tensor([[-0.13514385 -0.44147342  0.92278075]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.21661288 0.15945826 0.6239289 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.17, 0.15, 0.26, 0.186, 0.146, 0.78, 0.037, 0.002, 0.544, 0.12]
0.7847894999999999
2.148809833333333
Reward 17.288105759927586
Current State [[0.17  0.15  0.26  0.186 0.146 0.78  0.037 0.002 0.544 0.12 ]]
Logits tf.Tensor([[-0.16576429 -0.5073926   0.9555659 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2092249  0.14867778 0.64209735]], shape=(1, 3), dtype=float32)
Selected action 2
[0.11, 0.15, 0.26, 0.157, 0.146, 0.9, 0.035, 0.001, 0.45999999999999996, 0.14]
0.8996536666666665
1.0488095
Reward 20.10819857184743
Current State [[0.11  0.15  0.26  0.157 0.146 0.9   0.035 0.001 0.46  0.14 ]]
Logits tf.Tensor([[-0.15624918 -0.50960934  0.9573178 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.21063605 0.1479348  0.6414292 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.09, 0.15, 0.26, 0.194, 0.146, 0.9, 0.035, 0.001, 0.45999999999999996, 0.14]
0.8996536666666665
1.0488095
Reward 20.10819857184743
Episode: 161 | Average Reward: 300 | Episode Reward: 355 | Loss: 984.075 | Steps: 19 | Worker: 0
Current State [[-0.00201939  0.00421578  0.00675506  0.00610566 -0.0073415   0.00992953
  -0.00301759  0.002174   -0.00229792 -0.00142934]]
Logits tf.Tensor([[-0.04161429 -0.07095426  0.12111676]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.31768158 0.30849618 0.37382227]], shape=(1, 3), dtype=float32)
Selected action 1
[0.06, 0.08, 0.26, 0.153, 0.146, 0.94, 0.024, 0.003, 0.42400000000000004, 0.07]
0.9439709999999999
2.9458334999999995
Reward 11.080066735275583
Current State [[0.06  0.08  0.26  0.153 0.146 0.94  0.024 0.003 0.424 0.07 ]]
Logits tf.Tensor([[-0.1388604  -0.48085973  0.93367416]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.21583696 0.15331951 0.6308435 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.15, 0.23, 0.153, 0.146, 0.96, 0.044, 0.001, 0.479, 0.14]
0.9634918333333332
0.7315474999999999
Reward 23.726197976116318
Current State [[0.08  0.15  0.23  0.153 0.146 0.96  0.044 0.001 0.479 0.14 ]]
Logits tf.Tensor([[-0.16353315 -0.5367761   1.0013677 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.20432755 0.14067909 0.6549934 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.16, 0.15, 0.27, 0.164, 0.146, 0.96, 0.044, 0.001, 0.479, 0.14]
0.9634918333333332
0.7315474999999999
Reward 23.726197976116318
Current State [[0.16  0.15  0.27  0.164 0.146 0.96  0.044 0.001 0.479 0.14 ]]
Logits tf.Tensor([[-0.17603819 -0.5586106   1.0180863 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.20069154 0.1368926  0.66241586]], shape=(1, 3), dtype=float32)
Selected action 2
[0.1, 0.15, 0.25, 0.164, 0.146, 0.92, 0.031, 0.001, 0.45099999999999996, 0.09]
0.9162601666666667
1.318452666666667
Reward 19.06187897823179
Current State [[0.1   0.15  0.25  0.164 0.146 0.92  0.031 0.001 0.451 0.09 ]]
Logits tf.Tensor([[-0.15581985 -0.5133411   0.9744137 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.20851634 0.14583796 0.6456457 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.12, 0.15, 0.24, 0.165, 0.146, 0.9, 0.027, 0.003, 0.422, 0.11]
0.9001854999999999
3.4416670000000003
Reward 16.817542689169468
Current State [[0.12  0.15  0.24  0.165 0.146 0.9   0.027 0.003 0.422 0.11 ]]
Logits tf.Tensor([[-0.15327771 -0.5117444   0.9490317 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.21232057 0.14835836 0.6393211 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.14, 0.15, 0.26, 0.125, 0.146, 0.93, 0.039, 0.001, 0.461, 0.08]
0.932933
0.5916663333333333
Reward 26.215204730171486
Current State [[0.14  0.15  0.26  0.125 0.146 0.93  0.039 0.001 0.461 0.08 ]]
Logits tf.Tensor([[-0.16866091 -0.5333985   0.9859785 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.20545448 0.14266326 0.65188223]], shape=(1, 3), dtype=float32)
Selected action 2
[0.14, 0.15, 0.27, 0.135, 0.146, 0.96, 0.043, 0.001, 0.471, 0.13]
0.9574998333333332
1.0625000000000002
Reward 20.407304257451855
Current State [[0.14  0.15  0.27  0.135 0.146 0.96  0.043 0.001 0.471 0.13 ]]
Logits tf.Tensor([[-0.17276172 -0.5528311   1.0095708 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.20219225 0.13826187 0.65954584]], shape=(1, 3), dtype=float32)
Selected action 2
[0.17, 0.15, 0.28, 0.156, 0.146, 0.96, 0.043, 0.001, 0.471, 0.13]
0.9574998333333332
1.0625000000000002
Reward 20.407304257451855
Current State [[0.17  0.15  0.28  0.156 0.146 0.96  0.043 0.001 0.471 0.13 ]]
Logits tf.Tensor([[-0.17673802 -0.55901545  1.0159057 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.20088032 0.13706179 0.6620579 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.15, 0.15, 0.27, 0.185, 0.146, 0.82, 0.049, 0.007, 0.45499999999999996, 0.18]
0.8229875000000001
6.890476333333333
Reward 16.233351637992808
Current State [[0.15  0.15  0.27  0.185 0.146 0.82  0.049 0.007 0.455 0.18 ]]
Logits tf.Tensor([[-0.16491142 -0.52317035  0.9503275 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.21056227 0.14716029 0.6422774 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.15, 0.25, 0.177, 0.146, 0.69, 0.017, 0.002, 0.697, 0.07]
0.6923823333333333
1.6095238333333333
Reward 17.603239295287967
Current State [[0.08  0.15  0.25  0.177 0.146 0.69  0.017 0.002 0.697 0.07 ]]
Logits tf.Tensor([[-0.16163892 -0.4880225   0.99484956]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.20407   0.1472423 0.6486877]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.15, 0.25, 0.132, 0.146, 0.85, 0.033, 0.002, 0.6910000000000001, 0.16]
0.8539829999999999
1.6071431666666665
Reward 18.12679011968185
Current State [[0.07  0.15  0.25  0.132 0.146 0.85  0.033 0.002 0.691 0.16 ]]
Logits tf.Tensor([[-0.17764178 -0.5481223   1.0637425 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.19414449 0.13403784 0.67181766]], shape=(1, 3), dtype=float32)
Selected action 1
[0.05, 0.08, 0.3, 0.145, 0.146, 0.91, 0.036, 0.002, 0.622, 0.13]
0.9138621666666666
1.6107143333333334
Reward 12.322957966945648
Current State [[0.05  0.08  0.3   0.145 0.146 0.91  0.036 0.002 0.622 0.13 ]]
Logits tf.Tensor([[-0.16516435 -0.5211008   1.0396447 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.1985451  0.13908425 0.6623707 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.19, 0.15, 0.27, 0.204, 0.146, 0.91, 0.036, 0.002, 0.622, 0.13]
0.9138621666666666
1.6107143333333334
Reward 18.322957966945648
Current State [[0.19  0.15  0.27  0.204 0.146 0.91  0.036 0.002 0.622 0.13 ]]
Logits tf.Tensor([[-0.18610066 -0.574971    1.0753709 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.19199625 0.13013929 0.6778645 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.12, 0.15, 0.27, 0.208, 0.146, 0.9, 0.044, 0.001, 0.648, 0.18]
0.8985868333333333
1.1815476666666669
Reward 19.468929389271082
Current State [[0.12  0.15  0.27  0.208 0.146 0.9   0.044 0.001 0.648 0.18 ]]
Logits tf.Tensor([[-0.18405074 -0.5694449   1.0841136 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.19104004 0.1299421  0.6790179 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.09, 0.15, 0.25, 0.179, 0.146, 0.88, 0.038, 0.004, 0.678, 0.16]
0.8849761666666667
3.847023833333333
Reward 16.682087860373798
Current State [[0.09  0.15  0.25  0.179 0.146 0.88  0.038 0.004 0.678 0.16 ]]
Logits tf.Tensor([[-0.17998418 -0.5578944   1.0778415 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.19219472 0.13170949 0.6760957 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.15, 0.15, 0.26, 0.14, 0.146, 0.86, 0.038, 0.007, 0.504, 0.15]
0.8601698333333334
7.330952666666668
Reward 16.225204261261943
Current State [[0.15  0.15  0.26  0.14  0.146 0.86  0.038 0.007 0.504 0.15 ]]
Logits tf.Tensor([[-0.16920538 -0.5380301   0.98323494]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2058691  0.14236808 0.65176284]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.26, 0.113, 0.146, 0.85, 0.028, 0.005, 0.658, 0.06]
0.8465178333333333
5.0476186666666685
Reward 4.424174910858744
Current State [[0.04  0.04  0.26  0.113 0.146 0.85  0.028 0.005 0.658 0.06 ]]
Logits tf.Tensor([[-0.15946329 -0.4855492   0.9967162 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.20410194 0.14730918 0.6485889 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.19, 0.15, 0.28, 0.168, 0.146, 0.85, 0.028, 0.005, 0.658, 0.06]
0.8465178333333333
5.0476186666666685
Reward 16.424174910858746
Current State [[0.19  0.15  0.28  0.168 0.146 0.85  0.028 0.005 0.658 0.06 ]]
Logits tf.Tensor([[-0.18307376 -0.55480826  1.0599023 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.19396947 0.13374919 0.6722813 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.19, 0.15, 0.3, 0.19, 0.146, 0.88, 0.079, 0.007, 0.371, 0.23]
0.8750415
7.4809525
Reward 16.223793702764873
Current State [[0.19  0.15  0.3   0.19  0.146 0.88  0.079 0.007 0.371 0.23 ]]
Logits tf.Tensor([[-0.1741122  -0.55294263  0.9482174 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.21023136 0.14393736 0.6458313 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.11, 0.15, 0.29, 0.147, 0.146, 0.91, 0.058, 0.003, 0.40599999999999997, 0.19]
0.9089345000000001
2.7642855
Reward 17.118397981621904
Episode: 162 | Average Reward: 301 | Episode Reward: 350 | Loss: 854.007 | Steps: 19 | Worker: 0
Current State [[-0.00904983 -0.00762385 -0.0070489  -0.00960306  0.00323778  0.004101
  -0.00713121 -0.00924366 -0.00264243  0.00112039]]
Logits tf.Tensor([[-0.04170205 -0.06517291  0.11672436]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3176148  0.31024688 0.37213835]], shape=(1, 3), dtype=float32)
Selected action 1
[0.09, 0.08, 0.33, 0.138, 0.146, 0.93, 0.07, 0.001, 0.38, 0.16]
0.9289908333333333
0.9613103333333333
Reward 14.873230819652122
Current State [[0.09  0.08  0.33  0.138 0.146 0.93  0.07  0.001 0.38  0.16 ]]
Logits tf.Tensor([[-0.16474    -0.52379197  0.96374005]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2087991  0.14581235 0.64538854]], shape=(1, 3), dtype=float32)
Selected action 1
[0.06, 0.08, 0.31, 0.149, 0.146, 0.93, 0.07, 0.001, 0.38, 0.16]
0.9289908333333333
0.9613103333333333
Reward 14.873230819652122
Current State [[0.06  0.08  0.31  0.149 0.146 0.93  0.07  0.001 0.38  0.16 ]]
Logits tf.Tensor([[-0.15936378 -0.5136415   0.95713294]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.21026887 0.14754146 0.6421897 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.11, 0.15, 0.27, 0.194, 0.146, 0.9, 0.066, 0.001, 0.417, 0.17]
0.8990085
1.2767854999999997
Reward 19.11765835227032
Current State [[0.11  0.15  0.27  0.194 0.146 0.9   0.066 0.001 0.417 0.17 ]]
Logits tf.Tensor([[-0.17278066 -0.5408609   0.9908155 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.20435326 0.14142504 0.65422165]], shape=(1, 3), dtype=float32)
Selected action 2
[0.14, 0.15, 0.26, 0.167, 0.146, 0.85, 0.051, 0.005, 0.42800000000000005, 0.21]
0.8458850000000001
5.3970234999999995
Reward 16.380116909384533
Current State [[0.14  0.15  0.26  0.167 0.146 0.85  0.051 0.005 0.428 0.21 ]]
Logits tf.Tensor([[-0.17030084 -0.5466641   0.96918356]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.207835   0.14264816 0.6495169 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.16, 0.15, 0.31, 0.146, 0.146, 0.96, 0.055, 0.0, 0.414, 0.11]
0.9570678333333333
0.37321466666666664
Reward 37.804592819749004
Current State [[0.16  0.15  0.31  0.146 0.146 0.96  0.055 0.    0.414 0.11 ]]
Logits tf.Tensor([[-0.18129557 -0.562573    1.0192819 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.19979927 0.1364606  0.66374016]], shape=(1, 3), dtype=float32)
Selected action 2
[0.19, 0.15, 0.28, 0.177, 0.146, 0.96, 0.055, 0.0, 0.414, 0.11]
0.9570678333333333
0.37321466666666664
Reward 37.804592819749004
Current State [[0.19  0.15  0.28  0.177 0.146 0.96  0.055 0.    0.414 0.11 ]]
Logits tf.Tensor([[-0.18538097 -0.56687945  1.0149086 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.1998435  0.13646062 0.66369593]], shape=(1, 3), dtype=float32)
Selected action 2
[0.09, 0.15, 0.25, 0.15, 0.146, 0.97, 0.056, 0.002, 0.40099999999999997, 0.18]
0.9735975000000001
1.7023806666666668
Reward 18.348071050319916
Current State [[0.09  0.15  0.25  0.15  0.146 0.97  0.056 0.002 0.401 0.18 ]]
Logits tf.Tensor([[-0.16948968 -0.5559975   0.99774075]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2043942  0.13887061 0.6567352 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.16, 0.15, 0.27, 0.152, 0.146, 0.96, 0.078, 0.0, 0.361, 0.1]
0.9631044999999999
0.0029759999999999995
Reward 62.0
Current State [[0.16  0.15  0.27  0.152 0.146 0.96  0.078 0.    0.361 0.1  ]]
Logits tf.Tensor([[-0.18527794 -0.5545624   0.9829392 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.20377046 0.14085202 0.6553775 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.15, 0.15, 0.3, 0.165, 0.146, 0.99, 0.047, 0.0, 0.368, 0.14]
0.9940458333333333
0.2511893333333334
Reward 52.55640408306764
Current State [[0.15  0.15  0.3   0.165 0.146 0.99  0.047 0.    0.368 0.14 ]]
Logits tf.Tensor([[-0.17358357 -0.5618066   1.0043525 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.20300755 0.13769211 0.6593003 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.08, 0.08, 0.34, 0.134, 0.146, 0.96, 0.064, 0.002, 0.41, 0.21]
0.9582425000000002
2.0083336666666667
Reward 11.841143709033464
Current State [[0.08  0.08  0.34  0.134 0.146 0.96  0.064 0.002 0.41  0.21 ]]
Logits tf.Tensor([[-0.16625899 -0.54382604  0.9944166 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.20501818 0.14054555 0.65443623]], shape=(1, 3), dtype=float32)
Selected action 2
[0.16, 0.15, 0.28, 0.2, 0.146, 0.96, 0.064, 0.002, 0.41, 0.21]
0.9582425000000002
2.0083336666666667
Reward 17.841143709033464
Current State [[0.16  0.15  0.28  0.2   0.146 0.96  0.064 0.002 0.41  0.21 ]]
Logits tf.Tensor([[-0.18178073 -0.57772857  1.0184057 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2002492  0.13477609 0.6649747 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.1, 0.15, 0.26, 0.174, 0.146, 1.0, 0.04, 0.001, 0.41, 0.12]
1.0043728333333335
0.5077383333333334
Reward 30.620762759550665
Current State [[0.1   0.15  0.26  0.174 0.146 1.    0.04  0.001 0.41  0.12 ]]
Logits tf.Tensor([[-0.16630638 -0.55098724  1.0146099 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2025101 0.1378421 0.6596478]], shape=(1, 3), dtype=float32)
Selected action 2
[0.12, 0.15, 0.27, 0.157, 0.146, 0.97, 0.041, 0.002, 0.40099999999999997, 0.08]
0.9703553333333335
1.8791668333333333
Reward 18.046648630824695
Current State [[0.12  0.15  0.27  0.157 0.146 0.97  0.041 0.002 0.401 0.08 ]]
Logits tf.Tensor([[-0.1674127  -0.54127604  0.99838245]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.20422569 0.14052175 0.6552526 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.19, 0.15, 0.32, 0.163, 0.146, 0.97, 0.054, 0.001, 0.43499999999999994, 0.14]
0.9730955
0.7226196666666667
Reward 23.993630413257335
Current State [[0.19  0.15  0.32  0.163 0.146 0.97  0.054 0.001 0.435 0.14 ]]
Logits tf.Tensor([[-0.18813583 -0.5822724   1.0410914 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.19635375 0.13239387 0.67125237]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.04, 0.39, 0.14, 0.146, 0.94, 0.048, 0.002, 0.45499999999999996, 0.18]
0.9367643333333331
1.6303569999999996
Reward 6.362898111465891
Current State [[0.05  0.04  0.39  0.14  0.146 0.94  0.048 0.002 0.455 0.18 ]]
Logits tf.Tensor([[-0.15506086 -0.5186272   1.0003533 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.20531641 0.14273447 0.6519491 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.11, 0.08, 0.3, 0.146, 0.146, 0.94, 0.048, 0.002, 0.45499999999999996, 0.18]
0.9367643333333331
1.6303569999999996
Reward 12.362898111465892
Current State [[0.11  0.08  0.3   0.146 0.146 0.94  0.048 0.002 0.455 0.18 ]]
Logits tf.Tensor([[-0.16745222 -0.5432748   0.9975098 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.20439342 0.1403619  0.65524465]], shape=(1, 3), dtype=float32)
Selected action 1
[0.08, 0.08, 0.34, 0.139, 0.146, 0.92, 0.044, 0.0, 0.476, 0.17]
0.9196013333333332
0.4827383333333333
Reward 23.774061804231497
Current State [[0.08  0.08  0.34  0.139 0.146 0.92  0.044 0.    0.476 0.17 ]]
Logits tf.Tensor([[-0.16327369 -0.5325172   1.007793  ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.20338894 0.14059405 0.65601707]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.15, 0.25, 0.156, 0.146, 0.93, 0.043, 0.001, 0.48600000000000004, 0.2]
0.9344576666666665
1.0089281666666667
Reward 20.583685556098274
Current State [[0.07  0.15  0.25  0.156 0.146 0.93  0.043 0.001 0.486 0.2  ]]
Logits tf.Tensor([[-0.16791183 -0.55460626  1.0251453 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2009467  0.13650282 0.6625505 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.15, 0.26, 0.202, 0.146, 0.93, 0.043, 0.001, 0.48600000000000004, 0.2]
0.9344576666666665
1.0089281666666667
Reward 20.583685556098274
Current State [[0.08  0.15  0.26  0.202 0.146 0.93  0.043 0.001 0.486 0.2  ]]
Logits tf.Tensor([[-0.16793713 -0.5532003   1.0321743 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.19996963 0.13603368 0.6639967 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.03, 0.04, 0.35, 0.149, 0.146, 0.9, 0.04, 0.001, 0.45099999999999996, 0.18]
0.8983393333333333
1.1452376666666668
Reward 7.6220230899798125
Episode: 163 | Average Reward: 303 | Episode Reward: 467 | Loss: 1630.29 | Steps: 19 | Worker: 0
Current State [[-0.00581523  0.00813786 -0.00178477 -0.00432827  0.0031417   0.0072001
   0.00993179 -0.00679923  0.0030131  -0.00495864]]
Logits tf.Tensor([[-0.05121765 -0.07599334  0.13784532]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3141053  0.30641875 0.37947598]], shape=(1, 3), dtype=float32)
Selected action 1
[0.08, 0.08, 0.29, 0.123, 0.146, 0.72, 0.036, 0.005, 0.607, 0.17]
0.7197158333333333
4.7309525
Reward 10.361757916584947
Current State [[0.08  0.08  0.29  0.123 0.146 0.72  0.036 0.005 0.607 0.17 ]]
Logits tf.Tensor([[-0.17058232 -0.5154896   0.9881259 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2043276 0.1447224 0.65095  ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.06, 0.04, 0.39, 0.154, 0.146, 0.72, 0.036, 0.005, 0.607, 0.17]
0.7197158333333333
4.7309525
Reward 4.361757916584947
Current State [[0.06  0.04  0.39  0.154 0.146 0.72  0.036 0.005 0.607 0.17 ]]
Logits tf.Tensor([[-0.16350283 -0.5006959   0.99700963]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2038595 0.145509  0.6506315]], shape=(1, 3), dtype=float32)
Selected action 1
[0.07, 0.08, 0.29, 0.155, 0.146, 0.88, 0.04, 0.001, 0.42800000000000005, 0.11]
0.8812479999999999
1.2863089999999997
Reward 13.002337180799392
Current State [[0.07  0.08  0.29  0.155 0.146 0.88  0.04  0.001 0.428 0.11 ]]
Logits tf.Tensor([[-0.1597263 -0.5039786  0.9717001]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.207951   0.14738528 0.6446637 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.35, 0.145, 0.146, 0.94, 0.028, 0.001, 0.429, 0.09]
0.9377266666666667
1.0083333333333333
Reward 8.610654644913081
Current State [[0.04  0.04  0.35  0.145 0.146 0.94  0.028 0.001 0.429 0.09 ]]
Logits tf.Tensor([[-0.15037695 -0.49725154  0.99044544]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.20677243 0.14616619 0.6470614 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.11, 0.08, 0.34, 0.134, 0.146, 0.76, 0.022, 0.003, 0.5780000000000001, 0.11]
0.763692
3.202381000000001
Reward 10.718003974854533
Current State [[0.11  0.08  0.34  0.134 0.146 0.76  0.022 0.003 0.578 0.11 ]]
Logits tf.Tensor([[-0.17067993 -0.5115239   1.0032219 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.20219345 0.1437939  0.6540126 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.25, 0.15, 0.28, 0.183, 0.146, 0.76, 0.022, 0.003, 0.5780000000000001, 0.11]
0.763692
3.202381000000001
Reward 16.718003974854533
Current State [[0.25  0.15  0.28  0.183 0.146 0.76  0.022 0.003 0.578 0.11 ]]
Logits tf.Tensor([[-0.18971299 -0.5707099   1.033209  ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.19683956 0.13447686 0.6686836 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.15, 0.15, 0.26, 0.147, 0.146, 0.74, 0.018, 0.004, 0.852, 0.13]
0.7401405000000002
3.8505949999999998
Reward 16.52401125707761
Current State [[0.15  0.15  0.26  0.147 0.146 0.74  0.018 0.004 0.852 0.13 ]]
Logits tf.Tensor([[-0.19977443 -0.59541523  1.1462784 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.18130796 0.12206531 0.6966268 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.02, 0.04, 0.3, 0.146, 0.146, 0.69, 0.018, 0.002, 0.657, 0.12]
0.6871241666666666
2.4059525000000006
Reward 4.923210568468078
Current State [[0.02  0.04  0.3   0.146 0.146 0.69  0.018 0.002 0.657 0.12 ]]
Logits tf.Tensor([[-0.16051371 -0.47124144  0.98138165]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2055239  0.15063123 0.64384484]], shape=(1, 3), dtype=float32)
Selected action 2
[0.14, 0.15, 0.27, 0.143, 0.146, 0.84, 0.037, 0.001, 0.46399999999999997, 0.06]
0.8432748333333334
1.291667333333333
Reward 18.8104380525694
Current State [[0.14  0.15  0.27  0.143 0.146 0.84  0.037 0.001 0.464 0.06 ]]
Logits tf.Tensor([[-0.17760359 -0.5270248   0.99830264]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.20217644 0.1425538  0.65526974]], shape=(1, 3), dtype=float32)
Selected action 2
[0.1, 0.15, 0.25, 0.18, 0.146, 0.84, 0.037, 0.001, 0.46399999999999997, 0.06]
0.8432748333333334
1.291667333333333
Reward 18.8104380525694
Current State [[0.1   0.15  0.25  0.18  0.146 0.84  0.037 0.001 0.464 0.06 ]]
Logits tf.Tensor([[-0.16984743 -0.51208526  0.99460495]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.20348583 0.14451142 0.65200275]], shape=(1, 3), dtype=float32)
Selected action 2
[0.17, 0.15, 0.28, 0.165, 0.146, 0.94, 0.041, 0.001, 0.46799999999999997, 0.11]
0.9443538333333336
0.5440475
Reward 27.886678757168642
Current State [[0.17  0.15  0.28  0.165 0.146 0.94  0.041 0.001 0.468 0.11 ]]
Logits tf.Tensor([[-0.19063403 -0.5753899   1.0539433 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.19409621 0.13210513 0.6737987 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.1, 0.15, 0.26, 0.126, 0.146, 0.95, 0.033, 0.001, 0.458, 0.09]
0.9540211666666667
0.8184526666666668
Reward 22.42195423271479
Current State [[0.1   0.15  0.26  0.126 0.146 0.95  0.033 0.001 0.458 0.09 ]]
Logits tf.Tensor([[-0.17658341 -0.5540316   1.0360543 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.1981002  0.13581921 0.6660806 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.14, 0.15, 0.26, 0.149, 0.146, 0.89, 0.035, 0.001, 0.429, 0.13]
0.893993
0.8910711666666666
Reward 21.145754310891835
Current State [[0.14  0.15  0.26  0.149 0.146 0.89  0.035 0.001 0.429 0.13 ]]
Logits tf.Tensor([[-0.17718592 -0.54993904  1.0022497 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2023729  0.1394016  0.65822554]], shape=(1, 3), dtype=float32)
Selected action 2
[0.16, 0.15, 0.27, 0.153, 0.146, 0.88, 0.024, 0.001, 0.483, 0.1]
0.8799855
1.2357146666666667
Reward 19.166683512601566
Current State [[0.16  0.15  0.27  0.153 0.146 0.88  0.024 0.001 0.483 0.1  ]]
Logits tf.Tensor([[-0.1811457  -0.55437666  1.0278264 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.19847    0.1366478  0.66488224]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.32, 0.15, 0.146, 0.88, 0.024, 0.001, 0.483, 0.1]
0.8799855
1.2357146666666667
Reward 7.1666835126015656
Current State [[0.04  0.04  0.32  0.15  0.146 0.88  0.024 0.001 0.483 0.1  ]]
Logits tf.Tensor([[-0.15309946 -0.4918622   0.98559344]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.20681088 0.14738409 0.645805  ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.1, 0.15, 0.25, 0.162, 0.146, 0.9, 0.032, 0.001, 0.5509999999999999, 0.1]
0.8976404999999998
1.0690476666666666
Reward 19.985842770822074
Current State [[0.1   0.15  0.25  0.162 0.146 0.9   0.032 0.001 0.551 0.1  ]]
Logits tf.Tensor([[-0.18251471 -0.5537543   1.0654689 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.19330432 0.1333565  0.6733392 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.07, 0.08, 0.29, 0.131, 0.146, 0.8, 0.03, 0.001, 0.484, 0.1]
0.7975866666666666
0.7672619999999999
Reward 15.419720707719415
Current State [[0.07  0.08  0.29  0.131 0.146 0.8   0.03  0.001 0.484 0.1  ]]
Logits tf.Tensor([[-0.15914327 -0.4893148   0.9608203 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.20905006 0.15026529 0.64068466]], shape=(1, 3), dtype=float32)
Selected action 1
[0.09, 0.08, 0.27, 0.163, 0.146, 0.8, 0.03, 0.001, 0.484, 0.1]
0.7975866666666666
0.7672619999999999
Reward 15.419720707719415
Current State [[0.09  0.08  0.27  0.163 0.146 0.8   0.03  0.001 0.484 0.1  ]]
Logits tf.Tensor([[-0.16196214 -0.4933859   0.9611669 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.20866546 0.1498011  0.64153343]], shape=(1, 3), dtype=float32)
Selected action 2
[0.14, 0.15, 0.26, 0.169, 0.146, 0.76, 0.023, 0.001, 0.541, 0.1]
0.7632245
1.2226193333333335
Reward 18.643910666052896
Current State [[0.14  0.15  0.26  0.169 0.146 0.76  0.023 0.001 0.541 0.1  ]]
Logits tf.Tensor([[-0.17618993 -0.5245909   1.000855  ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.20199624 0.14257213 0.6554316 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.09, 0.15, 0.24, 0.163, 0.146, 0.96, 0.038, 0.001, 0.426, 0.08]
0.9623826666666666
0.8130943333333333
Reward 22.570936360210744
Episode: 164 | Average Reward: 303 | Episode Reward: 312 | Loss: 871.701 | Steps: 19 | Worker: 0
Current State [[-0.00738993 -0.00176897  0.00413525 -0.00401025  0.00124094 -0.0082731
  -0.00721212  0.00632614 -0.00856682 -0.00985212]]
Logits tf.Tensor([[-0.04376812 -0.06453435  0.11250097]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.31760263 0.3110752  0.37132215]], shape=(1, 3), dtype=float32)
Selected action 1
[0.07, 0.08, 0.28, 0.12, 0.146, 0.71, 0.014, 0.002, 0.37, 0.03]
0.7092305000000002
1.5720239999999996
Reward 11.708469888170487
Current State [[0.07  0.08  0.28  0.12  0.146 0.71  0.014 0.002 0.37  0.03 ]]
Logits tf.Tensor([[-0.14051495 -0.43146807  0.86496234]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.2231763  0.16683562 0.60998803]], shape=(1, 3), dtype=float32)
Selected action 0
[0.06, 0.04, 0.3, 0.143, 0.146, 0.89, 0.032, 0.002, 0.434, 0.08]
0.8905716666666665
1.5000001666666667
Reward 6.469935930346554
Current State [[0.06  0.04  0.3   0.143 0.146 0.89  0.032 0.002 0.434 0.08 ]]
Logits tf.Tensor([[-0.16051883 -0.49492043  0.9755693 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.20702532 0.14818174 0.644793  ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.13, 0.15, 0.25, 0.173, 0.146, 0.89, 0.032, 0.002, 0.434, 0.08]
0.8905716666666665
1.5000001666666667
Reward 18.469935930346555
Current State [[0.13  0.15  0.25  0.173 0.146 0.89  0.032 0.002 0.434 0.08 ]]
Logits tf.Tensor([[-0.18096927 -0.5417663   1.0185591 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.1993751  0.13898845 0.6616365 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.18, 0.15, 0.27, 0.188, 0.146, 0.99, 0.036, 0.001, 0.393, 0.09]
0.9895821666666667
0.7446428333333333
Reward 23.833129670495325
Current State [[0.18  0.15  0.27  0.188 0.146 0.99  0.036 0.001 0.393 0.09 ]]
Logits tf.Tensor([[-0.19392188 -0.5785535   1.0497345 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.19421348 0.13220137 0.6735851 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.29, 0.13, 0.146, 0.93, 0.026, 0.005, 0.378, 0.07]
0.9287353333333335
4.749405166666667
Reward 4.537744772048106
Current State [[0.04  0.04  0.29  0.13  0.146 0.93  0.026 0.005 0.378 0.07 ]]
Logits tf.Tensor([[-0.15111083 -0.48922205  0.9525868 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.21148755 0.15081514 0.63769734]], shape=(1, 3), dtype=float32)
Selected action 2
[0.12, 0.15, 0.26, 0.146, 0.146, 0.95, 0.032, 0.002, 0.46799999999999997, 0.02]
0.9451444999999998
1.710715166666667
Reward 18.241228851424143
Current State [[0.12  0.15  0.26  0.146 0.146 0.95  0.032 0.002 0.468 0.02 ]]
Logits tf.Tensor([[-0.18705095 -0.55244684  1.0579337 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.19354329 0.1343039  0.6721528 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.09, 0.08, 0.35, 0.168, 0.146, 0.95, 0.032, 0.002, 0.46799999999999997, 0.02]
0.9451444999999998
1.710715166666667
Reward 12.241228851424143
Current State [[0.09  0.08  0.35  0.168 0.146 0.95  0.032 0.002 0.468 0.02 ]]
Logits tf.Tensor([[-0.17477429 -0.523408    1.0532898 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.19530244 0.13781546 0.66688216]], shape=(1, 3), dtype=float32)
Selected action 2
[0.17, 0.15, 0.28, 0.21, 0.146, 0.83, 0.027, 0.002, 0.47800000000000004, 0.07]
0.8307255000000001
2.4327375000000004
Reward 17.176876175318057
Current State [[0.17  0.15  0.28  0.21  0.146 0.83  0.027 0.002 0.478 0.07 ]]
Logits tf.Tensor([[-0.1862503 -0.5394982  1.0286304]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.19714941 0.13847834 0.6643722 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.11, 0.15, 0.26, 0.176, 0.146, 0.84, 0.03, 0.004, 0.46399999999999997, 0.09]
0.8391068333333335
4.0083329999999995
Reward 16.594975276127194
Current State [[0.11  0.15  0.26  0.176 0.146 0.84  0.03  0.004 0.464 0.09 ]]
Logits tf.Tensor([[-0.17675762 -0.52905315  1.0133473 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.20038079 0.1408822  0.658737  ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.15, 0.24, 0.147, 0.146, 0.96, 0.045, 0.001, 0.567, 0.18]
0.9577101666666668
1.2125
Reward 19.657304195174387
Current State [[0.08  0.15  0.24  0.147 0.146 0.96  0.045 0.001 0.567 0.18 ]]
Logits tf.Tensor([[-0.19913195 -0.59687096  1.1196508 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.18481879 0.12416819 0.69101304]], shape=(1, 3), dtype=float32)
Selected action 2
[0.18, 0.15, 0.27, 0.184, 0.146, 0.96, 0.045, 0.001, 0.567, 0.18]
0.9577101666666668
1.2125
Reward 19.657304195174387
Current State [[0.18  0.15  0.27  0.184 0.146 0.96  0.045 0.001 0.567 0.18 ]]
Logits tf.Tensor([[-0.21533604 -0.62400985  1.1377684 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.18070272 0.12008257 0.6992147 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.12, 0.15, 0.25, 0.176, 0.146, 0.76, 0.017, 0.002, 0.528, 0.05]
0.7609891666666666
1.7857150000000004
Reward 17.583246871867466
Current State [[0.12  0.15  0.25  0.176 0.146 0.76  0.017 0.002 0.528 0.05 ]]
Logits tf.Tensor([[-0.17726317 -0.5103932   1.0036836 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.20104003 0.14408077 0.65487915]], shape=(1, 3), dtype=float32)
Selected action 0
[0.06, 0.04, 0.44, 0.151, 0.146, 0.8, 0.043, 0.022, 0.544, 0.15]
0.7984898333333333
21.507143000000003
Reward 3.925111689599407
Current State [[0.06  0.04  0.44  0.151 0.146 0.8   0.043 0.022 0.544 0.15 ]]
Logits tf.Tensor([[-0.16793075 -0.5153431   1.0276886 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.19951643 0.14096114 0.6595224 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.07, 0.08, 0.37, 0.164, 0.146, 0.79, 0.033, 0.002, 0.783, 0.12]
0.7947221666666666
1.7452381666666665
Reward 11.729785609317467
Current State [[0.07  0.08  0.37  0.164 0.146 0.79  0.033 0.002 0.783 0.12 ]]
Logits tf.Tensor([[-0.20386757 -0.56177425  1.1484479 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.17967819 0.12561992 0.69470197]], shape=(1, 3), dtype=float32)
Selected action 2
[0.13, 0.15, 0.26, 0.168, 0.146, 0.79, 0.033, 0.002, 0.783, 0.12]
0.7947221666666666
1.7452381666666665
Reward 17.729785609317467
Current State [[0.13  0.15  0.26  0.168 0.146 0.79  0.033 0.002 0.783 0.12 ]]
Logits tf.Tensor([[-0.21127279 -0.59790546  1.1568295 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.17834117 0.1211544  0.7005044 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.11, 0.15, 0.27, 0.179, 0.146, 0.77, 0.029, 0.002, 0.8109999999999999, 0.17]
0.7713018333333334
1.8434518333333334
Reward 17.54490968815546
Current State [[0.11  0.15  0.27  0.179 0.146 0.77  0.029 0.002 0.811 0.17 ]]
Logits tf.Tensor([[-0.20913537 -0.60408664  1.1641254 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.17787527 0.11983686 0.70228785]], shape=(1, 3), dtype=float32)
Selected action 2
[0.1, 0.15, 0.23, 0.141, 0.146, 0.99, 0.041, 0.001, 0.724, 0.2]
0.9899173333333332
0.8755951666666666
Reward 22.13555807370374
Current State [[0.1   0.15  0.23  0.141 0.146 0.99  0.041 0.001 0.724 0.2  ]]
Logits tf.Tensor([[-0.22204086 -0.6445178   1.2143266 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.17062478 0.11183113 0.7175441 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.42, 0.148, 0.146, 0.92, 0.046, 0.001, 0.43, 0.01]
0.9211268333333335
0.9958336666666666
Reward 8.575100748824113
Current State [[0.04  0.04  0.42  0.148 0.146 0.92  0.046 0.001 0.43  0.01 ]]
Logits tf.Tensor([[-0.16341601 -0.48526353  1.0166934 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.20082182 0.1455574  0.6536208 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.15, 0.15, 0.31, 0.187, 0.146, 0.92, 0.046, 0.001, 0.43, 0.01]
0.9211268333333335
0.9958336666666666
Reward 20.575100748824113
Current State [[0.15  0.15  0.31  0.187 0.146 0.92  0.046 0.001 0.43  0.01 ]]
Logits tf.Tensor([[-0.19002725 -0.5433099   1.0487198 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.19403668 0.13628721 0.6696761 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.13, 0.15, 0.26, 0.158, 0.146, 0.83, 0.045, 0.002, 0.5269999999999999, 0.19]
0.8250306666666668
2.0023805
Reward 17.513554269161382
Episode: 165 | Average Reward: 303 | Episode Reward: 305 | Loss: 734.587 | Steps: 19 | Worker: 0
Current State [[ 0.00244163 -0.00385384  0.00475519  0.00515781 -0.00747196 -0.00971569
  -0.00051678 -0.00699663  0.00439656  0.00494548]]
Logits tf.Tensor([[-0.05053072 -0.07306297  0.12796728]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.31514522 0.3081237  0.37673107]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.43, 0.144, 0.146, 0.95, 0.068, 0.001, 0.387, 0.19]
0.9462653333333332
0.7785713333333334
Reward 10.838299036997363
Current State [[0.04  0.04  0.43  0.144 0.146 0.95  0.068 0.001 0.387 0.19 ]]
Logits tf.Tensor([[-0.18162754 -0.53781664  1.0410929 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.19620326 0.13740903 0.6663877 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.13, 0.15, 0.28, 0.132, 0.146, 0.88, 0.064, 0.002, 0.417, 0.16]
0.8752756666666667
1.6291666666666667
Reward 18.158506599407815
Current State [[0.13  0.15  0.28  0.132 0.146 0.88  0.064 0.002 0.417 0.16 ]]
Logits tf.Tensor([[-0.20162292 -0.5729723   1.035522  ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.19472057 0.13431881 0.6709606 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.15, 0.15, 0.27, 0.151, 0.146, 0.98, 0.053, 0.0, 0.4, 0.11]
0.9750736666666666
0.4529756666666666
Reward 32.70060584427173
Current State [[0.15  0.15  0.27  0.151 0.146 0.98  0.053 0.    0.4   0.11 ]]
Logits tf.Tensor([[-0.20423858 -0.5886221   1.0655373 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.19080602 0.12991413 0.6792798 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.1, 0.08, 0.34, 0.159, 0.146, 0.98, 0.053, 0.0, 0.4, 0.11]
0.9750736666666666
0.4529756666666666
Reward 26.700605844271728
Current State [[0.1   0.08  0.34  0.159 0.146 0.98  0.053 0.    0.4   0.11 ]]
Logits tf.Tensor([[-0.18927214 -0.55503684  1.0520049 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.19403552 0.13459584 0.6713686 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.05, 0.08, 0.33, 0.149, 0.146, 0.98, 0.053, 0.0, 0.40700000000000003, 0.08]
0.9761854999999999
0.3755948333333334
Reward 32.236972583545864
Current State [[0.05  0.08  0.33  0.149 0.146 0.98  0.053 0.    0.407 0.08 ]]
Logits tf.Tensor([[-0.181499   -0.53630424  1.0463176 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.19550043 0.13710642 0.6673931 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.15, 0.15, 0.27, 0.123, 0.146, 0.88, 0.05, 0.001, 0.45999999999999996, 0.23]
0.8825041666666668
0.9904763333333333
Reward 20.33630297583337
Current State [[0.15  0.15  0.27  0.123 0.146 0.88  0.05  0.001 0.46  0.23 ]]
Logits tf.Tensor([[-0.20388032 -0.6002766   1.0556618 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.19243546 0.12945904 0.67810553]], shape=(1, 3), dtype=float32)
Selected action 1
[0.08, 0.08, 0.27, 0.12, 0.146, 0.85, 0.074, 0.015, 0.361, 0.11]
0.8526668333333334
15.480952000000002
Reward 9.99053602300234
Current State [[0.08  0.08  0.27  0.12  0.146 0.85  0.074 0.015 0.361 0.11 ]]
Logits tf.Tensor([[-0.17798728 -0.51363397  0.9485281 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.20834358 0.14893977 0.64271665]], shape=(1, 3), dtype=float32)
Selected action 2
[0.09, 0.15, 0.27, 0.18, 0.146, 0.85, 0.074, 0.015, 0.361, 0.11]
0.8526668333333334
15.480952000000002
Reward 15.99053602300234
Current State [[0.09  0.15  0.27  0.18  0.146 0.85  0.074 0.015 0.361 0.11 ]]
Logits tf.Tensor([[-0.18371591 -0.5302295   0.9880133 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.20264581 0.14330083 0.65405333]], shape=(1, 3), dtype=float32)
Selected action 2
[0.16, 0.15, 0.27, 0.179, 0.146, 0.96, 0.041, 0.0, 0.371, 0.07]
0.9629518333333333
0.24761933333333336
Reward 52.020345207400666
Current State [[0.16  0.15  0.27  0.179 0.146 0.96  0.041 0.    0.371 0.07 ]]
Logits tf.Tensor([[-0.19574793 -0.566061    1.0397983 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.19490232 0.13458358 0.6705141 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.11, 0.15, 0.25, 0.153, 0.146, 0.94, 0.065, 0.003, 0.413, 0.21]
0.9396953333333332
3.4869051666666664
Reward 16.852208751707824
Current State [[0.11  0.15  0.25  0.153 0.146 0.94  0.065 0.003 0.413 0.21 ]]
Logits tf.Tensor([[-0.20123385 -0.59059906  1.0542191 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.19279283 0.13061461 0.6765925 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.12, 0.15, 0.28, 0.142, 0.146, 0.98, 0.046, 0.002, 0.399, 0.14]
0.9812371666666666
1.899404833333333
Reward 18.04785607475725
Current State [[0.12  0.15  0.28  0.142 0.146 0.98  0.046 0.002 0.399 0.14 ]]
Logits tf.Tensor([[-0.19643071 -0.5856457   1.0648278 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.19203259 0.13011909 0.67784834]], shape=(1, 3), dtype=float32)
Selected action 2
[0.19, 0.15, 0.28, 0.141, 0.146, 0.95, 0.04, 0.002, 0.386, 0.1]
0.9452674999999999
2.464286333333334
Reward 17.37558711434124
Current State [[0.19  0.15  0.28  0.141 0.146 0.95  0.04  0.002 0.386 0.1  ]]
Logits tf.Tensor([[-0.20231989 -0.58551514  1.0462838 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.1935302  0.13192561 0.6745442 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.2, 0.15, 0.29, 0.181, 0.146, 0.95, 0.04, 0.002, 0.386, 0.1]
0.9452674999999999
2.464286333333334
Reward 17.37558711434124
Current State [[0.2   0.15  0.29  0.181 0.146 0.95  0.04  0.002 0.386 0.1  ]]
Logits tf.Tensor([[-0.20319666 -0.58425903  1.0539187 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.19236681 0.13141255 0.6762206 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.45, 0.162, 0.146, 0.91, 0.04, 0.002, 0.45099999999999996, 0.17]
0.9140248333333333
1.8910718333333334
Reward 5.8732238246690365
Current State [[0.04  0.04  0.45  0.162 0.146 0.91  0.04  0.002 0.451 0.17 ]]
Logits tf.Tensor([[-0.17423427 -0.527715    1.0562508 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.19511704 0.1370189  0.6678641 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.15, 0.15, 0.27, 0.139, 0.146, 0.85, 0.036, 0.002, 0.5820000000000001, 0.18]
0.8482396666666666
2.2107145
Reward 17.376105707992522
Current State [[0.15  0.15  0.27  0.139 0.146 0.85  0.036 0.002 0.582 0.18 ]]
Logits tf.Tensor([[-0.20916066 -0.5987932   1.1027535 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.18550879 0.12564616 0.6888451 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.09, 0.15, 0.28, 0.134, 0.146, 0.9, 0.051, 0.0, 0.413, 0.18]
0.9039506666666667
0.3226191666666667
Reward 40.745498485071394
Current State [[0.09  0.15  0.28  0.134 0.146 0.9   0.051 0.    0.413 0.18 ]]
Logits tf.Tensor([[-0.19152482 -0.56723046  1.0377618 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.19586356 0.13452    0.66961646]], shape=(1, 3), dtype=float32)
Selected action 2
[0.18, 0.15, 0.3, 0.17, 0.146, 0.9, 0.051, 0.0, 0.413, 0.18]
0.9039506666666667
0.3226191666666667
Reward 40.745498485071394
Current State [[0.18  0.15  0.3   0.17  0.146 0.9   0.051 0.    0.413 0.18 ]]
Logits tf.Tensor([[-0.20472428 -0.59127766  1.052944  ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.19243333 0.13073814 0.6768285 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.05, 0.08, 0.33, 0.167, 0.146, 1.0, 0.055, 0.001, 0.398, 0.12]
0.9998938333333333
0.5083331666666667
Reward 24.49093007593143
Current State [[0.05  0.08  0.33  0.167 0.146 1.    0.055 0.001 0.398 0.12 ]]
Logits tf.Tensor([[-0.1822156  -0.54741627  1.0541298 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.19466367 0.13510777 0.67022854]], shape=(1, 3), dtype=float32)
Selected action 2
[0.1, 0.15, 0.28, 0.16, 0.146, 0.92, 0.035, 0.001, 0.475, 0.12]
0.9192793333333333
1.0035711666666667
Reward 20.51154382918611
Current State [[0.1   0.15  0.28  0.16  0.146 0.92  0.035 0.001 0.475 0.12 ]]
Logits tf.Tensor([[-0.19288775 -0.56842077  1.0774318 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.19051562 0.13086957 0.67861485]], shape=(1, 3), dtype=float32)
Selected action 2
[0.12, 0.15, 0.27, 0.141, 0.146, 0.79, 0.048, 0.015, 0.43200000000000005, 0.21]
0.7900931666666666
14.8916675
Reward 15.983116009308942
Episode: 166 | Average Reward: 304 | Episode Reward: 454 | Loss: 1617.616 | Steps: 19 | Worker: 0
Current State [[ 0.00651794  0.00301808  0.00343186 -0.00466194 -0.00820488 -0.00134296
   0.0028162  -0.00331746 -0.00480946 -0.00513607]]
Logits tf.Tensor([[-0.05493967 -0.07632373  0.13191773]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.31404096 0.30739674 0.37856233]], shape=(1, 3), dtype=float32)
Selected action 1
[0.09, 0.08, 0.29, 0.16, 0.146, 0.79, 0.048, 0.015, 0.43200000000000005, 0.21]
0.7900931666666666
14.8916675
Reward 9.983116009308942
Current State [[0.09  0.08  0.29  0.16  0.146 0.79  0.048 0.015 0.432 0.21 ]]
Logits tf.Tensor([[-0.18397696 -0.53054184  0.9856056 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.20293191 0.1434958  0.65357226]], shape=(1, 3), dtype=float32)
Selected action 2
[0.15, 0.15, 0.27, 0.192, 0.146, 0.93, 0.055, 0.001, 0.454, 0.21]
0.9300969999999998
0.8124996666666667
Reward 22.250549027904537
Current State [[0.15  0.15  0.27  0.192 0.146 0.93  0.055 0.001 0.454 0.21 ]]
Logits tf.Tensor([[-0.21928942 -0.60676646  1.1000154 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.18451591 0.12524335 0.6902408 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.04, 0.31, 0.148, 0.146, 0.95, 0.037, 0.002, 0.41200000000000003, 0.12]
0.9481661666666666
2.2607145000000006
Reward 5.549886466786563
Current State [[0.05  0.04  0.31  0.148 0.146 0.95  0.037 0.002 0.412 0.12 ]]
Logits tf.Tensor([[-0.18128628 -0.5254874   1.026772  ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.19779398 0.14019367 0.6620124 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.14, 0.15, 0.28, 0.129, 0.146, 0.86, 0.025, 0.002, 0.673, 0.1]
0.8554576666666666
1.8654763333333333
Reward 17.74607688318782
Current State [[0.14  0.15  0.28  0.129 0.146 0.86  0.025 0.002 0.673 0.1  ]]
Logits tf.Tensor([[-0.22570264 -0.6013331   1.1654102 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.1752487  0.12037066 0.70438063]], shape=(1, 3), dtype=float32)
Selected action 1
[0.08, 0.08, 0.32, 0.167, 0.146, 0.95, 0.046, 0.002, 0.394, 0.15]
0.9546425
1.7654766666666668
Reward 12.177292260900169
Current State [[0.08  0.08  0.32  0.167 0.146 0.95  0.046 0.002 0.394 0.15 ]]
Logits tf.Tensor([[-0.19183668 -0.54954654  1.0457187 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.19430861 0.13587534 0.669816  ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.2, 0.15, 0.27, 0.198, 0.146, 0.95, 0.046, 0.002, 0.394, 0.15]
0.9546425
1.7654766666666668
Reward 18.177292260900167
Current State [[0.2   0.15  0.27  0.198 0.146 0.95  0.046 0.002 0.394 0.15 ]]
Logits tf.Tensor([[-0.21811537 -0.5995742   1.0751188 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.18770817 0.12817924 0.6841126 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.36, 0.15, 0.146, 0.78, 0.02, 0.004, 0.833, 0.07]
0.7797726666666668
4.401785666666667
Reward 4.4624032025528395
Current State [[0.04  0.04  0.36  0.15  0.146 0.78  0.02  0.004 0.833 0.07 ]]
Logits tf.Tensor([[-0.21748295 -0.5459486   1.1767862 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.17385092 0.12517747 0.70097154]], shape=(1, 3), dtype=float32)
Selected action 2
[0.15, 0.15, 0.27, 0.152, 0.146, 0.75, 0.018, 0.005, 1.0230000000000001, 0.09]
0.7465486666666667
5.021428500000001
Reward 16.34801594212018
Current State [[0.15  0.15  0.27  0.152 0.146 0.75  0.018 0.005 1.023 0.09 ]]
Logits tf.Tensor([[-0.2453426  -0.63546324  1.301916  ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.1568493  0.10618307 0.7369676 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.19, 0.15, 0.27, 0.131, 0.146, 0.89, 0.03, 0.002, 0.442, 0.16]
0.8938890000000002
1.6190476666666667
Reward 18.23916923463605
Current State [[0.19  0.15  0.27  0.131 0.146 0.89  0.03  0.002 0.442 0.16 ]]
Logits tf.Tensor([[-0.21366224 -0.5952793   1.063976  ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.18972047 0.1295329  0.6807466 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.15, 0.22, 0.119, 0.146, 0.89, 0.03, 0.002, 0.442, 0.16]
0.8938890000000002
1.6190476666666667
Reward 18.23916923463605
Current State [[0.07  0.15  0.22  0.119 0.146 0.89  0.03  0.002 0.442 0.16 ]]
Logits tf.Tensor([[-0.1924356  -0.55821174  1.0399824 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.19519165 0.13539626 0.66941214]], shape=(1, 3), dtype=float32)
Selected action 2
[0.16, 0.15, 0.27, 0.174, 0.146, 0.93, 0.038, 0.002, 0.418, 0.15]
0.9348813333333333
1.9803571666666664
Reward 17.815111572139237
Current State [[0.16  0.15  0.27  0.174 0.146 0.93  0.038 0.002 0.418 0.15 ]]
Logits tf.Tensor([[-0.20991427 -0.5883094   1.0723064 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.18905039 0.12949191 0.6814577 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.15, 0.22, 0.137, 0.146, 0.89, 0.022, 0.0, 0.488, 0.09]
0.8939210000000001
0.47321399999999997
Reward 29.592031892327114
Current State [[0.08  0.15  0.22  0.137 0.146 0.89  0.022 0.    0.488 0.09 ]]
Logits tf.Tensor([[-0.19461834 -0.5498207   1.0628656 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.19165921 0.13435915 0.67398167]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.15, 0.24, 0.133, 0.146, 0.99, 0.038, 0.0, 0.392, 0.04]
0.9850071666666668
0.20297616666666668
Reward 57.657912906297874
Current State [[0.07  0.15  0.24  0.133 0.146 0.99  0.038 0.    0.392 0.04 ]]
Logits tf.Tensor([[-0.19552897 -0.55418617  1.0576495 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.19230516 0.13434704 0.67334783]], shape=(1, 3), dtype=float32)
Selected action 2
[0.18, 0.15, 0.27, 0.176, 0.146, 0.99, 0.038, 0.0, 0.392, 0.04]
0.9850071666666668
0.20297616666666668
Reward 57.657912906297874
Current State [[0.18  0.15  0.27  0.176 0.146 0.99  0.038 0.    0.392 0.04 ]]
Logits tf.Tensor([[-0.2138058 -0.5821798  1.080192 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.1872941  0.12958099 0.68312496]], shape=(1, 3), dtype=float32)
Selected action 2
[0.16, 0.15, 0.28, 0.168, 0.146, 0.88, 0.017, 0.002, 0.40700000000000003, 0.06]
0.8816364999999998
2.470237833333334
Reward 17.24890461814232
Current State [[0.16  0.15  0.28  0.168 0.146 0.88  0.017 0.002 0.407 0.06 ]]
Logits tf.Tensor([[-0.19565216 -0.5494983   1.0371661 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.19482286 0.13676232 0.66841483]], shape=(1, 3), dtype=float32)
Selected action 2
[0.19, 0.15, 0.27, 0.165, 0.146, 0.89, 0.024, 0.001, 0.398, 0.07]
0.8918271666666666
0.7714288333333335
Reward 22.343240982126172
Current State [[0.19  0.15  0.27  0.165 0.146 0.89  0.024 0.001 0.398 0.07 ]]
Logits tf.Tensor([[-0.20353843 -0.56269693  1.0381293 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.19381179 0.13533172 0.6708565 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.09, 0.08, 0.3, 0.13, 0.146, 0.94, 0.048, 0.001, 0.445, 0.12]
0.9423986666666668
1.2190478333333334
Reward 13.548978438075938
Current State [[0.09  0.08  0.3   0.13  0.146 0.94  0.048 0.001 0.445 0.12 ]]
Logits tf.Tensor([[-0.20002043 -0.55548716  1.0603886 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.19128835 0.13406372 0.6746479 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.09, 0.08, 0.29, 0.168, 0.146, 0.94, 0.048, 0.001, 0.445, 0.12]
0.9423986666666668
1.2190478333333334
Reward 13.548978438075938
Current State [[0.09  0.08  0.29  0.168 0.146 0.94  0.048 0.001 0.445 0.12 ]]
Logits tf.Tensor([[-0.19858247 -0.55138254  1.0614387 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.1912699  0.13440874 0.67432135]], shape=(1, 3), dtype=float32)
Selected action 2
[0.14, 0.15, 0.26, 0.179, 0.146, 0.93, 0.039, 0.001, 0.465, 0.15]
0.9284756666666667
0.7089285000000001
Reward 23.660163498083893
Current State [[0.14  0.15  0.26  0.179 0.146 0.93  0.039 0.001 0.465 0.15 ]]
Logits tf.Tensor([[-0.21224847 -0.59029627  1.0950564 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.18582538 0.12732713 0.68684745]], shape=(1, 3), dtype=float32)
Selected action 2
[0.11, 0.15, 0.25, 0.167, 0.146, 0.88, 0.027, 0.003, 0.46799999999999997, 0.13]
0.8819406666666667
2.933333
Reward 16.990495950245084
Episode: 167 | Average Reward: 305 | Episode Reward: 413 | Loss: 1585.529 | Steps: 19 | Worker: 0
Current State [[-0.00022859 -0.0022928   0.00084224  0.00858934 -0.00728497 -0.00668155
   0.00762909 -0.00186376  0.00687975  0.00633291]]
Logits tf.Tensor([[-0.05777478 -0.07671164  0.13876554]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.31265384 0.30678883 0.38055733]], shape=(1, 3), dtype=float32)
Selected action 2
[0.1, 0.15, 0.26, 0.135, 0.146, 0.92, 0.023, 0.002, 0.403, 0.06]
0.9169151666666668
2.2309523333333336
Reward 17.508514743310137
Current State [[0.1   0.15  0.26  0.135 0.146 0.92  0.023 0.002 0.403 0.06 ]]
Logits tf.Tensor([[-0.20315626 -0.54783523  1.0571601 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.19102253 0.13532947 0.673648  ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.08, 0.08, 0.31, 0.124, 0.146, 0.87, 0.039, 0.008, 0.398, 0.13]
0.8702365000000001
8.1916665
Reward 10.182466758474316
Current State [[0.08  0.08  0.31  0.124 0.146 0.87  0.039 0.008 0.398 0.13 ]]
Logits tf.Tensor([[-0.19608094 -0.52920705  1.0169789 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.19683331 0.14106643 0.66210026]], shape=(1, 3), dtype=float32)
Selected action 2
[0.17, 0.15, 0.28, 0.187, 0.146, 0.87, 0.039, 0.008, 0.398, 0.13]
0.8702365000000001
8.1916665
Reward 16.182466758474316
Current State [[0.17  0.15  0.28  0.187 0.146 0.87  0.039 0.008 0.398 0.13 ]]
Logits tf.Tensor([[-0.21614677 -0.5695148   1.0538157 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.19000433 0.13344358 0.67655206]], shape=(1, 3), dtype=float32)
Selected action 2
[0.1, 0.15, 0.25, 0.174, 0.146, 0.94, 0.035, 0.001, 0.46299999999999997, 0.12]
0.9403629999999998
1.0011906666666668
Reward 20.67691445908776
Current State [[0.1   0.15  0.25  0.174 0.146 0.94  0.035 0.001 0.463 0.12 ]]
Logits tf.Tensor([[-0.2168709 -0.5761507  1.1071799]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.18325777 0.1279467  0.6887955 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.19, 0.15, 0.28, 0.154, 0.146, 0.86, 0.027, 0.001, 0.46799999999999997, 0.09]
0.8613786666666666
1.2684521666666668
Reward 18.966167190629186
Current State [[0.19  0.15  0.28  0.154 0.146 0.86  0.027 0.001 0.468 0.09 ]]
Logits tf.Tensor([[-0.2248734 -0.5760468  1.0826626]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.18515381 0.13032268 0.68452346]], shape=(1, 3), dtype=float32)
Selected action 2
[0.11, 0.15, 0.26, 0.146, 0.146, 0.9, 0.038, 0.001, 0.513, 0.1]
0.9002643333333334
1.0482141666666667
Reward 20.115468426188126
Current State [[0.11  0.15  0.26  0.146 0.146 0.9   0.038 0.001 0.513 0.1  ]]
Logits tf.Tensor([[-0.2231471  -0.57460934  1.1157191 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.18121277 0.12751192 0.6912753 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.04, 0.37, 0.149, 0.146, 0.9, 0.038, 0.001, 0.513, 0.1]
0.9002643333333334
1.0482141666666667
Reward 8.115468426188126
Current State [[0.05  0.04  0.37  0.149 0.146 0.9   0.038 0.001 0.513 0.1  ]]
Logits tf.Tensor([[-0.2041375 -0.5293152  1.0916475]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.18600285 0.13436827 0.6796289 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.1, 0.15, 0.26, 0.17, 0.146, 0.82, 0.028, 0.005, 0.581, 0.11]
0.8190131666666666
4.9303576666666675
Reward 16.417767114313328
Current State [[0.1   0.15  0.26  0.17  0.146 0.82  0.028 0.005 0.581 0.11 ]]
Logits tf.Tensor([[-0.21913262 -0.56157374  1.1125551 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.18190202 0.12915678 0.6889412 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.17, 0.15, 0.27, 0.137, 0.146, 0.88, 0.037, 0.001, 0.44800000000000006, 0.1]
0.8815609999999998
1.1172618333333335
Reward 19.651943031844183
Current State [[0.17  0.15  0.27  0.137 0.146 0.88  0.037 0.001 0.448 0.1  ]]
Logits tf.Tensor([[-0.22489434 -0.5775463   1.0778521 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.18579727 0.13058238 0.68362033]], shape=(1, 3), dtype=float32)
Selected action 1
[0.09, 0.08, 0.28, 0.134, 0.146, 0.84, 0.034, 0.002, 0.567, 0.14]
0.8355811666666665
1.8505955
Reward 11.710303730388471
Current State [[0.09  0.08  0.28  0.134 0.146 0.84  0.034 0.002 0.567 0.14 ]]
Logits tf.Tensor([[-0.21472645 -0.5525638   1.0887989 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.18533735 0.13220322 0.6824594 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.08, 0.08, 0.33, 0.163, 0.146, 0.84, 0.034, 0.002, 0.567, 0.14]
0.8355811666666665
1.8505955
Reward 11.710303730388471
Current State [[0.08  0.08  0.33  0.163 0.146 0.84  0.034 0.002 0.567 0.14 ]]
Logits tf.Tensor([[-0.21383584 -0.55003816  1.1039213 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.18350263 0.13110867 0.6853887 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.11, 0.15, 0.25, 0.18, 0.146, 0.8, 0.03, 0.002, 0.576, 0.14]
0.7981966666666669
2.326190166666667
Reward 17.184571564955682
Current State [[0.11  0.15  0.25  0.18  0.146 0.8   0.03  0.002 0.576 0.14 ]]
Logits tf.Tensor([[-0.21917152 -0.5648344   1.1032716 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.18313913 0.1296169  0.68724394]], shape=(1, 3), dtype=float32)
Selected action 2
[0.27, 0.15, 0.29, 0.168, 0.146, 0.82, 0.037, 0.003, 0.778, 0.18]
0.8210121666666667
2.634524
Reward 17.04001354564161
Current State [[0.27  0.15  0.29  0.168 0.146 0.82  0.037 0.003 0.778 0.18 ]]
Logits tf.Tensor([[-0.25492176 -0.683949    1.2435579 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.16323805 0.10629118 0.7304708 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.07, 0.08, 0.33, 0.138, 0.146, 0.8, 0.033, 0.003, 0.72, 0.18]
0.7999303333333333
3.246428333333333
Reward 10.751983182441425
Current State [[0.07  0.08  0.33  0.138 0.146 0.8   0.033 0.003 0.72  0.18 ]]
Logits tf.Tensor([[-0.22709766 -0.5812386   1.1605977 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.17521164 0.12295933 0.7018291 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.11, 0.15, 0.27, 0.212, 0.146, 0.8, 0.033, 0.003, 0.72, 0.18]
0.7999303333333333
3.246428333333333
Reward 16.751983182441425
Current State [[0.11  0.15  0.27  0.212 0.146 0.8   0.033 0.003 0.72  0.18 ]]
Logits tf.Tensor([[-0.23429061 -0.60869914  1.1908115 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.17105778 0.1176357  0.71130645]], shape=(1, 3), dtype=float32)
Selected action 2
[0.14, 0.15, 0.26, 0.165, 0.146, 0.88, 0.034, 0.001, 0.725, 0.12]
0.8766523333333335
1.1101191666666668
Reward 19.656189183864136
Current State [[0.14  0.15  0.26  0.165 0.146 0.88  0.034 0.001 0.725 0.12 ]]
Logits tf.Tensor([[-0.24771735 -0.6265797   1.2242191 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.16549976 0.11330772 0.72119254]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.37, 0.151, 0.146, 0.89, 0.031, 0.003, 0.627, 0.15]
0.893258
3.2065473333333334
Reward 4.892139240253568
Current State [[0.04  0.04  0.37  0.151 0.146 0.89  0.031 0.003 0.627 0.15 ]]
Logits tf.Tensor([[-0.21560146 -0.55756265  1.1476299 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.17796195 0.12641984 0.6956183 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.19, 0.15, 0.28, 0.142, 0.146, 0.92, 0.04, 0.001, 0.528, 0.01]
0.9242658333333332
0.5880956666666666
Reward 26.162725077585748
Current State [[0.19  0.15  0.28  0.142 0.146 0.92  0.04  0.001 0.528 0.01 ]]
Logits tf.Tensor([[-0.23863986 -0.5889878   1.1394402 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.17631336 0.12420269 0.69948393]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.36, 0.148, 0.146, 0.92, 0.04, 0.001, 0.528, 0.01]
0.9242658333333332
0.5880956666666666
Reward 14.162725077585748
Current State [[0.04  0.04  0.36  0.148 0.146 0.92  0.04  0.001 0.528 0.01 ]]
Logits tf.Tensor([[-0.20560351 -0.51500505  1.1004279 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.18431887 0.13526902 0.68041205]], shape=(1, 3), dtype=float32)
Selected action 1
[0.08, 0.08, 0.32, 0.141, 0.146, 0.84, 0.043, 0.002, 0.505, 0.14]
0.8354755
1.6434529999999996
Reward 12.004204610709026
Episode: 168 | Average Reward: 305 | Episode Reward: 309 | Loss: 690.266 | Steps: 19 | Worker: 0
Current State [[-0.00121373  0.00340458 -0.0039515  -0.00684146  0.00544125  0.00364044
   0.00288136  0.00167019 -0.00413755 -0.00750317]]
Logits tf.Tensor([[-0.06023575 -0.07570351  0.14075375]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3117923 0.3070067 0.381201 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.38, 0.125, 0.146, 0.9, 0.062, 0.001, 0.41100000000000003, 0.18]
0.9049331666666666
0.8875000000000001
Reward 9.268675165842135
Current State [[0.04  0.04  0.38  0.125 0.146 0.9   0.062 0.001 0.411 0.18 ]]
Logits tf.Tensor([[-0.21522368 -0.5317413   1.0585977 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.18856652 0.13740505 0.6740284 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.15, 0.28, 0.15, 0.146, 0.77, 0.048, 0.005, 0.5, 0.17]
0.7749603333333334
4.570833666666667
Reward 16.43159369078442
Current State [[0.08  0.15  0.28  0.15  0.146 0.77  0.048 0.005 0.5   0.17 ]]
Logits tf.Tensor([[-0.22137147 -0.54495806  1.0648541 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.18717305 0.1354289  0.6773981 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.1, 0.15, 0.25, 0.161, 0.146, 0.77, 0.048, 0.005, 0.5, 0.17]
0.7749603333333334
4.570833666666667
Reward 16.43159369078442
Current State [[0.1   0.15  0.25  0.161 0.146 0.77  0.048 0.005 0.5   0.17 ]]
Logits tf.Tensor([[-0.22465983 -0.5492334   1.060995  ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.18727045 0.13536572 0.6773639 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.15, 0.15, 0.29, 0.17, 0.146, 0.91, 0.053, 0.002, 0.42400000000000004, 0.2]
0.9097449999999999
2.079762166666667
Reward 17.639407163814113
Current State [[0.15  0.15  0.29  0.17  0.146 0.91  0.053 0.002 0.424 0.2  ]]
Logits tf.Tensor([[-0.24005224 -0.5979924   1.1065406 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.18039407 0.12611617 0.69348973]], shape=(1, 3), dtype=float32)
Selected action 2
[0.16, 0.15, 0.24, 0.16, 0.146, 0.95, 0.055, 0.001, 0.41200000000000003, 0.17]
0.9486278333333333
0.5136901666666666
Reward 29.112230575138966
Current State [[0.16  0.15  0.24  0.16  0.146 0.95  0.055 0.001 0.412 0.17 ]]
Logits tf.Tensor([[-0.24380884 -0.6019822   1.1031418 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.1803546  0.1260592  0.69358623]], shape=(1, 3), dtype=float32)
Selected action 1
[0.08, 0.08, 0.3, 0.121, 0.146, 0.99, 0.056, 0.001, 0.398, 0.06]
0.990955
0.5601176666666667
Reward 22.250858512406964
Current State [[0.08  0.08  0.3   0.121 0.146 0.99  0.056 0.001 0.398 0.06 ]]
Logits tf.Tensor([[-0.22486502 -0.55047786  1.0805706 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.18479572 0.13343817 0.68176615]], shape=(1, 3), dtype=float32)
Selected action 1
[0.09, 0.08, 0.24, 0.124, 0.146, 0.99, 0.056, 0.001, 0.398, 0.06]
0.990955
0.5601176666666667
Reward 22.250858512406964
Current State [[0.09  0.08  0.24  0.124 0.146 0.99  0.056 0.001 0.398 0.06 ]]
Logits tf.Tensor([[-0.22585577 -0.55178833  1.0622723 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.18699116 0.13498029 0.6780286 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.18, 0.15, 0.28, 0.185, 0.146, 0.88, 0.075, 0.0, 0.379, 0.13]
0.8779693333333333
0.04880949999999999
Reward 61.9999906079817
Current State [[0.18  0.15  0.28  0.185 0.146 0.88  0.075 0.    0.379 0.13 ]]
Logits tf.Tensor([[-0.24515902 -0.57695746  1.0710491 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.18359114 0.13175088 0.684658  ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.07, 0.08, 0.31, 0.166, 0.146, 0.94, 0.039, 0.0, 0.389, 0.08]
0.9364035000000002
0.39999999999999997
Reward 29.016785293725068
Current State [[0.07  0.08  0.31  0.166 0.146 0.94  0.039 0.    0.389 0.08 ]]
Logits tf.Tensor([[-0.21020208 -0.52694446  1.0591426 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.18914181 0.1377933  0.6730649 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.1, 0.15, 0.26, 0.162, 0.146, 0.95, 0.06, 0.0, 0.45199999999999996, 0.13]
0.9496601666666664
0.3220235
Reward 42.520547473558985
Current State [[0.1   0.15  0.26  0.162 0.146 0.95  0.06  0.    0.452 0.13 ]]
Logits tf.Tensor([[-0.23977436 -0.5845658   1.1264175 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.17765898 0.12584797 0.696493  ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.15, 0.15, 0.22, 0.183, 0.146, 0.95, 0.06, 0.0, 0.45199999999999996, 0.13]
0.9496601666666664
0.3220235
Reward 42.520547473558985
Current State [[0.15  0.15  0.22  0.183 0.146 0.95  0.06  0.    0.452 0.13 ]]
Logits tf.Tensor([[-0.24714294 -0.59579015  1.1207421 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.17753544 0.12527648 0.69718814]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.33, 0.142, 0.146, 0.87, 0.05, 0.005, 0.41200000000000003, 0.19]
0.8719686666666667
4.525594333333333
Reward 4.525905893474369
Current State [[0.04  0.04  0.33  0.142 0.146 0.87  0.05  0.005 0.412 0.19 ]]
Logits tf.Tensor([[-0.20539759 -0.52130777  1.0289644 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.19359922 0.141158   0.6652428 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.39, 0.131, 0.146, 0.85, 0.043, 0.002, 0.5, 0.18]
0.8489221666666668
1.9470235
Reward 5.632320361656771
Current State [[0.04  0.04  0.39  0.131 0.146 0.85  0.043 0.002 0.5   0.18 ]]
Logits tf.Tensor([[-0.21173608 -0.5312032   1.0790062 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.18649687 0.1354967  0.6780064 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.1, 0.15, 0.25, 0.151, 0.146, 0.84, 0.076, 0.01, 0.425, 0.18]
0.8423610000000001
9.57321366666667
Reward 16.113077828019538
Current State [[0.1   0.15  0.25  0.151 0.146 0.84  0.076 0.01  0.425 0.18 ]]
Logits tf.Tensor([[-0.23271354 -0.56497604  1.0602205 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.18654071 0.13380548 0.6796538 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.12, 0.15, 0.26, 0.124, 0.146, 0.84, 0.076, 0.01, 0.425, 0.18]
0.8423610000000001
9.57321366666667
Reward 16.113077828019538
Current State [[0.12  0.15  0.26  0.124 0.146 0.84  0.076 0.01  0.425 0.18 ]]
Logits tf.Tensor([[-0.23663472 -0.57397467  1.0606555 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.18611461 0.13282369 0.6810617 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.18, 0.15, 0.28, 0.177, 0.146, 0.99, 0.051, 0.001, 0.42800000000000005, 0.2]
0.9905923333333334
0.6898811666666667
Reward 24.82622491580723
Current State [[0.18  0.15  0.28  0.177 0.146 0.99  0.051 0.001 0.428 0.2  ]]
Logits tf.Tensor([[-0.25136727 -0.6282929   1.1458749 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.17452012 0.11971504 0.70576483]], shape=(1, 3), dtype=float32)
Selected action 0
[0.03, 0.04, 0.41, 0.125, 0.146, 0.97, 0.06, 0.001, 0.417, 0.24]
0.9659161666666667
0.679762
Reward 12.684408194106672
Current State [[0.03  0.04  0.41  0.125 0.146 0.97  0.06  0.001 0.417 0.24 ]]
Logits tf.Tensor([[-0.2201012 -0.5626906  1.1050489]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.18272583 0.12972249 0.68755174]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.15, 0.27, 0.147, 0.146, 0.78, 0.026, 0.005, 0.581, 0.13]
0.777233
5.0166665
Reward 16.37292236626469
Current State [[0.08  0.15  0.27  0.147 0.146 0.78  0.026 0.005 0.581 0.13 ]]
Logits tf.Tensor([[-0.22456637 -0.54932344  1.1029716 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.18200189 0.1315333  0.6864648 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.04, 0.15, 0.27, 0.174, 0.146, 0.78, 0.026, 0.005, 0.581, 0.13]
0.777233
5.0166665
Reward 16.37292236626469
Current State [[0.04  0.15  0.27  0.174 0.146 0.78  0.026 0.005 0.581 0.13 ]]
Logits tf.Tensor([[-0.21915764 -0.5360218   1.1031445 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.18246582 0.1329135  0.6846207 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.09, 0.15, 0.27, 0.179, 0.146, 0.89, 0.052, 0.003, 0.433, 0.23]
0.8880086666666667
3.0636906666666666
Reward 16.94213255889942
Episode: 169 | Average Reward: 307 | Episode Reward: 439 | Loss: 1485.39 | Steps: 19 | Worker: 0
Current State [[ 0.00884371 -0.00318023 -0.002678   -0.00637674 -0.0045296  -0.00030249
   0.00530962 -0.0007079   0.00202751 -0.00754276]]
Logits tf.Tensor([[-0.06379653 -0.07688965  0.14102452]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.31110996 0.3070631  0.38182694]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.32, 0.137, 0.146, 0.89, 0.048, 0.002, 0.47000000000000003, 0.17]
0.8884164999999999
2.329166
Reward 5.365254286354109
Current State [[0.04  0.04  0.32  0.137 0.146 0.89  0.048 0.002 0.47  0.17 ]]
Logits tf.Tensor([[-0.22521952 -0.53067017  1.0772432 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.1846676  0.13606146 0.679271  ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.11, 0.15, 0.25, 0.172, 0.146, 0.89, 0.048, 0.002, 0.47000000000000003, 0.17]
0.8884164999999999
2.329166
Reward 17.36525428635411
Current State [[0.11  0.15  0.25  0.172 0.146 0.89  0.048 0.002 0.47  0.17 ]]
Logits tf.Tensor([[-0.24637681 -0.57762325  1.1169698 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.17770569 0.12759769 0.69469666]], shape=(1, 3), dtype=float32)
Selected action 2
[0.1, 0.15, 0.26, 0.154, 0.146, 0.87, 0.025, 0.001, 0.5559999999999999, 0.14]
0.8728691666666666
0.886905
Reward 21.003851940684534
Current State [[0.1   0.15  0.26  0.154 0.146 0.87  0.025 0.001 0.556 0.14 ]]
Logits tf.Tensor([[-0.24422139 -0.5739843   1.1464832 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.17431399 0.12534817 0.7003378 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.17, 0.15, 0.27, 0.191, 0.146, 1.01, 0.03, 0.001, 0.501, 0.1]
1.0064391666666668
0.6077375
Reward 27.035097853235794
Current State [[1.70e-01 1.50e-01 2.70e-01 1.91e-01 1.46e-01 1.01e+00 3.00e-02 1.00e-03
  5.01e-01 1.00e-01]]
Logits tf.Tensor([[-0.26222664 -0.6146596   1.1955768 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.16668092 0.11717262 0.7161465 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.26, 0.172, 0.146, 0.98, 0.05, 0.001, 0.41200000000000003, 0.14]
0.9843485000000001
1.278571
Reward 19.528622850124467
Current State [[0.05  0.15  0.26  0.172 0.146 0.98  0.05  0.001 0.412 0.14 ]]
Logits tf.Tensor([[-0.2358773  -0.56808037  1.123485  ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.17821972 0.12784444 0.6939358 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.15, 0.15, 0.28, 0.153, 0.146, 0.63, 0.026, 0.038, 0.602, 0.12]
0.6262466666666667
37.78809449999999
Reward 15.85140887940371
Current State [[0.15  0.15  0.28  0.153 0.146 0.63  0.026 0.038 0.602 0.12 ]]
Logits tf.Tensor([[-0.2209425 -0.5385923  1.0491437]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.18907106 0.13761681 0.6733121 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.35, 0.158, 0.146, 0.63, 0.026, 0.038, 0.602, 0.12]
0.6262466666666667
37.78809449999999
Reward 3.851408879403711
Current State [[0.04  0.04  0.35  0.158 0.146 0.63  0.026 0.038 0.602 0.12 ]]
Logits tf.Tensor([[-0.20170747 -0.47444192  1.0124035 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.19498521 0.14844127 0.65657353]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.32, 0.148, 0.146, 0.62, 0.015, 0.011, 0.8119999999999999, 0.1]
0.6208856666666664
10.6398805
Reward 4.00258267397208
Current State [[0.04  0.04  0.32  0.148 0.146 0.62  0.015 0.011 0.812 0.1  ]]
Logits tf.Tensor([[-0.23071833 -0.5033319   1.11444   ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.17856565 0.13595757 0.6854768 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.03, 0.04, 0.31, 0.121, 0.146, 0.86, 0.038, 0.001, 0.533, 0.11]
0.8636713333333332
1.2511909999999997
Reward 7.0335946665874065
Current State [[0.03  0.04  0.31  0.121 0.146 0.86  0.038 0.001 0.533 0.11 ]]
Logits tf.Tensor([[-0.22377971 -0.5150114   1.0848707 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.18353616 0.13716437 0.6792995 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.09, 0.15, 0.25, 0.164, 0.146, 0.77, 0.031, 0.003, 0.5860000000000001, 0.12]
0.7696139999999999
3.3101193333333336
Reward 16.692544615016743
Current State [[0.09  0.15  0.25  0.164 0.146 0.77  0.031 0.003 0.586 0.12 ]]
Logits tf.Tensor([[-0.23782846 -0.5467764   1.1103483 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.17906328 0.13147165 0.68946505]], shape=(1, 3), dtype=float32)
Selected action 2
[0.15, 0.15, 0.27, 0.174, 0.146, 0.77, 0.031, 0.003, 0.5860000000000001, 0.12]
0.7696139999999999
3.3101193333333336
Reward 16.692544615016743
Current State [[0.15  0.15  0.27  0.174 0.146 0.77  0.031 0.003 0.586 0.12 ]]
Logits tf.Tensor([[-0.24476764 -0.5662181   1.1221496 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.17704333 0.12837353 0.6945831 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.14, 0.15, 0.23, 0.174, 0.146, 0.83, 0.018, 0.001, 0.45999999999999996, 0.06]
0.8326935
1.0333336666666666
Reward 19.761425728345863
Current State [[0.14  0.15  0.23  0.174 0.146 0.83  0.018 0.001 0.46  0.06 ]]
Logits tf.Tensor([[-0.22997572 -0.5353342   1.0666097 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.18540327 0.13661608 0.6779806 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.04, 0.31, 0.127, 0.146, 0.98, 0.039, 0.0, 0.381, 0.02]
0.9809653333333335
0.15416633333333335
Reward 48.97139429425622
Current State [[0.05  0.04  0.31  0.127 0.146 0.98  0.039 0.    0.381 0.02 ]]
Logits tf.Tensor([[-0.21671328 -0.50963753  1.0529791 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.18847172 0.14061472 0.6709136 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.1, 0.08, 0.24, 0.157, 0.146, 0.98, 0.039, 0.0, 0.381, 0.02]
0.9809653333333335
0.15416633333333335
Reward 54.97139429425622
Current State [[0.1   0.08  0.24  0.157 0.146 0.98  0.039 0.    0.381 0.02 ]]
Logits tf.Tensor([[-0.22753674 -0.53116244  1.0570543 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.18686955 0.13793533 0.6751951 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.32, 0.142, 0.146, 0.87, 0.02, 0.002, 0.513, 0.08]
0.8693778333333333
2.0666665
Reward 5.556090240551518
Current State [[0.04  0.04  0.32  0.142 0.146 0.87  0.02  0.002 0.513 0.08 ]]
Logits tf.Tensor([[-0.21637581 -0.5055922   1.0791963 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.18511882 0.13862625 0.6762549 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.03, 0.08, 0.31, 0.146, 0.146, 0.66, 0.023, 0.005, 0.621, 0.12]
0.6645078333333334
5.311904999999999
Reward 10.255333137028531
Current State [[0.03  0.08  0.31  0.146 0.146 0.66  0.023 0.005 0.621 0.12 ]]
Logits tf.Tensor([[-0.21636802 -0.48970374  1.0481477 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.18860044 0.14349425 0.6679053 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.08, 0.15, 0.26, 0.162, 0.146, 0.85, 0.032, 0.001, 0.548, 0.1]
0.8479848333333332
0.7910721666666666
Reward 21.670085872979378
Current State [[0.08  0.15  0.26  0.162 0.146 0.85  0.032 0.001 0.548 0.1  ]]
Logits tf.Tensor([[-0.23924422 -0.5522454   1.1301986 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.17654094 0.12909542 0.6943636 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.02, 0.04, 0.31, 0.136, 0.146, 0.85, 0.032, 0.001, 0.548, 0.1]
0.8479848333333332
0.7910721666666666
Reward 9.670085872979376
Current State [[0.02  0.04  0.31  0.136 0.146 0.85  0.032 0.001 0.548 0.1  ]]
Logits tf.Tensor([[-0.22172618 -0.50824434  1.0871539 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.1833887  0.1377017  0.67890954]], shape=(1, 3), dtype=float32)
Selected action 1
[0.07, 0.08, 0.32, 0.152, 0.146, 0.81, 0.026, 0.002, 0.5650000000000001, 0.14]
0.8054296666666666
1.7374996666666669
Reward 11.771469864613593
Current State [[0.07  0.08  0.32  0.152 0.146 0.81  0.026 0.002 0.565 0.14 ]]
Logits tf.Tensor([[-0.23013932 -0.53399605  1.1036284 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.18072453 0.13336867 0.68590677]], shape=(1, 3), dtype=float32)
Selected action 2
[0.1, 0.15, 0.25, 0.144, 0.146, 0.9, 0.029, 0.002, 0.481, 0.11]
0.9001460000000001
1.7000003333333331
Reward 18.116746412882296
Episode: 170 | Average Reward: 307 | Episode Reward: 355 | Loss: 1041.918 | Steps: 19 | Worker: 0
Current State [[ 0.00024068  0.00241034 -0.00139089 -0.00386318 -0.00071984 -0.0078793
   0.00244093 -0.00438027  0.0006688  -0.00405574]]
Logits tf.Tensor([[-0.06357989 -0.07100465  0.13746299]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.3110149  0.30871427 0.38027084]], shape=(1, 3), dtype=float32)
Selected action 1
[0.05, 0.08, 0.3, 0.167, 0.146, 0.9, 0.029, 0.002, 0.481, 0.11]
0.9001460000000001
1.7000003333333331
Reward 12.116746412882296
Current State [[0.05  0.08  0.3   0.167 0.146 0.9   0.029 0.002 0.481 0.11 ]]
Logits tf.Tensor([[-0.2296865 -0.5262921  1.1012856]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.18089536 0.13446623 0.6846384 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.32, 0.147, 0.146, 0.78, 0.024, 0.004, 0.437, 0.05]
0.7753701666666666
4.4619045
Reward 4.448711561060013
Current State [[0.04  0.04  0.32  0.147 0.146 0.78  0.024 0.004 0.437 0.05 ]]
Logits tf.Tensor([[-0.20464545 -0.4567804   0.9967677 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.19600342 0.15232207 0.6516745 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.15, 0.26, 0.157, 0.146, 0.77, 0.023, 0.002, 0.454, 0.07]
0.7721490000000001
1.9244048333333335
Reward 17.460872087106495
Current State [[0.07  0.15  0.26  0.157 0.146 0.77  0.023 0.002 0.454 0.07 ]]
Logits tf.Tensor([[-0.22003572 -0.4976878   1.038209  ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.18950883 0.14356437 0.6669268 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.06, 0.08, 0.29, 0.129, 0.146, 0.89, 0.025, 0.001, 0.437, 0.1]
0.8901049999999999
1.1970236666666665
Reward 13.362079963370252
Current State [[0.06  0.08  0.29  0.129 0.146 0.89  0.025 0.001 0.437 0.1  ]]
Logits tf.Tensor([[-0.22390673 -0.51820457  1.064026  ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.18620798 0.13873512 0.6750569 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.15, 0.26, 0.182, 0.146, 0.89, 0.025, 0.001, 0.437, 0.1]
0.8901049999999999
1.1970236666666665
Reward 19.362079963370252
Current State [[0.07  0.15  0.26  0.182 0.146 0.89  0.025 0.001 0.437 0.1  ]]
Logits tf.Tensor([[-0.23092328 -0.53599936  1.0944308 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.18179885 0.13399798 0.68420315]], shape=(1, 3), dtype=float32)
Selected action 2
[0.13, 0.15, 0.27, 0.167, 0.146, 0.98, 0.035, 0.001, 0.43499999999999994, 0.02]
0.9829083333333333
1.0029759999999999
Reward 20.973016166594945
Current State [[0.13  0.15  0.27  0.167 0.146 0.98  0.035 0.001 0.435 0.02 ]]
Logits tf.Tensor([[-0.25166088 -0.56558114  1.1391604 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.1739516  0.12708507 0.6989633 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.16, 0.15, 0.27, 0.18, 0.146, 0.96, 0.02, 0.002, 0.372, 0.08]
0.9562033333333333
2.2136901666666664
Reward 17.612059485632823
Current State [[0.16  0.15  0.27  0.18  0.146 0.96  0.02  0.002 0.372 0.08 ]]
Logits tf.Tensor([[-0.24248067 -0.5650942   1.0978566 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.18035613 0.13062361 0.6890203 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.32, 0.126, 0.146, 0.88, 0.044, 0.002, 0.454, 0.13]
0.8833728333333334
2.1994045
Reward 5.462825008097427
Current State [[0.04  0.04  0.32  0.126 0.146 0.88  0.044 0.002 0.454 0.13 ]]
Logits tf.Tensor([[-0.22650212 -0.51277375  1.063209  ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.18577704 0.13952945 0.6746935 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.16, 0.15, 0.27, 0.179, 0.146, 0.72, 0.018, 0.006, 0.734, 0.07]
0.7163035
6.0672619999999995
Reward 16.228015104389762
Current State [[0.16  0.15  0.27  0.179 0.146 0.72  0.018 0.006 0.734 0.07 ]]
Logits tf.Tensor([[-0.25559723 -0.5695442   1.1744123 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.16922489 0.12362854 0.7071465 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.1, 0.15, 0.26, 0.168, 0.146, 0.72, 0.018, 0.006, 0.734, 0.07]
0.7163035
6.0672619999999995
Reward 16.228015104389762
Current State [[0.1   0.15  0.26  0.168 0.146 0.72  0.018 0.006 0.734 0.07 ]]
Logits tf.Tensor([[-0.2518593 -0.5513494  1.1648526]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.17051066 0.12638184 0.7031075 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.23, 0.15, 0.27, 0.177, 0.146, 0.89, 0.031, 0.001, 0.6769999999999999, 0.1]
0.8887981666666666
0.6511913333333333
Reward 24.160875031924547
Current State [[0.23  0.15  0.27  0.177 0.146 0.89  0.031 0.001 0.677 0.1  ]]
Logits tf.Tensor([[-0.28434652 -0.6362344   1.2430321 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.15849255 0.11147715 0.73003036]], shape=(1, 3), dtype=float32)
Selected action 2
[0.16, 0.15, 0.29, 0.162, 0.146, 0.93, 0.048, 0.001, 0.601, 0.25]
0.9295438333333333
1.3547620000000002
Reward 19.008556938975943
Current State [[0.16  0.15  0.29  0.162 0.146 0.93  0.048 0.001 0.601 0.25 ]]
Logits tf.Tensor([[-0.28204334 -0.6495936   1.2304378 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.16050322 0.111137   0.72835976]], shape=(1, 3), dtype=float32)
Selected action 2
[0.16, 0.15, 0.29, 0.169, 0.146, 0.85, 0.039, 0.002, 0.6839999999999999, 0.18]
0.8462706666666667
2.3125001666666662
Reward 17.291579192109587
Current State [[0.16  0.15  0.29  0.169 0.146 0.85  0.039 0.002 0.684 0.18 ]]
Logits tf.Tensor([[-0.27510315 -0.62648124  1.2292706 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.16115901 0.11341045 0.72543055]], shape=(1, 3), dtype=float32)
Selected action 0
[0.03, 0.04, 0.39, 0.158, 0.146, 0.85, 0.039, 0.002, 0.6839999999999999, 0.18]
0.8462706666666667
2.3125001666666662
Reward 5.291579192109588
Current State [[0.03  0.04  0.39  0.158 0.146 0.85  0.039 0.002 0.684 0.18 ]]
Logits tf.Tensor([[-0.25214276 -0.55976236  1.193944  ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.16717769 0.12290819 0.70991415]], shape=(1, 3), dtype=float32)
Selected action 2
[0.17, 0.15, 0.27, 0.176, 0.146, 0.84, 0.036, 0.002, 0.6719999999999999, 0.11]
0.8366451666666668
1.7791668333333335
Reward 17.805705700110344
Current State [[0.17  0.15  0.27  0.176 0.146 0.84  0.036 0.002 0.672 0.11 ]]
Logits tf.Tensor([[-0.27264518 -0.60633594  1.2110027 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.16325799 0.11693762 0.71980435]], shape=(1, 3), dtype=float32)
Selected action 2
[0.07, 0.15, 0.23, 0.132, 0.146, 0.82, 0.019, 0.009, 0.612, 0.07]
0.8185848333333333
9.023809333333332
Reward 16.12336597211528
Current State [[0.07  0.15  0.23  0.132 0.146 0.82  0.019 0.009 0.612 0.07 ]]
Logits tf.Tensor([[-0.24320139 -0.54402     1.1345234 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.17525166 0.12972338 0.69502497]], shape=(1, 3), dtype=float32)
Selected action 2
[0.11, 0.15, 0.25, 0.115, 0.146, 0.97, 0.059, 0.001, 0.42300000000000004, 0.1]
0.973871
0.5142859999999999
Reward 29.644464666087064
Current State [[0.11  0.15  0.25  0.115 0.146 0.97  0.059 0.001 0.423 0.1  ]]
Logits tf.Tensor([[-0.25833964 -0.5811155   1.1242938 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.1751461  0.12682962 0.6980243 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.17, 0.15, 0.29, 0.157, 0.146, 0.93, 0.05, 0.002, 0.389, 0.18]
0.9269426666666665
2.0494054999999998
Reward 17.71424099522938
Current State [[0.17  0.15  0.29  0.157 0.146 0.93  0.05  0.002 0.389 0.18 ]]
Logits tf.Tensor([[-0.25827047 -0.5944388   1.1100695 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.17720045 0.12661023 0.69618934]], shape=(1, 3), dtype=float32)
Selected action 2
[0.12, 0.15, 0.29, 0.206, 0.146, 0.93, 0.05, 0.002, 0.389, 0.18]
0.9269426666666665
2.0494054999999998
Reward 17.71424099522938
Current State [[0.12  0.15  0.29  0.206 0.146 0.93  0.05  0.002 0.389 0.18 ]]
Logits tf.Tensor([[-0.24821115 -0.57518995  1.1116078 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.17804407 0.1283874  0.6935685 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.37, 0.138, 0.146, 0.92, 0.054, 0.0, 0.385, 0.12]
0.9233696666666668
0.3226204999999999
Reward 29.47734198548065
Episode: 171 | Average Reward: 307 | Episode Reward: 337 | Loss: 958.271 | Steps: 19 | Worker: 0
Current State [[0.00159509 0.00577496 0.00683485 0.00030464 0.00740759 0.00410813
  0.00244949 0.00386231 0.00254011 0.00382037]]
Logits tf.Tensor([[-0.06498343 -0.08112157  0.15500024]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.30959296 0.3046368  0.38577026]], shape=(1, 3), dtype=float32)
Selected action 1
[0.11, 0.08, 0.35, 0.133, 0.146, 0.81, 0.056, 0.003, 0.44000000000000006, 0.16]
0.8059521666666666
2.8119046666666674
Reward 10.92777533809576
Current State [[0.11  0.08  0.35  0.133 0.146 0.81  0.056 0.003 0.44  0.16 ]]
Logits tf.Tensor([[-0.24330866 -0.5351145   1.0614191 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.1840401  0.13746202 0.6784979 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.08, 0.08, 0.34, 0.165, 0.146, 0.81, 0.056, 0.003, 0.44000000000000006, 0.16]
0.8059521666666666
2.8119046666666674
Reward 10.92777533809576
Current State [[0.08  0.08  0.34  0.165 0.146 0.81  0.056 0.003 0.44  0.16 ]]
Logits tf.Tensor([[-0.23840721 -0.52207285  1.0614111 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.18444574 0.13889106 0.6766633 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.03, 0.04, 0.32, 0.139, 0.146, 0.92, 0.046, 0.001, 0.46799999999999997, 0.17]
0.9173848333333333
0.9386903333333334
Reward 8.953235429906027
Current State [[0.03  0.04  0.32  0.139 0.146 0.92  0.046 0.001 0.468 0.17 ]]
Logits tf.Tensor([[-0.2374901 -0.5320983  1.0996381]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.1800856  0.13413195 0.6857825 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.43, 0.123, 0.146, 0.88, 0.043, 0.001, 0.483, 0.12]
0.8781175
1.275595
Reward 7.022233193870784
Current State [[0.04  0.04  0.43  0.123 0.146 0.88  0.043 0.001 0.483 0.12 ]]
Logits tf.Tensor([[-0.23669662 -0.5192289   1.1106411 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.17853822 0.134595   0.6868668 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.06, 0.15, 0.29, 0.232, 0.146, 0.88, 0.043, 0.001, 0.483, 0.12]
0.8781175
1.275595
Reward 19.022233193870782
Current State [[0.06  0.15  0.29  0.232 0.146 0.88  0.043 0.001 0.483 0.12 ]]
Logits tf.Tensor([[-0.24680346 -0.5427761   1.1397744 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.17406616 0.12947175 0.69646204]], shape=(1, 3), dtype=float32)
Selected action 2
[0.28, 0.15, 0.29, 0.176, 0.146, 0.82, 0.037, 0.003, 0.532, 0.2]
0.8199546666666666
2.655952
Reward 17.026829881582614
Current State [[0.28  0.15  0.29  0.176 0.146 0.82  0.037 0.003 0.532 0.2  ]]
Logits tf.Tensor([[-0.27483717 -0.6334145   1.1491852 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.1708682  0.1193804  0.70975137]], shape=(1, 3), dtype=float32)
Selected action 2
[0.05, 0.15, 0.3, 0.202, 0.146, 0.94, 0.073, 0.002, 0.361, 0.13]
0.9383153333333333
1.5107138333333334
Reward 18.625805388090768
Current State [[0.05  0.15  0.3   0.202 0.146 0.94  0.073 0.002 0.361 0.13 ]]
Logits tf.Tensor([[-0.2471473 -0.5464891  1.1061298]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.17820886 0.1321073  0.68968385]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.04, 0.43, 0.121, 0.146, 0.97, 0.042, 0.0, 0.372, 0.09]
0.9693901666666667
0.33869099999999996
Reward 29.478243800396527
Current State [[0.05  0.04  0.43  0.121 0.146 0.97  0.042 0.    0.372 0.09 ]]
Logits tf.Tensor([[-0.2336389 -0.5223288  1.0929011]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.18125044 0.13580091 0.68294865]], shape=(1, 3), dtype=float32)
Selected action 0
[0.03, 0.04, 0.37, 0.178, 0.146, 0.97, 0.042, 0.0, 0.372, 0.09]
0.9693901666666667
0.33869099999999996
Reward 29.478243800396527
Current State [[0.03  0.04  0.37  0.178 0.146 0.97  0.042 0.    0.372 0.09 ]]
Logits tf.Tensor([[-0.22592165 -0.50811315  1.0823454 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.18335553 0.13827375 0.6783708 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.05, 0.04, 0.4, 0.162, 0.146, 0.81, 0.048, 0.002, 0.538, 0.19]
0.8092565
1.9821428333333335
Reward 5.495178571739122
Current State [[0.05  0.04  0.4   0.162 0.146 0.81  0.048 0.002 0.538 0.19 ]]
Logits tf.Tensor([[-0.23807667 -0.5287532   1.1083214 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.17884883 0.13373555 0.6874156 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.15, 0.15, 0.26, 0.131, 0.146, 0.86, 0.039, 0.002, 0.517, 0.12]
0.8606005000000001
2.113095
Reward 17.49027256091001
Current State [[0.15  0.15  0.26  0.131 0.146 0.86  0.039 0.002 0.517 0.12 ]]
Logits tf.Tensor([[-0.26419923 -0.5778115   1.133126  ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.17315508 0.12654214 0.7003028 ]], shape=(1, 3), dtype=float32)
Selected action 0
[0.04, 0.04, 0.38, 0.183, 0.146, 0.86, 0.039, 0.002, 0.517, 0.12]
0.8606005000000001
2.113095
Reward 5.49027256091001
Current State [[0.04  0.04  0.38  0.183 0.146 0.86  0.039 0.002 0.517 0.12 ]]
Logits tf.Tensor([[-0.2368668 -0.5136119  1.1140552]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.17796028 0.13493799 0.6871017 ]], shape=(1, 3), dtype=float32)
Selected action 2
[0.11, 0.15, 0.26, 0.206, 0.146, 0.85, 0.042, 0.002, 0.499, 0.18]
0.8511661666666667
1.8857135
Reward 17.709575552329813
Current State [[0.11  0.15  0.26  0.206 0.146 0.85  0.042 0.002 0.499 0.18 ]]
Logits tf.Tensor([[-0.2564168  -0.56796217  1.1307372 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.17434499 0.12767534 0.6979797 ]], shape=(1, 3), dtype=float32)
Selected action 1
[0.05, 0.08, 0.32, 0.19, 0.146, 0.85, 0.042, 0.002, 0.499, 0.18]
0.8511661666666667
1.8857135
Reward 11.709575552329813
Current State [[0.05  0.08  0.32  0.19  0.146 0.85  0.042 0.002 0.499 0.18 ]]
Logits tf.Tensor([[-0.240177  -0.5328735  1.1083473]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.17863566 0.13330662 0.68805766]], shape=(1, 3), dtype=float32)
Selected action 2
[0.12, 0.15, 0.26, 0.182, 0.146, 0.94, 0.064, 0.009, 0.393, 0.27]
0.9422028333333333
9.315476
Reward 16.16299800641182
Current State [[0.12  0.15  0.26  0.182 0.146 0.94  0.064 0.009 0.393 0.27 ]]
Logits tf.Tensor([[-0.2584824  -0.60350263  1.1190537 ]], shape=(1, 3), dtype=float32)
Probs tf.Tensor([[0.17626347 0.12483083 0.6989057 ]], shape=(1, 3), dtype=float32)
Selected action 0
Traceback (most recent call last):
  File "/home/kaiser/Git/drl-a3c/A3C/agent.py", line 391, in <module>
    main()
  File "/home/kaiser/Git/drl-a3c/A3C/agent.py", line 379, in main
    train(env, global_model)
  File "/home/kaiser/Git/drl-a3c/A3C/agent.py", line 84, in train
    reward = res_queue.get()
  File "/usr/lib/python3.8/queue.py", line 170, in get
    self.not_empty.wait()
  File "/usr/lib/python3.8/threading.py", line 302, in wait
    waiter.acquire()
KeyboardInterrupt

Process finished with exit code 137 (interrupted by signal 9: SIGKILL)

frame=2396368 fps= 60 q=-1.0 Lsize=132488507kB time=11:05:39.56 bitrate=27174.7kbits/s speed=   1x    
video:121888997kB audio:629461kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 8.137589%

